---
title: About
layout: default
---
{% include header.html %}
<div class="g-banner tags-banner {{ site.postPatterns | prepend: 'post-pattern-' }} {{ site.theme-color | prepend: 'bgcolor-' }}" data-theme="{{ site.theme-color }}">
    <h2>ABOUT</h2>
</div>

<main class="tags-content" style="margin-top: 0px">
    <ul class="tags-list" style="list-style-type: none;padding: 40px;">
		<h2><span style="font-size: 0.6em;">About</span></h2>
	<br/>
		<p><span style="font-size: 0.6em;">我目前在阿里巴巴达摩院从事计算机视觉和AI4S的研究工作。</span></p>
	<br/>
		<p><span style="font-size: 0.6em;">2019-2024年，我在中国科学院大学攻读工学博士学位，培养单位是中国科学院空天信息创新研究院。在此期间，我曾获得国家奖学金、中国科学院院长奖、中国电子教育学会优秀博士论文提名奖等荣誉。</span></p>
	<br/>
		<p><span style="font-size: 0.6em;">2015-2019年，我在华中科技大学攻读工学学士学位。在此期间，我曾获得国家奖学金、本科特优生等荣誉。</span></p>
	<br/>
		<h2><span style="font-size: 0.6em;">Publications</span></h2>
	<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/10260326"style="color:#5bbd72;">[Paper]</a>RadarFormer: End-to-End Human Perception With Through-Wall Radar and Transformers</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">D. Zhang, X. Liang, X. Liu, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Transactions on Neural Networks and Learning Systems,</span>
	<span style="color: black; font-size: 0.6em;">vol. 35, no. 12, pp. 18285-18299, Dec. 2024</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/10182341"style="color:#5bbd72;">[Paper]</a>Through-Wall Human Pose Estimation by Mutual Information Maximizing Deeply Supervised Nets</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">J. Pan, D. Zhang, X. Liang, X. Liu, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Internet of Things Journal,</span>
	<span style="color: black; font-size: 0.6em;">vol. 11, no. 2, pp. 3190-3205, 15 Jan.15, 2024</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/9989420"style="color:#5bbd72;">[Paper]</a>Unsupervised Human Contour Extraction From Through-Wall Radar Images Using Dual UNet</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">D. Zhang, X. Liang, X. Liu, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Geoscience and Remote Sensing Letters,</span>
	<span style="color: black; font-size: 0.6em;">vol. 20, pp. 1-5, 2023, Art no. 3500705</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.2em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/9924237"style="color:#5bbd72;">[Paper]</a>Through-Wall Human Pose Reconstruction Based on Cross-Modal Learning and Self-Supervised Learning</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">D. Zhang, X. Liang, X. Liu, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Geoscience and Remote Sensing Letters,</span>
	<span style="color: black; font-size: 0.6em;">vol. 19, pp. 1-5, 2022, Art no. 4027905</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/9793087"style="color:#5bbd72;">[Paper]</a>Self-supervised Human Pose Recovery for Through-wall Radar Based on Convolutional Neural Networks</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">S. Ye, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">2022 Photonics & Electromagnetics Research Symposium (PIERS),</span>
	<span style="color: black; font-size: 0.6em;">Hangzhou, China, 2022, pp. 613-616</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/9741729"style="color:#5bbd72;">[Paper]</a>Recovering Human Pose and Shape From Through-the-Wall Radar Images</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">J. Pan, Z. Ni, C. Shi, D. Zhang, X. Liu, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Transactions on Geoscience and Remote Sensing,</span>
	<span style="color: black; font-size: 0.6em;">vol. 60, pp. 1-15, 2022, Art no. 5112015</span>
      		</p>   
		<br/>
		<p>
        <span style="color: black; font-size: 0.6em;"><a target="_blank" href="https://ieeexplore.ieee.org/document/9420808"style="color:#5bbd72;">[Paper]</a>Human Posture Reconstruction for Through-the-Wall Radar Imaging Using Convolutional Neural Networks</span><br/>
        <span style="color: black; font-size: 0.6em;">Z. Zheng,</span> 
        <span style="color: lightgray; font-size: 0.6em;">J. Pan, Z. Ni, C. Shi, S. Ye, and G. Fang</span><br/>
        <span style="color: black; font-style: italic; font-size: 0.6em;">IEEE Geoscience and Remote Sensing Letters,</span>
	<span style="color: black; font-size: 0.6em;">vol. 19, pp. 1-5, 2022, Art no. 3505205</span>
      		</p>   
		<br/>
    </ul>



</main>
    
{% include footer.html %}
