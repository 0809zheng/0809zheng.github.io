---
layout: post
title: '距离度量(Distance Metric)方法'
date: 2021-02-08
author: 郑之杰
cover: 'https://img.imgdb.cn/item/6023879a3ffa7d37b3a2a681.jpg'
tags: 数学
---

> Distance metric methods.

在许多机器学习任务中需要用到距离测量。不同的距离测量方法各有优缺点，适用于不同的场合。本文介绍以下距离测量方法：
- **向量距离**：欧氏距离
- **集合距离**：

# 1. 向量距离



1. 欧几里得距离 Euclidean Distance
2. 余弦相似度 Cosine Similarity
3. 汉明距离 Hamming Distance
4. 曼哈顿距离 Manhattan Distance
5. 切比雪夫距离 Chebyshev Distance
6. 闵可夫斯基距离 Minkowski Distance
7. Jaccard指数 Jaccard Index
8. 半正矢距离 Haversine Distance
9. Dice指数 Dice Index
10. 马氏距离 Mahalanobis Distance

# 1. 欧几里得距离 Euclidean Distance
**欧式距离**是最常见的距离测量方法之一，它衡量两点之间的线段长度，计算如下：

$$ D(x,y) = \sqrt{\sum_{i=1}^{d} (x_i-y_i)^2} $$

![](https://img.imgdb.cn/item/602388a23ffa7d37b3a33782.jpg)

### 主要缺点
欧式距离并不是**尺度不变**的，这意味着计算出的距离可能会根据特征的**单位**而有所偏斜。通常在使用这种距离测量之前，需要对数据进行**归一化**。而**Mahalanobis**距离尺度不变的。

此外，随着数据维度的增加，欧式距离的作用减小。这与**维度诅咒**(数据在高维空间中的分布是不均匀的)有关。

### 应用场合
对于低维数据，且需要考虑向量本身的大小时，可以使用欧氏距离。如对低维数据进行**kNN**或**HDBSCAN**。


# 2. 余弦相似度 Cosine Similarity
**余弦相似度**计算两个向量之间夹角的余弦。两个方向完全相同的向量的余弦相似度为$1$，而两个方向截然相反的向量的相似度为$-1$。余弦相似度是**方向**的度量，其向量的大小并不重要。计算如下：

$$ D(x,y) = cos(\theta) = \frac{x \cdot y}{||x|| \cdot ||y||} $$

![](https://img.imgdb.cn/item/60238ce43ffa7d37b3a588d1.jpg)

### 主要缺点
余弦相似度的主要缺点是没有考虑向量的**大小**，只考虑其**方向**。在实际应用中，这意味着没有考虑数值的差异。

### 应用场合
对于高维数据且向量的大小并不重要时，可以使用余弦相似度。比如在文本分析中，每一个文档用不同词语出现次数组成的向量表示。当一个词语在一个文档中出现的频率高于另一个文档时，并不意味着该文档与该词的关系更大，可能是文档的长度不均匀，因此计数的大小并不重要，此使可以使用不考虑大小的余弦相似度。

# 3. 汉明距离 Hamming Distance
**汉明距离**用来计算两个向量之间相差的位数。它通常用于比较两个长度相等的二进制字符串之间的相似度，也可以用来计算两个字符串之间不同的字符数。

![](https://img.imgdb.cn/item/60238fc53ffa7d37b3a71d36.jpg)

### 主要缺点
当两个向量的长度**不相等**时，无法计算汉明距离。汉明距离比较两个向量的差异，而不考虑他们之间差值的**大小**。

### 应用场合
汉明距离通常用在计算机网络上传输数据时的**纠错/检测**。它可以用来确定二进制字符串中的失真位数。
此外，汉明距离还可以用来测量**分类变量**之间的距离。

# 4. 曼哈顿距离 Manhattan Distance
**曼哈顿距离**也被称作**出租车距离**或**城市街区距离**。计算曼哈顿距离时考虑两个向量之间的“直角”距离，计算如下：

$$ D(x,y) = \sum_{i=1}^{n} |x_i-y_i| $$

![](https://img.imgdb.cn/item/6023919c3ffa7d37b3a82226.jpg)

### 主要缺点
曼哈顿距离的测量并不**直观**，且不可能是**最短路径**。

### 应用场合
当数据集是**离散**或**二进制**的，此时欧氏距离是没有意义的，可以用曼哈顿距离。

# 5. 切比雪夫距离 Chebyshev Distance
**切比雪夫距离**也被称为**棋盘距离**，它衡量两个向量沿任何坐标维度之间的最大差异，即沿某一轴线的最大距离。计算如下：

$$ D(x,y) = \mathop{\max}_i (|x_i-y_i|) $$

![](https://img.imgdb.cn/item/602392f13ffa7d37b3a8f7bb.jpg)

### 主要缺点
切比雪夫距离并不是一个通用的距离测量方法，只适用于非常特殊的情况。

### 应用场合
切比雪夫距离可以用来测量从一个方格到另一个方格所需的最少步数。
在实践中，切比雪夫距离经常被用于仓库物流。

# 6. 闵可夫斯基距离 Minkowski Distance
**闵可夫斯基距离**是在规范向量空间（$n$维实空间）中使用的一种距离度量方法，计算如下：

$$ D(x,y) = (\sum_{i=1}^{n} |x_i-y_i|^p)^{\frac{1}{p}} $$

参数$p$选择不同时，闵可夫斯基距离退化为不同的距离：
- $p=1$：曼哈顿距离
- $p=2$：欧几里得距离
- $p=∞$：切比雪夫距离

![](https://img.imgdb.cn/item/6023944d3ffa7d37b3a9f2fc.jpg)

### 主要缺点
实际使用时选择合适的参数$p$并不容易。

### 应用场合
闵可夫斯基距离的优点是是可以对参数$p$进行迭代，找到最适合的距离度量，使得距离度量具有很大的灵活性。

# 7. Jaccard指数 Jaccard Index
**Jaccard指数**也被称为**交并比联合**，用于衡量样本集的相似性。它是两个样本集交集的大小除以并集的大小。

![](https://img.imgdb.cn/item/602396cd3ffa7d37b3ab4d18.jpg)

**Jaccard距离**是用$1$减去**Jaccard**指数，计算如下：

$$ D(x,y) = 1-\frac{|x∩y|}{|x∪y|} $$

### 主要缺点
**Jaccard**指数受数据集大小影响较大。大的数据集会使并集大小显著增大。

### 应用场合
**Jaccard**指数可以用于目标检测中计算边界框交并比；也可以用于文本相似性分析，以衡量文档之间用词的重叠程度。

# 8. 半正矢距离 Haversine Distance
**半正矢距离**是指球面上两点的经纬度距离，相当于球面上的欧式距离。计算如下：

$$ d = 2arcsin(\sqrt{sin^2(\frac{\phi_2-\phi_1}{2})+cos(\phi_1)cos(\phi_2)sin^2(\frac{\phi_2-\phi_1}{2})}) $$

![](https://img.imgdb.cn/item/6023992a3ffa7d37b3ac703e.jpg)

### 主要缺点
半正矢距离假设数据点分布在球体上，在实践中很少有标准的球体。如地球并不是标准的球体。**Vincenty**距离则建立在椭圆体假设上。

### 应用场合
半正矢距离常用于导航，计算两个国家之间的飞行距离。

# 9. Dice指数 Dice Index
**Dice**指数与**Jaccard**指数类似，都是衡量两个样本集的相似性。**Dice**指数的计算更为直观，衡量两个样本集的重叠百分比，其取值范围是$\[0,1\]$。计算如下：

$$ D(x,y) = \frac{2|x∩y|}{|x|+|y|} $$

![](https://img.imgdb.cn/item/60239a733ffa7d37b3ad1c87.jpg)

### 主要缺点
与**Jaccard**指数相似，受数据集大小影响较大。

### 应用场合
与**Jaccard**指数相似，通常用于图像分割任务或文本相似性分析。

# 10. 马氏距离 Mahalanobis Distance
