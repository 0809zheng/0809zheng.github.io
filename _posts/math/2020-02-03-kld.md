---
layout: post
title: 'KL散度'
date: 2020-02-03
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/62ac690b0947543129746277.jpg'
tags: 数学
---

> The Kullback-Leibler Divergence.

1. KL散度的定义和性质
2. 前向KL散度与反向KL散度

# 1. KL散度的定义和性质
**KL散度(Kullback-Leibler Divergence)**用来衡量同一个**随机变量(random variable)**的两个**概率分布(distribution)**的“距离”（**KL**散度并不是标准的距离，因为它不满足可交换性）。

记随机变量$z$的两个概率分布$p$和$q$，对于**离散型(discrete)**随机变量，**KL**散度形式如下：

$$ KL[q||p] = \sum_{z}^{} {q(z) \log \frac{q(z)}{p(z)}} = -\sum_{z}^{} {q(z) \log \frac{p(z)}{q(z)}} $$

对于**连续型(continuous)**随机变量，**KL**散度形式如下：

$$ KL[q||p] = \int_{}^{} {q(z) \log \frac{q(z)}{p(z)} dz} = -\int_{}^{} {q(z) \log \frac{p(z)}{q(z)} dz} $$

总的来说，上述各种形式可以统一写作**期望(expectation)**的形式：

$$ KL[q||p] = \mathbb{E}_{q(z)} \log \frac{q(z)}{p(z)} = -\mathbb{E}_{q(z)} \log \frac{p(z)}{q(z)} $$

**KL**散度的性质：
- $KL[q\|\|p] ≠ KL[p\|\|q]$
- $KL[q\|\|p] ≥ 0 \quad \forall q,p$



# 2. 前向KL散度与反向KL散度

实践中，常用一个**近似(approximate)**概率分布$q$去估计一个**理论(theoretic)**但是**不可解(intractable)**的概率分布$p$。通常假设近似分布$q$形式比理论分布$p$简单，比如$q$是**单模态(unimodal)**的，$p$是**双模态(bimodal)**的。

![](https://pic.imgdb.cn/item/62ac6803094754312972d57e.jpg)

**前向KL散度(Forward KL)**形式如下：

$$ KL[p||q] = \sum_{z}^{} {p(z) \log \frac{p(z)}{q(z)}} $$


从上述公式和图像中可以看出，在$p(z)>0$而$q(z)=0$的位置将有较大的惩罚，由于$\mathop{\lim}_{q(z)→0} log \frac{p(z)}{q(z)} → ∞$，这造成了学习到的分布$q$将会覆盖任何分布$p$的区域，造成**zero avoiding**现象。

**反向KL散度(Reverse KL)**形式如下：

$$ KL[q||p] = \sum_{z}^{} {q(z) \log \frac{q(z)}{p(z)}} $$


从上述公式和图像中可以看出，在$p(z)=0$的位置只有$q(z)=0$才能使其值不趋近于$∞$，这造成了学习到的分布$q$在$p(z)=0$的位置也为$0$。这造成**zero forcing**现象。
