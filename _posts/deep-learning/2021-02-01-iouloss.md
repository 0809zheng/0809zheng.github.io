---
layout: post
title: '目标检测中的回归损失函数'
date: 2021-02-01
author: 郑之杰
cover: ''
tags: 深度学习
---

> Regression loss functions in object detection.

目标检测的损失函数包括**分类损失**和边界框的**回归损失**。其中回归损失衡量预测边界框坐标$x_{pred}$和**GT**边界框坐标$x_{gt}$之间的差异，本文介绍常用的回归损失函数：
1. **L1 / L2 loss**
2. **smooth L1 loss**
3. **IoU loss**
4. **GIoU loss**
5. **DIoU loss**
6. **CIoU loss**
7. **EIoU loss**

# 1. L1 / L2 Loss
通用的回归损失采用**L1 / L2 loss**，计算如下：

$$ L1 = |x| $$

$$ L2 = x^2 $$

这两种损失函数存在缺点：
- **L1 Loss**的导数为常数，在训练后期，真实值与预测值的差值$x=x_{gt}-x_{pred}$很小时，如果学习率不变，损失函数会在稳定值附近波动，难以收敛到更高精度；
- **L2 Loss**在差值很大时，其导数非常大，故在训练初期不稳定。

# 2. smooth L1 loss
- paper：[Fast R-CNN](https://arxiv.org/abs/1504.08083)

针对**L1 / L2 loss**的问题，修正后得到**smooth L1 loss**：

$$ smooth_{L1}(x) = \begin{cases} |x|-0.5, \quad \text{if } x ≥ 1 \\ 0.5x^2, \quad \text{if } x < 1 \end{cases} $$

该损失函数在差值$x$较大时是**L1 Loss**，在其较小时是**L2 Loss**。

第**1**、**2**小节介绍的损失函数存在共通的缺点：
- 这些损失函数独立地计算每一个坐标分量(如$x$,$y$,$h$,$w$)的差异，然后相加得到最终的损失。这样做忽略了不同坐标分量之间的联系(如$x$,$y$靠近图像边缘时，$h$,$w$会受到限制)；
- 目标检测的评估指标是**交并比 IoU**，与上述损失函数的计算是不匹配的(如具有相同损失值的不同坐标组合可能具有不同的**IoU**)。

# 3. IoU loss
- paper：[UnitBox: An Advanced Object Detection Network](https://arxiv.org/abs/1608.01471)

**IoU loss**的计算与评估指标**IoU**是匹配的：

$$ \text{IoU loss} = -ln\frac{Intersection(x_{gt},x_{pred})}{Union(x_{gt},x_{pred})} $$

实际计算中也简化为：

$$ \text{IoU loss} = 1-\frac{Intersection(x_{gt},x_{pred})}{Union(x_{gt},x_{pred})} $$

该损失将不同坐标分量(如$x$,$y$,$h$,$w$)联系起来，具有尺度不变性。

**IoU loss**的缺点：
- 当预测边界框和实际边界框不相交时，**IoU**为$0$。此时**IoU loss**是不可导的，不能反映两个边界框的远近程度，无法优化；
- 假设预测框和目标框的大小都确定，只要两个框的相交值是确定的，其**IoU**值是相同时，不能反映两个框是如何相交的。如下图所示，通常认为右边的边界框更好，但两者**IoU**值相同：

![](https://img.imgdb.cn/item/60177c843ffa7d37b3a8976c.jpg)

# 4. GIoU loss
- paper：[Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression](https://arxiv.org/abs/1902.09630)

**IoU**不能区分一些边界框的相交情况。作者提出了评估指标**GIoU (Generalized IoU)**，不仅关注重叠区域，还关注非重叠区域，能更好的反映两者的重合度。计算如下：

$$ \text{GIoU} = \text{IoU} - \frac{|C-(A∪B)|}{|C|} $$

其中$A$、$B$表示两个边界框区域，$C$表示$A$和$B$的外接矩形。**GIoU**的取值范围是$-1 \text{~} 1$，当两框重合时取$1$，当两框未相交时取$-1$。

通过**GIoU**可以定义**GIoU loss**：

$$ \text{GIoU loss} = 1-\text{GIoU} $$

**GIoU loss**的缺点：
- 当一个边界框完全包含另一个边界框时，**GIoU**退化为**IoU**，无法区分两者的相对位置关系。如下图三者的**GIoU**相同，但我们认为右边的结果更好：

![](https://img.imgdb.cn/item/60177d613ffa7d37b3a92f2f.jpg)

# 5. DIoU loss
- paper：[Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression](https://arxiv.org/abs/1911.08287)

作者分析边界框回归的三个重要因素：**中心点距离**、**重叠面积**和**长宽比**。笔者的理解如下，对于给定的**GT**边界框，中心点距离能够对预测框进行粗定位，重叠面积能够进一步筛选预测框，长宽比能够最终确定预测框。

**IoU**只衡量重叠面积，需要进一步考虑预测框和**GT**框的惩罚项，损失函数的通用范式如下：

$$ L = 1-IoU+R(B_{pred},B_{gt}) $$

作者提出了评估指标**DIoU (Distance IoU)**，将惩罚项设置为：

$$ R_{DIoU} = \frac{ρ^2(b_{pred},b_{gt})}{c^2} $$

其中$b_{pred}$,$b_{gt}$表示边界框的中心点，$ρ$是欧式距离，$c$表示最小外接矩形的对角线距离，如下图所示：

![](https://img.imgdb.cn/item/6017d99c3ffa7d37b3ec6a3e.jpg)

**DIoU**是在**IoU**的基础上加上中心点的归一化距离，能够更好的表达两框的距离，计算如下：

$$ \text{DIoU} = \text{IoU} - R_{DIoU} $$

通过**DIoU**可以定义**DIoU loss**：

$$ \text{DIoU loss} = 1-\text{DIoU} $$

**DIoU loss**的缺点是没有考虑长宽比的影响。

# 6. CIoU loss
- paper：[Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression](https://arxiv.org/abs/1911.08287)

**DIoU**的作者又进一步提出了**CIoU (Complete IoU)**，在惩罚项上增加长宽比影响因子$\alpha v$：

$$ R_{CIoU} = \frac{ρ^2(b_{pred},b_{gt})}{c^2} + \alpha v $$

其中$v$衡量边界框长宽比的一致性，$\alpha$用于平衡$v$的值，计算如下：

$$ \alpha = \frac{v}{(1-IoU)+v} $$

$$ v = \frac{4}{\pi^2} (arctan\frac{w^{gt}}{h^{gt}}-arctan\frac{w}{h})^2 $$

通过**CIoU**可以定义**CIoU loss**：

$$ \text{CIoU loss} = 1-\text{CIoU} $$

**CIoU loss**的主要缺点如下：
- 衡量长宽比的$v$计算过于复杂，减缓了收敛速度；
- 推导可得$\frac{\partial v}{\partial w}=-\frac{h}{w}\frac{\partial v}{\partial h}$，$w$和$h$的优化是相反的。

# 7. EIoU loss
- paper：[Focal and Efficient IOU Loss for Accurate Bounding Box Regression](https://arxiv.org/abs/2101.08158)

为简化**CIoU**中长宽比影响因子$\alpha v$的计算，作者提出**EIoU (Efficient IoU)**，用下式作为长宽比的影响因子：

$$ \frac{ρ^2(w_{pred},w_{gt})}{c_w^2} + \frac{ρ^2(h_{pred},h_{gt})}{c_h^2} $$

$$ L_{EIoU} = L_{IoU} + L_{dis} + L_{asp} = \\ 1-IoU+ \frac{ρ^2(b_{pred},b_{gt})}{c^2} + \frac{ρ^2(w_{pred},w_{gt})}{c_w^2} + \frac{ρ^2(h_{pred},h_{gt})}{c_h^2} $$
