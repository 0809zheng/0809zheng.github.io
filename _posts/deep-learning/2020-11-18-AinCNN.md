---
layout: post
title: '卷积神经网络中的注意力机制(Attention Mechanism)'
date: 2020-11-18
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63aaba3608b6830163a51dfb.jpg'
tags: 深度学习
---

> Attention Mechanism in Convolutional Neural Networks.

卷积神经网络中的**注意力机制(Attention Mechanism)**表现为在特征的某个维度上计算相应**统计量**，并根据所计算的统计量对该维度上的每一个元素赋予不同的权重，用以增强网络的特征表达能力。

```python
class Attention(nn.Module):
    def __init__(self, ):
        super(Attention, self).__init__()
        self.layer() = nn.Sequential()
    
    def forward(self, x):
        b, c, h, w = x.size()
        w = self.layer(x)         # 在某特征维度上计算权重
        return x * w.expand_as(x) # 对特征进行加权
```

卷积层的特征维度包括通道维度$C$和空间维度$H,W$，因此注意力机制可以应用在不同维度上：
- 通道注意力(**Channel Attention**)：**SENet**, **GSoP**, **SKNet**, **ECA-Net**, **FcaNet**
- 空间注意力(**Spatial Attention**)：**SGE**,
- 通道+空间：(并联)**scSE**, **BAM**, **SA-Net**; (串联)**CBAM**; (融合)**CBAM**
- 其他注意力：


## 1. 通道注意力

### ⚪ [<font color=blue>Squeeze-and-Excitation Network (SENet)</font>](https://0809zheng.github.io/2020/10/01/senet.html)

**SENet**对输入特征沿着通道维度计算一阶统计量(全局平均池化)，然后通过带有瓶颈层的全连接层学习通道之间的相关性。

![](https://pic.imgdb.cn/item/63a41844b1fccdcd36de13f2.jpg)

### ⚪ [<font color=blue>Competitive Squeeze and Excitation (CMPT-SE)</font>](https://0809zheng.github.io/2020/11/04/cmptse.html)

**CMPT-SE**通过残差流和恒等流进行竞争建模，以共同决定通道注意力分布，使得恒等流能自主参与对特征的权重调控。

![](https://pic.imgdb.cn/item/63c00db5be43e0d30e58e019.jpg)

### ⚪ [<font color=blue>Gather-Excite Network (GENet)</font>](https://0809zheng.github.io/2020/10/10/genet.html)

**GENet**对输入特征使用通道卷积提取每个局部空间位置的统计量，然后将其进行缩放还原回原始尺寸，并通过带有瓶颈层的$1\times 1$卷积层学习通道之间的相关性。

![](https://pic.imgdb.cn/item/63ad7a4808b6830163c30e7b.jpg)

### ⚪ [<font color=blue>Global Second-order Pooling (GSoP)</font>](https://0809zheng.github.io/2020/10/03/gsopnet.html)

**GSoP**对输入特征沿着通道维度进行降维后，计算通道之间的协方差矩阵(二阶统计量)，然后通过按行卷积和全连接层学习通道之间的相关性。

![](https://pic.imgdb.cn/item/63a441b408b6830163cd168d.jpg)

### ⚪ [<font color=blue>Style-based Recalibration Module (SRM)</font>](https://0809zheng.github.io/2020/11/03/srm.html)

**SRM**首先通过风格池化将每个特征图的通道级统计信息（均值和标准差）用作风格特征，然后通过风格集成来估计每个通道的重校准权重。

![](https://pic.imgdb.cn/item/63b9763bbe43e0d30e612cfc.jpg)



### ⚪ [<font color=blue>Selective Kernel Network (SKNet)</font>](https://0809zheng.github.io/2020/10/02/sknet.html)

**SKNet**首先同时使用不同大小的卷积核作为不同的分支提取特征，然后通过通道注意力机制融合这些特征，以获得不同感受野的信息。

![](https://pic.imgdb.cn/item/63a4269bb1fccdcd36f4c6b3.jpg)

### ⚪ [<font color=blue>Dense-and-Implicit-Attention (DIA)</font>](https://0809zheng.github.io/2020/10/18/dianet.html)

**DIA**在不同的网络层共享同一个注意力模块，以鼓励分层信息的集成。具体地通过**LSTM**共享模块参数并捕获长距离依赖性。

![](https://pic.imgdb.cn/item/63b293545d94efb26ffd9365.jpg)


### ⚪ [<font color=blue>Efficient Channel Attention (ECA-Net)</font>](https://0809zheng.github.io/2020/10/07/ecanet.html)

**ECA-Net**通过把通道注意力模块中的全连接层替换为一维卷积层，实现了轻量级的通道注意力。

![](https://pic.imgdb.cn/item/63a5570808b6830163258973.jpg)

### ⚪ [<font color=blue>Spatial Pyramid Attention (SPANet)</font>](https://0809zheng.github.io/2020/10/27/spanet.html)

**SPANet**在**4×4**、**2×2**和**1×1**三个尺度上对输入特征图进行自适应平均池化，然后将三个输出特征连接并调整为一维向量以生成通道注意力分布。

![](https://pic.imgdb.cn/item/63b56326be43e0d30e36b559.jpg)

### ⚪ [<font color=blue>Multi-Spectral Channel Attention (FcaNet)</font>](https://0809zheng.github.io/2020/10/09/fcanet.html)

**FcaNet**首先选择应用离散余弦变换后**Top-n**个性能最佳的频率分量标号，然后把输入特征沿通道划分为$n$等份，对每份计算其对应的**DCT**频率分量，并与对应的特征分组相乘。

![](https://pic.imgdb.cn/item/63a6645a08b6830163bc8227.jpg)

### ⚪ [<font color=blue>Efficient Pyramid Split Attention (EPSA)</font>](https://0809zheng.github.io/2020/10/25/epsanet.html)

**EPSA**首先根据拆分和拼接模块生成多尺度的特征图，通过通道注意力机制提取不同尺度特征图的注意力向量，利用**Softmax**重新校准不同尺度的注意力向量，并对多尺度特征图进行加权。

![](https://pic.imgdb.cn/item/63b55eefbe43e0d30e2fc791.jpg)

### ⚪ [<font color=blue>Tiled Squeeze-and-Excite (TSE)</font>](https://0809zheng.github.io/2020/11/02/tse.html)

**TSE**把通道注意力的全局平均池化替换成更小的池化核，为针对数据流设计的**AI**加速器中的元素乘法引入更小的缓冲区。

![](https://pic.imgdb.cn/item/63b958a2be43e0d30e28f946.jpg)

## 2. 空间注意力

### ⚪ [<font color=blue>Spatial Group-wise Enhance (SGE)</font>](https://0809zheng.github.io/2020/10/08/sge.html)

**SGE**把输入特征进行分组，对每组特征在空间维度上与其全局平均池化特征做点积后进行标准化，然后通过学习两个仿射参数(缩放和偏移)实现空间注意力。

![](https://pic.imgdb.cn/item/63a55f3d08b683016332fdc6.jpg)

### ⚪ [<font color=blue>Ultra-Lightweight Subspace Attention Module (ULSAM)</font>](https://0809zheng.github.io/2020/11/27/ulsam.html)

**ULSAM**对输入特征进行分组，对每组特征通过深度可分离卷积构造空间注意力分布，进行空间上的重新校准；最后把所有特征连接作为输出特征。

![](https://pic.imgdb.cn/item/63fdbffff144a01007d918c3.jpg)

## 3.1 并联通道+空间注意力

### ⚪ [<font color=blue>Concurrent Spatial and Channel Squeeze & Excitation (scSE)</font>](https://0809zheng.github.io/2020/10/06/scse.html)

**scSE**通过并联使用通道注意力和空间注意力增强特征的表达能力。通道注意力通过全局平均池化和全连接层实现；空间注意力通过$1\times 1$卷积实现。

![](https://pic.imgdb.cn/item/63a51eee08b6830163cb93b0.jpg)

### ⚪ [<font color=blue>Bottleneck Attention Module (BAM)</font>](https://0809zheng.github.io/2020/10/04/bam.html)

**BAM**通过并联使用通道注意力和空间注意力增强特征的表达能力。通道注意力通过全局平均池化和全连接层实现；空间注意力通过$1\times 1$卷积和空洞卷积实现。

![](https://pic.imgdb.cn/item/63a50e2908b6830163b5939c.jpg)


### ⚪ [<font color=blue>Shuffle Attention (SA-Net)</font>](https://0809zheng.github.io/2021/01/30/sanet.html)

**SA-Net**把输入特征沿通道维度拆分为$g$组，对每组特征再次沿通道平均拆分后应用并行的通道注意力和空间注意力，之后集成所有特征，并通过通道置换操作进行不同通道间的交互。

![](https://img.imgdb.cn/item/601cb04a3ffa7d37b3c0b9c2.jpg)

### ⚪ [<font color=blue>Triplet Attention</font>](https://0809zheng.github.io/2020/10/14/triplet.html)

**Triplet Attention**分别沿着通道维度、高度维度和宽度维度应用注意力机制，其中输入特征可以通过维度交换构造；统计函数$Z$选用全局最大池化和全局平均池化。

![](https://pic.imgdb.cn/item/63aee0f708b68301639e2448.jpg)



## 3.2 串联通道+空间注意力

### ⚪ [<font color=blue>Convolutional Block Attention Module (CBAM)</font>](https://0809zheng.github.io/2020/10/05/cbam.html)

**CBAM**通过串联使用通道注意力和空间注意力增强特征的表达能力，每种注意力机制构造两个一阶统计量（全局最大池化和全局平均池化）。

![](https://pic.imgdb.cn/item/63a516a408b6830163c0658b.jpg)

## 3.3 融合通道+空间注意力

### ⚪ [<font color=blue>Self-Calibrated Convolution (SCNet)</font>](https://0809zheng.github.io/2020/10/13/scnet.html)

**SCNet**把输入特征沿通道维度拆分成两部分，一部分直接应用标准的卷积操作；另一部分在两个不同的尺度空间中进行卷积特征转换：原始特征空间和下采样后具有较小分辨率的隐空间。

![](https://pic.imgdb.cn/item/63ad903808b6830163e5047d.jpg)

### ⚪ [<font color=blue>Coordinate Attention</font>](https://0809zheng.github.io/2021/03/06/ca.html)

**坐标注意力**能够同时建模通道之间的相关性和特征的位置信息。通过沿水平或垂直方向进行平均池化，以捕捉精确的互补位置信息。

![](https://pic.imgdb.cn/item/63b2546d5d94efb26faf5a86.jpg)




## 4. 其他注意力

### ⚪ [<font color=blue>Deep Connected Attention Network (DCANet)</font>](https://0809zheng.github.io/2020/10/15/dcanet.html)

**DCANet**把相邻的注意力模块连接起来，使信息在注意力模块之间流动。实现过程是把前一个注意力模块中转换模块的输出$T_{n-1}$乘以提取模块的输出$E_{n-1}$后（用注意力分布对统计特征进行加权），连接到当前注意力模块中提取模块的输出$E_{n}$。

![](https://pic.imgdb.cn/item/63b23e955d94efb26f974f43.jpg)

### ⚪ [<font color=blue>Weight Excitation (WE)</font>](https://0809zheng.github.io/2020/10/20/we.html)

**WE**对卷积核的不同权重赋予注意力机制，通过**SENet**模块调整卷积核每个权重通道的重要性，通过激活函数调整卷积核每个权重幅值的重要性。

![](https://pic.imgdb.cn/item/63b3964fbe43e0d30e51f580.jpg)

### ⚪ [<font color=blue>Attentional Activation (ATAC)</font>](https://0809zheng.github.io/2020/10/29/atac.html)

**ATAC**是一种同时用于非线性激活和逐元素特征细化的局部通道注意力模块，该模块局部地聚合了逐点跨通道特征上下文信息。

![](https://pic.imgdb.cn/item/63b8cdf2be43e0d30e457c3b.jpg)

### ⚪ [<font color=blue>Attentional Feature Fusion (AFF)</font>](https://0809zheng.github.io/2020/12/01/aff.html)

**AFF**把来自不同层或不同分支的特征通过注意力机制进行组合。

![](https://pic.imgdb.cn/item/63b24e6b5d94efb26fa89166.jpg)

### ⚪ [<font color=blue>AW-Convolution</font>](https://0809zheng.github.io/2020/11/01/awconv.html)

**AW-conv**通过生成与卷积核尺寸相同的注意力图并作用于卷积核，实现了多通道、多区域的注意力机制。

![](https://pic.imgdb.cn/item/63b93ac7be43e0d30eef26ff.jpg)

### ⚪ [<font color=blue>Batch Aware Attention Module (BA^2M)</font>](https://0809zheng.github.io/2020/10/22/baam.html)

在图像分类任务中，由于图像内容的复杂性不同，在计算损失的时候不同图像应该具有不同的重要性。**BA^2M**在批量训练中为每个样本$x_i$根据注意力机制赋予一个重要性权重$w_i$，从而调整其在损失计算中的重要性：

$$ \begin{aligned}  L &=  -\frac{1}{N} \sum_i^N \log (\frac{e^{w_i\cdot f_{y_i}}}{\sum_j^K e^{w_i\cdot f_j}})  \end{aligned} $$

![](https://pic.imgdb.cn/item/63b555d0be43e0d30e205daf.jpg)

### ⚪ [<font color=blue>Interflow</font>](https://0809zheng.github.io/2020/10/28/interflow.html)

**Interflow**根据深度把卷积网络划分为几个阶段，并利用每个阶段的特征映射进行预测。把这些预测分支输入到一个注意力模块中学习这些预测分支的权值，并将其聚合得到最终的输出。

![](https://pic.imgdb.cn/item/63b81ab0be43e0d30e146939.jpg)


### ⚪ [<font color=blue>Normalization-based Attention Module (NAM)</font>](https://0809zheng.github.io/2020/10/31/nam.html)

**NAM**对输入特征应用**Batch Norm**，并通过**Batch Norm**中可学习的尺度变换参数$\gamma$构造注意力分布。

![](https://pic.imgdb.cn/item/63b92d4dbe43e0d30ed8ac4b.jpg)



### ⭐ 参考文献
- [Attention Mechanisms in Computer Vision: A Survey](https://arxiv.org/abs/2111.07624)：(arXiv1709)一篇卷积神经网络中的注意力机制综述。
- [An Attentive Survey of Attention Models](https://arxiv.org/abs/1904.02874)：(arXiv1904)包括**NLP**/**CV**/推荐系统等方面的注意力机制。
- [<font color=blue>Squeeze-and-Excitation Networks</font>](https://0809zheng.github.io/2020/10/01/senet.html)：(arXiv1709)SENet：卷积神经网络的通道注意力机制。
- [<font color=blue>Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks</font>](https://0809zheng.github.io/2020/10/06/scse.html)：(arXiv1803)scSE：全卷积网络中的并行空间和通道注意力模块。
- [<font color=blue>Competitive Inner-Imaging Squeeze and Excitation for Residual Network</font>](https://0809zheng.github.io/2020/11/04/cmptse.html)：(arXiv1807)残差网络的竞争性内部图像通道注意力机制。
- [<font color=blue>BAM: Bottleneck Attention Module</font>](https://0809zheng.github.io/2020/10/04/bam.html)：(arXiv1807)BAM：瓶颈注意力模块。
- [<font color=blue>CBAM: Convolutional Block Attention Module</font>](https://0809zheng.github.io/2020/10/05/cbam.html)：(arXiv1807)CBAM：卷积块注意力模块。
- [<font color=blue>Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/10/10/genet.html)：(arXiv1810)GENet：在通道注意力中利用特征上下文。
- [<font color=blue>Global Second-order Pooling Convolutional Networks</font>](https://0809zheng.github.io/2020/10/03/gsopnet.html)：(arXiv1811)GSoP-Net：全局二阶池化卷积网络。
- [<font color=blue>SRM: A Style-based Recalibration Module for Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/11/03/srm.html)：(arXiv1903)SRM：一种基于风格的卷积神经网络重校准模块。
- [<font color=blue>Selective Kernel Networks</font>](https://0809zheng.github.io/2020/10/02/sknet.html)：(arXiv1903)SKNet：通过注意力机制实现卷积核尺寸选择。
- [<font color=blue>DIANet: Dense-and-Implicit Attention Network</font>](https://0809zheng.github.io/2020/10/18/dianet.html)：(arXiv1905)DIANet：密集的隐式注意力网络。
- [<font color=blue>Spatial Group-wise Enhance: Improving Semantic Feature Learning in Convolutional Networks</font>](https://0809zheng.github.io/2020/10/08/sge.html)：(arXiv1905)通过空间分组增强模块提高卷积网络的语义特征学习能力。
- [<font color=blue>ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/10/07/ecanet.html)：(arXiv1910)ECA-Net：卷积神经网络的高效通道注意力机制。
- [<font color=blue>Improving Convolutional Networks with Self-Calibrated Convolutions</font>](https://0809zheng.github.io/2020/10/13/scnet.html)：(CVPR2020)SCNet：通过自校正卷积改进卷积神经网络。
- [<font color=blue>Weight Excitation: Built-in Attention Mechanisms in Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/10/20/we.html)：(AAAI2020)权重激励：卷积神经网络中的内部注意力机制。
- [<font color=blue>Spanet: Spatial Pyramid Attention Network for Enhanced Image Recognition</font>](https://0809zheng.github.io/2020/10/27/spanet.html)：(ICME2020)SPANet：图像识别的空间金字塔注意力网络。
- [<font color=blue>ULSAM: Ultra-Lightweight Subspace Attention Module for Compact Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/11/27/ulsam.html)：(arXiv2006)ULSAM：超轻量级子空间注意力机制。
- [<font color=blue>DCANet: Learning Connected Attentions for Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/10/15/dcanet.html)：(arXiv2007)DCANet：学习卷积神经网络中的连接注意力。
- [<font color=blue>Attention as Activation</font>](https://0809zheng.github.io/2020/10/29/atac.html)：(arXiv2007)使用注意力机制作为激活函数。
- [<font color=blue>Attentional Feature Fusion</font>](https://0809zheng.github.io/2020/12/01/aff.html)：(arXiv2009)AFF：特征通道注意力融合。
- [<font color=blue>Rotate to Attend: Convolutional Triplet Attention Module</font>](https://0809zheng.github.io/2020/10/14/triplet.html)：(arXiv2010)通过旋转特征构造卷积三元注意力模块。
- [<font color=blue>FcaNet: Frequency Channel Attention Networks</font>](https://0809zheng.github.io/2020/10/09/fcanet.html)：(arXiv2012)FcaNet：频域通道注意力网络。
- [<font color=blue>An Attention Module for Convolutional Neural Networks</font>](https://0809zheng.github.io/2020/11/01/awconv.html)：(arXiv2012)AW-conv：一个卷积神经网络的注意力模块。
- [<font color=blue>SA-Net: Shuffle Attention for Deep Convolutional Neural Networks</font>](https://0809zheng.github.io/2021/01/30/sanet.html)：(arXiv2102)SANet：通过特征分组和通道置换实现轻量型置换注意力。
- [<font color=blue>Coordinate Attention for Efficient Mobile Network Design</font>](https://0809zheng.github.io/2021/03/06/ca.html)：(arXiv2103)为轻量型网络设计的坐标注意力机制。
- [<font color=blue>BA^2M: A Batch Aware Attention Module for Image Classification</font>](https://0809zheng.github.io/2020/10/22/baam.html)：(arXiv2103)BA^2M：图像分类的批量注意力模块。
- [<font color=blue>EPSANet: An Efficient Pyramid Split Attention Block on Convolutional Neural Network</font>](https://0809zheng.github.io/2020/10/25/epsanet.html)：(arXiv2105)EPSANet：卷积神经网络的高效金字塔拆分注意力模块。
- [<font color=blue>Interflow: Aggregating Multi-layer Feature Mappings with Attention Mechanism</font>](https://0809zheng.github.io/2020/10/28/interflow.html)：(arXiv2106)Interflow：通过注意力机制汇聚多层特征映射。
- [<font color=blue>Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context</font>](https://0809zheng.github.io/2020/11/02/tse.html)：(arXiv2107)TSE：通过局部空间上下文构造通道注意力。
- [<font color=blue>NAM: Normalization-based Attention Module</font>](https://0809zheng.github.io/2020/10/31/nam.html)：(arXiv2111)NAM：基于归一化的注意力模块。






- [ResNeSt: Split-Attention Networks](https://0809zheng.github.io/2020/09/09/resnest.html)：(arXiv2004)ResNeSt：拆分注意力网络。


### Residual Attention Network for Image Classification
- intro:Residual Attention Network
- keypoint:trunk brunch + mask brunch
- arXiv:[https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)

![](https://pic.downk.cc/item/5e82b31f504f4bcb04d14747.png)




