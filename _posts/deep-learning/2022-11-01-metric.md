---
layout: post
title: '度量学习(Metric Learning)'
date: 2022-11-01
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63c22967be43e0d30eb7ce66.jpg'
tags: 深度学习
---

> Metric Learning.

**度量学习(Metric Learning)**是指通过理解样本之间的相似关系，学习到合适的距离度量。给定数据集$$\{(x_i,y_i)\}$$，度量学习通过学习一个函数$f_{\theta}(\cdot)$把样本$x$嵌入到特征空间，使得变换后的特征向量能够满足某种相似度度量，从而通过点积等方法可以近似实现不同样本的相似度评估，进而应用在人脸识别、行人重识别、图像检索等任务中。

传统的度量学习方法通常使用**线性投影**将原始数据的特征空间转化为具有距离信息的新的变换空间，然后在变换空间中应用[距离度量]()衡量样本之间的相似性。深度度量学习通过共享权重的神经网络实现样本间的关联，并设计合理的度量损失减少相似样本之间的距离，增大不相似样本之间的距离。

本文目录：
1. 正负样本的采样
2. 网络结构的设计
3. 损失函数的设计
4. 使用**PyTorch Metric Learning**实现度量学习


# 1. 正负样本的采样

度量学习的目标在于最小化相似样本之间的距离，最大化不相似样本之间的距离。因此对于输入样本$x$，需要合理地选择正样本(相似样本)和负样本(不相似样本)。

在深度度量学习中，负样本对的数量(不同标签的样本)通常远大于正样本对(相同标签的样本)的数量。如果采用简单的随机样本采样策略，即随机选择两个不相似的样本作为正负样本对，则网络的学习过程可能会受到限制。主要原因是存在低质量的负样本对无法为网络带来有用的信息，因此通过**负样本挖掘(negtive mining)**策略选择负样本对。
- **Easy Negative Mining**：选择显著不同的负样本，可能会产生过于简单的负样本对；
- **Hard Negative Mining**：选择由训练数据确定的假阳性样本；
- **Semi-Hard Negative Mining**：在给定范围内寻找负样本。


![](https://pic.imgdb.cn/item/63c234cbbe43e0d30ec8f834.jpg)


# 2. 网络结构的设计

深度度量学习使用深度神经网络衡量样本对的距离。典型结构是**Siamese**网络，通过共享权重的网络分别接收成对的图像(包括正、负样本)，通过损失函数计算成对图像之间的距离。**Siamese**网络的本质是对同一个网络执行两次前向传播。


![](https://pic.imgdb.cn/item/63c236fabe43e0d30ecc3de4.jpg)

# 3. 损失函数的设计

深度度量学习的损失函数旨在最小化正样本对$(x,x^+)$之间的特征距离，最大化负样本对$(x,x^-)$之间的特征距离。根据同时考虑的样本数量，可分为：
- **局部**度量损失：每次只考虑少数几个样本之间的关系，如**Contrastive Loss**
- **全局**度量损失：同时考虑一个批次中所有样本的关系，如

### ⚪ [Contrastive Loss](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf)

对比损失判断给定的样本对$(x_i,x_j)$之间的正负关系，若为正样本对则使其特征距离接近$0$，若为负样本对则使其特征距离不小于$\epsilon$。

$$ \Bbb{I}(y_i=y_j) D[f_{\theta}(x_i),f_{\theta}(x_j)] + \Bbb{I}(y_i\neq y_j) \max(0,\epsilon- D[f_{\theta}(x_i),f_{\theta}(x_j)]) $$


### ⚪ [<font color=blue>Triplet Loss</font>](https://0809zheng.github.io/2022/11/02/triplet.html)

三元组损失为每一个样本$x$选择一个正样本$x^+$和一个负样本$x^-$，同时最小化正样本对之间的距离和最大化负样本对之间的距离。

$$ \max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x),f_{\theta}(x^-)] + \epsilon) $$

![](https://pic.imgdb.cn/item/63c50a18be43e0d30eae7254.jpg)

### ⚪ [<font color=blue>N-pair Loss</font>](https://0809zheng.github.io/2022/11/05/npair.html)

**N-pair Loss**把**Triplet**损失扩展到同时比较所有负类样本的距离。对于每一个样本$x$，选择一个正样本$x^+$和所有其他类别的负样本$x_1^-,...,x_{N-1}^-$构造$(N+1)$元组，则**N-pair**损失定义为：

$$ - \log\frac{\exp(f_{\theta}(x)^Tf_{\theta}(x^+))}{\exp(f_{\theta}(x)^Tf_{\theta}(x^+))+ \sum_{i=1}^{N-1} \exp(f_{\theta}(x)^Tf_{\theta}(x_i^-))} $$

![](https://pic.imgdb.cn/item/63c75ba1be43e0d30eab4295.jpg)

### ⚪ [<font color=blue>Angular Loss</font>](https://0809zheng.github.io/2022/11/07/angular.html)

**角度损失(angular loss)**引入了三元组$(x_a,x_p,x_n)$的三阶几何限制，具有尺度不变性和旋转不变性。构造样本$x_a$和正样本$x_p$的中心点$x_c=(x_a+x_p)/2$，并以其为圆心作圆；连接$x_n$与$x_c$后作垂线与圆相交于点$x_m$。若角度$n'$减小，则负样本$x_n$沿着$x_cx_n$方向远离样本$x_a$和正样本$x_p$，而样本$x_a$和正样本$x_p$彼此接近。

$$  \max(0, ||f_{\theta}(x_a)-f_{\theta}(x_p)||^2 -4 \tan^2 \alpha||f_{\theta}(x_n)-f_{\theta}(x_c)||^2) $$

![](https://pic.imgdb.cn/item/63c7db41be43e0d30e9cde87.jpg)

### ⚪ [<font color=blue>Quadruplet Loss</font>](https://0809zheng.github.io/2022/11/08/quadruplet.html)

**Quadruplet Loss**为每一个样本$x$选择一个正样本$x^+$和两个负样本$x^-_1,x^-_2$，使得正样本对之间的距离同时小于负样本对之间的距离和两个负样本之间的距离：

$$ \max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x),f_{\theta}(x^-_1)] + \alpha) \\ + \max(0, D[f_{\theta}(x),f_{\theta}(x^+)] -D[f_{\theta}(x^-_2),f_{\theta}(x^-_1)] + \beta) $$

![](https://pic.downk.cc/item/5ec23be0c2a9a83be54a3bb6.jpg)

### ⚪ [<font color=blue>Hierarchical Triplet Loss</font>](https://0809zheng.github.io/2022/11/10/hierarchical.html)

**Hierarchical Triplet Loss**根据数据集构造分层树，对其进行**Anchor neighbor**采样生成三元组，并根据构造的分层树的类间关系设置**violate margin**:

$$ \alpha_z = \beta + d_{H(y_a,y_n)} - S_{y_a} $$

![](https://pic.imgdb.cn/item/63ca599cbe43e0d30eadec68.jpg)






### ⚪ [<font color=blue>Lifted Structured Loss</font>](https://0809zheng.github.io/2022/11/03/lifted.html)

**Lifted Structured Loss**同时考虑了一批样本内的所有样本对之间的关系，在保证相似样本距离最小的同时，尽可能增大最困难的不相似样本的特征距离。

$$ \frac{1}{2| \mathcal{P}|} \sum_{(i,j) \in \mathcal{P}} \max(0,D_{ij} + \max(\mathop{\max}_{(i,k) \in \mathcal{N}} \epsilon-D_{ik},\mathop{\max}_{(j,l) \in \mathcal{N}} \epsilon-D_{jl}))^2 $$

![](https://pic.imgdb.cn/item/63c51218be43e0d30ebd98f7.jpg)

### ⚪ [<font color=blue>Histogram Loss</font>](https://0809zheng.github.io/2022/11/04/histogram.html)

直方图损失(**Histogram Loss**)首先估计正样本对和负样本对所对应的两个特征距离分布$p^+(x),p^-(x)$（通过直方图$H^+$和$H^-$近似），然后计算正样本对之间的相似度比负样本对之间的相似度还要小的概率：

$$  \int_{-1}^{1}p^-(x) [\int_{-1}^{x}p^+(y)dy] dx ≈ \sum_{r=1}^R (h^-_r \sum_{q=1}^rh_q^+) $$

![](https://pic.imgdb.cn/item/63c51a55be43e0d30ed19d40.jpg)



### ⚪ [<font color=blue>Magnet Loss</font>](https://0809zheng.github.io/2022/11/06/magnet.html)

**Magnet Loss**检索聚类簇的所有局部邻域，并惩罚它们的重叠区域。随机选择$M$个聚类簇，每个簇选取$D$个样本，最小化每个聚类簇中的样本与对应聚类中心的距离，并最大化与其他簇的聚类中心的距离：

$$ \frac{1}{MD} \sum_{m=1}^M \sum_{d=1}^D -\log \frac{e^{-\frac{1}{2\sigma^2}||f_{\theta}(x_d^m)-\mu_m||_2^2-\alpha}}{\sum_{\mu: c(\mu) \neq c(f_{\theta}(x_d^m))}e^{-\frac{1}{2\sigma^2}||f_{\theta}(x_d^m)-\mu||_2^2}}  $$

![](https://pic.imgdb.cn/item/63c7b1f1be43e0d30e51f202.jpg)

### ⚪ [<font color=blue>Clustering Loss</font>](https://0809zheng.github.io/2022/11/09/clustering.html)

**Clustering Loss**预先为每个类别的样本指定一个聚类中心，使得每一类样本的距离之和尽可能小，不同类样本间的距离尽可能大。对于有标签的样本集$(X,Y)$，要求最佳聚类得分$$\tilde{F}$$比任意其他聚类划分$g(S)$的聚类得分不低于结构化边界$\Delta$：

$$ \max(0, \mathop{\max}_{S \subset V,|S| = |Y|} \{ F(X,S;\theta)+\gamma \Delta(g(S),Y) \} - \tilde{F}(X,Y;\theta) ) $$

![](https://pic.imgdb.cn/item/63ca176ebe43e0d30e48fcc8.jpg)









**Triplet Hard Loss**:

在选取训练数据时，通常选择难训练的三元组(**Hard Sample Mining**)，具体可参考论文:
- [In Defense of the Triplet Loss for Person Re-Identification](https://arxiv.org/abs/1703.07737)

**(4).Improved Triplet Loss**

- 参考论文：[Person re-identification by multi-channel parts-based CNN with improved triplet loss function](https://www.researchgate.net/publication/311610684_Person_Re-identification_by_Multi-Channel_Parts-Based_CNN_with_Improved_Triplet_Loss_Function)

![](https://pic.downk.cc/item/5ec23a04c2a9a83be5485919.jpg)

**Improved Triplet Loss**是在**Triplet Loss**的基础上，对**anchor**和**positive**的距离加上约束$β$，定义为：

$$ L(A,P,N) = max(|| f(A)-f(P) ||^2 + α - || f(A)-f(N) ||^2, 0) \\ + max(|| f(A)-f(P) ||^2 - β, 0) $$






### ⭐ 参考文献
- [<font color=blue>FaceNet: A Unified Embedding for Face Recognition and Clustering</font>](https://0809zheng.github.io/2022/11/02/triplet.html)：(arXiv1503)FaceNet：通过三元组损失实现人脸识别和聚类的统一嵌入。
- [<font color=blue>Deep Metric Learning via Lifted Structured Feature Embedding</font>](https://0809zheng.github.io/2022/11/03/lifted.html)：(arXiv1511)基于提升结构化特征嵌入的深度度量学习。
- [<font color=blue>Metric Learning with Adaptive Density Discrimination</font>](https://0809zheng.github.io/2022/11/06/magnet.html)：(arXiv1511)通过自适应密度判别实现度量学习。
- [<font color=blue>Learning Deep Embeddings with Histogram Loss</font>](https://0809zheng.github.io/2022/11/04/histogram.html)：(arXiv1611)通过直方图损失学习深度嵌入。
- [<font color=blue>Improved Deep Metric Learning with Multi-class N-pair Loss Objective</font>](https://0809zheng.github.io/2022/11/05/npair.html)：(NIPS2016)通过多类别N-pair损失改进深度度量学习。
- [<font color=blue>Deep Metric Learning via Facility Location</font>](https://0809zheng.github.io/2022/11/09/clustering.html)：(arXiv1612)通过设施位置实现深度度量学习。
- [<font color=blue>Beyond triplet loss: a deep quadruplet network for person re-identification</font>](https://0809zheng.github.io/2022/11/08/quadruplet.html)：(arXiv1704)用于行人重识别的四元组损失。
- [<font color=blue>Deep Metric Learning with Angular Loss</font>](https://0809zheng.github.io/2022/11/07/angular.html)：(arXiv1708)通过角度损失实现深度度量学习。
- [<font color=blue>Deep Metric Learning with Hierarchical Triplet Loss</font>](https://0809zheng.github.io/2022/11/10/hierarchical.html)：(arXiv1810)通过层次化三元组损失实现深度度量学习。

# 4. 使用PyTorch Metric Learning实现度量学习

[PyTorch Metric Learning](https://kevinmusgrave.github.io/pytorch-metric-learning/)库是一个为深度度量学习设计的第三方库，安装方式如下：

```python
pip install pytorch-metric-learning
```

首先初始化一个度量损失函数，以计算训练集中样本对的度量损失：

```python
from pytorch_metric_learning import losses
loss_func = losses.TripletMarginLoss()
```

通常正样本对由共享相同标签的特征嵌入构成，负样本对由具有不同标签的特征嵌入构成；可以通过设置采样策略构造样本对的难例挖掘：

```python
from pytorch_metric_learning import miners
miner = miners.MultiSimilarityMiner()
```

在训练过程中传入模型构造的特征嵌入（尺寸为`(batch_size, embedding_size)`）以及相应的标签（尺寸为`(batch_size)`）：

```python
# your training loop
for i, (data, labels) in enumerate(dataloader):
    optimizer.zero_grad()
    embeddings = model(data)
    hard_pairs = miner(embeddings, labels)
    loss = loss_func(embeddings, labels, hard_pairs)
    loss.backward()
    optimizer.step()
```

损失函数可通过`distances, reducers, regularizers`定义。通过难例挖掘可以找到不同的样本对索引，然后通过定义的距离函数计算样本对之间的距离，并进一步计算损失函数；正则化器则为每个样本计算正则化损失；然后通过衰减器仅保留数值较高的损失项。

```python
from pytorch_metric_learning.distances import CosineSimilarity
from pytorch_metric_learning.reducers import ThresholdReducer
from pytorch_metric_learning.regularizers import LpRegularizer
from pytorch_metric_learning import losses
loss_func = losses.TripletMarginLoss(distance = CosineSimilarity(), 
                                    reducer = ThresholdReducer(high=0.3), 
                                    embedding_regularizer = LpRegularizer())
```

![](https://pic.imgdb.cn/item/63c37193be43e0d30ee5aa75.jpg)