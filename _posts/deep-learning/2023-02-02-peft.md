---
layout: post
title: '大型预训练模型的参数高效微调(Parameter-Efficient Fine-Tuning)'
date: 2023-02-02
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/648d6a3c1ddac507ccb6536c.jpg'
tags: 深度学习
---

> Parameter-Efficient Fine-Tuning for Large Pretrained Models.

基于[Transformer](https://0809zheng.github.io/2020/04/25/transformer.html)架构的大型语言模型(**LLM**)在自然语言处理、计算机视觉和音频等任务上取得突出的表现。然而这些模型通常具有大量参数（如**GPT3.5**具有**1.75**万亿参数），从头训练需要极大的算力和训练成本；因此为不同的下游任务训练不同的大型模型是不现实的。

将预训练好的大型模型在下游任务上进行微调已成为处理不同任务的通用范式。与直接使用冻结参数的预训练模型相比，在下游数据集上微调这些预训练模型会带来巨大的性能提升。但是随着模型越来越大，对模型进行全部参数的微调（**full fine-tuning**）变得非常昂贵，因为微调模型（调整模型的所有参数）与原始预训练模型的大小完全相同。

近年来研究者们提出了各种各样的**参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）**方法，即冻结预训练模型的大部分参数，仅微调少量或额外的模型参数（微调参数可以是模型的自有参数，也可以是额外引入的一些参数），以此达到与微调全部参数相当的性能。参数高效微调方法大大降低了计算和存储成本，甚至在某些情况下比全部参数的微调效果更好，可以更好地泛化到域外场景。

参数高效微调方法有三种形式：
- 增加额外参数(**addition**)：在原始模型中引入额外的可训练参数，如**P-Tuning**, **Prompt Tuning**, **Prefix-Tuning**, **P-Tuning v2**, 
- 选取部分参数(**specification**)：指定原始模型中的部分参数可训练，如**BitFit**, **Child-Tuning**
- 重参数化(**reparameterization**)：将微调过程重参数化为低维子空间的优化，如

![](https://pic.imgdb.cn/item/648d6de51ddac507ccbea4ec.jpg)

扩展阅读：
- [Parameter-efficient Fine-tuning of Large-scale Pre-trained Language Models](https://www.nature.com/articles/s42256-023-00626-4)

# 1. 增加额外参数的参数高效微调方法

这类方法在原始模型中引入额外的可训练参数，比如将小规模的神经网络模块插入到模型中，并且只微调这一小部分参数。由于引入了额外参数，这类方法的优化效率往往比其他微调范式更低，收敛时间更长，并且在中小型模型上表现不佳。

### ⚪ P-Tuning
- arXiv2103：[<font color=blue>GPT Understands, Too</font>](https://0809zheng.github.io/2023/02/06/ptuning.html)

**P-Tuning**方法把传统人工设计模版中的真实**token**替换成可微的**virtual token**，并用提示编码器(**MLP+LSTM**)进行一层处理。

![](https://pic.imgdb.cn/item/648d8fa31ddac507cc059627.jpg)

### ⚪ Prompt Tuning
- arXiv2104：[<font color=blue>The Power of Scale for Parameter-Efficient Prompt Tuning</font>](https://0809zheng.github.io/2023/02/05/prompttuning.html)

**Prompt Tuning**方法给每个任务定义了自己的**Prompt**（可学习**token**），然后在输入层拼接到输入数据上。

![](https://pic.imgdb.cn/item/648d89fb1ddac507ccfda28d.jpg)


### ⚪ Prefix-Tuning
- arXiv2106：[<font color=blue>Prefix-Tuning: Optimizing Continuous Prompts for Generation</font>](https://0809zheng.github.io/2023/02/04/prefixtuning.html)

**Prefix-Tuning**在每一层输入**token**之前构造一段任务相关的**virtual tokens**作为**Prefix**，在训练时只更新**Prefix**部分的参数，而语言模型中的其他部分参数固定。对于自回归结构，构造**z = [PREFIX; x; y]**；对于编码器-解码器结构，构造**z = [PREFIX; x; PREFIX'; y]**。

![](https://pic.imgdb.cn/item/648d79631ddac507ccda7778.jpg)

### ⚪ P-Tuning v2
- arXiv2110：[<font color=blue>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</font>](https://0809zheng.github.io/2023/02/07/ptuning2.html)

**P-Tuning v2**在**Transformer**网络的每一层都加入了可学习的**Prompts tokens**作为输入。

![](https://pic.imgdb.cn/item/648d92c61ddac507cc0a44b0.jpg)

# 2. 选取部分参数的参数高效微调方法

这类方法指定原始模型中的某些特定参数变得可训练，而其他参数则被冻结。这类方法不会在模型中引入任何新参数，也不改变模型的结构，而是直接指定要优化的部分参数。尽管方法简单，但是通常效果比较好。

### ⚪ BitFit (Bias-terms Fine-tuning)
- arXiv2106：[<font color=blue>BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models</font>](https://0809zheng.github.io/2023/02/03/bitfit.html)

**BitFit**训练时只更新网络中的**bias**参数。**Transformer**模型涉及到的**bias**参数有：**attention**模块中计算**query,key,value**与合并多个**attention**结果时涉及到的**bias**、**MLP**层和**LayerNorm**层的**bias**。

![](https://pic.imgdb.cn/item/648d76471ddac507ccd1f4fd.jpg)

### ⚪ Child-Tuning
- arXiv2109：[<font color=blue>Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning</font>](https://0809zheng.github.io/2020/09/29/childtuning.html)

**ChildTuning**方法每次从预训练模型中选择一个子网络进行优化；子网络的选择又分为两种方式：**ChildTuning-D**和**ChildTuning-F**。

![](https://pic.imgdb.cn/item/647af86ef024cca173e0f099.jpg)

**ChildTuning-D**是任务相关的选择方式，通过计算每个参数的**Fisher**信息作为该参数的重要性，选择最重要的**top**-$p$个参数，在模型更新过程中只优化这些参数。

**ChildTuning-F**是任务无关的选择方式。在每步更新时随机构建一个与梯度同尺寸的**0/1**矩阵$M$，其中设置$1$的比例为$p$，然后将梯度修改为$$g \leftarrow \frac{g \otimes M}{p}$$。



# 3. 重参数化的参数高效微调方法

这类方法将现有的优化过程重参数化为参数高效的形式。重参数化方法通常假设预训练模型的微调过程本质上是低秩或者低维的，通过将微调过程重参数化为一个低维子空间的优化过程，可以仅仅通过微调子空间内的参数就达到令人满意的性能。

