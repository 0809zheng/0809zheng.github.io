---
layout: post
title: '多实例学习(Multiple Instance Learning)'
date: 2025-10-01
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/68ecb993c5157e1a886c51da.png'
tags: 深度学习
---

> Multiple Instance Learning.

在标准的监督学习框架下，每一个实例(**instance**)都会被赋予一个标签(**label**)。在弱监督学习场景下，标签可能是模糊的：比如在数字病理学中，一张数亿像素的全切片影像（**WSI**）可能包含数千个组织切片，但医生只有一个宏观的诊断结论——“癌变”或“正常”，无法逐一标注每一个切片。

![](https://pic1.imgdb.cn/item/68ecb96dc5157e1a886c51d5.png)

**多实例学习（Multiple Instance Learning, MIL）**是一种弱监督学习框架，它将数据组织成一种层级结构：由多个实例构成一个**包（Bag）**，标签是在“包”的层面上给出的。

![](https://pic1.imgdb.cn/item/68ecb993c5157e1a886c51da.png)

多实例学习的标准假设（**standard assumption**）是：
- **正包（Positive Bag）**：一个包被标记为正，当且仅当它至少包含一个正实例。
- **负包（Negative Bag）**：一个包被标记为负，当且仅当它所有实例均为负。

此外，还存在其他更加契合现实世界复杂性的假设：
- **存在性假设 (Presence-based Assumption)**: 一个包为正，当且仅当它同时包含多种特定类型的实例。
- **阈值假设 (Threshold-based Assumption)**: 一个包为正，当且仅当某种特定类型的实例数量达到一定阈值。


# 1. 建模多实例学习

给定一个包 $B=\{x_1,x_2,\cdots,x_n\}$，其中 $x_i$ 是一个实例，$y$ 是包的标签。多实例学习的目标是学习一个函数 $\theta(\cdot)$，使得 $\theta(B)$ 尽可能接近 $y$。函数 $\theta(\cdot)$可以建模为：

$$
\theta(B) = g(\sigma(f(x_1),...,f(x_n)))
$$

其中 $f(\cdot)$ 是实例级的特征提取器；$\sigma(\cdot)$ 是一个聚合函数，称为**MIL池化**；$g(\cdot)$ 是一个包级的分类器。由于我们不假设包内实例的顺序和依赖关系，因此$\sigma(\cdot)$应具有**置换不变性（permutation-invariant）**。

# 2. 常见的多实例学习方法

现有的**Deep MIL**方法根据其分类粒度(**Classification Granularity**)可以分为：
- 实例级(**instance-level**) **MIL**：先对每个实例分别做预测，再对预测结果进行聚合；如**mi-Net**, **Adaptive Pooling**, **Certainty Pooling**, **Power Pooling**, **DSMIL**, **MIVAE**, **CausalMIL**, **Additive MIL**, **MILLET**, **MIREL**, **FocusMIL**。
- 包级(**bag-level**) **MIL**：先将所有实例的特征向量聚合，再对包特征做预测；如**MI-Net**, **Attention MIL**, **DP-MINN**, **GNN-MIL**, **Loss-Attention**, **TransMIL**, **SA-AbMILP**, **DTFD-MIL**, **IBMIL**, **DAS-MIL**, **MHIM-MIL**, **Extreme MIL**。

论文[<font color=blue>Are Multiple Instance Learning Algorithms Learnable for Instances?</font>](https://0809zheng.github.io/2025/10/02/milpac.html)指出，引入注意力能够让模型在**包级别**可学习；但只有将注意力机制作用于**预测结果**层面而非特征层面的实例级**Deep MIL**方法才能够满足**实例级可学习性（instance-level learnability）**：即模型学会了如何正确地分类单个实例。


## 2.1 Instance-level Deep MIL

### ⚪ [<font color=blue>mi-Net</font>](https://0809zheng.github.io/2025/10/03/minet.html)
- (arXiv1610) Revisiting Multiple Instance Neural Networks

**mi-Net** 的工作流程如下：
1.  包中的每个实例独立地通过一系列全连接层进行特征变换。
2.  为每个实例预测一个“为正”的概率得分。
3. **MIL**池化层接收所有实例的得分，并将其聚合成一个包得分的标量。

![](https://pic1.imgdb.cn/item/68ef1023c5157e1a887297b8.png)

### ⚪ [<font color=blue>Adaptive Pooling</font>](https://0809zheng.github.io/2025/10/19/adaptivepooling.html)
- (ICCV 2017) Adaptive Pooling in Multi-Instance Learning for Web Video Annotation

**Adaptive Pooling**利用了**广义均值（Generalized Mean）**来构建池化函数。对于一个包$i$和一个类别$c$，所有实例的预测概率为$\{q_{ij}^c\}_{j=1}^{N_i}$。包级别的预测概率$p_i^c$计算为：

$$ p_i^c = \left( \frac{1}{N_i} \sum_{j=1}^{N_i} (q_{ij}^c)^{r_c^{(t)}} \right)^{\frac{1}{r_c^{(t)}}} $$

指数$r$是一个可学习的参数，$r$是为每个类别$c$独立学习的，即$r_c$；$r$还是训练阶段$t$的函数，即$r_c^{(t)}$，它会随着训练的进行而变化。

### ⚪ [<font color=blue>Certainty Pooling</font>](https://0809zheng.github.io/2025/10/18/certaintypooling.html)
- (arXiv2008) Certainty Pooling for Multiple Instance Learning

**Certainty Pooling**认为一个实例对最终包标签的贡献，应该由它的预测分数和模型对这个预测的确定性共同决定。通过在推理时多次启用**蒙特卡洛 Dropout (MC-Dropout)**并进行预测，可以得到一组预测结果，这组结果的标准差的倒数被用作该预测的“确定性”度量。
- 计算实例确定性 $C_k$: 对于包中的每个实例$k$，进行$T$次带**Dropout**的前向传播，得到预测结果向量$X_k$。计算$X_k$的标准差$σ(X_k)$。确定性$C_k$被定义为标准差的倒数。

$$ C_k = \frac{1}{\sigma(X_k) + \epsilon} $$

- 确定性加权的最大化选择: 对于每个实例$k$，计算其确定性加权分数：$C_k * h_{km}$，其中$h_{km}$是该实例的平均预测分数。**Certainty Pooling**的输出$Z_m$不再是分数最高的实例，而是确定性加权分数最高的那个实例的预测值。
  
$$ k^* = \arg\max_k (C_k \cdot h_{km}) \\ Z_m = h_{k^*m} $$

![](https://pic1.imgdb.cn/item/68ff1dea3203f7be00a64c4e.png)

### ⚪ [<font color=blue>Power Pooling</font>](https://0809zheng.github.io/2025/10/17/powerpooling.html)
- (arXiv2010) Power pooling: An adaptive pooling function for weakly labelled sound event detection

**Power Pooling**在计算实例预测概率$y_f^i$的加权平均时，使用它的$n$次幂$(y_f)^n$，指数$n$是一个非负的可学习参数，使其能够根据实例自身的特性动态调整其聚合策略。

$$ y_c = \frac{\sum_i y_f^i \cdot (y_f^i)^n}{\sum_i (y_f^i)^n} $$


### ⚪ [<font color=blue>DSMIL</font>](https://0809zheng.github.io/2025/10/09/dsmil.html)
- (arXiv2011) Dual-stream Multiple Instance Learning Network for Whole Slide Image Classification with Self-supervised Contrastive Learning

**DSMIL**采用**双流（Dual-stream）**架构：
- 关键实例流：实例分类器（线性层$W_0$）为每个实例$h_i$计算一个分数。对所有实例分数进行**max-pooling**，得到这个流的包分数$c_m(B) = \max_i \{ W_0 h_i \}$，以及得分最高的那个关键实例的嵌入$h_m$。
- 非局部上下文流：将每个实例$h_i$（包括关键实例$h_m$）分别通过两个线性层$W_q$和$W_v$得到查询向量$q_i$和信息向量$v_i$。计算每个实例的查询向量$q_i$与关键实例的查询向量$q_m$之间的内积相似度，并通过**softmax**归一化，得到注意力权重$U(h_i, h_m)$。使用注意力权重对所有实例的信息向量$v_i$进行加权求和，得到最终的包嵌入$b$。用一个线性层$W_b$对包嵌入$b$进行分类，得到这个流的包分数$c_b(B)$。

最终两个流的输出被简单地平均，得到最终的包预测分数：

$$ c(B) = \frac{1}{2} (c_m(B) + c_b(B)) $$

![](https://pic1.imgdb.cn/item/68f0a6aac5157e1a8878e18e.png)


### ⚪ [<font color=blue>MIVAE</font>](https://0809zheng.github.io/2025/10/06/mivae.html)
- (arXiv2105) Non-I.I.D. Multi-Instance Learning for Predicting Instance and Bag Labels using Variational Auto-Encoder

**MIVAE**假设观测到的实例是由两种不同层级的潜在因子共同生成的。
-   $z_B$: **包级别潜在因子 (Bag-level Latent Factor)**。这是共享的，包内所有实例都依赖于它。它负责编码这个包共有的上下文、结构或风格信息。**MIVAE**假设包标签主要与共享的包级别因子$z_B$相关。
-   $z_{ij}^I$: **实例级别潜在因子 (Instance-level Latent Factor)**。这是独立的，每个实例$x_{ij}$都有一个自己专属的$z_{ij}^I$。它负责编码这个实例独特的、区别于其他实例的变异信息。

**MIVAE**采用了**变分自编码器（VAE）**框架，包括一个**生成网络（解码器）**和一个**推断网络（编码器）**。
1. 生成网络$p_θ(x_j \| z_B, z_j^I)$从潜在因子重构实例。输入是共享的$z_B$和独立的$z_j^I$，输出是重构的实例$x_j$。
2. 推断网络需要解决两个挑战：如何从一堆实例中推断出共享的$z_B$，以及如何推断出每个实例独立的$z_j^I$。
- 推断独立的$z_j^I$ **(Instance-level Encoder)**: 对于每个实例$x_j$，都有一个独立的编码器$q_{\phi_I}(z_j^I \| x_j)$来推断其专属的$z_j^I$。
- 推断共享的$z_B$ **(Bag-level Encoder)**: 首先使用编码器$q_{φ_B}(ẑ_{B_j} \| x_j)$为每个实例$x_j$推断一个“临时的”包级别因子$ẑ_{B_j}$。然后将所有这些临时的$ẑ_{B_j}$的分布参数（均值和方差）进行平均，得到最终的、共享的包级别因子$z_B$的分布。

![](https://pic1.imgdb.cn/item/68f05c2ac5157e1a8876a8a7.png)

### ⚪ [<font color=blue>CausalMIL</font>](https://0809zheng.github.io/2025/10/03/minet.html)
- (arXiv2202) Multi-Instance Causal Representation Learning for Instance Label Prediction and Out-of-Distribution Generalization

**CausalMIL** 假设任何一个实例的产生都源于两类潜在因素：
1. **因果因素 (causal factors, $z_c$)**，即决定其标签的核心特征；
2. **非因果/混淆因素 (non-causal factors, $z_e$)**，即与标签无关的风格、环境等信息。

将**MIL**建模为一个**因果图模型**：观测到的实例$x_{ij}$由因果表征$z_{ij}^c$和非因果表征$z_{ij}^e$共同生成。**CausalMIL**使用一个$g(\sigma(f(x_1),...,f(x_n)))$模型从包中提取代表整个包共享环境的特征向量$B$，然后将实例和特征向量$B$输入一个条件变分自编码器进行因果表征$z_{ij}^c$提取和实例标签分类。

![](https://pic1.imgdb.cn/item/68ef67ddc5157e1a8874ce31.png)

### ⚪ [<font color=blue>Additive MIL</font>](https://0809zheng.github.io/2025/10/21/additivemil.html)
- (arXiv2206) Additive MIL: Intrinsically Interpretable Multiple Instance Learning for Pathology

标准的**Attention MIL**模型的计算流程是特征提取 -> 注意力加权 -> 求和聚合 -> 分类。**Additive MIL**的核心改动是交换最后两个操作的顺序：特征提取 -> 注意力加权 -> （对每个实例）计算类别贡献度 -> 求和聚合。

在这个定义下，最终的预测结果被强制定义为所有实例贡献度的线性总和；贡献度分数有正有负。正值代表该实例促进了某个类别的预测（**excitatory**），负值代表抑制（**inhibitory**）。

![](https://pic1.imgdb.cn/item/6901d2903203f7be00b077d3.png)


### ⚪ [<font color=blue>MILLET</font>](https://0809zheng.github.io/2025/10/25/millet.html)
- (arXiv2311) Inherently Interpretable Time Series Classification via Multiple Instance Learning

**MILLET**认为一个实例要想对最终结果有重要贡献，必须同时被注意力和分类器都认为是重要的，基于此提出了**Conjunctive Pooling**，这是**Attention**和**Instance**的并行组合。注意力头$ψ_{ATTN}$和分类器$ψ_{CLF}$独立地作用于原始的实例嵌入$z_j$，分别得到权重$a_j$和预测得分$ŷ_j$。最后，用权重$a_j$来加权预测$ŷ_j$。
    
$$ a_{ji} = \psi_{ATTN}(z_i^j); \quad \hat{y}_i^j = \psi_{CLF}(z_i^j); \quad \hat{Y} = \frac{1}{t} \sum_{j=1}^t (a_{ji} \hat{y}_i^j) $$

![](https://pic1.imgdb.cn/item/692947d47f8e1c7378227956.png)

### ⚪ [<font color=blue>MIREL</font>](https://0809zheng.github.io/2025/10/08/mirel.html)
- (arXiv2405) Weakly-Supervised Residual Evidential Learning for Multi-Instance Uncertainty Estimation

**MIREL**是一个即插即用的多实例不确定性估计模块，在包级别和实例级别同时对高阶不确定性进行建模，能够显著提升现有**MIL**网络的不确定性估计能力。

包估计器建模为 $S(X) = g(\sum_k f(x_k))$，实例估计器$R(x)$引入了残差学习的思想：$R(x) = g \circ f + r_\pi(f_\psi(x))$。**MIREL**引入了**证据深度学习 (EDL)** 框架来量化不确定性，**EDL**模型的输出被用来参数化一个**狄利克雷分布 (Dirichlet distribution)**。

包级别的不确定性建模为：

$$ p(\mu|X) = \text{Dir}(\mu|\alpha_{bag}) \\ \alpha_{bag} = e_{bag} + 1 = A(S(X)) + 1 $$

其中，$e_{bag}$是从包分类器$S(X)$得到的证据，$A(\cdot)$是一个保证证据非负的激活函数。

实例级别的不确定性建模为：

$$ p(\nu|x) = \text{Dir}(\nu|\alpha_{ins}) \\ \alpha_{ins} = e_{ins} + 1 = A(R(x)) + 1 $$

其中，$e_{ins}$是从实例残差估计器$R(x)$得到的证据。

### ⚪ [<font color=blue>FocusMIL</font>](https://0809zheng.github.io/2025/10/16/focusmil.html)
- (arXiv2408) Max-Pooling-Based Multi-Instance Learning Leads to More Robust Whole Slide Image Classification

**FocusMIL**在**mi-Net**的基础上引入了两个改进：采用变分编码器学习实例表示（注入随机性）和采用**Mini-batch**训练（引入多样性），缓解了**max-pooling**的过拟合问题，使其能够专注于学习真正的因果知识。
- **FocusMIL**把实例编码为一个多元高斯分布的参数（均值$μ$和方差$σ²$）。然后从这个分布中采样出一个潜在表示$z$，用于后续的分类。从分布中采样为实例表示引入了随机性。
- **FocusMIL**在每个**mini-batch**中同时处理多个（$n > 1$）包。一个**batch**中的不同实例的背景信息是不同的，为了最小化损失，模型需要忽略掉不稳定的背景信息，转而专注于在所有包中都保持不变的因果特征。

![](https://pic1.imgdb.cn/item/68f5a0413203f7be007ffaee.png)


## 2.2 Bag-level Deep MIL

### ⚪ [<font color=blue>MI-Net</font>](https://0809zheng.github.io/2025/10/03/minet.html)
- (arXiv1610) Revisiting Multiple Instance Neural Networks

**MI-Net** 的工作流程如下：
1.  包中的每个实例独立地通过一系列全连接层进行特征变换。
2.  **MIL**池化层将包内所有实例的特征向量聚合成一个单一的、固定长度的包表示向量 。
3.  包表示向量随后被送入**FC**层进行最终的包分类，得到包得分。

![](https://pic1.imgdb.cn/item/68ef1127c5157e1a8872adb8.png)

### ⚪ [<font color=blue>Attention MIL</font>](https://0809zheng.github.io/2025/10/07/attentionmil.html)
- (arXiv1802) Attention-based Deep Multiple Instance Learning

**Attention MIL**采用基于注意力机制的**MIL**池化算子，为每个实例学习一个注意力权重，然后对实例的特征表示进行加权平均，从而得到整个包的表示。这个权重的大小直观地反映了该实例对最终包标签的贡献度。

$$ a_k = \frac{\exp\{ \mathbf{w}^T \tanh(\mathbf{V} \mathbf{h}_k^T) \}}{\sum_{j=1}^{K} \exp\{ \mathbf{w}^T \tanh(\mathbf{V} \mathbf{h}_j^T) \}} $$

![](https://pic1.imgdb.cn/item/68f092e0c5157e1a88789d00.png)

作者进一步引入了门控机制来增强非线性，提出了**Gated-Attention**。

$$ a_k = \frac{\exp\{\mathbf{w}^T (\tanh(\mathbf{V} \mathbf{h}_k^T) \odot \text{sigm}(\mathbf{U} \mathbf{h}_k^T))\}}{\sum_{j=1}^{K} \exp\{\mathbf{w}^T (\tanh(\mathbf{V} \mathbf{h}_j^T) \odot \text{sigm}(\mathbf{U} \mathbf{h}_j^T))\}} $$

### ⚪ [<font color=blue>DP-MINN</font>](https://0809zheng.github.io/2025/10/11/dpminn.html)
- (PMLR 2018) Deep Multi-instance Learning with Dynamic Pooling

动态池化的本质是一个迭代的权重更新过程。它不再一次性计算出所有实例的最终权重，而是在$T$次迭代中，不断地优化这些权重。**DP-MINN**的输入实例先经过一个实例嵌入网络（如**MLP**），然后送入动态池化层(**Dynamic Pooling**)得到包嵌入。

动态池化层初始化所有实例的临时权重$b_i$为0；每次迭代将临时权重$b_i$通过一个$\text{softmax}$函数得到归一化的贡献度权重$c_i$，使用当前的贡献度权重$c_i$对所有实例嵌入进行加权求和得到当前的包嵌入$σ^t(X)$，将包嵌入$σ$通过一个“挤压”函数进行非线性变换得到$s^t(X)$，计算每个实例嵌入$f(x_i)$与当前整个包的嵌入$s^t(X)$的点积（相似度），将这个相似度累加到临时权重$b_i$上，用于下一次迭代；经过$T$次迭代后，返回最终的包嵌入$s^T(X)$。

![](https://pic1.imgdb.cn/item/68f1aaeac5157e1a887a2dba.png)


### ⚪ [<font color=blue>GNN-MIL</font>](https://0809zheng.github.io/2025/10/10/gnnmil.html)
- (arXiv1906) Multiple instance learning with graph neural networks

**GNN-MIL**把**MIL**建模为图分类任务，主要包括三个步骤：图的构建、图的嵌入学习，以及最终的分类。
- 图的构建：把一个包转换成一个图$G = (A, V)$，包中的每个实例$x_i$为图中的一个节点，所有实例的特征构成了节点特征矩阵 $V$；计算任意两个实例$x_m$和$x_n$之间的欧氏距离，设定一个阈值$η$。如果两个实例的距离小于$η$，则在它们之间添加一条边。由此得到图的邻接矩阵 $A$。
- 图的**DiffPool**：使用一个**GNN**模型更新每个节点的嵌入$Z_i = \text{GNN}_{\text{embd}}(A_i, V_i)$，用另一个**GNN**来为每个节点学习一个到$C$个簇的分配概率$S_i = \text{softmax}(\text{GNN}_{\text{cluster}}(A_i, V_i))$。利用分配矩阵$S_i$将原始图的节点“软分配”到$C$个簇中$V_i^* = S_i^T Z_i$，对$V^*$的每个簇的表示进行**max-pooling**或拼接，得到最终的图嵌入。
- 图的分类：在得到固定长度的图（包）嵌入后，将其送入一个标准的多层感知机分类器，进行最终的标签预测。

![](https://pic1.imgdb.cn/item/68f0b8fdc5157e1a887914ff.png)

### ⚪ [<font color=blue>Loss-Attention</font>](https://0809zheng.github.io/2025/10/24/lossattention.html)
- (AAAI 2020) Loss-based Attention for Deep Multiple Instance Learning

**Loss-Attention**直接利用了计算最终分类**logits**的全连接层来同时定义实例的注意力权重。假设一个包$i$有$n_i$个实例，每个实例的**logits**为$z_{i,j}$，**Loss-Attention**的权重公式计算为:

$$ \alpha_{i,j} = \frac{\sum_{c=0}^{K-1} \exp(z_{i,j,c})}{\sum_{t=1}^{n_i} \sum_{c=0}^{K-1} \exp(z_{i,t,c})} $$

分子是实例$j$所有类别**logits**的指数和，可以理解为这个实例的激活强度；分母是整个包内所有实例、所有类别**logits**的指数总和。计算权重$α$和计算最终分类**logits** $z$使用同一套参数。一个实例要想获得高权重$α_{i,j}$，它的总能量$\sum_c \exp(z_{i,j,c})$就必须大。

![](https://pic1.imgdb.cn/item/6926ebbd3203f7be00343e56.png)


### ⚪ [<font color=blue>TransMIL</font>](https://0809zheng.github.io/2025/10/20/transmil.html)
- (arXiv2106) TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification

**TransMIL**将**Transformer**架构引入多实例学习，核心是一个专门为**WSI**设计的**TPT模块（Transformer-Position encoding-Transformer）**。

**TPT**模块是一个包含两个**Transformer**层和一个**PPEG**位置编码层的结构；其中自注意力采用了**Nyström**方法近似自计算，**PPEG**将一个全切片图像中的所有实例（**patches**）视为一个序列，在**2D**空间使用多尺度卷积来进行条件位置编码。

![](https://pic1.imgdb.cn/item/6901ca983203f7be00b069bd.png)

### ⚪ [<font color=blue>SA-AbMILP</font>](https://0809zheng.github.io/2025/10/13/saabmilp.html)
- (WACV 2021) Kernel Self-Attention for Weakly-supervised Image Classification using Deep Multiple Instance Learning

**SA-AbMILP**在基于注意力的**MIL**之前插入一个**自注意力（Self-Attention, SA）**层建模实例间的依赖关系。标准的自注意力使用**点积（dot product）**来衡量**Query**和**Key**的相似度，作者进一步探索了用其他**核函数 (Kernel)** 来代替点积的可能性，以期在特征空间更复杂或小样本场景下获得更好的效果：
-   **径向基函数核 (RBF, GSA-AbMILP)**: 

$$ k(x, y) = \exp(-\alpha \|x-y\|^2_2) $$

-   **逆二次核 (Inverse Quadratic, IQSA-AbMILP)**:

$$ k(x, y) = \frac{1}{\alpha \|x-y\|^2_2 + 1} $$

-   **拉普拉斯核 (Laplace, LSA-AbMILP)**: 

$$ k(x, y) = -\|x-y\|_1 $$

-   **模块核 (Module, MSA-AbMILP)**: $α$是一个可学习的参数

$$ k(x, y) = \|x-y\|^\alpha - \|x\|^\alpha - \|y\|^\alpha $$

![](https://pic1.imgdb.cn/item/68f1e4d8c5157e1a887cabf8.png)

### ⚪ [<font color=blue>DTFD-MIL</font>](https://0809zheng.github.io/2025/10/15/dtfdmil.html)
- (arXiv2203) DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification

**DTFD-MIL**将每个父包中的实例随机地划分为若干个更小的**伪包(Pseudo-bags)**，并构建了双层架构：**Tier-1**负责处理大量的伪包$X_n^m$，进行初步的特征筛选和分析，预测伪包标签$y_n^m$和每个实例的阳性概率。**Tier-2**接收从每个伪包中蒸馏出的最具代表性的实例特征，进行最终的父包级别分类。

![](https://pic1.imgdb.cn/item/68f207f2c5157e1a887d5448.png)

### ⚪ [<font color=blue>IBMIL</font>](https://0809zheng.github.io/2025/10/23/ibmil.html)
- (arXiv2303) Interventional Bag Multi-Instance Learning On Whole-Slide Pathological Images

**IBMIL**在**MIL**标准的“特征提取+聚合器训练”两阶段之后加入了第三阶段：因果干预训练。

作者将共享于包级别但与标签无直接因果关系的包上下文视为混杂因子$C$。正常训练一个**MIL**模型；然后对所有训练集的包级别特征进行**K-means**聚类，每个聚类中心被视为一个具体的混杂因子状态$c_i$。通过注意力机制，计算当前**WSI**的包特征与所有混杂因子原型的相似度，然后将这些混杂因子加权融合到原始包特征中，再进行最终预测。

![](https://pic1.imgdb.cn/item/690309d33203f7be00b4c757.png)

### ⚪ [<font color=blue>DAS-MIL</font>](https://0809zheng.github.io/2025/10/12/dasmil.html)
- (arXiv2305) Deep Multiple Instance Learning with Distance-Aware Self-Attention

**DAS-MIL**在标准的嵌入式**MIL**模型中引入了**距离感知自注意力（Distance-Aware Self-Attention）**。在计算实例$i$和一个实例$j$之间的注意力时，加入与实例$i$和$j$之间相对距离$δ_ij$相关的可学习偏置项：

$$ e_{ij} = \frac{(x_i W^Q + b_{ij}^Q)(x_j W^K + b_{ij}^K)^T - (b_{ij}^Q)(b_{ij}^K)^T}{\sqrt{d_z}} $$

在最终的加权求和中，也加入了一个距离相关的偏置项 $b_{ij}^V$：

$$ z_i = \sum_{j=1}^n \alpha_{ij} (x_j W^V + b_{ij}^V) $$

偏置项$b_{ij}$是距离$\delta_{ij}$的函数，作者提出了一种插值方案来对连续距离进行编码：

$$ b_{ij}^K = \phi(\delta_{ij}) u^K + (1 - \phi(\delta_{ij})) v^K $$

其中$u^K, v^K$是两个可学习的嵌入向量，$\phi(\delta_{ij})$是一个可学习的插值函数，参数化为一个经过缩放和平移的**Sigmoid**函数$\phi(\delta) = \text{sigmoid}(\beta \cdot \delta + \theta)$。

![](https://pic1.imgdb.cn/item/68f1b7cbc5157e1a887a8526.png)

### ⚪ [<font color=blue>MHIM-MIL</font>](https://0809zheng.github.io/2025/10/14/mhimmil.html)
- (arXiv2307) Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification

**MHIM-MIL**是一个**教师-学生（Teacher-Student）**框架的**孪生（Siamese）**结构，通过“掩码”操作来间接地实现难样本挖掘。
- 学生模型$S$可以是任何基于注意力的**MIL**模型，它接收经过教师模型“筛选”后的难样本，提取包表示并进行分类。
- 教师模型$T$为每个实例计算一个注意力分数，将所有实例根据其注意力分数从高到低排序。将注意力分数排在前$β_h\%$的实例标记为“掩盖”。它的参数是通过对学生模型的参数进行指数移动平均来平滑更新的。

![](https://pic1.imgdb.cn/item/68f1edfdc5157e1a887cf1cc.png)

### ⚪ [<font color=blue>Extreme MIL</font>](https://0809zheng.github.io/2025/10/26/extrememil.html)
- (arXiv2503) Extreme Learning Machines for Attention-based Multiple Instance Learning in Whole-Slide Image Classification

**Extreme MIL**在注意力权重的计算公式中，用于特征变换的矩阵$V$，在随机初始化后，其参数被完全“冻结”，在整个训练过程中不进行任何更新。唯一的可训练参数在注意力模块中的权重向量$w$。作者认为随机的$V$同样能提供一个足够丰富的高维特征空间，并且大幅减少了参数量和优化成本。

![](https://pic1.imgdb.cn/item/692966b67f8e1c737822fe6e.png)


### ⚪ Reference
- [Exploring Multiple Instance Learning (MIL): A brief survey](https://www.sciencedirect.com/science/article/abs/pii/S0957417424007590)