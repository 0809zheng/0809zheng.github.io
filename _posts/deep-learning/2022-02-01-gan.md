---
layout: post
title: '生成对抗网络(Generative Adversarial Network)'
date: 2022-02-01
author: 郑之杰
cover: 'https://pic.downk.cc/item/5ebd0c69c2a9a83be54ed281.jpg'
tags: 深度学习
---

> Generative Adversarial Networks.

本文目录：
1. 建模生成对抗网络
2. 使用Pytorch实现生成对抗网络
3. 生成对抗网络的评估指标
4. 生成对抗网络的训练困难
5. 生成对抗网络的各种变体

# 1. 建模生成对抗网络

**生成对抗网络(Generative Adversarial Network, GAN)**是一种生成模型，可以用来生成图像、文本、语音等结构化数据(**structured data**)。

假设真实数据具有概率分布$$P_{data}(x)$$，**GAN**使用一个**生成器generator**构造真实分布的一个近似分布$$P_G(x)$$，并使用一个**判别器discriminator**衡量生成分布和真实分布之间的差异。

- **生成器** $G$：生成器是一个神经网络，从一个简单的概率分布$P_Z(z)$中采样$z$，经过生成器$G$得到输入数据概率分布$$P_{data}$$的估计$$P_G(x)=G(z)$$；![](https://pic.downk.cc/item/5eb555dcc2a9a83be5b2b166.jpg)
- **判别器** $D$：判别器是一个二分类器，用于区分从输入数据分布$$P_{data}$$（标记为$1$）和生成分布$$P_G$$（标记为$0$）中采样得到的数据。![](https://pic.downk.cc/item/5eb55bb7c2a9a83be5b7fced.jpg)

对于判别器$D$，希望其能正确地区分真实数据与生成数据。若输入数据来自真实分布$$P_{data}$$，则希望其输出结果接近$1$；反之若数据来自生成分布$P_G$，则希望其输出结果接近$0$。优化目标采用二元交叉熵：

$$ D^* = \mathop{\arg \max}_{D} \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{z \text{~} P_{Z}(z)}[\log(1-D(G(z)))] $$

对于生成器$G$，希望其能够成功地欺骗判别器，使其将生成样本误分类成真实样本：

$$ G^* = \mathop{\arg \min}_{G} \Bbb{E}_{z \text{~} P_{Z}(z)}[\log(1-D(G(z)))] $$

### ⚪ 从博弈论视角理解生成对抗网络

若将判别器$D$和生成器$G$的目标函数合并，记为：

$$ \begin{aligned} \mathop{ \min}_{G} \mathop{\max}_{D} L(G,D) & =  \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{z \text{~} P_{Z}(z)}[\log(1-D(G(z)))] \\ & =  \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))] \end{aligned} $$


上式表示判别器$D$和生成器$G$在进行**极小极大博弈(minimax game)**：这也是一个**零和博弈(zero-sum game)**，参与博弈的双方，在严格竞争下，一方的收益必然意味着另一方的损失，博弈各方的收益和损失相加总和永远为“零”。
在交替迭代的过程中，双方都极力优化自己的网络，从而形成竞争对抗，直到双方达到**纳什均衡 (Nash equilibrium)**。

观察目标可知博弈过程旨在寻找使得判别器$D$造成的损失$L(G,D)$最大值最小的生成器$G$。

![](https://pic.imgdb.cn/item/632eaa8a16f2c2beb1cc7ff3.jpg)

### ⚪ 从优化视角理解生成对抗网络

将目标函数写成积分形式：

$$ \begin{aligned}  L(G,D)  & =  \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))]  \\ & =\int_x  (P_{data}(x)\log D(x) + P_{G}(x)\log(1-D(x))) dx \end{aligned} $$

下面先求判别器$D$的最优值$D^{\*}$，注意到积分不影响最优值的取得，因此计算被积表达式的极值$$\frac{\partial L(G,D)}{\partial D} = 0$$，得：

$$ D^*(x) = \frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)} \in [0,1] $$

若生成器$G$也训练到最优值，此时有$$P_{data}(x)≈P_{G}(x)$$，则判别器退化为**常数** $D^{\*}(x)=\frac{1}{2}$，失去判别能力。

当判别器$D$取得最优值$D^{\*}$时，目标函数为：

$$ \begin{aligned}  L(G,D^*)  & =\int_x  (P_{data}(x)\log D^*(x) + P_{G}(x)\log(1-D^*(x))) dx \\ & =\int_x  (P_{data}(x)\log \frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)} + P_{G}(x)\log\frac{P_{G}(x)}{P_{data}(x)+P_{G}(x)}) dx \\ & =\int_x  (P_{data}(x)\log \frac{P_{data}(x)}{\frac{P_{data}(x)+P_{G}(x)}{2}} + P_{G}(x)\log\frac{P_{G}(x)}{\frac{P_{data}(x)+P_{G}(x)}{2}}-2\log 2) dx \\ & = 2D_{JS}[P_{data}(x) || P_G(x)]-2\log 2 \end{aligned} $$

其中$D_{JS}$表示[<font color=blue>JS散度</font>](https://0809zheng.github.io/2020/02/03/kld.html#3-js%E6%95%A3%E5%BA%A6)。因此当判别器$D$取得最优时，**GAN**的损失函数衡量了真实分布$$P_{data}(x)$$与生成分布$$P_G(x)$$之间的**JS散度**。若生成器$G$也取得最优值，则损失函数取得**最小值** $-2\log 2$。

在**GAN**的交替训练步骤中，先优化判别器再优化生成器，并且判别器的更新次数通常更多一些；这样做的目的也是为了让判别器先取得局部最优，从而让生成器的优化过程趋近于**JS**散度的最小化过程。

另一方面，传统的基于**极大似然估计(maximum likelihood estimation)**的生成模型本质上是在最小化真实分布$$P_{data}(x)$$与生成分布$$P_G(x)$$之间的[<font color=blue>KL散度</font>](https://0809zheng.github.io/2020/02/03/kld.html#1-kl%E6%95%A3%E5%BA%A6%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E6%80%A7%E8%B4%A8)：

$$ \begin{aligned} \mathop{ \max}_{G} L(G) & = \prod_{i=1}^{n} {P_G(x^i)} = \log(\prod_{i=1}^{n} {P_G(x^i)}) = \sum_{i=1}^{n} {\log P_G(x^i)} \\ & = \Bbb{E}_{x \text{~} P_{data}(x)}[\log P_G(x)] = \int_x P_{data}(x)\log P_G(x) dx \\ &  = \int_x P_{data}(x)\log \frac{P_G(x)}{P_{data}(x)} dx +  \int_x P_{data}(x)\log P_{data}(x) dx \\ & = -D_{KL}[P_{data}(x) || P_G(x)] + Const.  \end{aligned} $$

由于**JS**散度相比于**KL**散度具有对称性、平滑性等优点，因此通常认为**GAN**相比于传统的生成模型能够取得更好的表现。

### ⚪ 从概率论视角理解生成对抗网络


均匀分布到指定分布的变换


# 2. 使用Pytorch实现生成对抗网络

### ⚪ GAN的算法流程

初始化生成器$G(z;\theta_G)$和判别器$D(x;\theta_D)$，在训练的每一次迭代中，先更新判别器$D$，再更新生成器$G$：
- **固定生成器$G$，更新判别器$D$**，重复$k$次：
1. 从训练数据集中采样$$\{x^1,x^2,...,x^n\}$$；
2. 从随机噪声中采样$$\{z^1,z^2,...,z^n\}$$；
3. 根据生成器$G$获得生成数据$$\{\tilde{x}^1,\tilde{x}^2,...,\tilde{x}^n\}$$；

$$ θ_D \leftarrow \mathop{\arg \max}_{\theta_D} \frac{1}{n} \sum_{i=1}^{n} {\log D(x^i)} + \frac{1}{n} \sum_{i=1}^{n} {\log (1-D(\tilde{x}^i))} $$

- **固定判别器$D$，更新生成器$G$**，进行$1$次：
1. 从随机噪声中采样$$\{z^1,z^2,...,z^n\}$$；
2. 根据生成器$G$获得生成数据$$\{\tilde{x}^1,\tilde{x}^2,...,\tilde{x}^n\}$$；

$$ \theta_G \leftarrow \mathop{\arg \min}_{\theta_G} \frac{1}{n} \sum_{i=1}^{n} {\log (1-D(\tilde{x}^i))} $$

上述即为**GAN**的标准训练流程，采用该流程的**GAN**也被称作**Minimax GAN (MMGAN)**。

### ⚪ 从MMGAN到NSGAN


由于上式在计算$θ_G$时，函数$\log (1-D(x))$在$D(x)$接近$0$（即训练的初始阶段）时梯度较小，在$D(x)$接近$1$（即优化后期）时梯度较大，会造成优化困难；因此在实践中采用下式代替：

$$ \theta_G \leftarrow \mathop{\arg \max}_{\theta_G} \frac{1}{n} \sum_{i=1}^{n} {\log D(\tilde{x}^i)} $$

使用上式的**GAN**被称作**Non-saturating GAN (NSGAN)**。

![](https://pic.imgdb.cn/item/632ec75916f2c2beb1f0b96d.jpg)




### ⚪ GAN的Pytorch实现

```python
import torch

# 定义生成器和判别器
generator = Generator()
discriminator = Discriminator()

# 定义损失函数
adversarial_loss = torch.nn.BCELoss()

# 定义优化器
optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

for epoch in range(n_epochs):
    for i, real_imgs in enumerate(dataloader):
        # 构造对抗标签
        valid = torch.ones(real_imgs.shape[0], 1)
        fake = torch.zeros(real_imgs.shape[0], 1)

        # 训练判别器
        for _ in range(k):
            # 采样并生成样本
            z = torch.randn(real_imgs.shape[0], latent_dim)
            gen_imgs = generator(z)
            optimizer_D.zero_grad()
            # 计算判别器的损失
            real_loss = adversarial_loss(discriminator(real_imgs), valid)
            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) # 此处不计算生成器的梯度
            d_loss = (real_loss + fake_loss) / 2
            # 更新判别器参数
            d_loss.backward()
            optimizer_D.step()

        # 训练生成器
        z = torch.randn(real_imgs.shape[0], latent_dim)
        gen_imgs = generator(z)
        optimizer_G.zero_grad()
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)
        g_loss.backward()
        optimizer_G.step()
```







# 3. 生成对抗网络的评估指标

**GAN**的训练过程是交替迭代的，其总目标函数无法同时有效地显示生成器和判别器的训练过程。缺乏有效的评估指标使得**GAN**的训练过程不知何时停止，也不方便对不同模型的性能进行比较。

本节介绍几种**GAN**的评估指标：
- Kernel Density Estimation
- Inception Score

### Kernel Density Estimation
从生成器$G$中随机采样一些样本，使用高斯混合模型拟合这些样本，得到生成样本概率分布的估计值$P_G$，

![](https://pic.downk.cc/item/5ed9e0abc2a9a83be5e94672.jpg)

选择一些真实样本$x^i$，计算其在估计的生成样本分布中的极大似然概率：

$$ L = \frac{1}{N} \sum_{i=1}^{N} {log(P_G(x^i))} $$

将这个似然值作为$GAN$模型的好坏。这种评估方法存在一些问题：
- 一些高质量样本的似然值较低：模型可能产生不同于已知样本集的高质量样本；
- 一些低质量样本的似然值较高

### Inception Score
把生成图像作为图像分类任务的样本集，进行进一步的实验；分成两步：
1. 对于一张生成的图像，将其喂入训练好的分类网络（如Inception），若分类置信度越高则图像质量越好；
![](https://pic.downk.cc/item/5ed9e362c2a9a83be5ecc47e.jpg)
2. 对于不同的生成图像，若分类网络分类后结果越平均（意味着$GAN$不会只生成某几个类）则图像质量越好；
![](https://pic.downk.cc/item/5ed9e388c2a9a83be5ecea9c.jpg)

**Inception Score**的定义是对某一具体的生成图像，分类网络的输出分布越集中越好（熵越小越好）；对于生成的所有图像，分类网络的输出分布越平均越好（熵越大越好）：

$$ \sum_{x}^{} {\sum_{y}^{} {P(y \mid x)logP(y \mid x)}} - \sum_{y}^{} {P(y)logP(y)} $$

![](https://pic.downk.cc/item/5ed9e3e9c2a9a83be5ed87a3.jpg)














# 4. 生成对抗网络的训练困难

众所周知，**GAN**模型的训练比较困难，训练速度较慢且训练过程不稳定。主要体现在以下几点：

## （1）难以实现纳什均衡 Hard to achieve Nash equilibrium

**GAN**使用梯度下降算法优化两人**非合作博弈(non-cooperative)**，通常梯度下降算法只有在目标函数为凸函数时才能保证实现纳什均衡。而判别器和生成器独立地优化各自的损失，在博弈中没有考虑到另一方。因此同时更新两个模型的梯度不能保证收敛。

在[<font color=Blue>Improved Techniques for Training GANs</font>](https://0809zheng.github.io/2022/02/02/improve.html)中，提出了几点使得**GAN**训练更快收敛的方法：
- **feature matching**：检测生成器的输出是否与真实样本的预期统计值(如均值或中位数)相匹配。
- **minibatch discrimination**：使得判别器了解一批训练样本中的数据点之间的近似程度，而不是独立地处理每个样本。
- **historical averaging**：强迫生成器和判别器的参数接近过去训练过程中的历史平均参数。
- **label smoothing**：设置判别器的标签为软标签(如$0.1$和$0.9$)，以此降低模型的脆弱性。
- **virtual batch normalization**：在进行批归一化时使用一个固定批次(参考批次, 在训练开始时选定)的统计量进行归一化。

## （2）低维流形 Low dimensional manifold

许多真实世界的数据集分布$$P_{data}(x)$$通常集中在高维空间中的一个低维流形上，这是因为真实图像要遵循主题或目标的限制；生成分布$$P_G(x)$$通常也位于一个低维流形上，因为它是由一个低维噪声变量$z$定义的。高维空间中的两个低维流形几乎不可能重叠，从而导致**GAN**训练的不稳定性。

![](https://pic.imgdb.cn/item/633107ba16f2c2beb14cbe22.jpg)

在[[<font color=Blue>Towards Principled Methods for Training Generative Adversarial Networks</font>](https://0809zheng.github.io/2022/02/03/principle.html)]中，提出了几点解决分布不匹配的方法：
- 增加噪声：通过在判别器的输入中增加连续噪声，可以人为地扩大真实分布$$P_{data}(x)$$与生成分布$$P_G(x)$$的范围，使得两个概率分布有更大的概率重叠。
- 使用更好的分布相似度度量：**GAN**的损失函数(在一定条件下)衡量真实分布$$P_{data}(x)$$与生成分布$$P_G(x)$$之间的**JS**散度，这在两个分布不相交时没有意义；可以选择具有更平滑值空间的分布度量。

## （3）梯度消失 Vanishing gradient

**GAN**的训练过程进退两难：如果判别器表现较差，则生成器没有准确的反馈，损失函数不能代表真实情况；如果判别器表现较好，则损失函数及其梯度趋近于$0$，训练过程变得非常慢甚至卡住。


![](https://pic.imgdb.cn/item/6331125716f2c2beb156fc56.jpg)

## （4）模式崩溃 Mode collapse

**Mode Collapse**是指在训练过程中生成器可能会崩溃到一种始终产生相同输出的设置。由于生成器无法学习表示复杂的真实世界数据分布，所学习到的生成分布会陷入一个缺乏多样性的局部空间中，只能集中在真实数据分布的一小部分。

![](https://pic.imgdb.cn/item/633115cf16f2c2beb15a9918.jpg)

与之类似的一个问题是**Mode Dropping**，是指真实数据分布通常有多个簇，而生成器的每次迭代过程中只能生成其中某一个簇。

![](https://pic.imgdb.cn/item/6331164716f2c2beb15b5d28.jpg)

- 解决措施：**Ensemble**，即在**GAN**的训练过程中同时训练多个生成器，每次随机选择一个生成器来生成样本。


# 5. 生成对抗网络的各种变体


近些年来$GAN$的发展：

![](https://pic.downk.cc/item/5ed86506c2a9a83be5b4e88c.jpg)

**GAN**的演化：
- 选用不同的损失以减小优化困难：vanilla GAN、fGAN、LSGAN、WGAN
- 加入条件控制生成样本：conditional GAN、InfoGAN
- 领域迁移：cycleGAN、GauGAN、GANILLA
- 与自编码器一起训练：EBGAN、VAE-GAN、BiGAN
- 图像生成：DCGAN、LAPGAN、SAGAN、BigGAN
- 特殊的模型：SinGAN（使用单张图像训练）、NICE-GAN（生成器是判别器的一部分）、StackGAN（文本生成图像）


| 方法 | 目标函数 | 
| :---: | :---: |
| Minimax GAN (MMGAN) |  $$ \begin{aligned} D^* &= \mathop{\arg \max}_{D} \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))]  \\ G^* &= \mathop{\arg \min}_{G} \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))] \end{aligned} $$ | 
| Non-Saturating GAN (NSGAN) |  $$ \begin{aligned} D^* &= \mathop{\arg \max}_{D} \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))]  \\ G^* &= \mathop{\arg \max}_{G}  \Bbb{E}_{x \text{~} P_{G}(x)}[\log D(x)] \end{aligned} $$ | 
| [<font color=Blue>Deep Convolutional GAN (DCGAN)</font>](https://0809zheng.github.io/2022/02/05/dcgan.html) |  同NSGAN | 
| [<font color=Blue>Wasserstein GAN (WGAN)</font>](https://0809zheng.github.io/2022/02/04/wgan.html) | $$ \begin{aligned} D^* &= \mathop{\arg \max}_{D,||D||_L \leq K} \Bbb{E}_{x \text{~} P_{data}(x)}[D(x)]-\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)]  \\ G^* &= \mathop{\arg \min}_{G}  -\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)] \end{aligned} $$ |


$$ \begin{aligned} D^* &= \mathop{\arg \max}_{D} \Bbb{E}_{x \text{~} P_{data}(x)}[D(x)]-\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)]- λ \Bbb{E}_{x \text{~} \epsilon P_{data}(x) + (1-\epsilon)P_{G}(x) }[(\| \nabla_xD(x) \| -1)^2]  \\ G^* &= \mathop{\arg \min}_{G}  -\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)] \end{aligned} $$




**本文目录**：

1. conditional GAN
2. cycleGAN
3. fGAN
4. Least Square GAN (LSGAN)
5. Energy-based GAN (EBGAN)
6.  InfoGAN
7.  VAE-GAN
8.  BiGAN
9.  DCGAN
10. Self-attention GAN (SAGAN)
11. BigGAN
12. SinGAN
13. GauGAN
14. GANILLA
15. NICE-GAN
16. GAN的评估指标
17. LAPGAN
18. StackGAN






# 4. conditional GAN
$GAN$无法控制生成的图像，**conditional GAN**可以生成给定条件的图像。

- **Generator**：在输入随机噪声$z$的同时还输入了条件$c$：

![](https://pic.downk.cc/item/5ebba5c9c2a9a83be51ed12f.jpg)

- **Discriminator**：输入图像和条件，判断图像是否是真实的并且是否与条件匹配：

![](https://pic.downk.cc/item/5ebba610c2a9a83be51f0865.jpg)

也有论文在设计时把判断是否真实和判断条件匹配分开：

![](https://pic.downk.cc/item/5ebba65cc2a9a83be51f6912.jpg)

# 5. cycleGAN
**cycleGAN**可以实现domain迁移，即从一种风格的图像转变成另一种风格的图像。

假设有两类domain的图像$X$和$Y$，给定$X$的图像，希望能转换成$Y$的类型；或给定$Y$的图像转换成$X$的类型。

训练两个**Generator**，$$G_{X→Y}$$实现从类型$X$转换成类型$Y$，$$G_{Y→X}$$实现从类型$Y$转换成类型$X$；

训练两个**Discriminator**，$$D_{X}$$判断图像是否属于类型$X$；$$D_{Y}$$判断图像是否属于类型$Y$；

为保证转换后的图像仍具有转换前的信息，引入**Cycle Consistency Loss**，保持循环转换后的结果尽可能相似：

![](https://pic.downk.cc/item/5ebba8ebc2a9a83be521d466.jpg)

# 6. fGAN
- paper：[f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization](https://arxiv.org/abs/1606.00709v1)

$GAN$的生成器在优化时试图减小$$P_{data}$$和$$P_G$$之间的**KL散度**。

$KL$散度是两个概率分布的不对称性度量，若$P$表示随机变量的真实分布，$Q$表示理论或拟合分布，则$$KL(P \mid\mid Q)$$被称为**前向KL散度（forward KL divergence）**；$$KL(Q \mid\mid P)$$被称为**后向KL散度（backward KL divergence）**，也叫**reverse KL散度**。

前向散度中拟合分布是$KL$散度公式的分母，因此若在随机变量的某个取值范围中，拟合分布的取值趋于$0$，则此时$KL$散度的取值趋于无穷。因此使用前向$KL$散度最小化拟合分布和真实分布的距离时，拟合分布趋向于覆盖理论分布的所有范围。前向KL散度的上述性质被称为“**0避免（zero avoiding）**”。

相反地，当使用后向$KL$散度求解拟合分布时，由于拟合分布是分子，其$0$值不影响$KL$散度的积分，反而是有利的，因此后项$KL$散度是“**0趋近（zero forcing）**”的。

![](https://pic.downk.cc/item/5ebcf68cc2a9a83be53cf38d.jpg)

**KL散度**并不是唯一的选择。一般地，可以优化$$p(x)$$和$$q(x)$之间的$f$**散度**：

$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x)f(\frac{p(x)}{q(x)})dx} $$

函数$f$的性质：
- $$f(1)=0$$：当$$p(x)=q(x)$$时，散度为$0$;
- $f$是凸函数：该性质使散度恒大于等于零，$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x)f(\frac{p(x)}{q(x)})dx} ≥ f(\int_{x}^{} {q(x)\frac{p(x)}{q(x)}dx}) = f(1) = 0 $$

当函数$f$不同时，对应的散度也不同：
- **KL散度**：$$f(x) = xlogx$$

$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x) \frac{p(x)}{q(x)} log(\frac{p(x)}{q(x)})dx} = \int_{x}^{} {p(x) log(\frac{p(x)}{q(x)})dx} $$

- **Reverse KL散度**：$$f(x) = -logx$$

$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x) (-log(\frac{p(x)}{q(x)}))dx} = \int_{x}^{} {q(x) log(\frac{q(x)}{p(x)})dx} $$

- $$\chi^2$$**散度**：$$f(x) = (x-1)^2$$

$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x) (\frac{p(x)}{q(x)}-1)^2dx} = \int_{x}^{} {\frac{(p(x)-q(x))^2}{q(x)}dx} $$

### Fenchel Conjugate
每一个凸函数$f$都有一个共轭函数（conjugate function）$f^*$：

$$ f^*(t) = max_{(x \in dom(f))} \{ xt - f(x) \} $$

![](https://pic.downk.cc/item/5ebcfd25c2a9a83be542cee6.jpg)

$f^*$的性质：
- $f^*$也是凸函数；
- $$(f^*)^*$$=$$f$$

例题：**KL散度**的$$f(x) = xlogx$$对应$$ f^*(t) = e^{t-1} $$

求解下式：

$$ f^*(t) = max_{(x \in dom(f))} \{ xt - xlogx \} $$

令$$\frac{\partial(xt-xlogx)}{\partial x}=0$$得$$t-logx-1=0$$，即$$x=e^{t-1}$$,代入得：

$$ f^*(t) = e^{t-1}t - e^{t-1}(t-1) = e^{t-1} $$

同理$f$可表达为：

$$ f(x) = max_{(t \in dom(f^*))} \{ xt - f^*(t) \} $$

则$f$**散度**可以进行化简：

$$ D_f(P \mid\mid Q) = \int_{x}^{} {q(x)f(\frac{p(x)}{q(x)})dx} \\ = \int_{x}^{} {q(x)(max_{(t \in dom(f^*))} \{ \frac{p(x)}{q(x)} t - f^*(t) \})dx} \\ ≈ max_D \int_{x}^{} {p(x)D(x)dx} - \int_{x}^{} {q(x)f^*(D(x))dx} \\ = max_D \{ E_{x \text{~} P}[D(x)]- E_{x \text{~} Q}[f^*(D(x))] \} $$

其中$$D(x)$$是一个函数，拟合从$x$到$t$的映射。

则网络的生成器优化目标为：

$$ G^* = argmin_G D_f(P_{data} \mid\mid P_G) \\ = argmin_G max_D \{ E_{x \text{~} P}[D(x)]- E_{x \text{~} Q}[f^*(D(x))] \} \\ = argmin_G max_D V(G,D) $$

在实践中可以选择不同的散度：
![](https://pic.downk.cc/item/5ebd05ccc2a9a83be549a221.jpg)

# 7. Least Square GAN (LSGAN)
GAN的优化通常考虑$$P_{data}$$和$$P_G$$之间的散度，但散度并不一定是最好的选择。

在实践中，$$P_{data}$$和$$P_G$$之间几乎没有重叠，原因如下：
1. 这些概率通常是高维空间中的低维流形，重合可以被忽略；
2. 即使两个概率会有重合，由于实践中是对概率进行采样，也很难采集到重合的样本。

对于散度，当两个概率分布没有重合时，无论两个概率分布差距如何，散度的值都是恒定的(如对于JS散度，恒为$log2$)，从而优化的梯度为0，不利于优化。

![](https://pic.downk.cc/item/5ebe8dbbc2a9a83be5d06ebb.jpg)

**LSGAN**对判别器不再使用Sigmoid分类，而是使用线性回归代替：

![](https://pic.downk.cc/item/5ebe8e6cc2a9a83be5d133ab.jpg)


# 9. Energy-based GAN (EBGAN)
**EBGAN**的生成器和之前的GAN类似，判别器用一个自编码器代替：

如果一幅图像经过自编码器可以被很好的还原，则判别器认为其是正样本。用负的重构误差作为判别得分。

![](https://pic.downk.cc/item/5ebe9985c2a9a83be5de5db6.jpg)

- 优点：判别器可以使用实际图像独立训练，不需要借助生成器。

在实践中，通常限制判别器对于正负样本的得分差值不超过$m$:

![](https://pic.downk.cc/item/5ebe9a22c2a9a83be5df14d8.jpg)

# 10. InfoGAN
**conditional GAN**通过输入条件$c$可以生成给定条件的图像。但是如果我们想要改变条件生成不同的图像是非常困难的，因为条件控制的输出空间是不规则的，当我们改变条件中的某一个维度，很难有确切的含义。

**InfoGAN**把生成器的输入$z$拆分成条件$c$和噪声$z'$，通过生成器获得人造样本$x$；

一方面，该样本通过一个分类器解码，用来预测之前输入的条件$c$；

另一方面，该样本通过一个判别器，用来区分是否为人造样本。

分类器和判别器的大部分参数是共享的，只有最后一层不同。

![](https://pic.downk.cc/item/5ed0a85cc2a9a83be56f2e44.jpg)

通过这种方法人为的为条件$c$对样本$x$生成设置确切的影响。

# 11. VAE-GAN
**VAE-GAN**是一种用$GAN$训练$VAE$（或用$VAE$训练$GAN$）的方法。

![](https://pic.downk.cc/item/5ed0ab11c2a9a83be571db25.jpg)

该模型包括编码器、解码器（生成器）、判别器三部分。
- **编码器**：把真实图像编码成正态分布$z$；训练目标：最小化重构误差，最小化$z$与正态分布的散度；
- **解码器（生成器）**：从$z$中抽样生成重构图像；训练目标：最小化重构误差，同时重构图像骗过判别器；
- **判别器**：训练目标：区分真实图像和重构图像。

# 12. BiGAN
**BiGAN**是一种用$GAN$训练自编码器的方法。

![](https://pic.downk.cc/item/5ed0ac9dc2a9a83be573ee7a.jpg)

该模型包括编码器、解码器、判别器三部分。
- **编码器**：把真实图像$x$编码成$z$；
- **解码器**：把$z$解码成重构图像；
- **判别器**：给定图像$x$和编码$z$，区分是编码器还是解码器提供的。

# 14. SAGAN
**SAGAN(self-attention GAN)**是一种应用于图像生成的$GAN$，主要特点有：
- 使用**自注意力（self-attention）**
- 对$G$和$D$都使用**Spectral Norm（SN）**
- 训练$G$和$D$的学习率不相同（**TTUR**）

### （1）self-attention

![](https://pic.downk.cc/item/5ed864eac2a9a83be5b4cee2.jpg)

### （2）Spectral Norm
在$SNGAN$中，**Spectral Norm**被用于判别器$D$；而在$SAGAN$中，**Spectral Norm**同时用于判别器$D$和生成器$G$。

### （3）TTUR
在$SAGAN$的训练中，判别器$D$和生成器$G$的学习率是不平衡的，这种方法被称作**Two-Timescale Update Rule（TTUR）**。
- 判别器$D$的学习率设置为$0.0004$;
- 生成器$G$的学习率设置为$0.0001$.

# 15. BigGAN
**BigGAN**是在$SAGAN$的基础上使用更大的模型。包括：
- 两到四倍的参数量
- 八倍的$batch$ $size$

$BigGAN$还提出了一种**truncation trick**，用于平衡模型生成某一具体的图像或生成不同类型的图像：

具体地，在对噪声采样时进行截断，若噪声$z$的取值范围越小则生成图像越相近；反之生成的图像越丰富：

![](https://pic.downk.cc/item/5ed868d3c2a9a83be5ba48c5.jpg)

# 16. SinGAN
**SinGAN**通过使用**单张**图像来训练$GAN$。

具体的做法是将单张图像进行不同尺度的裁剪，用来生成大量的子图像，

并在每次训练时采用**progressively training**：

![](https://pic.downk.cc/item/5ed86a5ac2a9a83be5bcfa93.jpg)

# 17. GauGAN
**GauGAN**给定一张绘制图像和一张实际图像，希望能够生成具有真实图像风格的绘制图像：

![](https://pic.downk.cc/item/5ed86e88c2a9a83be5c47fae.jpg)

网络结构如下图所示，其主要步骤如下：
1. 对输入的实际图像进行编码，产生均值和方差，用来构建噪声分别；
2. 生成器接收输入的绘制图像和采样噪声，用来生成图像；
3. 判别器判断实际图像与生成图像，以及生成图像是否与绘制图像相似。

![](https://pic.downk.cc/item/5ed86cd4c2a9a83be5c1735e.jpg)

网络还提出了一种新的Normalization方法：**SPADE**，在标准化过程中引入绘制图像：

![](https://pic.downk.cc/item/5ed86c8fc2a9a83be5c0f2eb.jpg)

# 18. GANNILLA
**GANNILLA**实现了图像的**domain transform**，即把一张现实图像转换成具有儿童绘本风格的插图。

该论文提出了一个儿童绘本图像数据集，网络结构如下：

![](https://pic.downk.cc/item/5ed870b3c2a9a83be5c7d6e8.jpg)

该网络加入了一些残差连接、实例标准化和局部级联。

# 19. NICE-GAN
**NICE-GAN**提出了一种不显式的使用生成器的方法，而是使用判别器的前半部分作为生成器：

![](https://pic.downk.cc/item/5ed8710fc2a9a83be5c85b3e.jpg)



# 21. LAPGAN
- LAPGAN：Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks.

在原始 GAN和CGAN中，还只能生成$16×16$,$32×32$这种低像素小尺寸的图片。

而**LAPGAN**首次实现$64×64$的图像生成。采用**coarse-to-fine**的思路，与其一下子生成这么大的（包含信息量这么多），不如一步步由小到大，这样每一步生成的时候，可以基于上一步的结果，而且还只需要“填充”和“补全”新图片所需要的那些信息。

![](https://pic.downk.cc/item/5ee7304bc2a9a83be50d3720.jpg)

# 22. StackGAN
解决文本到图像生成分辨率不高的问题，采用与LAPGAN相似的思路，采用coarse-to-fine的思路，构建两个GAN。
- 第一个GAN用于根据文本描述生成一张低分辨率的图像。
- 第二个GAN将低分辨率图像和文本作为输入，修正之前生成的图像，添加细节纹理，生成高分辨率图像。

![](https://pic.downk.cc/item/5ee7314fc2a9a83be50ed01c.jpg)



# ⚪ 参考文献



- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)：(arXiv1406)GAN的原始论文。
- [From GAN to WGAN](https://lilianweng.github.io/posts/2017-08-20-gan/)：Blog by Lilian Weng.
- [互怼的艺术：从零直达WGAN-GP](https://spaces.ac.cn/archives/4439)：Blog by 苏剑林.
- [The GAN Zoo](https://github.com/AntixK/PyTorch-VAE)：(github)A list of all named GANs!
- [PyTorch-GAN: PyTorch implementations of Generative Adversarial Networks](https://github.com/eriklindernoren/PyTorch-GAN)：(github)GAN的PyTorch实现。
- [<font color=Blue>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</font>](https://0809zheng.github.io/2022/02/05/dcgan.html)：(arXiv1511)DCGAN：使用深度卷积神经网络构造GAN。
- [<font color=Blue>Improved Techniques for Training GANs</font>](https://0809zheng.github.io/2022/02/02/improve.html)：(arXiv1606)训练生成对抗网络的改进技巧。
- [<font color=Blue>Towards Principled Methods for Training Generative Adversarial Networks</font>](https://0809zheng.github.io/2022/02/03/principle.html)：(arXiv1701)训练生成对抗网络的原则性方法。
- [<font color=Blue>Wasserstein GAN</font>](https://0809zheng.github.io/2022/02/04/wgan.html)：(arXiv1701)WGAN：使用Wasserstein距离构造GAN。