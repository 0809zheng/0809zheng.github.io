---
layout: post
title: '图像超分辨率'
date: 2020-08-27
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f47223b160a154a672d2333.jpg'
tags: 深度学习
---

> Image Super Resolution.

**本文目录：**
1. 问题阐述
2. 降级模型
3. 传统方法
4. 深度学习方法
5. 评估指标
6. Benchmarks

# 1. 问题阐述
**图像超分辨率（Super Resolution，SR）**技术是指通过技术手段对图像的分辨率进行放大，从而得到更清晰的图像。

将超分辨率问题看作监督学习任务，将**高分辨率(High Resolution, HR)**图像作为标签$I_y$；将对应的**低分辨率(Low Resolution, LR)**图像作为输入$I_x$。

通过训练模型，学习从**LR**到**HR**的映射$F$。记模型参数为$θ$，则通过模型得到超分辨率图像$\hat{I}_y$：

$$ \hat{I}_y = F(I_x;θ) $$

若记损失函数为$L$，正则化函数为$Φ$，模型的学习目标函数可以表示为：

$$ \hat{θ} = \mathop{\arg \max}_{θ} L(\hat{I}_y,I_y) + λΦ(θ) $$

# 2. 降级模型

通常给定**HR**图像，通过技术手段将其缩小为**LR**图像，这个过程称为**降级(Degradation)**。

记降级模型为$D$，其模型参数为$δ$，则这一过程表示为：

$$ I_x = D(I_y;δ) $$

在实际问题中，对图像降级往往会引入如下问题:
- 压缩失真
- 散焦
- 传感器噪声

![](https://pic.downk.cc/item/5f474976160a154a674c9f8e.jpg)

常用的降级模型包括：
- 简单的下采样：$↓$表示下采样操作，$S$表示下采样倍数

$$ I_x = (I_y)↓_S $$

- 加入模糊和噪声的下采样：$\bigotimes$表示卷积，$k$表示卷积核，$↓$表示下采样操作，$S$表示下采样倍数，$n$表示噪声

$$ I_x = (I_y \bigotimes k)↓_S + n $$

# 3. 传统方法
在深度学习时代之前，图像超分辨率重建技术主要分为三类：
1. 基于插值的方法
2. 基于重建的方法
3. 机器学习的方法

## （1）基于插值的方法
以放大$2$倍为例，将低分辨率图像插值为对应的高分辨率图像：

![](https://pic.downk.cc/item/5f47591f160a154a6750f55a.jpg)

### ⚪最近邻插值 Nearest Neighbor
**最近邻插值**是指高分辨率图像的像素点选择与其坐标位置最近的低分辨率图像像素值，其几何解释如下：

![](https://pic.downk.cc/item/5f475954160a154a67510336.jpg)

如上图**HR**中位置$H5W6$的像素点对应**LR**中位置$H3W3$像素点的右上区域，则该点对应的像素按照最近邻的原则应该取$1$。

### ⚪双线性插值 Bilinear Interpolation
**双线性插值**是指在两个方向分别进行一次线性插值。高分辨率图像的像素点选择与其坐标位置最近的$4$个低分辨率图像像素点的像素值的距离加权平均，其几何解释如下：

![](https://pic.downk.cc/item/5f475966160a154a675108c4.jpg)

如上图**HR**中位置$H5W6$的像素点对应**LR**中位置$H3W3$像素点的右上区域。

距离该点最近的四个**LR**中像素点位置分别是$H2W3$、$H2W4$、$H3W3$、$H3W4$，其距离分别为$A$、$B$、$B$、$C$。

双线性插值的计算过程如下：

![](https://pic.downk.cc/item/5f475fe0160a154a6752d5a7.jpg)

双线性插值的平滑作用可能使得图像的细节产生退化，这种现象在进行图像放大时尤其明显。

### ⚪双三次插值 Bicubic Interpolation
**双三次插值**能创造出比**双线性插值**更平滑的图像边缘。

在二维空间中，函数$f$在点$(x,y)$的值可以通过矩形网格中最近的$16$个采样点的加权平均得到：

![](https://pic.downk.cc/item/5f476276160a154a67539efe.jpg)

![](https://pic.downk.cc/item/5f4762a2160a154a6753acd7.jpg)

其中$W$为插值函数，根据**LR**像素点到**SR**像素点之间的水平距离或垂直距离赋予其不同的权重。

![](https://pic.downk.cc/item/5f4762f6160a154a6753cd13.jpg)

使用`python`实现双三次插值：
```
from PIL import Image
im = Image.open(image_path).convert('RGB')
im = im.resize(new_size, resample=Image.BICUBIC)
```

## （2）基于重建的方法

![](https://pic.downk.cc/item/5f474aac160a154a674d2057.jpg)

## （3）机器学习的方法

![](https://pic.downk.cc/item/5f474ac3160a154a674d28f7.jpg)

# 4. 深度学习方法
使用卷积神经网络进行超分辨率任务的模型根据上采样的位置不同可以划分成：

![](https://pic.downk.cc/item/5f43c9ae160a154a6741a280.jpg)

1. **Predefined upsampling**：首先对图像进行插值上采样（如**Bicubic**），再通过卷积网络增加细节，如SRCNN, VDSR, DRCN；
2. **Single upsampling**：先通过卷积网络提取丰富的特征，再通过单次上采样增加分辨率，如FSRCNN, ESPCN, EDSR；
3. **Progressive upsampling**：通过拉普拉斯金字塔网络逐渐增加分辨率，如LapSRN；
4. **Iterative up and downsampling**：循环地进行上采样和下采样，增加丰富的特征信息，如DBPN。

# 5. 评估指标
图像超分辨率的评估指标分为**客观指标**和**主观指标**。下面介绍一些客观指标。

## （1）峰值信噪比
**峰值信噪比（Peak signal-to-noise ratio，PSNR）**，是衡量图像失真水平的客观标准，评价结果以$dB$（分贝）为单位表示。两个图像间**PSNR**值越大，则越趋于无劣化，劣化程度较大时，**PSNR**值趋于$0dB$。

大小为$m×n$的噪声图像$\hat{I}_y$和干净图像$I_y$的**PSNR**可由其均方误差计算：

$$ MSE = \frac{1}{mn}\sum_{i=1}^{m} {\sum_{i=1}^{n} {(\hat{I}_y-I_y)^2}} $$

$$ PSNR = 10·log_{10}(\frac{L^2}{MSE}) $$

其中$L$为图像像素的取值范围，如浮点型数据$1.0$或**uint8**数据$255$。

上面是针对**灰度**图像的计算方法，如果是**彩色**图像，通常有三种方法来计算。
1. 分别计算**RGB**三个通道的**PSNR**，然后取平均值。
2. 计算**RGB**三通道的**MSE**，然后再除以$3$。
3. 将图片转化为**YCbCr**格式，然后只计算**Y**分量（亮度分量）的**PSNR**。

**PSNR**是最普遍和使用最为广泛的一种图像客观评价指标，然而它是基于对应像素点间的误差，即基于误差敏感的图像质量评价。

其并未考虑到人眼的视觉特性（人眼对空间频率较低的对比差异敏感度较高，人眼对亮度对比差异的敏感度较色度高，人眼对一个区域的感知结果会受到其周围邻近区域的影响等），因而经常出现评价结果与人的主观感觉不一致的情况。

使用`python`实现**PSNR**：

```
import math
import numpy as np
from skimage.measure import compare_psnr

# 方法一
def psnr(img1, img2):
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    img1 = img1.astype(np.float64)
    img2 = img2.astype(np.float64)
    mse = np.mean((img1 - img2)**2)
    if mse == 0:
        return float('inf')
    return 20 * math.log10(255.0 / math.sqrt(mse))
	
# 方法二
def psnr(img1, img2):：
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    return psnr = compare_psnr(img1, img2, data_range=255)
```

## （2）结构相似度
**结构相似度（Structural Similarity，SSIM）**从**亮度 (luminance)**、**对比度 (contrast) **和**结构(structure)**三个角度出发衡量图像之间的差异。

**SSIM**通过图像的均值、方差和协方差计算：

![](https://pic.downk.cc/item/5f47a6ce160a154a6766bf11.jpg)

其中$C_1$、$C_2$、$C_3$是避免分母为零的常数； $α$,$β$,$γ$ 设为 $1$。

使用`python`实现**SSIM**：

```
from skimage.measure import compare_ssim

def ssim(img1, img2):
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    return compare_ssim(img1, img2, data_range=255, multichannel=False)
```

# 6. Benchmarks
常见的图像超分辨率模型包括：
- **Set5**
- **Set14**
- **BSDS100**
- **Urban100**
- **Manga109**
- **DIV2K**
- **Flickr2K**
