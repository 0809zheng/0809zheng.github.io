---
layout: post
title: '图像超分辨率(Super Resolution)'
date: 2020-08-27
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f47223b160a154a672d2333.jpg'
tags: 深度学习
---

> Image Super Resolution.

**本文目录：**
1. 问题阐述
2. 降级模型
3. 传统方法：基于插值的方法、基于重建的方法、机器学习方法
4. 深度学习方法：预定义上采样、单次上采样、渐进上采样、循环采样
5. 评估指标：峰值信噪比**PSNR**、结构相似度**SSIM**
6. Benchmarks

# 1. 问题阐述
**图像超分辨率（Super Resolution，SR）**技术是指通过技术手段对图像的分辨率进行放大，从而得到更清晰的图像。

将超分辨率问题看作监督学习任务，将**高分辨率(High Resolution, HR)**图像作为标签$I_y$；将对应的**低分辨率(Low Resolution, LR)**图像作为输入$I_x$。

通过训练模型，学习从**LR**到**HR**的映射$F(\cdot)$。记模型参数为$θ$，则通过模型得到超分辨率图像$\hat{I}_y$：

$$ \hat{I}_y = F(I_x;θ) $$

若记损失函数为$L(\cdot)$，正则化函数为$\Phi(\cdot)$，模型的学习目标函数可以表示为：

$$ \hat{θ} = \mathop{\arg \max}_{θ} L(\hat{I}_y,I_y) + λΦ(θ) $$

# 2. 降级模型

通常给定**HR**图像，通过技术手段将其缩小为**LR**图像，这个过程称为**降级(Degradation)**。

记降级模型为$D$，其模型参数为$δ$，则这一过程表示为：

$$ I_x = D(I_y;δ) $$

在实际问题中，对图像降级往往会引入压缩失真、散焦、传感器噪声等问题，因此会向图像中加入一些模拟噪声。

![](https://pic.downk.cc/item/5f474976160a154a674c9f8e.jpg)

常用的降级模型包括：
- 简单的下采样：$↓$表示下采样操作，$S$表示下采样倍数

$$ I_x = (I_y)↓_S $$

- 加入模糊和噪声的下采样：$\otimes$表示卷积，$k$表示卷积核，$↓$表示下采样操作，$S$表示下采样倍数，$n$表示噪声

$$ I_x = (I_y \otimes k)↓_S + n $$

# 3. 传统方法
在深度学习时代之前，图像超分辨率重建技术主要分为三类：
1. 基于插值的方法：最邻近插值、双线性插值、双三次插值
2. 基于重建的方法
3. 机器学习的方法

## （1）基于插值的方法
以放大$2$倍为例，将低分辨率图像插值为对应的高分辨率图像：

![](https://pic.downk.cc/item/5f47591f160a154a6750f55a.jpg)

### ⚪最近邻插值 Nearest Neighbor
**最近邻插值**是指高分辨率图像的像素点选择与其坐标位置最近的低分辨率图像像素值，其几何解释如下：

![](https://pic.downk.cc/item/5f475954160a154a67510336.jpg)

如上图**HR**中位置$H5W6$的像素点对应**LR**中位置$H3W3$像素点的右上区域，则该点对应的像素按照最近邻的原则应该取$1$。

### ⚪双线性插值 Bilinear Interpolation
**双线性插值**是指在两个方向分别进行一次线性插值。高分辨率图像的像素点选择与其坐标位置最近的$4$个低分辨率图像像素点的像素值的距离加权平均，其几何解释如下：

![](https://pic.downk.cc/item/5f475966160a154a675108c4.jpg)

如上图**HR**中位置$H5W6$的像素点对应**LR**中位置$H3W3$像素点的右上区域。

距离该点最近的四个**LR**中像素点位置分别是$H2W3$、$H2W4$、$H3W3$、$H3W4$image.png。

双线性插值的计算过程如下：

![](https://pic.imgdb.cn/item/62d9fdb2f54cd3f937b88324.jpg)

双线性插值的平滑作用可能使得图像的细节产生退化，这种现象在进行图像放大时尤其明显。

### ⚪双三次插值 Bicubic Interpolation
**双三次插值**能创造出比**双线性插值**更平滑的图像边缘。

在二维空间中，函数$f$在点$(x,y)$的值可以通过矩形网格中最近的$16$个采样点的加权平均得到：

![](https://pic.imgdb.cn/item/62d9fe0df54cd3f937bab06b.jpg)

![](https://pic.downk.cc/item/5f4762a2160a154a6753acd7.jpg)

其中$W$为插值函数，根据**LR**像素点到**SR**像素点之间的水平距离或垂直距离赋予其不同的权重。

![](https://pic.downk.cc/item/5f4762f6160a154a6753cd13.jpg)

使用`python`实现双三次插值：
```
from PIL import Image
im = Image.open(image_path).convert('RGB')
im = im.resize(new_size, resample=Image.BICUBIC)
```

## （2）基于重建的方法

![](https://pic.downk.cc/item/5f474aac160a154a674d2057.jpg)

## （3）机器学习的方法

![](https://pic.downk.cc/item/5f474ac3160a154a674d28f7.jpg)

# 4. 深度学习方法
使用卷积神经网络进行超分辨率任务的模型根据**上采样的位置**不同可以划分成：

![](https://pic.downk.cc/item/5f43c9ae160a154a6741a280.jpg)

1. **预定义上采样(Predefined upsampling)**：首先对图像应用预定义的插值方法进行上采样（如**Bicubic**），再通过卷积网络增加细节，如[<font color=blue>SRCNN</font>](https://0809zheng.github.io/2020/08/03/srcnn.html), [<font color=blue>VDSR</font>](https://0809zheng.github.io/2020/08/05/vdsr.html)。
2. **单次上采样(Single upsampling)**：先通过卷积网络提取丰富的特征，再通过单次上采样(预定义或可学习)增加分辨率，如[<font color=blue>FSRCNN</font>](https://0809zheng.github.io/2020/08/04/fsrcnn.html), [<font color=blue>ESPCN</font>](https://0809zheng.github.io/2020/08/11/pixelshuffle.html), [<font color=blue>EDSR</font>](https://0809zheng.github.io/2020/08/06/edsr.html), [<font color=blue>RCAN</font>](https://0809zheng.github.io/2020/08/01/rcan.html), [<font color=blue>SAN</font>](https://0809zheng.github.io/2020/08/09/san.html)。
3. **渐进上采样(Progressive upsampling)**：通过多次上采样逐渐增加分辨率，如[<font color=blue>LapSRN</font>](https://0809zheng.github.io/2020/09/07/lapsrn.html)。
4. **循环采样(Iterative up and downsampling)**：循环地进行上采样和下采样，增加丰富的特征信息，如[<font color=blue>DBPN</font>](https://0809zheng.github.io/2020/08/02/dbpn.html), [<font color=blue>DRN</font>](https://0809zheng.github.io/2020/08/17/drn.html)。
5. 其他结构：如[<font color=blue>SRGAN</font>](https://0809zheng.github.io/2020/08/10/srresnet.html), [<font color=blue>ESRGAN</font>](https://0809zheng.github.io/2020/08/12/esrgan.html)引入生成对抗网络；[<font color=blue>LIIF</font>](https://0809zheng.github.io/2020/12/22/liif.html)学习二维图像的连续表达形式。

### ⚪ 参考文献

- [<font color=blue>Image Super-Resolution Using Deep Convolutional Networks</font>](https://0809zheng.github.io/2020/08/03/srcnn.html)：(arXiv1501)SRCNN：图像超分辨率的开山之作。
- [<font color=blue>Accurate Image Super-Resolution Using Very Deep Convolutional Networks</font>](https://0809zheng.github.io/2020/08/05/vdsr.html)：(arXiv1511)VDSR：非常深的超分辨率模型。
- [<font color=blue>Accelerating the Super-Resolution Convolutional Neural Network</font>](https://0809zheng.github.io/2020/08/04/fsrcnn.html)：(arXiv1608)FSRCNN：加速SRCNN模型。
- [<font color=blue>Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network</font>](https://0809zheng.github.io/2020/08/11/pixelshuffle.html)：(arXiv1609)ESPCN：基于PixelShuffle上采样的超分辨率网络。
- [<font color=blue>Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution</font>](https://0809zheng.github.io/2020/09/07/lapsrn.html)：(arXiv1704)LapSRN：多尺度超分辨率的拉普拉斯金字塔网络。
- [<font color=blue>Enhanced Deep Residual Networks for Single Image Super-Resolution</font>](https://0809zheng.github.io/2020/08/06/edsr.html)：(arXiv1707)EDSR：增强的深度超分辨率网络。
- [<font color=blue>Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</font>](https://0809zheng.github.io/2020/08/10/srresnet.html)：(arXiv1719)SRResnet/SRGAN：使用生成对抗网络进行图像超分辨率。
- [<font color=blue>Deep Back-Projection Networks For Super-Resolution</font>](https://0809zheng.github.io/2020/08/02/dbpn.html)：(arXiv1803)DBPN：一种反复下采样与上采样的超分辨率模型。
- [<font color=blue>Image Super-Resolution Using Very Deep Residual Channel Attention Networks</font>](https://0809zheng.github.io/2020/08/01/rcan.html)：(arXiv1807)RCAN：残差通道注意力网络。
- [<font color=blue>ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks</font>](https://0809zheng.github.io/2020/08/12/esrgan.html)：(arXiv1809)ESRGAN：增强的图像超分辨率生成对抗网络。
- [<font color=blue>Second-order Attention Network for Single Image Super-Resolution</font>](https://0809zheng.github.io/2020/08/09/san.html)：(CVPR1906)SAN：超分辨率二阶注意力网络。
- [<font color=blue>Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution</font>](https://0809zheng.github.io/2020/08/17/drn.html)：(arXiv2003)DRN：一种闭环的图像超分辨率模型。
- [<font color=blue>Learning Continuous Image Representation with Local Implicit Image Function</font>](https://0809zheng.github.io/2020/12/22/liif.html)：(arXiv2012)LIIF：学习2D图像的连续表达形式。

# 5. 评估指标
图像超分辨率的评估指标分为**客观指标**和**主观指标**。主观指标通常招募志愿者人为地判断超分图像的质量；下面介绍一些客观指标。

## （1）峰值信噪比 PSNR
**峰值信噪比（Peak signal-to-noise ratio，PSNR）**，是衡量图像失真水平的客观标准，评价结果以$dB$（分贝）为单位表示。两个图像间**PSNR**值越大，则越趋于无劣化，劣化程度较大时，**PSNR**值趋于$0dB$。

大小为$m×n$的噪声图像$\hat{I}_y$和干净图像$I_y$的**PSNR**可由其均方误差计算：

$$ MSE = \frac{1}{mn}\sum_{i=1}^{m} {\sum_{i=1}^{n} {(\hat{I}_y-I_y)^2}} $$

$$ PSNR = 10·\log_{10}(\frac{L^2}{MSE}) $$

其中$L$为图像像素的取值范围，如浮点型数据$1.0$或**uint8**数据$255$。

上面是针对**灰度**图像的计算方法，如果是**彩色**图像，通常有三种方法来计算。
1. 分别计算**RGB**三个通道的**PSNR**，然后取平均值。
2. 计算**RGB**三通道的**MSE**，然后再除以$3$。
3. 将图片转化为**YCbCr**格式，然后只计算**Y**分量（亮度分量）的**PSNR**。

**PSNR**是最普遍和使用最为广泛的一种图像客观评价指标，然而它是基于对应像素点间的误差，即基于误差敏感的图像质量评价。

其并未考虑到人眼的视觉特性（人眼对空间频率较低的对比差异敏感度较高，人眼对亮度对比差异的敏感度较色度高，人眼对一个区域的感知结果会受到其周围邻近区域的影响等），因而经常出现评价结果与人的主观感觉不一致的情况。

使用`python`实现**PSNR**：

```
import math
import numpy as np
from skimage.measure import compare_psnr

# 方法一
def psnr(img1, img2):
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    img1 = img1.astype(np.float64)
    img2 = img2.astype(np.float64)
    mse = np.mean((img1 - img2)**2)
    if mse == 0:
        return float('inf')
    return 20 * math.log10(255.0 / math.sqrt(mse))
	
# 方法二
def psnr(img1, img2):：
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    return psnr = compare_psnr(img1, img2, data_range=255)
```

## （2）结构相似度 SSIM
**结构相似度（Structural Similarity，SSIM）**从**亮度 (luminance)**、**对比度 (contrast) **和**结构(structure)**三个角度出发衡量图像之间的差异。

**SSIM**通过图像的均值、方差和协方差计算：

![](https://pic.downk.cc/item/5f47a6ce160a154a6766bf11.jpg)

其中$C_1$、$C_2$、$C_3$是避免分母为零的常数； $α$,$β$,$γ$ 设为 $1$。

使用`python`实现**SSIM**：

```
from skimage.measure import compare_ssim

def ssim(img1, img2):
    assert img1.dtype == img2.dtype == np.uint8, 'np.uint8 is supposed.'
    return compare_ssim(img1, img2, data_range=255, multichannel=False)
```

# 6. Benchmarks

对于常见的图像超分辨率数据集，通常使用一些大型数据集进行训练，使用一些小型数据集进行测试。

训练集包括：
- [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/)：包含1000张高清图(2K分辨率)及其$2,3,4,8$倍下采样图，其中800张作为训练，100张作为验证，100张作为测试。
- [Flickr2K](http://cv.snu.ac.kr/research/EDSR/Flickr2K.tar)：包含2650张png图像，包含人物、动物、风景；格式与DIV2K相同。

测试集则包括**Set5**、**Set14**、**BSDS100**、**Urban100**、**Manga109**等。

