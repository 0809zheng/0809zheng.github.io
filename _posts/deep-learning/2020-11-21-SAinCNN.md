---
layout: post
title: '卷积神经网络中的自注意力机制(Self-Attention Mechanism)'
date: 2020-11-21
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63b80741be43e0d30edb9553.jpg'
tags: 深度学习
---

> Self-Attention Mechanism in Convolutional Neural Networks.

卷积神经网络中的**自注意力(Self-Attention)**机制表现为**非局部滤波(non-local filtering)**操作，其实现过程与[<font color=Blue>Seq2Seq模型的自注意力机制</font>](https://0809zheng.github.io/2020/04/24/self-attention.html)类似。

标准的卷积层是一种局部滤波操作，其输出特征上的任意位置是由对应输入特征的一个邻域构造的，只能捕捉局部特征之间的关系。而自注意力机制通过计算任意两个位置之间的关系直接捕捉远程依赖，而不用局限于相邻点，相当于构造了一个**和特征图尺寸一样大**的卷积核，从而可以捕捉更多信息。

![](https://pic.imgdb.cn/item/63b808dabe43e0d30edf6519.jpg)

在卷积网络的自注意力机制中，首先构造输入特征$x$的键特征$f(x)$, 查询特征$g(x)$和值特征$h(x)$；然后应用点积注意力构造自注意力特征图：

$$ \alpha_{i} = \text{softmax}\left(f(x_i)^Tg(x_j)\right) =\frac{e^{f(x_i)^Tg(x_j)}}{\sum_j e^{f(x_i)^Tg(x_j)}} $$

在计算输出位置$i$的响应$y_i$时，考虑所有输入值特征$h(x_j)$的加权：

$$ y_i=  \sum_{j}^{} \alpha_{j}h(x_j) =  \sum_{j}^{} \frac{e^{f(x_i)^Tg(x_j)}}{\sum_k e^{f(x_i)^Tg(x_k)}} h(x_j) $$

上式可以被写作更一般的形式：

$$
y_i=\frac{1}{C\left(x_i\right)} \sum_j f\left(x_i, x_j\right) h\left(x_j\right)
$$

其中相似度函数$f(\cdot,\cdot)$计算两个特征位置$x_i,x_j$的相似程度，输出被权重因子$C(x_i)$归一化。注意到当相似度函数取**Embedded Gaussian**函数：

$$
f\left(\mathbf{x}_i, \mathbf{x}_j\right)=e^{\theta\left(\mathbf{x}_i\right)^T \phi\left(\mathbf{x}_j\right)}
$$

此时自注意力机制等价于上述**query-key-value**形式。

![](https://pic.imgdb.cn/item/63b80c02be43e0d30ee766fd.jpg)


自注意力机制的实现可参考：

```python
class SelfAttention(nn.Module):
    def __init__(self, in_channels):
        super(SelfAttention, self).__init__()
        self.f = nn.Conv2d(in_channels, in_channels, 1)
        self.g = nn.Conv2d(in_channels, in_channels, 1)
        self.h = nn.Conv2d(in_channels, in_channels, 1)
        self.o = nn.Conv2d(in_channels, in_channels, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        fx = self.f(x).view(b, c, -1) # [b, c, hw]
        fx = fx.permute(0, 2, 1) # [b, hw, c]
        gx = self.g(x).view(b, c, -1) # [b, c, hw]
        attn = torch.matmul(fx, gx) # [b, hw, hw]
        attn = F.softmax(attn, dim=2) # 按行归一化

        hx = self.h(x).view(b, c, -1) # [b, c, hw]
        hx = hx.permute(0, 2, 1) # [b, hw, c]
        y = torch.matmul(attn, hx) # [b, hw, c]
        y = y.permute(0, 2, 1).contiguous() # [b, c, hw]
        y = y.view(b, c, h, w)
        return self.o(y)
```

卷积神经网络中的自注意力机制包括：
- 增强特征提取能力：**Non-local Net**, **DANet**, **A^2-Net**, **RNL**, **DMSANet**, **SAN**, **PSA**, 
- 降低计算复杂度：**CCNet**, **GCNet**, **EMANet**, **ISANet**, **ANNNet**, **LightNL**, **NLSA**

# （1）增强特征提取能力

## ⚪ [<font color=blue>Non-local Net</font>](https://0809zheng.github.io/2020/11/06/nonlocal.html)

**Non-Local Net**设计了卷积网络中自注意力机制的基本结构。

![](https://pic.imgdb.cn/item/63fc1688f144a010074cf050.jpg)

## ⚪ [<font color=blue>Dual Attention Network (DANet)</font>](https://0809zheng.github.io/2020/11/13/danet.html)

**DANet**设计了**Dual Attention**，同时引入了沿空间维度和和通道维度的自注意力。

![](https://pic.imgdb.cn/item/64099facf144a010078cd559.jpg)

## ⚪ [<font color=blue>Double Attention Network (A^2-Net)</font>](https://0809zheng.github.io/2020/11/25/a2net.html)

$A^2$**-Net**首先使用双线性池化提取特征的一系列描述子，然后使用注意力机制将这些特征描述子分配给特征的每个位置。

![](https://pic.imgdb.cn/item/64352bd60d2dde57778be5d6.jpg)

## ⚪ [<font color=blue>Region-based Non-local (RNL)</font>](https://0809zheng.github.io/2021/10/07/rnl.html)

基于区域的**non-local**计算两个特征位置$x_i,x_j$的相似程度时，不仅仅与这两个点本身有关，还与其周边**region**有关。
$$
y_i=\frac{1}{C\left(x_i\right)} \sum_j f\left( \theta(\mathcal{N}_i),\theta(\mathcal{N}_j)\right) x_j
$$

![](https://pic.imgdb.cn/item/643fad670d2dde5777fa6e62.jpg)


## ⚪ [<font color=blue>Dual Multi Scale Attention Network (DMSANet)</font>](https://0809zheng.github.io/2021/10/03/dmsanet.html)

**DMSANet**首先把特征按通道进行分组，并行地应用空间和特征自注意力机制，再通过注意力机制聚合特征。
 
![](https://pic.imgdb.cn/item/643689320d2dde5777651994.jpg)

## ⚪ [<font color=blue>Self-attention Network (SAN)</font>](https://0809zheng.github.io/2021/10/06/san.html)

作者设计了两种**self-attention**形式：**pairwise self-attention**和**patchwise self-attention**。

$$ \mathbf y_i = \sum\limits_{j\in \mathcal{R}(i)}\alpha(\mathbf x_i,\mathbf x_j) \odot \beta(\mathbf x_j) \\ \mathbf y_i = \sum\limits_{j\in \mathcal{R}(i)}\alpha(\mathbf{x}_{\mathcal{R}_{(i)}})_j \odot \beta(\mathbf x_j) $$

![](https://pic.imgdb.cn/item/643e565d0d2dde577785fd2a.jpg)

## ⚪ [<font color=blue>Polarized Self-Attention (PSA)</font>](https://0809zheng.github.io/2021/10/04/polarized.html)

极化自注意力基于摄影中的极化滤波原理。先在某个方向（通道维度或空间维度）上对特征进行压缩，然后对损失的强度范围进行增强或者抑制。

![](https://pic.imgdb.cn/item/643fa55c0d2dde5777ee0c52.jpg)

# （2）降低计算复杂度

## ⚪ [<font color=blue>Criss-Cross Attention (CCNet)</font>](https://0809zheng.github.io/2020/11/08/ccnet.html)

**CCNet**设计了**Criss-Cross Attention**，计算一个点的横纵位置的**attention**信息，通过串行两个**Criss-Cross attention**模块间接与全图位置内的任意点进行注意力计算。

![](https://pic.imgdb.cn/item/64099a43f144a0100782dc4c.jpg)

## ⚪ [<font color=blue>Global Context Network (GCNet)</font>](https://0809zheng.github.io/2020/11/07/gcnet.html)

**GCNet**设计了**Global Context Block**，通过**query**和**key**权重共享简化了**attention map**的构造，并且引入了通道注意力。

![](https://pic.imgdb.cn/item/63fd6c84f144a010075c40f9.jpg)


## ⚪ [<font color=blue>Expectation-Maximization Attention Network (EMANet)</font>](https://0809zheng.github.io/2020/11/14/emanet.html)

**EMANet**通过期望最大化（**EM**）算法迭代出一组紧凑的基，在这组基上运行注意力机制。

![](https://pic.imgdb.cn/item/640addbef144a010079cef75.jpg)

## ⚪ [<font color=blue>Interlaced Sparse Self-Attention (ISANet)</font>](https://0809zheng.github.io/2020/11/22/isanet.html)

**ISANet**把特征图进行分块，先进行块内的**self attention**计算得到**Long-range**的**attention**；然后进行块之间计算**self attention**得到**Short-range**的**attention**。

![](https://pic.imgdb.cn/item/640c52fff144a0100720a61f.jpg)

## ⚪ [<font color=blue>Asymmetric Non-local Neural Network (ANNNet)</font>](https://0809zheng.github.io/2020/11/15/annnet.html)

**ANNNet**通过**Pyramid Pooling**对**Non-Local**中的**Key**和**Value**进行采样以减少计算量。

![](https://pic.imgdb.cn/item/640c3ab2f144a01007ef66a3.jpg)

## ⚪ [<font color=blue>Lightweight Non-Local Network (LightNL)</font>](https://0809zheng.github.io/2020/11/24/lightnl.html)

**LightNL**是为神经结构搜索设计的轻量级**Non-Local**模块，主要有三点差异：$Q,K,V$的生成去掉了$1\times 1$卷积、输出卷积替换为深度卷积、使用更小的特征图计算相关性。

![](https://pic.imgdb.cn/item/6433eb340d2dde5777fb6a43.jpg)



## ⚪ [<font color=blue>Non-Local Sparse Attention (NLSA)</font>](https://0809zheng.github.io/2021/10/05/nlsa.html)

**NLSA**通过局部敏感哈希构造**attention bucket**，只对同一个**attention bucket**内的特征进行自注意力计算。

![](https://pic.imgdb.cn/item/643d1bdc0d2dde57773338ab.jpg)

## ⭐ 参考文献
- [<font color=blue>Non-local Neural Networks</font>](https://0809zheng.github.io/2020/11/06/nonlocal.html)：(arXiv1711)非局部神经网络。
- [<font color=blue>Dual Attention Network for Scene Segmentation</font>](https://0809zheng.github.io/2020/11/13/danet.html)：(arXiv1809)场景分割的对偶注意力网络。
- [<font color=blue>A^2-Nets: Double Attention Networks</font>](https://0809zheng.github.io/2020/11/25/a2net.html)：(arXiv1810)A^2-Net：双重注意力网络。
- [<font color=blue>CCNet: Criss-Cross Attention for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/08/ccnet.html)：(arXiv1811)CCNet：语义分割中的交叉注意力机制。
- [<font color=blue>GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</font>](https://0809zheng.github.io/2020/11/07/gcnet.html)：(arXiv1904)GCNet：结合非局部神经网络和通道注意力。
- [<font color=blue>Expectation-Maximization Attention Networks for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/14/emanet.html)：(arXiv1907)EMANet: 语义分割的期望最大化注意力网络。
- [<font color=blue>Interlaced Sparse Self-Attention for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/22/isanet.html)：(arXiv1907)ISANet：语义分割的交错稀疏自注意力网络。
- [<font color=blue>Asymmetric Non-local Neural Networks for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/15/annnet.html)：(arXiv1908)ANNNet：语义分割的非对称非局部神经网络。
- [<font color=blue>Neural Architecture Search for Lightweight Non-Local Networks</font>](https://0809zheng.github.io/2020/11/24/lightnl.html)：(arXiv2004)轻量级非局部网络的神经结构搜索。
- [<font color=blue>Exploring Self-attention for Image Recognition</font>](https://0809zheng.github.io/2021/10/06/san.html)：(arXiv2004)探索图像识别的自注意力机制。
- [<font color=blue>Region-based Non-local Operation for Video Classification</font>](https://0809zheng.github.io/2021/10/07/rnl.html)：(arXiv2007)为视频分类设计的基于区域的非局部网络。
- [<font color=blue>DMSANet: Dual Multi Scale Attention Network</font>](https://0809zheng.github.io/2021/10/03/dmsanet.html)：(arXiv2106)DMSANet: 对偶多尺度注意力网络。
- [<font color=blue>Polarized Self-Attention: Towards High-quality Pixel-wise Regression</font>](https://0809zheng.github.io/2021/10/04/polarized.html)：(arXiv2107)极化自注意力: 面向高质量像素级回归。
- [<font color=blue>Image Super-Resolution with Non-Local Sparse Attention</font>](https://0809zheng.github.io/2021/10/05/nlsa.html)：(CVPR2021)通过非局部稀疏注意力实现图像超分辨率。
