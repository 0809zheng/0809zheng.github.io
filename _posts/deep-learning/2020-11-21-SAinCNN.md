---
layout: post
title: '卷积神经网络中的自注意力机制(Self-Attention Mechanism)'
date: 2020-11-21
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63b80741be43e0d30edb9553.jpg'
tags: 深度学习
---

> Self-Attention Mechanism in Convolutional Neural Networks.

卷积神经网络中的**自注意力(Self-Attention)**机制表现为**非局部滤波(non-local filtering)**操作，其实现过程与[<font color=Blue>Seq2Seq模型的自注意力机制</font>](https://0809zheng.github.io/2020/04/24/self-attention.html)类似。

标准的卷积层是一种局部滤波操作，其输出特征上的任意位置是由对应输入特征的一个邻域构造的，只能捕捉局部特征之间的关系。而自注意力机制通过计算任意两个位置之间的关系直接捕捉远程依赖，而不用局限于相邻点，相当于构造了一个**和特征图尺寸一样大**的卷积核，从而可以捕捉更多信息。

![](https://pic.imgdb.cn/item/63b808dabe43e0d30edf6519.jpg)

在卷积网络的自注意力机制中，首先构造输入特征$x$的键特征$f(x)$, 查询特征$g(x)$和值特征$h(x)$；然后应用点积注意力构造自注意力特征图：

$$ \alpha_{i} = \text{softmax}\left(f(x_i)^Tg(x_j)\right) =\frac{e^{f(x_i)^Tg(x_j)}}{\sum_j e^{f(x_i)^Tg(x_j)}} $$

在计算输出位置$i$的响应$y_i$时，考虑所有输入值特征$h(x_j)$的加权：

$$ y_i=  \sum_{j}^{} \alpha_{j}h(x_j) =  \sum_{j}^{} \frac{e^{f(x_i)^Tg(x_j)}}{\sum_k e^{f(x_i)^Tg(x_k)}} h(x_j) $$

上式可以被写作更一般的形式：

$$
y_i=\frac{1}{C\left(x_i\right)} \sum_j f\left(x_i, x_j\right) h\left(x_j\right)
$$

其中相似度函数$f(\cdot,\cdot)$计算两个特征位置$x_i,x_j$的相似程度，输出被权重因子$C(x_i)$归一化。注意到当相似度函数取**Embedded Gaussian**函数：

$$
f\left(\mathbf{x}_i, \mathbf{x}_j\right)=e^{\theta\left(\mathbf{x}_i\right)^T \phi\left(\mathbf{x}_j\right)}
$$

此时自注意力机制等价于上述**query-key-value**形式。

![](https://pic.imgdb.cn/item/63b80c02be43e0d30ee766fd.jpg)


自注意力机制的实现可参考：

```python
class SelfAttention(nn.Module):
    def __init__(self, in_channels, k=8):
        super(SelfAttention, self).__init__()
        self.f = nn.Conv2d(in_channels, in_channels, 1)
        self.g = nn.Conv2d(in_channels, in_channels, 1)
        self.h = nn.Conv2d(in_channels, in_channels, 1)
        self.o = nn.Conv2d(in_channels, in_channels, 1)

    def forward(self, x):
        b, c, h, w = x.shape
        fx = self.f(x).view(b, c, -1) # [b, c, hw]
        fx = fx.permute(0, 2, 1) # [b, hw, c]
        gx = self.g(x).view(b, c, -1) # [b, c, hw]
        attn = torch.matmul(fx, gx) # [b, hw, hw]
        attn = F.softmax(attn, dim=2) # 按行归一化

        hx = self.h(x).view(b, c, -1) # [b, c, hw]
        hx = hx.permute(0, 2, 1) # [b, hw, c]
        y = torch.matmul(attn, hx) # [b, hw, c]
        y = y.permute(0, 2, 1).contiguous() # [b, c, hw]
        y = y.view(b, c, h, w)
        return self.o(y)
```

值得一提的是，大多数自注意力机制方法起初都是为[图像分割网络](https://0809zheng.github.io/2020/05/07/semantic-segmentation.html#2-%E5%9F%BA%E4%BA%8E%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%A8%A1%E5%9E%8B)设计的。这些方法通过自注意力机制的全局交互性来捕获视觉场景中的全局依赖，并以此构造上下文模块，从而从图像中提取多尺度特征用于分割预测。向卷积神经网络中引入自注意力机制的方法包括**Non-Local Net**。

## ⚪ [<font color=blue>Non-local Net</font>](https://0809zheng.github.io/2020/11/06/nonlocal.html)

**Non-Local Net**设计了卷积网络中自注意力机制的基本结构。

![](https://pic.imgdb.cn/item/63fc1688f144a010074cf050.jpg)

## ⚪ [<font color=blue>Dual Attention Network (DANet)</font>](https://0809zheng.github.io/2020/11/13/danet.html)

**DANet**设计了**Dual Attention**，同时引入了沿空间维度和和通道维度的自注意力。

![](https://pic.imgdb.cn/item/64099facf144a010078cd559.jpg)

## ⚪ [<font color=blue>Double Attention Network (A^2-Net)</font>](https://0809zheng.github.io/2020/11/25/a2net.html)

$A^2$**-Net**首先使用双线性池化提取特征的一系列描述子，然后使用注意力机制将这些特征描述子分配给特征的每个位置。

![](https://pic.imgdb.cn/item/64352bd60d2dde57778be5d6.jpg)

## ⚪ [<font color=blue>Criss-Cross Attention (CCNet)</font>](https://0809zheng.github.io/2020/11/08/ccnet.html)

**CCNet**设计了**Criss-Cross Attention**，计算一个点的横纵位置的**attention**信息，通过串行两个**Criss-Cross attention**模块间接与全图位置内的任意点进行注意力计算。

![](https://pic.imgdb.cn/item/64099a43f144a0100782dc4c.jpg)

## ⚪ [<font color=blue>Global Context Network (GCNet)</font>](https://0809zheng.github.io/2020/11/07/gcnet.html)

**GCNet**设计了**Global Context Block**，通过**query**和**key**权重共享简化了**attention map**的构造，并且引入了通道注意力。

![](https://pic.imgdb.cn/item/63fd6c84f144a010075c40f9.jpg)


## ⚪ [<font color=blue>Expectation-Maximization Attention Network (EMANet)</font>](https://0809zheng.github.io/2020/11/14/emanet.html)

**EMANet**通过期望最大化（**EM**）算法迭代出一组紧凑的基，在这组基上运行注意力机制。

![](https://pic.imgdb.cn/item/640addbef144a010079cef75.jpg)

## ⚪ [<font color=blue>Interlaced Sparse Self-Attention (ISANet)</font>](https://0809zheng.github.io/2020/11/22/isanet.html)

**ISANet**把特征图进行分块，先进行块内的**self attention**计算得到**Long-range**的**attention**；然后进行块之间计算**self attention**得到**Short-range**的**attention**。

![](https://pic.imgdb.cn/item/640c52fff144a0100720a61f.jpg)

## ⚪ [<font color=blue>Asymmetric Non-local Neural Network (ANNNet)</font>](https://0809zheng.github.io/2020/11/15/annnet.html)

**ANNNet**通过**Pyramid Pooling**对**Non-Local**中的**Key**和**Value**进行采样以减少计算量。

![](https://pic.imgdb.cn/item/640c3ab2f144a01007ef66a3.jpg)

## ⚪ [<font color=blue>Lightweight Non-Local Network (LightNL)</font>](https://0809zheng.github.io/2020/11/24/lightnl.html)

**LightNL**是为神经结构搜索设计的轻量级**Non-Local**模块，主要有三点差异：$Q,K,V$的生成去掉了$1\times 1$卷积、输出卷积替换为深度卷积、使用更小的特征图计算相关性。

![](https://pic.imgdb.cn/item/6433eb340d2dde5777fb6a43.jpg)

## ⚪ [<font color=blue>Dual Multi Scale Attention Network (DMSANet)</font>](https://0809zheng.github.io/2021/10/03/dmsanet.html)

**DMSANet**首先把特征按通道进行分组，并行地应用空间和特征自注意力机制，再通过注意力机制聚合特征。

![](https://pic.imgdb.cn/item/643689320d2dde5777651994.jpg)



## ⭐ 参考文献
- [<font color=blue>Non-local Neural Networks</font>](https://0809zheng.github.io/2020/11/06/nonlocal.html)：(arXiv1711)非局部神经网络。
- [<font color=blue>Dual Attention Network for Scene Segmentation</font>](https://0809zheng.github.io/2020/11/13/danet.html)：(arXiv1809)场景分割的对偶注意力网络。
- [<font color=blue>A^2-Nets: Double Attention Networks</font>](https://0809zheng.github.io/2020/11/25/a2net.html)：(arXiv1810)A^2-Net：双重注意力网络。
- [<font color=blue>CCNet: Criss-Cross Attention for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/08/ccnet.html)：(arXiv1811)CCNet：语义分割中的交叉注意力机制。
- [<font color=blue>GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond</font>](https://0809zheng.github.io/2020/11/07/gcnet.html)：(arXiv1904)GCNet：结合非局部神经网络和通道注意力。
- [<font color=blue>Expectation-Maximization Attention Networks for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/14/emanet.html)：(arXiv1907)EMANet: 语义分割的期望最大化注意力网络。
- [<font color=blue>Interlaced Sparse Self-Attention for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/22/isanet.html)：(arXiv1907)ISANet：语义分割的交错稀疏自注意力网络
- [<font color=blue>Asymmetric Non-local Neural Networks for Semantic Segmentation</font>](https://0809zheng.github.io/2020/11/15/annnet.html)：(arXiv1908)ANNNet：语义分割的非对称非局部神经网络。
- [<font color=blue>Neural Architecture Search for Lightweight Non-Local Networks</font>](https://0809zheng.github.io/2020/11/24/lightnl.html)：(arXiv2004)轻量级非局部网络的神经结构搜索。
- [<font color=blue>DMSANet: Dual Multi Scale Attention Network</font>](https://0809zheng.github.io/2021/10/03/dmsanet.html)：(arXiv2106)DMSANet: 对偶多尺度注意力网络。
