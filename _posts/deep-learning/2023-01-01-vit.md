---
layout: post
title: '视觉Transformer(Vision Transformer)'
date: 2023-01-01
author: 郑之杰
cover: ''
tags: 深度学习
---

> Vision Transformer.

[<font color=blue>Transformer</font>](https://0809zheng.github.io/2020/04/25/transformer.html)是基于**自注意力机制(self-attention mechanism)**的深度神经网络，该模型在$2017$年$6$月被提出，并逐渐在自然语言处理任务上取得最好的性能。

![](https://pic.downk.cc/item/5fe9916d3ffa7d37b3c174be.jpg)

**Transformer**最近被扩展到计算机视觉任务上，并在这些任务上表现出比**CNN**等更具有竞争力的结果。按照应用场合对视觉**Transformer**进行分类，包括：
- 图像分类：
- 下游任务：



# 1. 图像分类

### ⚪ [<font color=Blue>ViT</font>](https://0809zheng.github.io/2020/12/30/vit.html)

在**ViT**中，输入图像被划分为一系列图像块(**patch**)；使用嵌入层把每个图像块编码为序列向量，再使用**Transformer**的编码器进行特征提取。**Transformer**采用**pre-norm**的形式。

![](https://pic.imgdb.cn/item/63f48f89f144a0100755912f.jpg)

### ⚪ [<font color=Blue>SimpleViT</font>](https://0809zheng.github.io/2023/01/02/simplevit.html)

**SimpleViT**对**ViT**模型结构进行如下改动：位置编码采用**sincos2d**；分类特征采用全局平均池化；分类头采用单层线性层；移除了**Dropout**。在训练方面采用**RandAug**和**MixUP**数据增强，训练**batch size**采用$1024$。

### ⚪ [<font color=Blue>DeiT</font>](https://0809zheng.github.io/2023/01/03/deit.html)

**DeiT**在输入图像块序列尾部添加了一个蒸馏**token**，蒸馏**token**的输出特征以教师网络输出作为目标进行学习。蒸馏方式包括硬蒸馏(通过交叉熵学习教师网络决策结果)和软蒸馏(通过**KL**散度学习教师网络预测概率)。

![](https://pic.imgdb.cn/item/63f6c8f2f144a01007973b06.jpg)


## ⚪ 视觉Transformer

- [Image Transformer](https://0809zheng.github.io/2021/02/04/it.html)：(arXiv1802)基于Transformer的图像生成自回归模型。



- [On the Relationship between Self-Attention and Convolutional Layers](https://0809zheng.github.io/2021/01/04/SAandConv.html)：(arXiv1911)理解自注意力和卷积层的关系。

- [Generative Pretraining from Pixels](https://0809zheng.github.io/2020/12/29/igpt.html)：(ICML2020)iGPT：像素级的图像预训练模型。

- [DETR：End-to-End Object Detection with Transformers](https://0809zheng.github.io/2020/06/20/detr.html)：(arXiv2005)DETR：使用Transformer进行目标检测。

- [Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://0809zheng.github.io/2020/12/31/ddetr.html)：(arXiv2010)Deformable DETR：使用多尺度可变形的注意力模块进行目标检测。



- [Pre-Trained Image Processing Transformer](https://0809zheng.github.io/2021/02/09/ipt.html)：(arXiv2012)IPT：使用Transformer解决超分辨率、去噪和去雨等底层视觉任务。



- [Bottleneck Transformers for Visual Recognition](https://0809zheng.github.io/2021/01/31/botnet.html)：(arXiv2101)BotNet：CNN与Transformer结合的backbone。

- [TransGAN: Two Transformers Can Make One Strong GAN](https://0809zheng.github.io/2021/03/02/transgan.html)：(arXiv2102)TransGAN：用Transformer实现GAN。

- [Transformer in Transformer](https://0809zheng.github.io/2021/03/08/tnt.html)：(arXiv2103)TNT：对图像块与图像像素同时建模的Transformer。

- [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://0809zheng.github.io/2021/12/10/swint.html)：(arXiv2103)Swin Transformer: 基于移动窗口的分层视觉Transformer。



# ⚪ 参考文献
- [vit-pytorch](https://github.com/lucidrains/vit-pytorch)：(github) Implementation of Vision Transformer in Pytorch。
- [<font color=Blue>A Survey on Visual Transformer</font>](https://0809zheng.github.io/2021/02/10/visual-transformer.html)：(arXiv2012)一篇关于视觉Transformer的综述。
- [<font color=Blue>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</font>](https://0809zheng.github.io/2020/12/30/vit.html)：(arXiv2010)ViT：使用图像块序列的Transformer进行图像分类。
- [<font color=Blue>Training data-efficient image transformers & distillation through attention</font>](https://0809zheng.github.io/2023/01/03/deit.html)：(arXiv2012)DeiT：通过注意力蒸馏训练数据高效的视觉Transformer。
- [<font color=Blue>Better plain ViT baselines for ImageNet-1k</font>](https://0809zheng.github.io/2023/01/02/simplevit.html)：(arXiv2205)在ImageNet-1k数据集上更好地训练视觉Transformer。

