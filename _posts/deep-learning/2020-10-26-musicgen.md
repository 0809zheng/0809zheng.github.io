---
layout: post
title: '音乐生成'
date: 2020-10-26
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f96a5481cd1bbb86bd97f47.jpg'
tags: 深度学习
---

> Music Generation.

在计算机出现之前，人类历史上第一个通过算法生成音乐的例子是莫扎特的**Dice Music**，首先像掷骰子一样随机选择一些预定的音乐片段，然后根据一定的风格连接片段构成音乐作品。

基于深度学习的音乐生成技术对音乐相关的专业知识没有过高的要求，而是利用数据驱动的方法，从音乐语料库中自动学习音乐的结构和风格，然后从学习到的分布中生成音乐样本。

本文目录：
1. 基础乐理
2. 音乐的表示
3. 音乐生成模型

# 1. 基础乐理
- **音符(Note)**：音符是组成音乐的基本单元；
- **小节(Bar)**：小节是包含特定节拍（音符）数的一小段时间，小节的边界由垂直的线条$\|$组成；
- **音阶(Scale)**：音阶是音符的子集，常用的音阶有四种类型：**Major(Minor)（大调(小调)）**、**Harmonic Minor（和声小调）**、**Melodic Minor（旋律小调）**和**Blues（蓝调）**。每种音阶类型都指定相对于起始音符起作用的一系列相对间隔（或移位）。如大调的顺序为$2→2→1→2→2→2→1$。因此**C Major**将起始音符指定为**C**并应用相对移位序列产生：$C2-→D2-→E1-→F2-→G2-→A2-→B1-→C$，其指定的音符子集为**C,D,E,F,G,A**和**B**（七个音符的子集）。除蓝调有六个音符外，所有音阶类型都有七个音符的子集。音阶总计$48$种，即四种类型和$12$种可能的起始音符。
- **和弦(Chord)**：和弦是一组动听的音符。类似于音阶，和弦也有起始音符和定义一组音程的类型。**三重和弦（triad chords）**主要有六种：**大和弦 Major Chord**, **小和弦 Minor Chord**, **增强和弦 Augmented Chord**, **减和弦 Diminished Chord**, **暂停的第二和弦 Suspended 2nd Chord**和**暂停的第四和弦 Suspended 4th Chord**.
- **五度圈(Circle of Fifths)**：五度圈用于产生和弦。它将$12$个和弦的起始音符映射到一个圆上。从一个和弦更改为另一个和弦时，通常首选移到圆上最近的和弦，从而产生和谐感。
- **十二平均律(12-tone)**：音乐通常遵守十二平均律，即$12$是所有音符的循环长度。

# 2. 音乐的表示
音乐的表示形式有**音频（Audio）**与**符号（Symbolic）**两种，分别对应于连续变量和离散变量。

### （1）Audio
基于**Audio**的音乐表示主要有**信号波（Signal Waveform）**和**频谱（Spectrum）**，这种音乐表示形式保留了完整的原始声音信息，但是对计算资源的消耗比较大，处理起来比较费时。

### （2）Symbolic
基于**Symbolic**的音乐表示主要有**MIDI**、**Piano Roll**和**文本表示（Text）**。
- **MIDI（Musical Instrument Digital Interface）**是一种技术标准协议，用于实现各种电子乐器、软件和设备之间的交互。**MIDI**使用两种**事件（Event）**消息：**音符开（Note On）**和**音符关（Note Off）**分别表示所演奏音符的开始和结束。**MIDI**使用$0$到$127$之间的整数作为**音符编号（Note Number）**来表示音符音高。每个音符**事件（Note Event）**都嵌入到一个包含**delta-time**值数据结构中，该值可以是相对时间或是绝对时间。
- **Piano Roll**是一个二维表，**x**轴表示连续的时间步长，**y**轴表示音调，表中**（x,y）**激活就表示在**x**时间点处音调**y**是激活的。该表示没有**note off**信号，无法区分长音符和重复的短音符，针对这一问题，一些框架中引入了额外的符号辅助表示。
- **文本**表示的一个代表性的例子是**ABC notion**，它是民间和传统音乐的标准。每个音符编码作为一个**token**，英文字母和数字表示音调及其持续时间，每个小节同样由$\|$分隔。

# 3. 音乐生成模型
- 一篇关于深度学习中的音乐生成模型综述：[From Artificial Neural Networks to Deep Learning for Music Generation -- History, Concepts and Trends](https://arxiv.org/abs/2004.03586)

按照模型使用的基本结构不同，可将音乐生成模型划分为以**Recurrent**、**Convolutional**、**Transformer**、**VAE**和**GAN**为基础的模型。

## （1）Recurrent模型

### ⚪A Recurrent Neural Network Music Generation Tutorial
- 首个使用**LSTM**生成**MIDI**形式的音乐。

### ⚪Song From PI: A Musically Plausible Network for Pop Music Generation
- 可以生成多音轨（**multi-track**）的流行音乐。

### ⚪DeepBach: a Steerable Model for Bach Chorales Generation
- 生成巴赫风格的四声部合唱。

## （2）Convolutional模型

### ⚪Counterpoint by Convolution
- 根据固定的规则将一段或几段旋律结合起来。

## （3）Transformer模型

### ⚪Music Transformer: Generating Music with Long-Term Structure
- 降低**Transformer**的时间复杂度，从而实现更长序列的音乐生成。

### ⚪MuseNet 

## （4）VAE模型

### ⚪A Hierarchical Latent Vector Model for Learning Long-Term Structure in Music
- 重建出与输入“相同”的音乐。

### ⚪MidiMe: Personalizing a MusicVAE model with user data
- **MidiMe**是**MusicVAE**的一个扩展应用，目的是生成与输入“类似”但又不同的音乐。

## （5）GAN模型

### ⚪C-RNN-GAN: Continuous recurrent neural networks with adversarial training
- 以噪声为输入生成**MIDI**形式的古典音乐。

### ⚪MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation
- 可以生成任意小节的MIDI音乐。