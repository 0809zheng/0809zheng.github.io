---
layout: post
title: '卷积神经网络(Convolutional Neural Network)'
date: 2020-03-06
author: 郑之杰
cover: 'http://static.zybuluo.com/csr/8t6t63353hg9ejy3mgjhx8qa/image.png'
tags: 深度学习
---

> Convolutional Neural Networks.

**卷积神经网络(Convolutional Neural Networks, CNN)**是一种为计算机视觉任务设计的深度网络，其结构设计灵感来自[Hubel和Wiesel的工作](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf)，因此在很大程度上遵循了灵长类动物视觉皮层的基本结构。

卷积神经网络的学习过程与灵长类动物的视觉皮层腹侧通路(**V1-V2-V4-IT/VTC**)非常相似。灵长类动物的视觉皮层首先从视网膜位区域接收输入，在该区域通过外侧膝状核执行多尺度高通滤波和对比度归一化。然后通过分类为**V1**,**V2**,**V3**和**V4**的视觉皮层的不同区域执行检测。实际上视觉皮层的**V1**和**V2**部分类似于卷积层和下采样层，而颞下区类似于更深的层，最终对图像进行推断。

![](https://pic.imgdb.cn/item/63a9813e08b6830163f8ed7b.jpg)

典型的卷积神经网络结构如图所示，通常是由卷积层、激活函数和池化层堆叠构成，用于从图像中自适应地提取**特征图(feature map)**，并进一步用于下游任务中。其中[<font color=blue>激活函数</font>](https://0809zheng.github.io/2020/03/01/activation.html)用于增强网络的非线性表示能力，[<font color=blue>池化层</font>](https://0809zheng.github.io/2021/07/02/pool.html)用于特征的空间尺寸下采样。本文主要介绍卷积神经网络中的卷积层。

![](https://pic.downk.cc/item/5ea54956c2a9a83be5d81c10.jpg)

# 1. 卷积神经网络中的卷积层

**卷积层(convolutional layer)**的目的是从输入图像中提取对下游任务有用的特征。卷积层的基本单位是**卷积核(kernel)**，也叫**滤波器(filter)**。

在传统图像处理方法中，图像滤波器算子通常是人工设计的，比如通过高斯滤波器可以进行噪声过滤，通过**Sobel**算子进行轮廓提取等等。而卷积层中的滤波器参数是从数据集中学习得到的，可以根据下游任务自适应地学习到最合适的参数。

卷积神经网络中的卷积层实际上是一种局部的**互相关(Cross-Correlation)**操作，相对于数学定义的卷积缺少对卷积核进行翻转的步骤。而翻转是为了使卷积运算满足**可交换性**，由于卷积层的参数是自动学习的，(如果需要)也可以学习到翻转的参数，因此没有必要显式地进行翻转。

## (1) 卷积层的计算

卷积层是一种局部操作，下面以二维卷积为例。假设输入图像(或特征图) $X\in \Bbb{R}^{H \times W \times C}$，其中$H,W$是图像的高度和宽度，$C$是图像的**通道(channel)**数（对于输入图像指代颜色通道，对于特征图指代深度）。

对于一个卷积核$K \in \Bbb{R}^{f \times f \times C}$，在图像上按照**光栅扫描顺序(raster scanning order)**滑动。当滑动到空间点$(i,j)$时，该点的输出值通过局部仿射变换计算：

$$ y_{i,j} = \sum_{c=1}^C \sum_{x \in \delta_X} \sum_{y \in \delta_Y} w_{x,y,c} \cdot x_{i+x,j+y,c} + b $$

其中$\delta_X = [-\lfloor\frac{f}{2}\rfloor,...,\lfloor\frac{f}{2}\rfloor]$,$\delta_Y = [-\lfloor\frac{f}{2}\rfloor,...,\lfloor\frac{f}{2}\rfloor]$。因此一个卷积核共有$f \times f \times C+1$个参数(权重+偏置)。

![](https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210930_10ebde22-21d5-11ec-ae67-00163e068ecd.png)

卷积层还具有**步长(stride)**参数和**填充(padding)**参数。步长是指卷积核在图像上进行一次滑动时所移动的像素数量，步长$s>1$会导致特征图的空间尺寸变小；填充参数是指在图像的四周填充像素，具有三种模式：
- **full**：对图像四周填充像素直至卷积核滑动的初始位置恰好与原图像相交，此时输出特征的空间尺寸变大；
- **same**：对图像四周填充像素直至卷积核滑动的初始中心位置恰好与原图像相交，此时卷积层不改变特征的空间尺寸；
- **valid**：不填充像素，此时输出特征的空间尺寸变小。

![](https://pic.downk.cc/item/5ea53ccdc2a9a83be5cc6a45.jpg)

若输入图像尺寸为$n\times n\times c$，使用卷积核的尺寸为$f\times f\times c$，步长为$s$，填充为$p$，则单个卷积核对应的输出特征的尺寸是：

$$ \lfloor \frac{n+2p-f}{s}\rfloor +1 \times  \lfloor\frac{n+2p-f}{s}\rfloor +1 $$

通常认为一个卷积核只捕捉输入图像中的一种特定的局部特征。因此通过使用多个卷积核提取包含不同语义信息的特征，其中每个卷积核对应输出特征的一个通道。

可以通过[torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)在**Pytorch**中定义二维卷积层：

```python
conv_layer = torch.nn.Conv2d(
    in_channels,  # 输入图像/特征的通道数量
    out_channels, # 输出特征的通道数量(所使用的卷积核数量)
    kernel_size,  # 卷积核的空间尺寸
    stride=1, padding=0, # 步长和填充参数
    dilation=1, groups=1, # 实现空洞卷积和组卷积
    bias=True, # 是否使用偏置项
    padding_mode='zeros', # 填充模式，可选'zeros', 'reflect', 'replicate', 'circular'
    device=None, dtype=None)
```

## (2) 卷积层的特点

### ⚪ 局部连接 (local connection)

[**全连接神经网络**](https://0809zheng.github.io/2020/04/17/feedforward-neural-network.html)中的神经元与上一层的所有神经元连接，参数量较大；而卷积层的输出特征中的每一个元素都只和上一层特征对应位置的局部邻域内的元素相连，构成一个局部连接网络。

![](https://pic.imgdb.cn/item/63a986e508b6830163023d27.jpg)

### ⚪ 参数共享 (parameter sharing)

参数共享是指卷积层的每一个卷积核在特征的不同位置上是共享参数的。参数共享能够进一步减少卷积层的参数量，此时每一个卷积核可以提取具有某种固定模式的特征(比如水平线段或竖直线段)，通过使用复数个卷积核能够提取不同语义信息的特征。

### ⚪ 平移等变性 (translation equivariance)

平移变换是指把一幅图像或一个空间中的每一个点沿相同方向移动相同的距离。平移等变性是指对输入进行平移变换时，系统在不同位置的工作原理相同，但它的响应随着目标位置的变化而变化。对于卷积层，输入图像经过平移后，输出特征图上的对应特征表达也是平移的。

![](https://pic.imgdb.cn/item/63a9a04d08b68301632d9c79.jpg)

进一步地，如果卷积层之后应用池化层、全连接层等结构，则整个网络具有**平移不变性(translation invariance)**。此时无论目标出现在图像中的哪个位置，它都会检测到相同的特征，输出同样的响应。

## (3) 卷积层的感受野

卷积层的特征提取能力可以用**感受野(receptive field)**衡量。感受野定义为每一层输出特征上的像素点对应输入图像上的区域大小。第$n$层卷积层的感受野计算为第$n$层输出特征图中的一个像素对应输入图像的像素数。

令网络第$n$层卷积层的卷积核大小为$f_n$，步长参数为$s_n$。则第$n$层卷积层的感受野$RF_n$可以递归地计算为：

$$ RF_n = RF_{n-1} + (f_{n}-1)*\prod_{i=1}^{n-1} {s_i} $$

第$n$层特征的每个像素对应第$n-1$层特征的$f_n$个像素，其中一个像素具有相对于输入图像的感受野$RF_{n-1}$，其余每个像素使得第$n-1$层感受野相对于第$n-2$层增大了$s_{n-1}$，递归地等价于相对于输入图像增大了$\prod_{i=1}^{n-1} {s_i}$。

下面给出了一个应用步长为$2$的$3 \times 3$卷积层堆叠两层的感受野情况。则第一层卷积层具有$3 \times 3$的感受野；第二层卷积层相对于第一层卷积层具有$3 \times 3$的感受野，相对于输入图像扩展了$(3-1)*2$个像素。

![](https://pic.imgdb.cn/item/63aab85908b6830163a259f8.jpg)

在构建卷积神经网络时，通常采用更小的卷积层堆叠更多层数来实现较大的感受野，以减少网络参数量。比如两层$3\times3$的卷积层和一层$5\times5$的卷积层具有相同的感受野，但前者的参数量更小（$2*3^2<5^2$）：

![](https://pic.imgdb.cn/item/63aab7ee08b6830163a18892.jpg)


# 2. 不同类型的卷积层

## (1) 

### (3)空洞卷积
**空洞卷积（Atrous Convolution）**，也称为**膨胀/扩张卷积（Dilated Convolution）**,不增加参数数量，增加输出单元感受野。

引入**膨胀/扩张率(Dilation Rate)**$D$，给卷积核插入“空洞”：

![](https://pic.downk.cc/item/5ea55491c2a9a83be5e1a595.jpg)

对于相同尺寸的输出特征，空洞卷积具有更大的感受野：

![](https://pic.downk.cc/item/5ebce737c2a9a83be52e30af.jpg)

### (4)转置卷积
**转置卷积（Transposed Convolution）**,也叫**反卷积（Deconvolution）**。

卷积操作实现高维特征到低维特征的转换，转置卷积将低维特征映射到高维特征。

转置卷积只需要先进行零填充再卷积：

![](https://pic.downk.cc/item/5ea5530bc2a9a83be5e0888f.jpg)

若输入图像尺寸为$c×n×n$，使用卷积核的尺寸为$c'×f×f$，步长为$s$，填充为$p$，则输出的尺寸是：

$$ c' × ((n-1) \times s - 2 \times p + f) × ((n-1) \times s - 2 \times p + f) $$

### (5)微步卷积
**微步卷积（Fractionally-Strided Convolution）**通过减少转置卷积的步长$s<1$来实现上采样操作，大幅提高特征维数。

可以在输入特征之间插入0来间接地使得步长变小:

![](https://pic.downk.cc/item/5ea553c0c2a9a83be5e1061b.jpg)

### (6)深度可分离卷积
**深度可分离卷积(Depthwise Separable Convolution)**先做Depthwise卷积，再做Pointwise卷积，实现空间维（卷积核大小）和通道维（特征图）的分离。

**Depthwise**在每个channel进行卷积操作：
![](https://pic.downk.cc/item/5ea55621c2a9a83be5e2d2a2.jpg)

**Pointwise**使用$1×1$卷积：
![](https://pic.downk.cc/item/5ea5563cc2a9a83be5e2e99b.jpg)


- [Involution: Inverting the Inherence of Convolution for Visual Recognition](https://0809zheng.github.io/2021/03/12/involution.html)：(arXiv2103)Involution：空间独立通道共享的卷积核。
- [Integrating Circle Kernels into Convolutional Neural Networks](https://0809zheng.github.io/2021/08/02/circle.html)：(arXiv2107)卷积神经网络中的圆形卷积核。 