---
layout: post
title: '变分自编码器'
date: 2022-04-01
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fb715b8b18d627113d7ae88.jpg'
tags: 深度学习
---

> Variational Autoencoder.

- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)

本文目录：
1. 建模**VAE**
2. **VAE**的优化目标与重参数化
3. 模型实现




# 1. 建模VAE
**变分自编码器(Variational Autoencoder,VAE)**是一种深度生成模型，旨在学习已有数据集$$\{x_1,x_2,...,x_n\}$$的概率分布$p(x)$，并从数据分布中采样生成新的数据$\hat{x}~p(x)$。由于已有数据(也称**观测数据, observed data**)的概率分布形式是未知的，**VAE**把输入数据编码到**隐空间(latent space)**中，构造**隐变量(latent variable)**的概率分布$p(z)$，从隐变量中采样并重构新的数据，整个过程与自编码器类似。**VAE**的概率模型如下：

$$ p(x) = \sum_{z}^{} p(x,z) = \sum_{z}^{}p(x|z)p(z) $$

如果人为指定隐变量的概率分布$p(z)$形式，则可以从中采样并通过解码器$p(x \| z)$(通常用神经网络拟合)生成新的数据。然而注意到此时隐变量的概率分布$p(z)$与输入数据无关，即给定一个输入数据$x_n$，从$p(z)$随机采样并重构为$\hat{x}_n$，将无法保证$x_n$与$\hat{x}_n$的对应性！此时生成模型常用的优化指标$Distance(x_n,\hat{x}_n)$也无法使用。

在**VAE**中并不是**直接指定**隐变量的概率分布$p(z)$形式，而是为每个输入数据$x_n$指定一个**后验分布**$q(z \| x_n)$(通常为标准正态分布)，则从该后验分布中采样并重构的$\hat{x}_n$对应于$x_n$。**VAE**指定后验分布$q(z \| x_n)$为标准正态分布$$\mathcal{N}(0,I)$$，则隐变量分布$p(z)$实际上也会是标准正态分布$$\mathcal{N}(0,I)$$：

$$ p(z) = \sum_{x}^{} q(z|x)p(x) = \sum_{x}^{} \mathcal{N}(0,I)p(x)= \mathcal{N}(0,I)\sum_{x}^{} p(x)= \mathcal{N}(0,I) $$

**VAE**使用编码器(通常用神经网络)拟合后验分布$q(z \| x_n)$的均值$\mu_n$和方差$\sigma_n^2$(其数量由每批次样本量决定)，通过训练使其接近标准正态分布$$\mathcal{N}(0,I)$$。实际上后验分布不可能**完全精确**地被拟合为标准正态分布，因为这样会使得$q(z \| x_n)$完全独立于输入数据$x_n$，从而使得重构效果极差。**VAE**的训练过程中隐含地存在着**对抗**的过程，最终使得$q(z \| x_n)$保留一定的输入数据$x_n$信息，并且对输入数据也具有一定的重构效果。

**VAE**的整体结构如下图所示。从给定数据中学习后验分布$q(z \| x)$的均值$\mu_n$和方差$\sigma_n^2$的过程称为**推断(inference)**，实现该过程的结构被称作**概率编码器(probabilistic encoder)**。从后验分布的采样结果中重构数据的过程$p(x \| z)$称为**生成(generation)**，实现该过程的结构被称作**概率解码器(probabilistic decoder)**。

![](https://pic.imgdb.cn/item/626b9206239250f7c5a98639.jpg)

### ⚪讨论：后验分布可以选取其他分布吗？

理论上，后验分布$q(z \| x_n)$可以选取任意可行的概率分布形式。然而从后续讨论中会发现对后验分布的约束是通过**KL**散度实现的，**KL**散度对于概率为$0$的点会发散，选择概率密度全局非负的标准正态分布$$\mathcal{N}(0,I)$$不会出现这种问题，且具有可以计算梯度的简洁的解析解。此外，由于服从正态分布的独立随机变量的和仍然是正态分布，因此隐空间中任意两点间的线性插值也是有意义的，并且可以通过线性插值获得一系列生成结果的展示。

### ⚪讨论：VAE的Bayesian解释

自编码器**AE**将观测数据$x$编码为特征向量$z$，每一个特征向量对应特征空间中的一个离散点，所有特征向量的分布是无序、散乱的，并且无法保证不存在特征向量的空间点能够重构出真实样本。**VAE**是**AE**的**Bayesian**形式，将特征向量看作随机变量，使其能够覆盖特征空间中的一片区域。进一步通过强迫所有数据的特征向量服从多维正态分布，从而解耦特征维度，使得特征的空间分布有序、规整。



# 2. VAE的优化目标与重参数化
**VAE**是一种隐变量模型$p(x,z)$，其优化目标为最大化观测数据的对数似然$\log p(x)=\log \sum_{z}^{} p(x,z)$。该问题是不可解的，因此采用[变分推断](https://0809zheng.github.io/2020/03/25/variational-inference.html)求解。变分推断的核心思想是引入一个新的分布$q(z \| x)$作为后验分布$p(z \| x)$的近似，从而构造对数似然$\log p(x)$的置信下界**ELBO**，通过最大化**ELBO**来代替最大化$\log p(x)$。采用[Jensen不等式]()可以快速推导**ELBO**的表达式：

$$ \log p(x) = \log \sum_{z}^{} p(x,z) = \log \sum_{z}^{} \frac{p(x,z)}{q(z|x)}q(z|x) \\ = \log \Bbb{E}_{z ~ q(z|x)}[\frac{p(x,z)}{q(z|x)}] \geq \Bbb{E}_{z ~ q(z|x)}[\log \frac{p(x,z)}{q(z|x)}] $$

在**VAE**中，最大化**ELBO**等价于最小化损失函数：

$$ \mathcal{L}  = -\mathbb{E}_{z \text{~} q(z|x)} [\log \frac{p(x,z)}{q(z|x)}] = -\mathbb{E}_{z \text{~} q(z|x)} [\log \frac{p(x|z)p(z)}{q(z|x)}] \\ = -\mathbb{E}_{z \text{~} q(z|x)} [\log p(x | z)] - \mathbb{E}_{z \text{~}q(z|x)} [\log \frac{p(z)}{q(z|x)}] \\ = \mathbb{E}_{z \text{~} q(z|x)} [-\log p(x | z)] + KL[q(z|x)||p(z)] $$

直观上损失函数可以分成两部分：其中$\mathbb{E}_{z \text{~} q(z\|x)} [-\log p(x \| z)]$表示生成模型$p(x\|z)$的重构损失，$KL[q(z\|x)\|\|p(z)]$表示后验分布$q(z\|x)$的**KL**损失。这两个损失并不是独立的，因为重构损失很小表明$p(x\|z)$置信度较大，即解码器重构比较准确，则编码器$q(z\|x)$不会太随机(即应和$x$相关性较高)，此时**KL**损失不会小；另一方面**KL**损失很小表明编码器$q(z\|x)$随机性较高(即和$x$无关)，此时重构损失不可能小。因此**VAE**的损失隐含着对抗的过程，在优化过程中总损失减小才对应模型的收敛。下面分别讨论这两种损失的具体形式。

## (1) 后验分布$q(z\|x)$的KL损失

损失$KL[q(z\|x)\|\|p(z)]$衡量后验分布$q(z\|x)$和先验分布$p(z)$之间的KL散度。$q(z\|x)$优化的目标是趋近标准正态分布，此时$p(z)$指定为标准正态分布$$z~\mathcal{N}(0,I)$$。$q(z\|x)$通过神经网络进行拟合(即概率编码器)，其形式人为指定为**多维对角正态分布**$$\mathcal{N}(\mu,\sigma^{2})$$。

由于两个分布都是正态分布，**KL**散度有闭式解(**closed-form solution**)，计算如下：

$$ KL[q(z|x)||p(z)] = KL[\mathcal{N}(\mu,\sigma^{2})||\mathcal{N}(0,1)]  \\ = \int_{}^{} \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \log \frac{\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}}{\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}} dx  \\= \int_{}^{} \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} [-\frac{1}{2}\log \sigma^2 + \frac{x^2}{2}-\frac{(x-\mu)^2}{2\sigma^2}] dx \\ = \frac{1}{2}  (-\log \sigma^2 + \mu^2+\sigma^2-1) $$

在实际实现时拟合$\log \sigma^2$而不是$\sigma^2$，因为$\sigma^2$总是非负的，需要增加激活函数进行限制；而$\log \sigma^2$的取值是任意的。**KL**损失的**Pytorch**实现如下：

```python
kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)
```


## (2) 生成模型$p(x\|z)$的重构损失

重构损失$\mathbb{E}_{z \text{~} q(z\|x)} [-\log p(x \| z)]$表示把观测数据映射到隐空间后再重构为原数据的过程。其中生成模型$p(x\|z)$也是通过神经网络进行拟合的(即概率解码器)，根据所处理数据的类型不同，$p(x\|z)$选择不同的分布形式。

### ⚪二值数据：伯努利分布
如果观测数据$x$为二值数据（如二值图像），则生成模型$p(x\|z)$建模为伯努利分布：

$$ p(x|z)= \begin{cases} \rho(z) , & x=1 \\ 1-\rho(z), & x=0 \end{cases} = (\rho(z))^{x}(1-\rho(z))^{1-x} $$

使用神经网络拟合参数$\rho$：

$$ \rho = \mathop{\arg \max}_{\rho} \log p(x|z) = \mathop{\arg \min}_{\rho} -x\log \rho(z)-(1-x)\log(1-\rho(z)) $$

上式表示交叉熵损失函数，且$\rho(z)$需要经过**sigmoid**等函数压缩到$[0,1]$。

### ⚪一般数据：正态分布

对于一般的观测数据$x$，将生成模型$p(x\|z)$建模为具有固定方差$\sigma^2_0$的正态分布：

$$ p(x|z) = \frac{1}{\sqrt{2\pi\sigma_0^2}}e^{-\frac{(x-\mu)^2}{2\sigma_0^2}} $$

使用神经网络拟合参数$\mu$：

$$ \mu = \mathop{\arg \max}_{\mu} \log p(x|z) = \mathop{\arg \min}_{\mu} \frac{(x-\mu)^2}{2\sigma_0^2} $$

上式表示**均方误差(MSE)**表示，**Pytorch**实现如下：

```python
recons_loss = F.mse_loss(recons, input, reduction = 'sum')
```

注意`reduction`参数可选`'sum'`和`'mean'`，应该使用`'sum'`，这使得损失函数计算与原式保持一致。笔者在实现时曾选用`'mean'`，导致即使训练损失有下降，也只能生成噪声图片，推测是因为取平均使重构损失误差占比过小，无法正常训练。


## (3) 重参数化技巧
**VAE**的损失函数如下：

$$ \mathcal{L} = \mathbb{E}_{z \text{~} q(z|x)} [-\log p(x | z)] + KL[q(z|x)||p(z)] $$

其中期望$$\mathbb{E}_{z \text{~} q(z|x)} [\cdot]$$表示从从$q(z\|x)$中采样$z$的过程。由于采样过程是不可导的，不能直接参与梯度传播，因此引入**重参数化(reparameterization)**技巧。

已经假设$z~q(z\|x)$服从$$\mathcal{N}(\mu,\sigma^{2})$$，则$\epsilon=\frac{z-\mu}{\sigma}$服从标准正态分布$$\mathcal{N}(0,I)$$。因此有如下关系：

$$ z = \mu + \sigma \cdot \epsilon $$

则从$$\mathcal{N}(0,I)$$中采样$\epsilon$，再经过参数变换构造$z$，可使得采样操作不用参与梯度下降，从而实现模型端到端的训练。

![](https://pic.imgdb.cn/item/627a22c909475431292e6d8d.jpg)

在实现时对于每个样本只进行一次采样，采样的充分性是通过足够多的批量样本与训练轮数来保证的。则损失函数也可写作：

$$ \mathcal{L} =  -\log p(x | z) + KL[q(z|x)||p(z)], \quad z \text{~} q(z|x)$$

重参数化技巧的**Pytorch**实现如下：

```python
def reparameterize(mu, log_var):
    std = torch.exp(0.5 * log_var)
    eps = torch.randn_like(std)
    return mu + eps * std
```