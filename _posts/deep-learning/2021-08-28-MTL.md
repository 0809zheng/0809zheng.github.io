---
layout: post
title: '多任务学习'
date: 2021-08-28
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/612ca4ee44eaada739024c7c.jpg'
tags: 深度学习
---

> Multi Task Learning.


本文目录：
1. 多任务学习的定义及特点
2. 多任务学习的网络结构
3. 多任务学习的损失函数

# 1. 多任务学习的定义及特点
**多任务学习**(**multi-task learning,MTL**)是指同时学习多个属于不同领域(**domain**)的任务，并通过特定任务的领域信息提高泛化能力。

**MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks**.

多任务学习的**特点**如下：
- 同时学习多个任务，若某个任务中包含对另一个任务有用的信息，则能够提高在后者上的表现；
- 具有正则化的效果，即模型不仅需要在一个任务上表现较好，还需要再别的任务上表现好；相当于引入了归纳偏置(**inductive bias**)，即倾向于学习到在多个任务上表现都比较好的特征；
- 模型可以共享部分结构，降低内存占用(**memory footprint**)，减少重复计算，提高推理速度。

通常**MTL**处理的任务应具有一定的关联性。若同时学习两个不相关甚至有冲突的任务，可能会损害模型的表现，这个现象称为**negative transfer**。

与标准的单任务学习相比，多任务学习的方法设计可以分别从**网络结构**与**损失函数**两个角度出发。

# 2. 多任务学习的网络结构

一个高效的多任务网络，应同时兼顾特征共享部分和任务特定部分，既需要学习任务之间的泛化表示(避免过拟合)，又需要学习每个任务独有的特征(避免欠拟合)。

根据模型在处理不同任务时网络参数的共享程度，**MTL**方法的网络结构可分为：
- **硬参数共享 (Hard Parameter Sharing)**：模型的主体部分共享参数，尾部输出任务独立。
- **软参数共享 (Soft Parameter Sharing)**：不同任务采用独立模型，模型参数彼此约束。

![](https://pic.imgdb.cn/item/62dbe42df54cd3f937f34a2a.jpg)

## (1) 硬参数共享 Hard Parameter Sharing

**Hard Parameter Sharing**是指模型在处理不同任务时，其主体部分共享参数，针对不同任务使用不同的输出结构。这类方法通过在不同任务上学习共享的特征，降低模型在单个任务上过拟合的风险。

### ⚪ [<font color=Blue>Multi-Task Attention Network</font>](https://0809zheng.github.io/2021/09/06/dwa.html)：使用注意力机制设置提取特征

![](https://pic.imgdb.cn/item/6132d2ef44eaada739241dd0.jpg)

## (2) 软参数共享 Soft Parameter Sharing


**Soft Parameter Sharing**是指针对每个任务使用具有独立参数的模型，对不同任务的模型参数进行额外的距离约束。这类方法通常能够在单个任务上实现更好的表现，但模型参数与任务数量呈倍数增长。




# 3. 多任务学习的损失函数

多任务学习将多个相关的任务共同训练，其总损失函数是每个任务的损失函数的加权求和式：$\mathcal{L}_{total} = \sum_{k}^{} w_k\mathcal{L}_k$。权重的选择应能够平衡每个任务的训练，使得各任务都获得有益的提升。

## (1) 如何设置权重

多任务学习的主要工作是寻找一个尽可能与每个任务的梯度都反向的方向作为更新方向


### ⚪ 如何设置权重

## (2) 权重的自动选择

多任务学习需要设计合理的损失函数$\mathcal{L}_{total} = \sum_{k}^{} w_k\mathcal{L}_k$，对每个任务的损失进行权重分配。如何自动进行权重选择，避免网络过于关注某任务是十分重要的。下面介绍一些权重自动选择方法：


| 方法 | 权重 | 辅助参数 |
| :---: | :---:  | :---:  |
| [<font color=Blue>Uncertainty</font>](https://0809zheng.github.io/2021/09/05/uncertainty.html)：根据**同方差不确定度**设置权重 | $$\sum_{k=1}^{K}\frac{1}{2\sigma_k^2}\mathcal{L}_k(\theta)+\log \sigma_k$$ | - |
| [<font color=Blue>Gradient Normalization</font>](https://0809zheng.github.io/2021/09/08/gradnorm.html)：根据**梯度量级**和**训练速度**更新权重 | $$w_k^{(t+1)}  \gets w_k^{(t)}-\lambda \nabla_{w_k}\mathcal{L}_{\text{grad}}$$ | $$\begin{aligned}  \mathcal{L}_{\text{grad}}(t;w_k^{(t)}) &= \sum_{k=1}^{K} \| G_k^{(t)}-\overline{G}^{(t)} \times [r_k^{(t)}]^{\alpha} \|_1 \\ G_k^{(t)} = \|\|\nabla_{\theta}w_k^{(t)}\mathcal{L}_k\|\|_2 ,&\overline{G}^{(t)} = \Bbb{E}_k[ G_k^{(t)}], r_k^{(t)} = \frac{\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}}{\Bbb{E}_k[\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}]} \end{aligned}$$ |
| [<font color=Blue>Dynamic Weight Average</font>](https://0809zheng.github.io/2021/09/06/dwa.html)：根据**损失相对下降率**设置权重 | $$w_k^{(t)} = \frac{K \exp(r_k^{(t-1)}/T)}{\sum_{i}^{}\exp(r_i^{(t-1)}/T)}$$ | $$r_k^{(t-1)}=\frac{\mathcal{L}_k^{(t-1)}}{\mathcal{L}_k^{(t-2)}}$$ |
| [<font color=Blue>Multi-Objective Optimization</font>](https://0809zheng.github.io/2021/09/25/pareto.html)：通过**Frank-Wolfe**算法求**帕累托最优解** | $$w_k^{(t+1)} = (1-\gamma)w_k^{(t)}+\gamma e_{\tau}$$ | $$\begin{aligned} \tau &= \mathop{\arg \min}_k \langle \nabla_{\theta} \mathcal{L}_k,\sum_k w_k^{(t)}\mathcal{L}_k \rangle \\ \gamma &=  \mathop{\arg \min}_{\gamma} \sum_k((1-\gamma)w_k^{(t)}+\gamma e_{\tau} )\mathcal{L}_k  \end{aligned}$$ |
| [<font color=Blue>Dynamic Task Prioritization</font>](https://0809zheng.github.io/2021/10/09/dtp.html)：根据**动态任务优先级**设置权重 | $$w_k^{(t)} =  -(1-\overline{\kappa}_k^{(t)})^{\gamma_t} \log(\overline{\kappa}_k^{(t)})$$ | $$\overline{\kappa}_k^{(t)} = \alpha * \kappa_k^{(t)} + (1-\alpha) * \overline{\kappa}_k^{(t-1)}$$ |
| [<font color=Blue>Loss-Balanced Task Weighting</font>](https://0809zheng.github.io/2021/09/07/lbtw.html)：根据**损失变化**设置权重 | $$w_k^{(t)} = (\frac{\mathcal{L}_k^{(t)}}{\mathcal{L}_k^{(0)}})^{\alpha}$$ | - |


- [<font color=Blue>Uncertainty</font>](https://0809zheng.github.io/2021/09/05/uncertainty.html)：根据**同方差不确定度**设置权重

$$ \mathcal{L}(\theta,\sigma_1,...,\sigma_K) = \sum_{k=1}^{K}\frac{1}{2\sigma_k^2}\mathcal{L}_k(\theta)+\log \sigma_k $$

- [<font color=Blue>Gradient Normalization</font>](https://0809zheng.github.io/2021/09/08/gradnorm.html)：根据**梯度量级**和**训练速度**更新权重
  
$$ \begin{aligned}  w_k^{(t+1)} & \gets w_k^{(t)}-\lambda \nabla_{w_k}\mathcal{L}_{\text{grad}} \\ \mathcal{L}_{\text{grad}}(t;w_k^{(t)}) &= \sum_{k=1}^{K} | G_k^{(t)}-\overline{G}^{(t)} \times [r_k^{(t)}]^{\alpha} |_1 \\ G_k^{(t)} = ||\nabla_{\theta}w_k^{(t)}\mathcal{L}_k||_2 ,&\overline{G}^{(t)} = \Bbb{E}_k[ G_k^{(t)}], r_k^{(t)} = \frac{\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}}{\Bbb{E}_k[\mathcal{L}_k^{(t)}/\mathcal{L}_k^{(0)}]} \end{aligned} $$

- [<font color=Blue>Dynamic Weight Average</font>](https://0809zheng.github.io/2021/09/06/dwa.html)：根据**损失相对下降率**设置权重

$$ w_k^{(t)} = \frac{K \exp(r_k^{(t-1)}/T)}{\sum_{i}^{}\exp(r_i^{(t-1)}/T)},r_k^{(t-1)}=\frac{\mathcal{L}_k^{(t-1)}}{\mathcal{L}_k^{(t-2)}} $$


- [<font color=Blue>Multi-Objective Optimization</font>](https://0809zheng.github.io/2021/09/25/pareto.html)：通过**Frank-Wolfe**算法求**帕累托最优解**

$$ \begin{aligned} w_k^{(t+1)} &= (1-\gamma)w_k^{(t)}+\gamma e_{\tau} \\  \tau &= \mathop{\arg \min}_k \langle \nabla_{\theta} \mathcal{L}_k,\sum_k w_k^{(t)}\mathcal{L}_k \rangle \\ \gamma &=  \mathop{\arg \min}_{\gamma} \sum_k((1-\gamma)w_k^{(t)}+\gamma e_{\tau} )\mathcal{L}_k  \end{aligned} $$

- [<font color=Blue>Dynamic Task Prioritization</font>](https://0809zheng.github.io/2021/10/09/dtp.html)：根据**动态任务优先级**设置权重

$$ \begin{aligned} w_k^{(t)} &=  -(1-\overline{\kappa}_k^{(t)})^{\gamma_t} \log(\overline{\kappa}_k^{(t)})  \\ \overline{\kappa}_k^{(t)} &= \alpha * \kappa_k^{(t)} + (1-\alpha) * \overline{\kappa}_k^{(t-1)} \end{aligned} $$

- [<font color=Blue>Loss-Balanced Task Weighting</font>](https://0809zheng.github.io/2021/09/07/lbtw.html)：根据**损失变化**设置权重

$$ w_k^{(t)} = (\frac{\mathcal{L}_k^{(t)}}{\mathcal{L}_k^{(0)}})^{\alpha} $$


# ⚪ 参考文献
- [An Overview of Multi-Task Learning in Deep Neural Networks](https://arxiv.org/abs/1706.05098)
- [A Survey on Multi-Task Learning](https://arxiv.org/abs/1707.08114)
- [Multi-Task Learning for Dense Prediction Tasks: A Survey](https://arxiv.org/abs/2004.13379)
- [Multi-Task Learning with Deep Neural Networks: A Survey](https://arxiv.org/abs/2009.09796)
- [<font color=Blue>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</font>](https://0809zheng.github.io/2021/09/05/uncertainty.html)：(arXiv1705)使用同方差不确定性调整多任务损失权重。
- [<font color=Blue>GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</font>](https://0809zheng.github.io/2021/09/08/gradnorm.html)：(arXiv1711)GradNorm: 使用梯度标准化调整多任务损失权重。
- [<font color=Blue>End-to-End Multi-Task Learning with Attention</font>](https://0809zheng.github.io/2021/09/06/dwa.html)：(arXiv1803)多任务注意力网络与动态权重平均。
- [<font color=Blue>Multi-Task Learning as Multi-Objective Optimization</font>](https://0809zheng.github.io/2021/09/25/pareto.html)：(arXiv1810)把多任务学习建模为多目标优化问题。
- [<font color=Blue>Dynamic Task Prioritization for Multitask Learning</font>](https://0809zheng.github.io/2021/10/09/dtp.html)：(ECCV2018)多任务学习中的动态任务优先级。
- [<font color=Blue>Loss-Balanced Task Weighting to Reduce Negative Transfer in Multi-Task Learning</font>](https://0809zheng.github.io/2021/09/07/lbtw.html)：(AAAI2019)通过损失平衡任务加权解决多任务学习中的负迁移。

