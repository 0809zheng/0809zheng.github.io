---
layout: post
title: 'YOLOv4'
date: 2020-04-26
author: 郑之杰
cover: 'https://pic.downk.cc/item/5ea3eea1c2a9a83be5996f6b.jpg'
tags: 目标检测
---

> Notes about YOLOv4.

- paper：YOLOv4: Optimal Speed and Accuracy of Object Detection
- arXiv：[https://arxiv.org/abs/2004.10934v1](https://arxiv.org/abs/2004.10934v1)

目录：
1. Related work
2. Methodology

# 1. Related work

## (1)Object detection models
![](https://pic.downk.cc/item/5ea3dd27c2a9a83be5823a71.jpg)

一个典型的目标检测模型包含以下part：

### **1.Input**
- Image
- Patches
- Image Pyramid

### **2.Backbones**
- **GPU platform**：VGG、ResNet、ResNeXt、DenseNet、DetNet、DetNAS
- **CPU platform**：SqueezeNet、MobileNet、 ShuffleNet
- **new whole model**：SpineNet、HitDetector

### **3.Neck**
Collect feature maps from different stages.

- **Additional blocks**：SPP、ASPP、RFB、SAM
- **Path-aggregation blocks**：FPN、PAN、NAS-FPN、Fully-connected FPN、BiFPN、ASFF、SFAM

### **4.Heads**
- **one-stage（Dense Prediction）**

**anchor-base**：RPN、YOLO、SSD、RetinaNet

**anchor-free**：CenterNet、CornerNet、 MatrixNet、FCOS

- **two-stage（Sparse Prediction）**

**anchor-base**：R-CNN、faster R-CNN、R-FCN、Libra R-CNN、Mask R-CNN

**anchor-free**：RepPoints

## (2)Bag of freebies
Methods that only change the training strategy or only increase the training cost.

### 1.data augmentation
Increase the variability of the input images, model has higher robustness to images obtained from different environments.

**i. pixel-wise adjustments**

- **photometric distortion**：brightness、contrast、hue、saturation、noise
- **geometric distortions**：random scaling、cropping、flipping、rotating

**ii. simulating object occlusion**

- **To images**：random erase、CutOut、hide-and-seek、grid mask
- **To feature maps**：DropOut、DropConnect、DropBlock、Spatial DropOut

**iii. using multiple images together**

-  MixUp、CutMix

**iv. others**

- style transfer GAN

### 2.data imbalance
**semantic distribution bias**：the semantic distribution in the dataset has bias.

- one-stage：focal loss
- two-stage：hard negative example mining、 online hard example mining

### 3.representation scheme

- label smoothing、label refinement network

### 4.objective function of BBox regression

- **Mean Square Error**

1. traditional：$$\{x_{center},y_{center},w,h\}$$、$$\{x_{top-left},y_{top-left},x_{bottom-right},y_{bottom-right}\}$$
2. anchor-based method：$$\{x_{center-offset},y_{center-offset},w_{offset},h_{offset}\}$$、$$\{x_{top-left-offset},y_{top-left-offset},x_{bottom-right-offset},y_{bottom-right-offset}\}$$

- **IoU loss**、**GIoU loss**、**DIoU loss**、**CIoU loss**

## (3)Bag of specials
Only increase the inference cost by a small amount but can significantly improve the accuracy.

### 1.enhance receptive field

- SPP、ASPP、RFB

### 2.introducing attention mechanism

- **channel-wise attention**：Squeeze-and-Excitation
- **point-wise attention**： Spatial Attention Module

### 3.strengthening feature integration capability
Integrate low-level physical feature to high-level semantic feature.

- early practice：skip connection、hyper-column
- integrate different feature pyramid：SFAM、ASFF、BiFPN

### 4.activation function
A good activation function can make the gradient more efficiently propagated, and not cause too much extra computational cost.

- ReLU、LReLU、PReLU
- designed for quantization networks：ReLU6、hard-Swish
- self-normalizing a neural network：SELU
- continuously differentiable activation function：Swish、Mish

### 5.post-processing method

- NMS、soft NMS、DIoU NMS


# 2. Methodology

## YOLOv4 consists of:

- **Backbone**: CSPDarknet53
- **Neck**: SPP, PANet
- **Head**: YOLOv3

## YOLOv4 uses:

- **Bag of Freebies (BoF) for backbone**:
1. CutMix and Mosaic data augmentation
2. DropBlock regularization
3. Class label smoothing
- **Bag of Specials (BoS) for backbone**:
1. Mish activation
2. Cross-stage partial connections
3. Multi-input weighted residual connections
- **Bag of Freebies (BoF) for detector**:
1. CIoU-loss
2. CmBN
3. DropBlock regularization
4. Mosaic data augmentation、Self-Adversarial Training
5. Eliminate grid sensitivity
6. Using multiple anchors for a single ground truth
7. Cosine annealing scheduler
8. Optimal hyper-parameters
9. Random training shapes
- **Bag of Specials (BoS) for detector**:
1. Mish activation
2. SPP-block、SAM-block、PAN path-aggregation block
3. DIoU-NMS

## New method of data augmentation

**1. Mosaic**

Mixes 4 training images, batch norm calculates activation statistics from 4 different images on each layer.

![](https://pic.downk.cc/item/5ea3f60fc2a9a83be5a308f2.jpg)

**2. Self-Adversarial Training (SAT)**

1. In the 1st stage, network alters the original image, executes an adversarial attack on itself, altering the original image to create the deception that there is no desired object on the image.
2. In the 2nd stage, the neural network is trained to detect an object on this modified image in the normal way.

## Modification

**1. CmBN**

from **CBN** to **Cross mini-Batch Normalization(CmBN)**:

![](https://pic.downk.cc/item/5ea3f784c2a9a83be5a4e224.jpg)

**2. SAM**

from **spatial-wise attention** to **point-wise attention**:

![](https://pic.downk.cc/item/5ea3f7f3c2a9a83be5a579df.jpg)

**3. PAN**

from **shortcut connection** to **concatenation**:

![](https://pic.downk.cc/item/5ea3f807c2a9a83be5a590c0.jpg)