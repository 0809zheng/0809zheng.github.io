---
layout: post
title: 'Bagging'
date: 2020-03-17
author: 郑之杰
cover: 'https://pic.downk.cc/item/5eda28cac2a9a83be55e3374.jpg'
tags: 机器学习
---

> An Ensemble Learning Method：Bagging.

**Bagging(Bootstrap Aggregation)**是一种集成学习的方法，主要关注如何获得不同的训练模型。

若在数据集上一共训练了$T$个模型$g_t,t=1,2,...,T$；如何得到这些模型呢？可以采取的方法有：
- 选择不同的模型假设空间；
- 设置不同的训练超参数；
- 由算法的随机性得到（如PLA）；
- 选择不同的训练样本集。

**Bagging**通过不同的训练集生成不同的模型。先通过**bootstrapping**方法从已有数据集生成若干子数据集，在每个子数据集上训练模型，再将模型集成起来。

### Bootstrapping
**自助抽样法(bootstrapping)**是统计学中的一种常用方法。

若已知数据集共有$N$个样本，每次从其中**有放回**地抽样若干个样本作为一个子数据集。

假设每个子数据集抽样$N$次，则恰好能还原原数据集的概率是$$\frac{N!}{N^N}$$。

### 应用
**Bagging**方法适用于模型复杂但容易拟合的情形，如用决策树构造[随机森林](https://0809zheng.github.io/2020/03/20/random-forest.html)。