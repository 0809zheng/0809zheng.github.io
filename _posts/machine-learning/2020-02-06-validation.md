---
layout: post
title: '模型评估方法'
date: 2020-02-06
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60e555435132923bf8188661.jpg'
tags: 机器学习
---

> Validation Methods for Machine Learning Methods.

通常需要通过实验测试对模型的泛化误差,时间开销,存储开销,可解释性等进行评估，并进一步对模型类型,模型结构,超参数等做出选择。不能用**训练集(training dataset)**进行评估，因为经过足够的训练，模型在训练集上的表现一定会过拟合；也不能用**测试集(test dataset)**进行评估，因为需要防止数据窥探导致测试集的信息泄露。实践中通常进一步把训练集划分成一个训练集和一个**验证集(validation dataset)**，使用验证集进行验证。

首先把训练集$\mathcal{D}$进一步划分成训练集$$\mathcal{D}_{ \text{train} }$$和验证集$$\mathcal{D}_{ \text{val} }$$，对于不同的模型$$\{\mathcal{H}_1,\mathcal{H}_2,...,\mathcal{H}_M\}$$，分别在训练集$\mathcal{D}$上训练后在验证集上测试，得到验证误差$$\{E_1,E_2,...,E_M\}$$；选择验证误差$E_{m^\*}$最小的模型假设$H_{m^\*}$作为最终的假设函数，再用所有训练集$\mathcal{D}$进行最终的训练，得到最终的模型$g_{m^\*}$。

![](https://pic.imgdb.cn/item/60e555435132923bf8188661.jpg)

验证集大小$K$的选择也很重要:
- 若$K$太小，则训练集足够多，但是验证集样本太少，评估结果不够稳定准确；
- 若$K$太大，则验证集足够多，但是训练集样本太少，不能代表测试集的数据分布，降低评估结果的保真性。

在对训练集$\mathcal{D}$进一步划分成训练集$$\mathcal{D}_{ \text{train} }$$和验证集$$\mathcal{D}_{ \text{val} }$$时，有以下几种方法：
1. 留出法 hold-out
2. 交叉验证法 Cross Validation
3. 自助法 Bootstrapping

## 1. 留出法
**留出法(hold-out)**是指直接把训练集$\mathcal{D}$划分成两个互斥的集合，一个作为训练集$$\mathcal{D}_{ \text{train} }$$，另一个作为验证集$$\mathcal{D}_{ \text{val} }$$。在训练集$$\mathcal{D}_{ \text{train} }$$上训练出模型后，用验证集$$\mathcal{D}_{ \text{val} }$$评估其测试误差，作为对泛化结果的估计。

训练/验证集的划分比例根据经验推荐为$2:1$至$4:1$。需要注意的是，训练/验证集的划分要尽可能保持数据分布的一致性，避免数据划分过程引入额外的偏差；例如分类任务中至少要保持样本的类别比例相似，因此采用**分层采样(stratified sampling)**。

## 2. 交叉验证法
**交叉验证法(cross validation)**是指将训练集$\mathcal{D}$划分为$k$个大小相同或接近的互斥子集，每个子集尽可能保持数据分布的一致性。每次取其中一份作为验证集，其余$k-1$份为训练集；共进行$k$次评估。最终返回$k$次评估结果的均值：

![](https://pic.downk.cc/item/5ed378fcc2a9a83be5352e0b.jpg)

该方法也被称为**k折交叉验证(k-fold cross validation)**，$k$最常用的取值是$10$，也可选$5-20$范围内的值。

当选择$k=1$，即每次仅选择$1$个样本作为验证集，其余所有样本作为训练集；此时也称为**留一交叉验证(Leave-One-Out Cross Validation)**。通常留一法不受样本随机划分方式的影响，评估结果更为准确。但当数据集比较大时，需要训练大量模型。


## 3. 自助法
**自助法(Bootstrapping)**又称为自举法或拔靴法，是以统计学中的**自助采样(bootstrapping sampling)**为基础。对于具有$m$个样本的训练集$\mathcal{D}$，**有放回**的随机采样$m$次，得到包含$m$个样本的数据集$\mathcal{D}'$，将该数据集作为训练集；$\mathcal{D}$中有一部分样本会在$\mathcal{D}'$中多次出现，而另一部分样本不会出现；选择$\mathcal{D}-\mathcal{D}'$作为验证集。

某一个样本在$m$次采样中始终不会被采集到的概率是：

$$ \mathop{lim}_{m→∞}(1-\frac{1}{m})^m=\frac{1}{e} $$

因此自助法采样后大约有$\frac{1}{e}≈36.8\%$的样本没有出现在数据集$\mathcal{D}'$中；故自助法的评估结果也被称作**out-of-bag estimate**。

自助法在数据集较小、训练/验证集划分较为困难时可以使用。由于其能够从原始数据集中生成多个不同分布的训练集，因此在集成学习中常用到。但数据分布的改变会引入估计偏差，需要慎重使用。

