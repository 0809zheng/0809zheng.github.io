---
layout: post
title: 'Energy-based Model：能量模型'
date: 2020-04-12
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/634e48dc16f2c2beb147c676.jpg'
tags: 机器学习
---

> Energy-based Model.

本文目录：
1. 能量模型的定义
2. 能量模型的正相-负相分解
3. 利用最大熵原理建立能量模型
4. 能量分布的MCMC采样
5. 常见的能量模型

# 1. 能量模型的定义

**能量模型(energy-based model)**是指使用如下概率模型拟合一批真实数据$x_1,x_2,\cdots,x_n$~$p(x)$：

$$ q_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} $$

其中$U_{\theta}(x)$是带参数的**能量函数**；$Z_{\theta}$是**配分函数**(**partition function**, 即归一化因子)：

$$ Z_{\theta} = \int e^{-U_{\theta}(x)}dx $$

上述概率形式被称为**能量分布**，对应物理学中的玻尔兹曼分布。玻尔兹曼分布形式容易处理，是一种比较常用的能量分布；比如**softmax**函数就是基于玻尔兹曼分布假设。

直观地，真实数据应该分布在能量函数中势最小的位置。能量模型的学习过程旨在通过调整能量函数$U_{\theta}(x)$，使得真实数据落入能量函数的极值点处。

![](https://pic1.imgdb.cn/item/634e13f716f2c2beb1b9d59f.jpg)

# 2. 能量模型的正相-负相分解

能量模型的目标函数为能量分布的负对数似然：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [- \log q_{\theta}(x)]  $$

计算目标函数的梯度：

$$ \begin{aligned} \nabla_{\theta} L_{\theta} & =  \Bbb{E}_{x \text{~} p(x)} [- \nabla_{\theta}\log q_{\theta}(x)] = \Bbb{E}_{x \text{~} p(x)} [- \nabla_{\theta}\log \frac{e^{-U_{\theta}(x)}}{Z_{\theta}}]\\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+ \nabla_{\theta}\log Z_{\theta}] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+\frac{1}{Z_{\theta}} \nabla_{\theta} Z_{\theta}] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+\frac{1}{Z_{\theta}} \nabla_{\theta} \int e^{-U_{\theta}(x)}dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)-\frac{1}{Z_{\theta}} \int e^{-U_{\theta}(x)}  \nabla_{\theta}U_{\theta}(x) dx]  \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)- \int \frac{e^{-U_{\theta}(x)}}{Z_{\theta}}  \nabla_{\theta}U_{\theta}(x) dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)- \int q_{\theta}(x) \nabla_{\theta}U_{\theta}(x) dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[\nabla_{\theta}U_{\theta}(x) ]] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[\nabla_{\theta}U_{\theta}(x) ] \\ & = \nabla_{\theta}(\Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[U_{\theta}(x) ]) \end{aligned} $$

因此目标函数可以等价地表示为：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[U_{\theta}(x) ] $$

上式称为**正相-负相分解**，表示能量函数$U_{\theta}(x)$在真实分布和能量分布下的均值之差。

# 3. 利用最大熵原理建立能量模型

[最大熵原理](https://0809zheng.github.io/2021/07/20/me.html#2-%E6%9C%80%E5%A4%A7%E7%86%B5%E5%8E%9F%E7%90%86-the-maximum-entropy-principle)是指对于一个未知的概率分布，在只掌握其部分知识的前提下，应选取符合这部分知识的同时使得熵最大的概率分布形式。

能量模型可以通过最大熵原理导出。对于某个概率分布$p(x)$，通过生活经验或先验信息可能会获得该分布的部分知识，将其以期望形式给出约束：

$$ E[f(x)] = \int_{x}^{} p(x)f(x)dx = \tau $$

注意到$f(x)=1,\tau=1$时该约束是概率之和为$1$，是一个平凡的约束。一般地，假设有$k$个约束，则最大熵原理等价于一个带有约束的极值问题，采用拉格朗日乘子法求解：

$$ \begin{aligned} L(p(x),\lambda) = &-\int_{x}^{}p(x) \log p(x)dx-\lambda_0(\int_{x}^{} p(x)dx-1)-\lambda_1(\int_{x}^{} p(x)f_1(x)dx-  \tau_1)\\&- \cdots -\lambda_k(\int_{x}^{} p(x)f_k(x)dx-  \tau_k) \end{aligned} $$


对上式求偏导令其为零$\frac{\partial L}{\partial p(x)}=0$，可得：
$$ -\log p(x) -1-\lambda_0-\lambda_1f_1(x)-...-\lambda_kf_k(x)=0 $$

解得：

$$ p(x) = e^{-1-\lambda_0-\sum_{i=1}^{k}\lambda_if_i(x)} $$

注意到$\int_{x}^{} p(x)dx=1$，因此：

$$ \int_{x}^{} p(x)dx=\int_{x}^{} e^{-1-\lambda_0-\sum_{i=1}^{k}\lambda_if_i(x)}dx = \int_{x}^{}e^{-1-\lambda_0}e^{-\sum_{i=1}^{k}\lambda_if_i(x)}dx=1 $$

因此$e^{-1-\lambda_0}=\frac{1}{\int_{x}^{}e^{-\sum_{i=1}^{k}\lambda_if_i(x)}dx}$，将其分母记为归一化因子$Z$，代回原式可得：

$$ p(x) = \frac{e^{-\sum_{i=1}^{k}\lambda_if_i(x)}}{\int_{x}^{}e^{-\sum_{i=1}^{k}\lambda_if_i(x)}dx} = \frac{1}{Z}e^{-\sum_{i=1}^{k}\lambda_if_i(x)} $$

上式即为能量分布的概率形式。

# 4. 能量分布的MCMC采样

能量模型训练完成后，需要从能量分布$q_{\theta}(x)$进行采样才能生成新的样本。采样方法常选择[MCMC方法](https://0809zheng.github.io/2022/10/17/sampling.html)，即构造以下随机过程：

$$ x_{t+1} = f(x_t,\alpha) $$

其中$\alpha$是一个容易实现的随机过程，比如均匀采样；若该随机过程的静态分布为$q_{\theta}(x)$，从$x_0$出发采样得到的序列$\{x_1,x_2,\cdots,x_t\}$服从$q_{\theta}(x)$分布。

特别地，考虑**Langevin**方程：

$$ x_{t+1} = x_t - \frac{1}{2}\epsilon \nabla_xU(x_t) + \sqrt{\epsilon} \alpha, \quad \alpha \text{~} \mathcal{N}(0,1) $$

上述随机微分方程当$\epsilon \to 0$时的静态分布恰为能量分布：

$$ q_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} $$

因此给定能量函数$U(x)$后，按照上述形式可以实现从能量分布中采样。

# 5. 常见的能量模型

**能量模型**的定义：

$$ q_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} , Z_{\theta} = \int e^{-U_{\theta}(x)}dx $$

不同的能量模型具有不同的能量函数$U_{\theta}(x)$形式。

## (1) [<font color=blue>Hopfield神经网络</font>](https://0809zheng.github.io/2020/04/13/hopfield-network.html)

![](https://pic.downk.cc/item/5e9464d5c2a9a83be50658b8.jpg)


**Hopfield**网络中每一个神经元都和除自己外的所有神经元相互连接，且通常每一个神经元的取值是离散的：$$\{0,1\}$$。

不同神经元之间连接权重是**对称**的，若记$w_{ij}$为神经元$i$和$j$之间的连接权重，则满足：

$$ w_{ij} = w_{ji}, \quad i ≠ j $$

**Hopfield**网络的能量函数$U_{\theta}(x)$定义为：

$$ U_{\theta}(x) = -\frac{1}{2}\sum_{i,j}^{} {w_{ij}x_ix_j} - \sum_{i}^{} {b_ix_i} $$


## (2) [<font color=blue>玻尔兹曼机</font>](https://0809zheng.github.io/2020/04/14/boltzmann-machine.html)

![](https://pic.downk.cc/item/5e954cbbc2a9a83be594d120.jpg)

**玻尔兹曼机(Boltzmann Machine)**结构上与离散型**Hopfield**网络相似，其神经元可以分为可观测变量(**visible variable**)和隐变量(**latent variable**)。

玻尔兹曼机的能量函数$U_{\theta}(x)$定义为：

$$ U_{\theta}(x) = -(\sum_{i<j}^{} {w_{ij}x_ix_j} + \sum_{i}^{} {b_{i}x_i}) $$

## (3) [<font color=blue>受限玻尔兹曼机</font>](https://0809zheng.github.io/2020/04/15/restricted-boltzmann-machine.html)

![](https://pic.downk.cc/item/5e9676a8c2a9a83be55aca1e.jpg)

**受限玻尔兹曼机(Restricted Boltzmann Machine，RBM)**的可观测变量$x$和隐变量$z$之间是全连接的；但是相同类型的节点之间没有连接。

受限玻尔兹曼机的能量函数$U_{\theta}(x,z)$定义为：

$$ U_{\theta}(x,z) = -(\sum_{i}^{} {a_ix_i} + \sum_{j}^{} {b_jz_j} + \sum_{i,j}^{} {w_{ij}x_iz_j})  $$