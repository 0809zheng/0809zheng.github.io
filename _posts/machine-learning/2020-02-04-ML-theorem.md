---
layout: post
title: '机器学习的一些定理'
date: 2020-02-04
author: 郑之杰
cover: ''
tags: 机器学习
---

> Some Machine Learning Theorems.

本文目录：
1. 没有免费午餐定理 No Free Lunch
1. 归纳偏置 Inductive Bias
6. 奥卡姆剃刀 Occam's Razor
7. 抽样偏差 Sampling Bias
8. 数据窥探 Data Snooping
9. 维度灾难 Curse of Dimensionality



# 1. 没有免费午餐定理
**没有免费午餐(No Free Lunch,NFL)**定理表明没有一个学习算法可以在任何领域总是产生最准确的学习器。不管采用何种学习算法，至少存在一个目标函数，能够使得随机猜测算法是更好的算法。

平常所说的一个学习算法比另一个算法更“优越”，效果更好，只是针对特定的问题、特定的先验信息、数据的分布、训练样本的数目、代价或奖励函数等。

# 2. 归纳偏置
**归纳偏置(inductive bias)**是指任何一个有效的机器学习算法必有其“偏好”，否则算法无法处理对于假设空间中看似在训练集上“等效”(如在数据集上具有相同的分类准确率)的假设，从而无法产生确定的学习结果。

# 3. 奥卡姆剃刀
**奥卡姆剃刀（Occam's Razor）**是自然学科研究中最基本的原则之一。
- 原理：“如无必要，勿增实体”（Entities must not be multiplied unnecessarily）
- 应用于机器学习：能够拟合数据的模型中最简单的是最好的。

奥卡姆剃刀提供了一种引导机器学习算法克服归纳偏置的一般性原则。衡量模型的“简单”程度这个问题本身并不简单。一种参考是模型复杂度低，即对于一个模型具有更少的假设空间，对于一个假设具有更少的参数量。

# 4. 抽样偏差
**抽样偏差（sampling bias）**是指：如果数据抽样时存在偏差，模型学习的结果也会产生偏差。

尽可能保持训练环境和测试环境接近，即训练数据的分布和测试数据的分布一致。

# 5. 数据窥探
要防止**数据窥探（data snooping）**，即测试数据不能以任何形式泄漏到训练过程中。

在实际应用中很难做到完全不窥探数据。比如某个研究领域使用某基准benchmarks，前人已发表论文中提到的方法在解决这个问题时，已经间接泄露了一些数据信息；当你在前人的基础上开发出新的模型，实际上已经应用了泄漏的数据，增加了过拟合的风险。

一种常用的防止数据窥探的方法是不人为的引入先验知识。比如解决某一问题时，先不观察具体的数据集，而是先提出一些可能的解决方法和应用技巧，再将其应用到数据上；而不是通过数据来选择模型。

# 6. 维度灾难
**维度灾难（the curse of dimensionality）**指出，数据在高维空间中的分布具有稀疏性，从而产生有悖于低维空间（如三维空间）常识的现象。
- **例1.** 考虑$k$维空间中边长为$1$的超立方体内接超球体，超球体半径为$\frac{1}{2}$，其体积（测度）为$\text{const} \cdot (\frac{1}{2})^k $，当$k→∞$时，超球体体积为$0$，即高维空间中边长为$1$的超立方体内的数据集中分布在立方体**角落**。
- **例2.** 考虑$k$维空间中半径为$r$和$r+ε$的同心超球体，其中$ε$是一个很小的数。两个超球体的体积分别为$\text{const} \cdot (r)^k $和$\text{const} \cdot (r+ε)^k $，其体积之比为$\frac{(r)^k}{(r+ε)^k}=\frac{1}{(1+\frac{ε}{r})^k}$，当$k→∞$时体积之比趋近于$0$。即高维空间中的超球体内数据集中分布在**表面**上。
