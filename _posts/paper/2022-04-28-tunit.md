---
layout: post
title: 'Rethinking the Truly Unsupervised Image-to-Image Translation'
date: 2022-04-28
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6398242eb1fccdcd3608824d.jpg'
tags: 论文阅读
---

> TUNIT：完全无监督图像到图像翻译.

- paper：[Rethinking the Truly Unsupervised Image-to-Image Translation](https://arxiv.org/abs/2006.06500)

作者指出，图像到图像翻译有三种不同的监督程度：
1. 图像级：有监督的图像翻译，提供两种图像域中一对一的图像对；
2. 集合级：提供几种不同的图像域的图像，但仍然给定了每个图像域的域标签；
3. 无监督：提供一个图像数据集，实现其中任意两张图像之间的翻译。

![](https://pic.imgdb.cn/item/63982480b1fccdcd36092541.jpg)

作者提出了一种无监督的图像到图像翻译方法**TUNIT**。该方法由编码器、生成器、判别器组成。
- 编码器：把输入图像编码为领域标签和风格编码；
- 生成器：根据输入图像和风格编码生成图像；
- 判别器：输入图像，根据领域标签判定该领域中图像的真实性。

![](https://pic.imgdb.cn/item/63982573b1fccdcd360b128c.jpg)

网络的训练过程有三个阶段。首先预训练编码器，编码器的领域标签头用**Invariant Information Clustering**方法进行无监督的聚类训练；编码器的风格编码头用**MoCo**方法进行对比学习。

其次训练判别器，判别器采用标准的对抗损失训练，接收图像后生成长度为领域数量的预测向量，根据编码器提供的领域标签选择对应的位置构造对抗损失。

最后训练生成器，生成器的损失包括**L1**重构损失、对抗损失和风格对比损失。其中重构损失需要先用编码器获取输入图像的风格编码，这一步导致编码器也能获得梯度，从而一起训练：

$$ \begin{aligned} \mathcal{L}_{\text{recon}} &=  \Bbb{E}_{x \text{~} p(x)}[||x-G(x,s)||_1 ]  \end{aligned} $$

风格对比损失(**style contrastive loss**)是指根据风格编码$\tilde{s}$生成图像后，再将图像通过编码器构造风格编码$s'=E_s(G(x,\tilde{s}))$，并与其余图像的风格编码共同构造对比损失：

$$  \mathcal{L}_{\text{style}}^G = \Bbb{E}_{x,\tilde{x} \text{~} p(x)} [-\log \frac{\exp(s' \cdot \tilde{s})}{\sum_{i=0}^N \exp(s' \cdot s_i^- / \tau)}] $$

总损失函数表示如下：

$$ \begin{aligned} \mathop{ \min}_{G,E} \mathop{\max}_{D} &\mathcal{L}_{\text{adv}}(D,G) + \lambda_{\text{style}}^G\mathcal{L}_{\text{style}}^G(G,E) + \lambda_{\text{rec}}\mathcal{L}_{\text{rec}}(G,E) \\ & - \lambda_{MI}\mathcal{L}_{MI}(E)+ \lambda_{\text{style}}^E\mathcal{L}_{\text{style}}^E(E) \end{aligned} $$