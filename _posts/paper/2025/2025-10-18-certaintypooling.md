---
layout: post
title: 'Certainty Pooling for Multiple Instance Learning'
date: 2025-10-18
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/68ff1ab73203f7be00a632e2.png'
tags: 论文阅读
---

> 多实例学习的确定性池化.

- paper：[Certainty Pooling for Multiple Instance Learning](https://arxiv.org/abs/2008.10548)


# 0. TL; DR

这篇论文提出了一种名为**确定性池化（Certainty Pooling）**的聚合算子，其核心思想是一个实例对最终包标签的贡献，应该由它的预测分数和模型对这个预测的确定性共同决定。通过在推理时多次启用**蒙特卡洛 Dropout (MC-Dropout)**并进行预测，可以得到一个实例的一组预测结果。这组结果的标准差的倒数被用作该预测的“确定性”度量。

在一个专门设计的、具有极低证据比率（1%）的**MNIST-Bags**数据集上，**Certainty Pooling**在小到中等训练集规模下显著优于**max、mean**和**attention pooling**。在真实的、极具挑战性的**Camelyon16**病理图像数据集上，**Certainty Pooling**在包级别和实例级别预测任务上，均全面超越了所有对比方法。

# 1. 背景介绍

多实例学习（**MIL**）面临**低证据比率（Low Evidence Ratio）**：在一个阳性“包”中，真正导致其为阳性的“实例”数量可能非常稀少。**MIL**的聚合（池化）常用的方法面临的问题：
-   **Mean-pooling (平均池化)**: 在一个包含999个阴性实例和1个阳性实例的包中，阳性实例的信号会被极度稀释，几乎淹没在大量阴性实例的“噪声”中。这很容易导致假阴性（漏诊）。
-   **Max-pooling (最大池化)**: 它只关注那个预测分数最高的实例。然而深度学习模型本身具有不稳定性，一个微小的输入扰动就可能导致预测结果的剧烈变化。这意味着一个阴性实例偶然获得了一个很高的预测分数，就可能导致整个包被错误地判断为阳性，造成假阳性（误诊）。
-   **Attention-pooling (注意力池化)**: 虽然它通过可学习的权重进行加权平均，但仍然没有从根本上解决问题。模型依然可能被少数几个高分噪声实例所主导，或者因为权重被大量低分实例分散而丢失关键信息。

作者认为，当阳性证据极其稀疏时，引入一个新的维度：预测的“确定性”，既能放大微弱的真实阳性信号，又能抑制偶然出现的虚假高分噪声。

# 2. Certainty Pooling

作者采用了**MC-Dropout**技术来量化模型的不确定性。这是一种将贝叶斯思想引入深度学习的巧妙方法。标准**Dropout**只在训练时以一定概率随机“关闭”一部分神经元，以防止过拟合；在测试时所有神经元都处于激活状态。**MC-Dropout**在测试（或推理）时，也保持**Dropout**的开启状态。

对于同一个输入实例，进行多次（例如T次）前向传播。由于每次**Dropout**随机关闭的神经元不同，会得到一组略有差异的预测结果 $\{p_1, p_2, \dots, p_T\}$。这组预测结果的方差（或标准差）反映了模型对这个实例预测的不确定性。方差越大，说明模型的预测越不稳定。

基于**MC-Dropout**，作者定义了**Certainty Pooling**。
- 计算实例确定性 $C_k$: 对于包中的每个实例$k$，进行$T$次带**Dropout**的前向传播，得到预测结果向量$X_k$。计算$X_k$的标准差$σ(X_k)$。确定性$C_k$被定义为标准差的倒数。其中$ε$是一个防止除以零的小常数。标准差越小（越确定），$C_k$值越大。

$$ C_k = \frac{1}{\sigma(X_k) + \epsilon} $$

- 确定性加权的最大化选择: 对于每个实例$k$，计算其确定性加权分数：$C_k * h_{km}$，其中$h_{km}$是该实例的平均预测分数。**Certainty Pooling**的输出$Z_m$不再是分数最高的实例，而是确定性加权分数最高的那个实例的预测值。
  
$$ k^* = \arg\max_k (C_k \cdot h_{km}) \\ Z_m = h_{k^*m} $$

![](https://pic1.imgdb.cn/item/68ff1dea3203f7be00a64c4e.png)

如果一个实例的预测分数$h$很高，但模型对它很“不确定”（$σ$大，$C$小），那么它的加权分数就会被惩罚，不容易被选为代表。这有效抑制了噪声实例的干扰。如果一个实例的预测分数$h$虽然不是最高，但模型对它的预测非常“确定”（$σ$小，$C$大），它的加权分数可能会反超那些高分但不确定的实例，从而被选中。这使得模型能够放大那些稳定、可信的阳性信号。在训练过程中，这种机制会引导模型产生更弱的梯度给那些不确定的实例，使得优化过程更加稳健。

# 3. 实验分析

作者在两个典型的“低证据比率”数据集上对**Certainty Pooling**进行了验证。

### 3.1 MNIST-Bags

为了检验不同池化方法在小样本和低证据比率下的性能，作者构建一个**MNIST-Bags**数据集，每个包包含100个数字实例：阳性包仅包含1个9，其余99个为其他数字。证据比率仅为1%。通过改变训练集的包数量（50到500），来测试模型在不同数据量下的表现。

结果表明，在训练包数量较少（50-300个）时，**Certainty Pooling**的包级别**AUC**显著优于**Attention Pooling**和传统的**max/mean pooling**。这说明在数据稀缺时，引入确定性度量能够帮助模型做出更可靠的决策。

![](https://pic1.imgdb.cn/item/68ff20a53203f7be00a663c9.png)

在更关键的实例级别**AUC**上，**Certainty Pooling**在所有训练集规模下都取得了最佳性能。这表明它不仅包预测得准，而且训练出的实例分类器本身也更强大，更能区分真正的阳性实例。

![](https://pic1.imgdb.cn/item/68ff20d13203f7be00a66554.png)

可视化结果显示，**Certainty Pooling**训练出的模型，其对阳性实例（"9"）和阴性实例的预测分数分布分离得更开，界限更清晰。而**Attention Pooling**的预测分数则有很大的重叠区域。

![](https://pic1.imgdb.cn/item/68ff20f23203f7be00a66680.png)


### 3.2 Camelyon16

乳腺癌淋巴结转移检测数据集**Camelyon16**是计算病理学中一个典型的、真实的低证据比率场景。使用在**ImageNet**上预训练的**ResNet50**提取**patch**特征。同样测试了不同训练数据规模（占总训练集的50%到100%）下的性能。

在所有训练集规模下，**Certainty Pooling**的包级别**AUC**都取得了最佳性能，再次超越了所有对比方法。

![](https://pic1.imgdb.cn/item/68ff21a93203f7be00a66d00.png)

**Certainty Pooling**在实例级别**AUC**上的表现同样是最佳的，进一步证实了其在小样本、低证据比率下的优越性。

![](https://pic1.imgdb.cn/item/68ff218b3203f7be00a66bde.png)

通过展示模型预测分数最高的**Top-10**实例，可以直观地看到，**Certainty Pooling**检索出的实例几乎全部是真实的肿瘤切片，而**Attention-MIL**则会混入大量非肿瘤切片。

![](https://pic1.imgdb.cn/item/68ff215f3203f7be00a669fe.png)