---
layout: post
title: 'DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification'
date: 2025-10-15
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/68f1f54dc5157e1a887d0928.png'
tags: 论文阅读
---

> DTFD-MIL: 用于组织病理学全切片图像分类的双层特征蒸馏多实例学习.

- paper：[DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2203.12081)


# 0. TL; DR

这篇论文提出了一种**双层特征蒸馏多实例学习（Double-Tier Feature Distillation MIL, DTFD-MIL）**框架。将每张**WSI**（父包）中的海量实例，随机地划分为若干个更小的**伪包(Pseudo-bags)**，构建了双层架构：**Tier-1**为每个伪包生成初步的预测和注意力分数，**Tier-2**接收从每个伪包中蒸馏出的最具代表性的实例特征，进行最终的父包级别分类。

论文探索了四种从伪包中“蒸馏”精华实例的策略。在**CAMELYON-16**数据集上，**DTFD-MIL**全面超越了所有最新的**SOTA**方法，在**TCGA**肺癌数据集上同样表现出色。

# 1. 背景介绍

在将多实例学习（**MIL**）应用于全切片图像（**WSI**）分类时，从“包”的层面看，样本量极小（一个临床研究队列可能只有几十到几百张**WSI**），从“实例”的层面看，数据量又极大（一张**WSI**可以被切分成数千甚至上万个图块）。

近年来涌现了许多先进的**MIL**方法通过建模实例间的关系来提升性能，但它们并没有从根本上解决“包少实例多”这个核心矛盾。本文旨在设计一种方法，既能增加“包”的数量以提供更丰富的学习信号，又能减小每个“包”的规模以降低学习难度，从而有效缓解过拟合问题。

# 2. DTFD-MIL

## 2.1 在AB-MIL中推导实例概率

论文首次在注意力**MIL（AB-MIL）**框架下，推导出了计算实例阳性概率的解析方法。作者指出，**AB-MIL**的范式，本质上是经典图像分类网络。
- 经典网络：特征提取 -> 全局平均池化 (GAP) -> 分类器
- **AB-MIL**：实例特征 ($h_k$) -> 注意力加权求和 -> 分类器

作者认为，实例特征${h_k}$可以看作是“特征图”，而注意力加权求和就扮演了“池化”的角色。作者将用于可视化和定位的**Grad-CAM**技术应用到**AB-MIL**框架中。通过计算分类器输出对每个实例特征的梯度，可以得到一个激活值$L_k^c$，它表示实例$k$属于类别$c$的“信号强度”。

$$ L_k^c = \sum_{d=1}^D \beta_d^c \hat{h}_{k,d} $$

其中$\beta_d^c$是梯度相关的权重。然后通过一个**softmax**，就可以得到实例$k$为阳性（$c=1$）的概率$p_k^1$。

$$ p_k^c = \frac{\exp(L_k^c)}{\sum_{t=1}^C \exp(L_k^t)} $$

![](https://pic1.imgdb.cn/item/68f20648c5157e1a887d49e1.png)

## 2.2 双层特征蒸馏架构

**DTFD-MIL**通过引入“伪包”和构建一个双层架构来实现多实例学习。

将一张**WSI**（父包）中的所有实例，随机地、不重叠地划分成$M$个更小的**伪包（pseudo-bags）**，每个伪包都继承其父包的标签。如果有$N$张**WSI**，划分后就得到了$N \times M$个包用于训练。这在形式上增加了训练样本的数量；同时每个伪包只包含少量实例，这使得后续的**MIL**模型处理起来更容易，计算效率也更高。

![](https://pic1.imgdb.cn/item/68f206f3c5157e1a887d505d.png)

对于一个阳性的父包，它的一些伪包可能不包含任何阳性实例，从而被错误地赋予了阳性标签。**DTFD-MIL**通过双层架构解决这个问题。

**Tier-1**相当于伪包分析器，负责处理大量的伪包$X_n^m$，进行初步的特征筛选和分析，预测伪包标签$y_n^m$和每个实例的阳性概率。**Tier-2**相当于父包决策器，负责对原始的**WSI**（父包）进行最终分类，其输入是从每个伪包中蒸馏出的实例特征。

![](https://pic1.imgdb.cn/item/68f207f2c5157e1a887d5448.png)

**特征蒸馏 (Feature Distillation)**是连接**Tier-1**和**Tier-2**的桥梁。对于父包$n$的每个伪包$m$，根据**Tier-1**计算出的实例概率，选择一个或多个最具代表性的实例特征，作为**Tier-2**的输入。

作者探索了四种蒸馏策略：
1.  **MaxS (Maximum Selection)**: 选择伪包内阳性概率最高的那个实例的特征。
2.  **MaxMinS (MaxMin Selection)**: 同时选择概率最高和最低的两个实例的特征，并将它们拼接起来。这是为了给**Tier-2**提供更丰富的正负对比信息，防止决策边界过于紧绷。
3.  **MAS (Maximum Attention Score)**: 作为对比，使用传统的注意力分数来选择实例。
4.  **AFS (Aggregated Feature Selection)**: 直接使用**Tier-1**为伪包聚合出的包嵌入作为蒸馏特征。


# 3. 实验分析

**CAMELYON-16**是一个正实例比例极低的经典**WSI**数据集，非常适合检验模型在“包少实例多”且正负实例严重不平衡下的性能。

**DTFD-MIL**性能远超所有对比方法，充分证明了框架设计的优越性。“伪包+双层蒸馏”的策略确实有效地解决了小样本队列带来的过拟合问题。其中**MaxMinS**和**AFS**策略表现最好，说明简单地只选择概率最高的实例（**MaxS**）并非最优。同时考虑正负信息（**MaxMinS**）或使用聚合后的信息（**AFS**）能为**Tier-2**提供更全面的视角。

![](https://pic1.imgdb.cn/item/68f208b5c5157e1a887d57d8.png)

**TCGA**肺癌数据集是一个实例分布相对更均衡的数据集。**DTFD-MIL**同样取得了**SOTA性能**，说明即使在数据不那么极端的情况下，**DTFD-MIL**的精细化学习框架依然能带来性能优势。

![](https://pic1.imgdb.cn/item/68f208e0c5157e1a887d57e3.png)

作者进一步消融了伪包数量的影响。在**CAMELYON-16**上，随着伪包数量增加（即每个伪包实例数减少），**Tier-1**模型的性能急剧下降。这是因为伪包太小，阳性实例被“漏掉”的概率大增，导致噪声标签问题严重。**Tier-2**模型的性能对伪包数量的增加表现出很强的鲁棒性，甚至在一定范围内性能还会提升。这证明了双层架构的必要性和有效性，**Tier-2**成功地从多个（可能包含噪声标签的）伪包中提纯出了真正有用的信息，克服了**Tier-1**的局限性。

![](https://pic1.imgdb.cn/item/68f20995c5157e1a887d584a.png)

通过可视化发现，使用本文推导的实例概率生成的热力图，相比于使用注意力分数生成的热力图，能够更准确、更清晰地定位肿瘤区域，并且在阴性切片上产生的假阳性显著更少。

![](https://pic1.imgdb.cn/item/68f209e7c5157e1a887d5867.png)