---
layout: post
title: 'The GAN is dead; long live the GAN! A Modern GAN Baseline'
date: 2025-01-13
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/6784f7b0d0e0a243d4f3f036.png'
tags: 论文阅读
---

> GAN 已死；GAN 万岁！现代 GAN 基线.

- paper：[The GAN is dead; long live the GAN! A Modern GAN Baseline](https://arxiv.org/abs/2501.05441)

# 0. TL;DR

本文提出了一种简化的生成对抗网络（**GAN**）架构，旨在阐明图像生成任务中**GAN**的最小必要组件。通过引入一个表现良好的正则化相对**GAN**（**RpGAN**）损失函数，解决了模式崩溃和非收敛问题，从而避免了使用一系列专门的技巧。该损失函数具有数学上证明的局部收敛性。

在此基础上，本文剥离了**StyleGAN**的所有特性，识别并保留了其核心组件，同时引入现代网络架构的改进，构建了一个简单而高效的**GAN**基线。

实验结果表明，该简化模型在保持输出多样性的同时，实现了稳定的训练过程。本文的工作重点在于为图像生成任务提供一个简化的**GAN**框架，以简洁性为优先，而非追求在所有数据集或任务上超越现有模型的性能。

# 1. 研究背景

[生成对抗网络（GAN）](https://0809zheng.github.io/2022/02/01/gan.html)自提出以来，在图像生成、视频合成等领域取得了显著进展。传统**GAN**通过生成器（**Generator**）和判别器（**Discriminator**）之间的最小最大博弈来实现数据的生成。

然而，**GAN**的训练过程往往不稳定，容易出现模式崩溃（**Mode Collapse**）和非收敛问题。为了解决这些问题，研究人员提出了多种技巧，如正则化项、梯度惩罚等。然而，这些技巧增加了模型的复杂性，使得理解和改进**GAN**变得更加困难。

近年来，**StyleGAN**等架构通过引入复杂的层结构和风格映射等特性，显著提高了**GAN**的生成质量。然而，这些特性是否都是必要的？能否在保持生成质量的同时，简化**GAN**的架构？本文正是基于这一思考，旨在阐明图像生成任务中**GAN**的最小必要组件。

# 2. 方法介绍

传统**GAN**被制定为一个生成器**G**和判别器**D**之间的最小最大博弈。给定真实数据和由**G**产生的假数据，**GAN**的一般形式可以表示为：

$$ \begin{aligned} \mathop{ \min}_{G} \mathop{\max}_{D}  \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{x \text{~} P_{G}(x)}[\log(1-D(x))] \end{aligned} $$

当生成器已经找到了一些可以轻易欺骗判别器的样本，从而导致判别器的梯度信息失效或变得非常微弱。由于缺乏有效的梯度指导，生成器可能无法继续学习和改进，开始重复生成一些特定的样本或仅覆盖数据分布中的有限模式，从而无法覆盖整个真实数据的多样性。这种现象称为模式崩溃（**Mode Collapse**）。

[<font color=Blue>RGAN</font>](https://0809zheng.github.io/2022/02/21/rgan.html)通过耦合真实数据和假数据来解决模式崩溃问题，即一个假样本通过相对于真实样本的真实度来评判，从而有效地在每个真实样本附近保持一个决策边界，从而禁止模式崩溃。**RGAN**的目标函数为：

$$ \begin{aligned} \mathop{ \min}_{G} \mathop{\max}_{D}  \Bbb{E}_{x \text{~} P_{data}(x),z \text{~} \mathcal{G}(z)}[f(D(G(z))-D(x))] \end{aligned} $$

作者指出，通过梯度下降优化上述目标函数并不总是收敛的。而引入以零为中心的梯度惩罚后能够保证局部收敛：

$$
\begin{aligned}
R_1 &= \frac{\gamma}{2}\Bbb{E}_{x \text{~} P_{data}(x)}[||\nabla_x D(x)||^2] \\
R_2 &= \frac{\gamma}{2}\Bbb{E}_{x \text{~} G(z)}[||\nabla_x D(x)||^2]
\end{aligned}
$$

![](https://pic1.imgdb.cn/item/6784ff9ad0e0a243d4f3f156.png)

在确定了稳定的损失函数后，作者剥离了**StyleGAN**的所有特性，识别了其核心组件，并在此基础上进行了现代化改进。具体地，本文保留了**ConvNet**架构的简单性，同时引入了增加宽度与深度卷积、倒置瓶颈、减少激活函数以及单独的重新采样层等有益特性。这些改进使得模型在保持简洁性的同时，提高了生成效率和质量。

![](https://pic1.imgdb.cn/item/678500e5d0e0a243d4f3f187.png)

基于上述改进，作者以最新的网络骨干进展为基础，构建一个极简的基准模型——**R3GAN**。**R3GAN**的每个分辨率阶段包含一个转换层和两个残差块。
- 转换层：由双线性重采样和一个可选的1×1卷积层组成，用于改变空间尺寸和特征图通道数。
- 残差块：包括以下五个操作：**Conv1×1→Leaky ReLU→Conv3×3→Leaky ReLU→Conv1×1**，其中最后的**Conv1×1**不带偏置项。

此外，对**4×4**分辨率阶段，转换层在**G**中被基础层替代，在**D**中被分类头替代：
- 基础层：类似于**StyleGAN**，使用**4×4**可学习特征图，通过线性层调制**z**。
- 分类头：使用全局**4×4**深度卷积去除空间维度，然后通过线性层生成**D**的输出。

![](https://pic1.imgdb.cn/item/678501ead0e0a243d4f3f1c6.png)

# 3. 实验分析

作者在不同的数据集上评估模型，性能优于现有的**StyleGAN**方法以及最新的基于扩散模型的方法。

![](https://pic1.imgdb.cn/item/678502add0e0a243d4f3f1ec.png)

尽管模型容量相对较小，但在**FID**指标上仍优于许多其他**GAN**方法。例如**StyleGAN-XL**的生成器参数量为**1800**万，判别器参数量为**1.25**亿，而新模型的生成器和判别器总参数量仅为**4000**万。

![](https://pic1.imgdb.cn/item/6785031fd0e0a243d4f3f1f8.png)