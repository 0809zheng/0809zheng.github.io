---
layout: post
title: 'Transformers without Normalization'
date: 2025-03-13
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67e530f90ba3d5a1d7e526e4.png'
tags: 论文阅读
---

> 无归一化的Transformer.

- paper：[Transformers without Normalization](https://arxiv.org/abs/2503.10622)

# 0. TL; DR

本文提出了一种名为**Dynamic Tanh（DyT）**的简单技术，用于替代**Transformer**架构中的归一化层。**DyT**通过一个可学习的标量参数$α$和**tanh**函数，实现了对输入激活值的动态缩放和极端值的压缩。实验表明，使用**DyT**的**Transformer**在多种任务和领域中均能达到与使用归一化层相当甚至更好的性能，同时在训练和推理速度上具有显著优势。这一发现挑战了归一化层在现代神经网络中不可或缺的传统观念。

# 1. 背景介绍

归一化层在现代神经网络中扮演着核心角色，尤其是在**Transformer**架构中。自**Batch Normalization（BN）**被提出以来，归一化层已成为加速深度网络训练和提高性能的关键技术。随后，**Layer Normalization（LN）**和**Root Mean Square Normalization（RMSNorm）**等变体在**Transformer**架构中得到了广泛应用。这些归一化层通过调整输入激活值的均值和方差，稳定了训练过程，提高了模型的收敛速度和泛化能力。

然而，归一化层的计算开销较大，尤其是在大规模模型中，这促使研究者探索无需归一化层的训练方法。本文提出了一种简单而有效的替代方案——**Dynamic Tanh（DyT）**，它通过一个元素级的操作来模拟归一化层的行为，同时避免了计算激活统计量的需要。

# 2. Dynamic Tanh

**DyT**的设计灵感来源于对归一化层行为的观察。研究者发现，在训练好的**Transformer**模型中，归一化层的输入-输出映射呈现出类似**tanh**函数的**S**形曲线。这种映射不仅对输入激活值进行了缩放，还对极端值进行了压缩。

![](https://pic1.imgdb.cn/item/67e532360ba3d5a1d7e52735.png)

**DyT**通过学习一个合适的缩放因子$α$，实现了类似的效果，同时避免了计算激活统计量的开销。

![](https://pic1.imgdb.cn/item/67e532640ba3d5a1d7e5273e.png)

**DyT**的核心思想是通过一个可学习的标量参数$α$和**tanh**函数来动态调整输入激活值：

$$
\text{DyT}(x)=γ⋅\tanh(αx)+β
$$

其中，$x$ 是输入张量，$α$ 是一个可学习的标量参数，用于调整输入的缩放比例；$γ$ 和 $β$ 是每个通道的可学习向量参数，用于调整输出的范围。**DyT**的操作非常简单，可以直接替换**Transformer**架构中的归一化层，而无需对其他部分进行修改。

![](https://pic1.imgdb.cn/item/67e532c10ba3d5a1d7e52758.png)
![](https://pic1.imgdb.cn/item/67e532e10ba3d5a1d7e5275e.png)

# 3. 实验分析

对于图像分类任务，研究者在**ImageNet-1K**数据集上对**Vision Transformer（ViT）**和**ConvNeXt**进行了实验。实验结果表明，使用**DyT**的模型在分类精度上与使用**LN**的模型相当，甚至在某些情况下表现更好。例如，**ViT-B**模型使用**DyT**后，分类精度从**82.3%**提升到**82.5%**；**ConvNeXt-B**模型使用**DyT**后，分类精度保持在**83.7%**。

![](https://pic1.imgdb.cn/item/67e5331f0ba3d5a1d7e52776.png)

在自监督学习任务中，研究者使用了**Masked Autoencoders（MAE）**和**DINO**两种方法。实验结果表明，**DyT**在这些任务中表现与**LN**相当。例如，**MAE ViT-B**模型使用**DyT**后，分类精度保持在**83.2%**；**DINO ViT-B**模型使用**DyT**后，分类精度从**83.2%**提升到**83.4%**。

![](https://pic1.imgdb.cn/item/67e533470ba3d5a1d7e52780.png)

对于扩散模型，研究者在**Diffusion Transformer（DiT）**模型上进行了实验，测试了不同大小的模型在**ImageNet-1K**数据集上的表现。实验结果表明，使用**DyT**的模型在**Fréchet Inception Distance（FID）**上与使用**LN**的模型相当或更好。例如，**DiT-B**模型使用**DyT**后，**FID**从**64.9**降低到**63.9**。

![](https://pic1.imgdb.cn/item/67e533660ba3d5a1d7e52785.png)

对于大型语言模型，研究者在**LLaMA**模型上进行了实验，测试了不同大小的模型在**The Pile**数据集上的表现。实验结果表明，使用**DyT**的模型在训练损失和零样本任务上的表现与使用**RMSNorm**的模型相当。例如，**LLaMA 7B**模型使用**DyT**后，性能从**1.59**提升到**1.60**。

![](https://pic1.imgdb.cn/item/67e533ae0ba3d5a1d7e52797.png)

对于语音自监督学习，研究者在**wav2vec 2.0**模型上进行了实验，测试了模型在**LibriSpeech**数据集上的表现。实验结果表明，使用**DyT**的模型在验证损失上与使用**LN**的模型相当。例如，**wav2vec 2.0 Base**模型使用**DyT**后，验证损失保持在**1.95**。

![](https://pic1.imgdb.cn/item/67e533d30ba3d5a1d7e5279c.png)

对于**DNA**序列建模，研究者在**HyenaDNA**和**Caduceus**模型上进行了实验，测试了模型在人类参考基因组数据上的表现。实验结果表明，使用**DyT**的模型在分类精度上与使用**LN**的模型相当。例如，**HyenaDNA**模型使用**DyT**后，分类精度保持在**85.2%**。

![](https://pic1.imgdb.cn/item/67e533ed0ba3d5a1d7e5279e.png)

研究者还对**DyT**的计算效率进行了分析。实验结果表明，**DyT**在训练和推理速度上显著优于**RMSNorm**。例如，在**LLaMA 7B**模型上，**DyT**在推理阶段的时间减少了**52.4%**，在训练阶段的时间减少了**8.2%**。这表明**DyT**在效率上有显著优势，适合用于对效率有要求的网络设计。

![](https://pic1.imgdb.cn/item/67e534270ba3d5a1d7e527ac.png)