---
layout: post
title: 'scNCL: transferring labels from scRNA-seq to scATAC-seq data with neighborhood contrastive regularization'
date: 2025-09-21
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/697714eca583b567209b7b7f.png'
tags: 论文阅读
---

> scNCL：通过邻域对比正则化从RNA迁移标签到ATAC.

- paper：[scNCL: transferring labels from scRNA-seq to scATAC-seq data with neighborhood contrastive regularization](https://academic.oup.com/bioinformatics/article/39/8/btad505/7243158)

# 0. TL; DR

**scNCL** 是一种从**scRNA-seq**向**scATAC-seq**进行标签迁移方法。**scNCL**首先将**scATAC-seq**的**peak**特征转换为**基因活性矩阵（gene activity matrix, GAM）**，引入**邻域对比学习（neighborhood contrastive learning, NCL）**，通过保持细胞在原始**peak**特征空间中的邻近结构，来弥补特征转换带来的信息损失。

为了学习一个可迁移的潜在特征，**scNCL**通过一个统一的神经网络框架，协同优化四个损失函数：
1.  **特征投影正则化损失（Projection Regularization Loss）：** 用于规范化潜在空间的结构。
2.  **特征对齐损失（Feature Alignment Loss）：** 用于协调**scRNA-seq**和**scATAC-seq**的嵌入。
3.  **交叉熵损失（Cross-Entropy Loss）：** 在**scRNA-seq**数据上进行有监督学习，以学习细胞类型的区分性特征。
4.  **邻域对比学习损失（NCL Loss）：** 在**scATAC-seq**数据上进行自监督学习，以保持其原始的拓扑结构。

在多个基准数据集上的实验表明，**scNCL**不仅在常见类型的标签迁移任务上实现了高准确性和鲁棒性，而且在新类型的检测上也表现出可靠的性能。

# 1. 背景介绍

单细胞**ATAC-seq**（**scATAC-seq**）技术为我们打开了一扇观察细胞表观遗传调控世界的窗户，它能够测量染色质的开放状态，从而帮助我们理解基因调控网络。然而，要从这些数据中准确地鉴定细胞类型，却是一项艰巨的任务。其主要挑战来自**scATAC-seq**数据固有的三大难题：高维度（数十万个**peaks**）、极端稀疏性（大量的零值）和不断增大的数据规模。

与此同时，我们已经积累了大量经过精心注释的单细胞**RNA-seq**（**scRNA-seq**）数据集。一个自然而然的想法是：我们能否利用这些注释丰富的**scRNA-seq**数据作为参考图谱，来自动地为那些难以注释的**scATAC-seq**数据打上标签？

这个任务被称为**标签迁移（label transfer）**，它属于**对角整合（diagonal integration）**的范畴。因为在这类任务中，两个数据集的细胞是**非配对（unpaired）**的，它们的特征也是**不匹配（unmatched）**的（一个是基因，一个是**peaks**）。

现有的对角整合方法主要采用两种策略来处理异构特征：
1.  简化为水平整合。这种策略首先将**scATAC-seq**的**peak**特征，通过一些生物学先验知识（如基因与启动子的关系），转换为一个基因活性矩阵。这样两种数据就有了共同的基因特征，问题就简化为了一个标准的水平整合任务。这种方法降低了**scATAC-seq**的特征维度，减少了计算复杂度，并通过共享特征空间降低了过度对齐的风险。但特征转换过程是有损的。将分散的**peak**信号强行聚合到基因上，不可避免地会丢失原始的、精细的调控信息，从而影响整合性能。
2.  直接对原始特征建模。这种策略直接将**scRNA-seq**的基因矩阵和**scATAC-seq**的**peak**矩阵，分别输入到不同的神经网络中，然后通过对抗训练或最大均值差异等方法，在潜在空间中对齐它们。这种方法保留了原始数据的全部信息。但由于缺乏任何先验的对应关系，这种端到端的对齐很容易陷入人工对齐或过度对齐的陷阱，即模型可能只是在数学上将两个分布拉近，而忽略了真实的生物学对应关系。

作者认为，简化为水平整合是一个很好的起点，但必须解决其信息损失的弊病。为此，作者提出了**scNCL**。它引入了邻域对比学习，旨在补偿特征转换过程中丢失的结构信息，从而实现更精准、更鲁棒的标签迁移。

# 2. scNCL 方法

**scNCL**是一个基于神经网络的半监督框架，其核心在于通过四个协同工作的损失函数，来学习一个既具区分度又可迁移的潜在空间。

![](https://pic1.imgdb.cn/item/69771783a583b567209b7c14.png)

## 2.1 模型架构

**scNCL**的架构主要包含两个部分：一个特征提取器网络 $f$，和一个分类器网络 $g$。

输入包括一个带标签的**scRNA-seq**数据集的**基因表达矩阵（GEM）** $X_l$、一个无标签的**scATAC-seq**数据集的**基因活性矩阵（GAM）** $X_u$、一个根据原始**scATAC-seq peak**数据构建的**kNN**图。

特征提取器 $f$（由参数 $\theta$ 化的神经网络）负责将输入的**GEM**或**GAM**投影到一个低维的嵌入空间中，得到嵌入向量 $h_u = f(x_u, \theta)$ 和 $h_l = f(x_l, \theta)$。分类器 $g$ 接收嵌入向量 $h$，并通过**Softmax**层输出其属于K个已知细胞类型的概率向量 $r$。

## 2.2 损失函数

为了训练出高质量的特征提取器 $f$ 和分类器 $g$，**scNCL**设计了四个损失函数，它们共同作用于模型的学习过程。

### 2.2.1 交叉熵损失 (Cross Entropy Loss, $L_{CE}$)

这是模型进行有监督学习的基础。它只作用于带标签的**scRNA-seq**数据 $X_l$，其目标是最小化预测标签与真实标签之间的交叉熵。

$$
L_{CE} = -\frac{1}{|B_l|} \sum_{b \in B_l} \sum_{k=1}^K 1(y_b^l = k) \cdot \log(r_b(k))
$$

这个损失函数驱动模型学习能够区分不同细胞类型的判别性特征。

### 2.2.2 投影正则化损失 (Projection Regularization Loss, $L_{PR}$)

该损失项改编自**scJoint**中的**NNDR**损失，旨在正则化整个潜在空间的结构，使其具有良好的形状（正交且变化大）。

原始**NNDR**损失包含三个部分：最大化嵌入的方差、最小化嵌入维度间的相关性（促使正交）、以及将嵌入的均值固定在零附近。作者发现，如果将完整的**NNDR**损失同时应用于**scRNA-seq**和**scATAC-seq**，可能会加剧两者嵌入空间的不对齐。因为**scRNA-seq**的嵌入还受到**CE**损失的影响，其方差会增长得更快。

因此对于**scRNA-seq**数据，只使用**NNDR**的后两项（正交化和中心化）；对于**scATAC-seq**数据，则使用完整的**NNDR**损失。这种非对称的正则化，有助于保持两种模态嵌入的方差增长速度一致，从而促进对齐。

### 2.2.3 特征对齐损失 (Feature Alignment Loss, $L_{FA}$)

这个损失项的目的是显式地协调和对齐**scRNA-seq**和**scATAC-seq**的嵌入。在每个**mini-batch**中，对于**scATAC**数据中的每个细胞，作者在**scRNA**数据中找到与其嵌入余弦相似度最高的那个细胞。然后，选取相似度得分最高的$p\%$的细胞对，并最大化它们之间的余弦相似度。

$$
L_{FA}(B_u) = - \frac{1}{|F_p|} \sum_{b \in F_p} \cos(h_b^u, h_i^l)
$$

这个损失项直接将可能属于同一类型的细胞在潜在空间中拉近。

### 2.2.4 邻域对比学习损失 (Neighborhood Contrastive Learning Loss, $L_{NCL}$)

这个损失旨在解决**GAM**转换带来的信息损失问题。如果两个**scATAC-seq**细胞在原始的**peak**空间中是近邻，那么它们在**scNCL**学习到的潜在空间中也应该是近邻。

首先在原始的**scATAC-seq peak**数据上构建一个**kNN**图。在训练时，对于**mini-batch**中的每个**scATAC**细胞 $x_b^u$，从其**kNN**图中随机采样一个邻居 $\hat{x}_b^u$，构成一个正样本对。**mini-batch**中的所有其他细胞都构成负样本对。

然后通过一个对比损失函数，来拉近正样本对的嵌入（$h_b^u$ 和 $\hat{h}_b^u$），同时推开负样本对的嵌入。

$$
L_{NCL} = -\frac{1}{2N} \sum_{b=1}^N \left( \log \frac{r(h_b^u, \hat{h}_b^u)}{\sum_r r(h_b^u, \hat{h}_r^u) + \sum_{r \ne b} r(h_b^u, h_r^u)} + \log \frac{r(\hat{h}_b^u, h_b^u)}{\sum_r r(\hat{h}_b^u, h_r^u) + \sum_{r \ne b} r(\hat{h}_b^u, \hat{h}_r^u)} \right)
$$

其中 $r(u, v) = \exp(\langle u, v \rangle / (\tau \|u\| \|v\|))$ 是基于余弦相似度的函数。

这个**NCL**损失作为一种强大的正则化项，有效地将原始**peak**空间的拓扑结构信息注入到模型的学习过程中，从而弥补了**GAM**转换造成的信息损失。

# 3. 实验分析

作者在四个大规模、跨物种、跨平台的数据集上，将**scNCL**与七种SOTA方法（**Seurat 4**, **scGCN**, **scNym**, **Portal**, **Concerto**, **scJoint**, **GLUE**）进行了全面的比较。

## 3.1 实验一：常见类型迁移

作者首先在**scRNA-seq**和**scATAC-seq**数据具有相同细胞类型的场景下，评估了各方法的标签迁移准确性。

在所有测试数据集上，**scNCL**的总体准确率均名列前茅。在复杂的**MCA-subset**和**HFA-subset**数据集上，**scNCL**的性能显著优于其他所有方法（图a）。混淆矩阵显示，**scNCL**不仅在大类上表现出色，在稀有细胞类型（如仅占2%的单核细胞）的识别上也远超其他方法（图b）。**UMAP**可视化直观地证实了这一点。在**scNCL**的嵌入空间中，稀有的单核细胞和**NK**细胞形成了清晰、独立的簇；而在**scJoint**的嵌入中，它们则与其他细胞类型混杂在一起（图c）。

![](https://pic1.imgdb.cn/item/69771b4ba583b567209b7d07.png)

## 3.2 实验二：新类型检测

在更真实的场景中，**scATAC-seq**数据中往往包含**scRNA-seq**参考数据中所没有的新类型。一个好的迁移学习方法，不仅要能准确标注常见类型，还要能可靠地识别出这些新类型。

作者使用**CITE-ASAP**和**MCAOS**两个包含新类型的数据集进行了测试，并通过**OSCR**（综合了常见类型准确率和新类型检测率的指标）和**AUROC**来评估性能。

在两个数据集上，**scNCL**都取得了最高的**OSCR**得分，实现了在准确标注和发现新奇之间的最佳平衡（图ab）。作者通过**核密度估计（KDE）**图，可视化了模型对常见类型和新类型的预测置信度分布。结果显示，**scNCL**对常见类型的预测置信度主要集中在1附近，而对新类型的预测置信度则集中在0附近，两者分布分离得非常清晰。相比之下，**scJoint**对所有类型的细胞都给出了高置信度，使其难以区分新类型（图c）。

![](https://pic1.imgdb.cn/item/69771b8ba583b567209b7d1e.png)

这些结果表明，**scNCL**拥有卓越的新类型检测能力。

## 3.3 实验三：优化现有图谱的注释

最后，作者展示了**scNCL**的一个强大应用：利用高质量的**scRNA-seq**图谱，来纠正和优化一个已标注的**scATAC-seq**图谱中的潜在错误。

在**MCA**数据集中，作者发现**scNCL**将一批原始被标注为内皮细胞的肺部细胞，高置信度地重新标注为了**基质细胞（stromal cells）**。通过检查**marker**基因（如**Pecam1**和**Col1a1**）的表达，作者证实了**scNCL**的新注释是正确的（图ab）。

类似地，**scNCL**将一批心脏中的内皮细胞修正为了**成纤维细胞（fibroblast）**，这也得到了**marker**基因（**Cav1**和**Dcn**）表达的支持（图cd）。

![](https://pic1.imgdb.cn/item/69771bd9a583b567209b7d29.png)

这些案例有力地证明，**scNCL**不仅是一个标签迁移工具，更是一个强大的生物学发现和注释优化工具。