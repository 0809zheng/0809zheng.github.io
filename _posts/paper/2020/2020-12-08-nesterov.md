---
layout: post
title: 'On the importance of initialization and momentum in deep learning'
date: 2020-12-08
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/61f50c0e2ab3f51d913fcb3b.jpg'
tags: 论文阅读
---

> Nesterov Momentum：一种动量梯度更新方法.

- paper：[On the importance of initialization and momentum in deep learning](http://www.cs.toronto.edu/~hinton/absps/momentum.pdf)



**Momentum**动量法是一种加速梯度下降的方法，它在参数更新的过程中不断累积梯度值：

$$ v_{t+1} = \mu v_t + \epsilon \nabla f(\theta_t) \\ \theta_{t+1} = \theta_t - v_{t+1} $$

其中$\epsilon$是学习率，$\mu$是动量系数。

**Nesterov**动量法也是一种一阶优化方法，它通常具有更好的收敛速率。**Nesterov**动量法计算为：

$$ v_{t+1} = \mu v_t + \epsilon \nabla f(\theta_t-\mu v_t) \\ \theta_{t+1} = \theta_t - v_{t+1} $$

**Momentum**更新方向是当前动量方向$\mu v_t$和当前梯度方向$\epsilon \nabla f(\theta_t)$的矢量和；而**Nesterov**更新方向是当前动量方向$\mu v_t$和沿当前动量方向的下一次梯度方向$\epsilon \nabla f(\theta_t-\mu v_t)$的矢量和：

![](https://pic.downk.cc/item/5e90327d504f4bcb047deaef.jpg)

直观来看，**Nesterov**使用$\theta_t-\mu v_t$处的梯度代替$\theta_t$处的梯度，以赋予算法一定的前瞻能力：即并不直接使用当前参数位置下的梯度更新参数，而是计算当前参数被当前梯度修正后的参数位置处的梯度。

在目前常用的深度学习框架中，计算梯度$\nabla f(\theta_t-\mu v_t)$比计算梯度$\nabla f(\theta_t)$更加繁琐，为了简化计算，对**Nesterov**动量更新公式做如下修改。

**Nesterov**的参数更新公式表示为：

$$  \theta_{t+1} = \theta_t - v_{t+1} = \theta_t - \mu v_t - \epsilon \nabla f(\theta_t-\mu v_t) $$

等式两端减去$\mu v_{t+1}$：

$$  \theta_{t+1} - \mu v_{t+1} = \theta_t - \mu v_t - \mu v_{t+1} - \epsilon \nabla f(\theta_t-\mu v_t) $$

定义：

$$ \Theta_t = \theta_t-\mu v_t $$

则参数更新的迭代公式也可以写作：

$$  \Theta_{t+1} = \Theta_t - \mu v_{t+1} - \epsilon \nabla f(\Theta_t) $$

其中动量的更新公式如下：

$$ v_{t+1} = \mu v_t + \epsilon \nabla f(\Theta_t)  $$

目前主流的深度学习框架均采用上述参数更新的形式，以避免计算梯度时的自变量变化。随着迭代逐渐靠近极值点，动量$v$逐渐减少，从而使得$\Theta$和$\theta$趋近于等价。

综上所述，实践中**Nesterov**的参数更新公式表示为：

$$ v_{t+1} = \mu v_t + \epsilon \nabla f(\theta_t) \\ \theta_{t+1} = \theta_t - \mu v_{t+1} - \epsilon \nabla f(\theta_t) $$

### ⚪ 另一种形式

在**Pytorch**等框架中，**Momentum**动量法采用如下形式：

$$ v_{t+1} = \mu v_t + \nabla f(\theta_t) \\ \theta_{t+1} = \theta_t -\epsilon  v_{t+1} $$

此时**Nesterov**也有类似的修改：

$$ v_{t+1} = \mu v_t +  \nabla f(\theta_t) \\ \theta_{t+1} = \theta_t - \epsilon(  \nabla f(\theta_t) + \mu v_{t+1} ) $$