---
layout: post
title: 'Generating Diverse High-Fidelity Images with VQ-VAE-2'
date: 2020-11-11
author: 郑之杰
cover: 'https://pic.downk.cc/item/5faa5c321cd1bbb86bb79557.jpg'
tags: 论文阅读
---

> VQ-VAE-2：改进VQ-VAE生成高保真度图像.

- paper：[Generating Diverse High-Fidelity Images with VQ-VAE-2](https://arxiv.org/abs/1906.00446?context=cs.CV)

**VQ-VAE-2**模型相比[<font color=Blue>VQ-VAE</font>](https://0809zheng.github.io/2020/11/10/vqvae.html)几乎没有本质上的技术更新，而是对结构进行了分层，即把编码和解码都分成两层来做（一层整体，一层局部），从而使得生成的图像更清晰。**VQ-VAE-2**模型的整体结构如下图所示。

![](https://pic.downk.cc/item/5facd9c11cd1bbb86b468c07.jpg)

将尺寸为$256 \times 256$的原始图像$x$输入网络，经过编码器获得**bottom**层和**top**层的编码。

**top**层编码得到全局特征$E_{top}(x)$，尺寸为$32 \times 32$。经过向量量化后得到离散编码$e_{top}$。

**bottom**层接收上层编码$e_{top}$，编码得到局部特征$E_{bottom}(x)$，尺寸为$64 \times 64$。经过量化后得到离散编码$e_{bottom}$。

将两个离散的编码喂入解码器，重构图像。

模型训练完成之后，需要对离散的隐空间进行建模，继而从中抽样进行图像生成。这一过程如下图所示。

![](https://pic.downk.cc/item/5facd9d31cd1bbb86b4690e8.jpg)

作者使用**PixelCNN**拟合离散的隐空间，该隐空间是通过所有图像数据构建的。对所有输入图像计算离散编码$e_{top}$和$e_{bottom}$，训练**PixelCNN**网络得到全局信息的联合概率密度$p_{top}$和局部信息的联合概率密度$p_{bottom}$。

对$e_{top}$建模，作者引入了多头自注意力机制。对$e_{bottom}$建模，使用了顶层作为条件信息。

完整的算法流程如下：

![](https://pic.downk.cc/item/5facdd551cd1bbb86b4790aa.jpg)