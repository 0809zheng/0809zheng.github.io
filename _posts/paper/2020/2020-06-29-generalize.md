---
layout: post
title: 'Do ImageNet Classifiers Generalize to ImageNet?'
date: 2020-06-29
author: 郑之杰
cover: 'https://pic.downk.cc/item/5ef959ea14195aa59406cdd0.jpg'
tags: 论文阅读
---

> 一篇讨论图像分类模型泛化能力的文章.

- paper：Do ImageNet Classifiers Generalize to ImageNet?
- arXiv：[link](https://arxiv.org/abs/1902.10811?context=cs.CV)

本文研究的问题是，对一个图像分类模型，在一个数据集上训练后测试得到准确率，将其应用到另一个测试数据集上会有怎样的表现。

# 初步的实验结果和假设

![](https://pic.downk.cc/item/5ef97edb14195aa59410a308.jpg)

把数据集划分成训练集和测试集，经过训练后在测试集上取得了很高的测试准确率，然后构造一个新的测试集，测试模型在其上的准确率。如上图所示，在CIFAR-10和ImageNet两个数据集上进行试验。

假设基准为在原测试集上测试的准确率等于在新测试集上测试的准确率，用图中的黑色虚线表示。当实验结果出现在虚线下时，表明模型出现了一定程度的过拟合。

观察实验结果，发现两个现象：
1. 新测试集上的准确率相比于原测试集有显著的下降；
2. 模型准确率近似于斜率大于1的线性函数。

若用$D$表示原测试集所属的数据分布，$S$表示原测试集；用$D'$表示新测试集所属的数据分布，$S'$表示新测试集；将模型在原测试集上的表现和新测试集上的表现差异拆分为：

![](https://pic.downk.cc/item/5ef9813814195aa59411359e.jpg)

- **Adaptivity gap**：原测试集采样带来的误差
- **Distribution gap**：两个数据集分布不同带来的误差。是造成**gap**的主要原因。
- **Generalization gap**：新测试集采样带来的误差

# 进一步的实验
作者在**MTurk**上以问卷调查的形式构造新的测试集。具体地，每次向实验者提供一些图像和一个类别，让实验者勾选出类别对应的图像。每一个类别图像根据实验者的勾选频率构造新的数据集，采用三种抽样策略：
- **MatchedFrequency**：每一类首先估计勾选频率分布，按照该分布进行抽样；
- **Threshold0.7**：每一类在勾选频率大于0.7的图像中随机选择10张；
- **TopImages**：每一类选择10张勾选频率最高的图像。

![](https://pic.downk.cc/item/5ef9850f14195aa5941259b6.jpg)

实验结果显示，人类更擅长区分的数据，模型泛化能达到更好的结果。

# 线性拟合模型
作者假设模型在原测试集上的表现$α_1$与模型在新测试集上的表现$α_2$呈线性关系，即：

$$ α_2 = u·α_1+v $$

假设第$i$个样本具有分类困难度$τ_i$，第$j$个模型具有能力$s_j$。当$s_j>>τ_i$时分类准确率是1，反之是0。采用均值为$μ$、方差为$σ^2$的高斯分布的累积分布函数建模：

$$ ξ_j(τ) = Φ(s_j-τ) $$

经推导可得线性模型的参数：

$$ u = \frac{\sqrt{σ_1^2+1}}{\sqrt{σ_2^2+1}} $$

$$ v = \frac{μ_1-μ_2}{\sqrt{σ_2^2+1}} $$
