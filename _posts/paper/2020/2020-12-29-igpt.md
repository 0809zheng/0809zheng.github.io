---
layout: post
title: 'Generative Pretraining from Pixels'
date: 2020-12-29
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fea917f3ffa7d37b3c2e7ac.jpg'
tags: 论文阅读
---

> iGPT：像素级的图像预训练模型.

- paper：Generative Pretraining from Pixels
- ICML2020：[link](https://paperswithcode.com/paper/generative-pretraining-from-pixels)
- code：[github](https://github.com/openai/image-gpt)

# 模型介绍

![](https://pic.downk.cc/item/5feab7293ffa7d37b3014ebb.jpg)

模型的整体流程如上图所示。模型包括预训练和微调两个阶段。预训练阶段可以看做一种初始化或正则化方法；微调阶段加了一层分类器进行图像分类任务。

首先把输入图像进行下采样，将其转化为$1D$序列；其次进行进行模型预训练，采用两种预训练方法：**next pixel prediction**和**masked pixel prediction**。值得一提的是，基于卷积神经网络的模型大多采用**分类**进行预训练，而这里使用**图像生成**进行预训练。

**next pixel prediction**是一种**自回归(auto-regressive)**的预训练方法，在**GPT**等预训练语言模型中也有类似的应用。该方法根据前面的像素值预测下一个像素的值（采用**光栅顺序 raster order**），并最终对图像的概率密度$p(x)$进行整体建模：

$$ p(x) = \prod_{i=1}^{n} p(x_{\pi_{i}}|x_{\pi_{1}},...,x_{\pi_{i-1}},\theta) $$

其训练的目标函数为最小化负对数似然：

$$ L_{AR} = \Bbb{E}_{x \text{~}X}[-logp(x)] $$

**masked pixel prediction**在**BERT**等预训练语言模型中有类似的应用。该方法首先遮挡输入序列若干位置的值，并对这些值进行预测。预先设置$M$个**mask**，则训练目标函数为最小化相应位置元素的负对数似然：

$$ L_{BERT} = \Bbb{E}_{x \text{~}X}\Bbb{E}_{M}\sum_{i \in M}^{}[-logp(x_i|x_{[1,n]/ m})] $$

通过预训练，模型学习到输入图像序列的分层特征表示。有两种进行评估和后续任务的方法：**linear probe**和**finetune**。

**linear probe**是采用一个简单的线性分类器对模型内部某一层的特征进行分类的方法。该方法能够测试中间特征的线性可分性。具体地，对某一层的所有特征进行全局平均池化，将其转化为一个特征张量，并根据该张量进行分类任务。而**finetune**允许进行下游任务时对原模型参数进行微调，使用模型最后一层的特征。**finetune**时同时优化$L_{GEN}+L_{CLF}$会得到更好的结果（$L_{GEN}$代表生成**AR**或**BERT**损失，$L_{CLF}$代表分类损失）。

# 实验分析
作者在**ImageNet**数据集上进行预训练，并测试了在三个不同的小型数据集上**linear probe**方法的准确率。如下图所示，作者发现提供分类准确率最高的特征并不是网络提取的深层特征，而是中间层的某个特征。作者认为，这是因为该模型在训练时浅层学习到低语义的通用特征；中间层学习到高语义的通用特征，而这些特征适合分类等**high-level**任务；更深层学习到属于该图像的更具体的特征，这些特征对图像生成等**low-level**任务有帮助。

![](https://pic.downk.cc/item/5feab74b3ffa7d37b30184d5.jpg)

作者按照**GPT-2**的模型结构设计了本实验的模型。通过设置不同的模型大小，实验发现越大的模型能够学习到更好的特征，并且其验证损失也会更小。

![](https://pic.downk.cc/item/5feab7a53ffa7d37b30215d6.jpg)

作者还比较了两种预训练方式的差别。下图蓝色表示使用**linear probe**进行验证，橙色表示使用**finetune**进行验证。实验发现仅通过预训练**AR**目标能够比**BERT**目标获得更高的准确率；但经过微调后两者就差不多了。

![](https://pic.downk.cc/item/5feab7c43ffa7d37b302450d.jpg)