---
layout: post
title: 'A Note on the Inception Score'
date: 2022-03-25
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/638ee015b1fccdcd36f560c2.jpg'
tags: 论文阅读
---

> GAN的Inception Score评估指标.

- paper：[A Note on the Inception Score](https://arxiv.org/abs/1801.01973)

对于**GAN**生成的图像，**Inception Score**借助图像分类任务评估生成图像的质量。具体地，使用在**ImageNet**数据集上训练的**Inception**模型对生成图像$x$进行分类，得到类别标签$y$；然后从两个方面分别评估图像的质量：
1. 单张图像的质量：对于任意一张图像，如果其包含的的主要物体容易被分类网络进行正确的分类，则说明图像生成的质量较高；较高的图像分类置信度对应$p(y\|x)$具有较小的熵；![](https://pic.downk.cc/item/5ed9e362c2a9a83be5ecc47e.jpg)
2. 图像集的多样性：对于所有生成的图像，希望具有多样性，即图像的平均标签$\overline{y}$分布比较均匀，对应$p(\overline{y})$具有较大的熵。![](https://pic.downk.cc/item/5ed9e388c2a9a83be5ecea9c.jpg)

综上考虑，对某一张具体的生成图像，分类网络的输出分布越集中越好（熵越小越好）；对于所有生成图像，分类网络的平均输出分布越平均越好（熵越大越好）。则评估指标应具有以下形式(数值越大越好)：

$$ \begin{aligned} &-H[P(y|x)] + H[P(y)] \\ &=   \frac{1}{N} \sum_{n}^{} P(y^n | x^n)\log P(y^n | x^n) - (\frac{1}{N} \sum_{n}^{} P(y^n | x^n)) \log (\frac{1}{N} \sum_{n}^{} P(y^n | x^n)) \end{aligned} $$

![](https://pic.downk.cc/item/5ed9e3e9c2a9a83be5ed87a3.jpg)

**Inception Score**定义如下：

$$ \begin{aligned} \text{IS}(G) &= \exp(\Bbb{E}_{x \text{~} p(x)}[D_{KL}(p(y|x)||p(y))])  \end{aligned} $$

其中$D_{KL}$表示[KL散度](https://0809zheng.github.io/2020/02/03/kld.html#-kl%E6%95%A3%E5%BA%A6-kullback-leibler-divergence)，它可以写作：

$$ \begin{aligned} D_{KL}(p(y|x)||p(y)) &= \Bbb{E}_{p(y|x)}[\log \frac{p(y|x)}{p(y)}] \\ & = \Bbb{E}_{p(y|x)}[\log p(y|x)] - \Bbb{E}_{p(y|x)}[\log p(y)] \\ & \text{（假设} x,y \text{独立）} \\ & = \Bbb{E}_{p(y|x)}[\log p(y|x)] - \Bbb{E}_{p(y)}[\log p(y)] \\ & = -H[p(y|x)] + H[p(y)] \end{aligned} $$

因此当$x$与$y$独立时，上述**KL**散度等价于$p(y\|x)$的负熵与$p(y)$的熵之和。若$p(y\|x)$的熵越小，表明单张图像的分类效果越好；若$p(y)$的熵越大，表明所有图像的多样性越好；两者都对应较大的**Inception Score**。

**Inception Score**的缺点是没有使用真实世界样本的统计数据；并且依赖于分类任务，比如使用**ImageNet**数据集训练的**Inception**评估生成其他数据集的**GAN**模型是不合适的。