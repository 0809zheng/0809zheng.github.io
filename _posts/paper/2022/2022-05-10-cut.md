---
layout: post
title: 'Contrastive Learning for Unpaired Image-to-Image Translation'
date: 2022-05-10
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63e354804757feff33126c1f.jpg'
tags: 论文阅读
---

> 无配对数据图像到图像翻译中的对比学习.

- paper：[Contrastive Learning for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2007.15651)

本文提出了一种基于对比学习的图像到图像翻译方法**Contrastive  Unpaired Translation (CUT)**，该方法不依赖于配对数据，而是根据任意边缘分布$p(X)$和$p(Y)$学习条件映射$f_{x \to y}=p(Y\|X)$和$f_{y \to x}=p(X\|Y)$。

**CUT**的整体结构是采用生成对抗网络实现的。生成器$G$把一种类型的图像$x$转换为另一种类型的图像$\hat{y}=G(x)$，损失函数构造为对比损失；判别器同时接收两种类型的图像$(\hat{y},y)$，判断其是否为真实图像，损失函数为对抗损失。

![](https://pic.imgdb.cn/item/63e3585d4757feff33191e07.jpg)

在构造对比损失时，把输入图像$x$和生成图像$\hat{y}$通过生成器的编码部分提取特征，然后使用多层感知机$H_l$对特征进行变换。此时特征的每个像素位置对应原始图像的一个图像块；则两个图像相同位置的图像块对应的特征向量为正样本对，其余位置的特征向量为负样本。基于此可以构造对比损失：

$$ \mathcal{L}(v,v^+,v^-) = -\log [\frac{\exp(v \cdot v^+/ \tau)}{\exp(v \cdot v^+/ \tau)+
\sum_{n=1}^N \exp(v \cdot v^-_n/ \tau)}] $$

![](https://pic.imgdb.cn/item/63e358b54757feff3319a783.jpg)

上述对比损失中的每个特征向量对应一个图像块，因此称为**PatchNCE**损失。其实现过程如下：

![](https://pic.imgdb.cn/item/63e35a634757feff331c7ca1.jpg)

此外，在构造对比损失时作者还采用了如下策略：
- **Multilayer**：对生成器的编码部分的不同层的特征构造对比损失；
- **Stop gradient**：停止查询特征$v$(来源于生成图像$\hat{y}$)的梯度；
- **Identity loss**：引入恒等损失，即目标域图像$y$经过生成器后图像风格应该保持不变。在实践中通过构造目标域图像$y$与其生成图像$$\tilde{y}$$之间的**PatchNCE**损失实现；
- **External NCE loss**：使用来自其他图像的特征向量作为负样本。

上述不同策略的消融结果如下：

![](https://pic.imgdb.cn/item/63e35c2e4757feff331f96b2.jpg)


