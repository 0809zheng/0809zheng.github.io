---
layout: post
title: 'Deep Active Learning: Unified and Principled Method for Query and Training'
date: 2022-08-22
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/632adb8516f2c2beb1020a93.jpg'
tags: 论文阅读
---

> WAAL：使用Wasserstein距离建模主动学习的查询过程.

- paper：[Deep Active Learning: Unified and Principled Method for Query and Training](https://arxiv.org/abs/1911.09162)

本文作者采用**Wasserstein**距离将主动学习中的查询过程建模为分布匹配问题，并设计了一种新的训练损失，通过交替优化优化深层神经网络参数和批量查询选择。其中深度神经网络训练的损失被表示为最小-最大优化问题；而批量查询选择实现了样本不确定性和多样性的权衡。

记真实的数据分布为$$\mathcal{D}$$，主动学习旨在学习一个数据分布$$\mathcal{Q}$$，以最小化泛化误差；通常$$\mathcal{D} \neq \mathcal{Q}$$。

[<font color=blue>Wasserstein距离</font>](https://0809zheng.github.io/2022/05/16/Wasserstein.html)反映了将一个配送点转移到另一个配送点的最佳运输成本，定义为搜索两个概率分布$$\mathcal{D} , \mathcal{Q}$$的联合概率分布的最小成本：

$$ \mathcal{W}_p(\mathcal{D},\mathcal{Q}) = \mathop{\inf}_{\gamma \in \Pi[\mathcal{D},\mathcal{Q}]} \int_{\mathcal{X} \times \mathcal{X}}  c(x_{\mathcal{D}},x_{\mathcal{Q}})^p d \gamma (x_{\mathcal{D}},x_{\mathcal{Q}})  $$

本文主要讨论**Wasserstein-1**距离，即$p=1$。根据对偶理论**Wasserstein**距离也可以写作：

$$ \mathcal{W}_1(\mathcal{D},\mathcal{Q}) =  \mathop{\sup}_{g, ||g||_L \leq 1} \{  \Bbb{E}_{x \text{~} p(x)} [ g(x)] -\Bbb{E}_{x \text{~}q(x)}[g(x)]\} $$

记已标注样本集为$$\hat{L} = \frac{1}{L} \sum_{i=1}^L\delta \{x_i^l\}$$，未标注样本集为$$\hat{U} = \frac{1}{U} \sum_{i=1}^U\delta \{x_i^u\}$$，总样本集为$$\hat{D} = \hat{L}∪ \hat{U}$$。则主动学习的目的是在每次迭代中从未标注池中寻找一批样本$$\hat{B} = \frac{1}{B} \sum_{i=1}^B\delta \{x_i^b\}$$进行标注，并使得模型$h$在$$\hat{L}∪ \hat{B}$$上的经验风险$$\hat{R}$$最小化。若使用**Wasserstein**距离进行分布匹配，则目标函数为：

$$  \mathop{\min}_{\hat{B},h} \hat{R}_{\hat{L}∪ \hat{B}}(h) + \mu \mathcal{W}_1(\hat{D},\hat{L}∪ \hat{B}) $$

在深度学习中，**Wasserstein**距离常常通过对抗学习来实现，对应的网络应该由三部分构成：特征提取器$\theta^f$、任务预测器$\theta^h$和分布判别器$\theta^d$。此时对应的问题可以建模为一个最小-最大优化问题：

$$  \mathop{\min}_{\theta^f,\theta^h,\hat{B}} \mathop{\max}_{\theta^d} \hat{R}(\theta^f,\theta^h) + \mu \hat{E}(\theta^f,\theta^d) $$

其中$$\hat{R}$$使用预测损失来表示：

$$ \begin{aligned} \hat{R}(\theta^f,\theta^h) &= \Bbb{E}_{(x,y)\text{~}\hat{L}∪ \hat{B}} [\mathcal{L}(h(x,y);\theta^f,\theta^h)] \\ & = \frac{1}{L+B}\sum_{(x,y) \in \hat{L}∪ \hat{B}}\mathcal{L}(h(x,y)) \\ & = \frac{1}{L+B}\sum_{(x,y) \in \hat{L}}\mathcal{L}(h(x,y))+\frac{1}{L+B}\sum_{(x,y^?) \in \hat{B}}\mathcal{L}(h(x,y^?)) \end{aligned} $$

$\hat{E}$使用对抗损失来表示：

$$  \begin{aligned} \hat{E}(\theta^f,\theta^d) &= \Bbb{E}_{x\text{~}\hat{D}} [g(x;\theta^f,\theta^d)]-\Bbb{E}_{x\text{~}\hat{L}∪ \hat{B}} [g(x;\theta^f,\theta^d)] \\ &= \frac{1}{L+U}\sum_{x \in \hat{L}∪ \hat{U}}g(x) -\frac{1}{L+B}\sum_{x \in \hat{L}∪ \hat{B}}g(x) \\ &= \frac{1}{L+U}\sum_{x \in \hat{L}}g(x)+\frac{1}{L+U}\sum_{x \in  \hat{U}}g(x) -\frac{1}{L+B}\sum_{x \in \hat{L}}g(x) -\frac{1}{L+B}\sum_{x \in \hat{B}}g(x)  \\ & = \frac{1}{L+U}\sum_{x \in  \hat{U}}g(x) - (\frac{1}{L+B}-\frac{1}{L+U})\sum_{x \in \hat{L}} g(x) -\frac{1}{L+B}\sum_{x \in \hat{B}}g(x)\end{aligned} $$

将上述两式结合起来，则总目标函数如下：

![](https://pic.imgdb.cn/item/632d5d2e16f2c2beb1655ca8.jpg)

上述目标可以分两阶段进行交替优化，即训练网络和批次选择。

### ⚪ 训练网络

在网络训练阶段，使用所有样本优化网络参数，对应的目标函数为：

$$  \begin{aligned} \mathop{\min}_{\theta^f,\theta^h} \mathop{\max}_{\theta^d} & \frac{1}{L+B}\sum_{(x,y) \in \hat{L}}\mathcal{L}(h(x,y)) \\ & +\frac{1}{L+U}\sum_{x \in  \hat{U}}g(x) - (\frac{1}{L+B}-\frac{1}{L+U})\sum_{x \in \hat{L}} g(x) \end{aligned}  $$

该目标函数一方面最小化预测误差，另一方面有效地区分样本属于标注集还是未标注集。网络$g(x)$通过引入梯度惩罚项被限制为**1-Lipschitz**函数。

### ⚪ 冗余技巧

在训练过程中标注样本与未标注样本之间存在数据不平衡。作者提出一种冗余技巧来缓解不平衡问题。记不平衡率为$\gamma=\frac{U}{L}$，查询率为$\alpha=\frac{B}{L}$，则将对抗损失部分修改为：

$$ \frac{\gamma}{1+\gamma}\mu(\frac{1}{U}\sum_{x \in  \hat{U}}g(x)-\frac{1}{\gamma}\frac{\gamma-\alpha}{1+\alpha}\frac{1}{L}\sum_{x \in \hat{L}} g(x)) $$

在每个批次中，用于计算对抗损失的标注样本和未标注样本都选择$S$个，则对抗损失重写为：

$$  \mathop{\min}_{\theta^f} \mathop{\max}_{\theta^d} \frac{\gamma}{1+\gamma}\mu( \frac{1}{S}\sum_{x \in  \hat{U}_S}g(x) - \frac{1}{\gamma^2}\frac{\gamma-\alpha}{1+\alpha}\frac{1}{S}\sum_{x \in \hat{L}_S} g(x)) $$

### ⚪ 查询策略

查询策略旨在从未标注池中采样$B$个样本，从而实现以下优化目标：

$$  \mathop{\arg \min}_{\hat{B}⊂ \hat{U}} \frac{1}{L+B}\sum_{(x,y^?) \in \hat{B}}\mathcal{L}(h(x,y^?))-\frac{1}{L+B}\sum_{x \in \hat{B}}g(x)  $$

由于查询过程中标签$y^?$是不可知的，因此转而优化上述目标的一个上限。假设对于分类任务共有$K$个类别，则可以构造的上限有两种形式：

① 选择具有最大的类别最小置信度得分的样本。最小标签预测置信度比较高的样本通常是不确定性较大的样本：

$$ \mathop{\min}_{x} \mathcal{L}(h(x,y^?)) \leq \mathop{\min}_{x} \mathop{\max}_{y \in \{1,...,K\}} -\log (h(x,y)) $$

② 选择类别预测得分最平均的样本。预测结果更平均（熵更大）的样本通常是不确定性较大的样本：

$$ \mathop{\min}_{x} \mathcal{L}(h(x,y^?)) \leq \mathop{\min}_{x} \sum_{y \in \{1,...,K\}} -\log (h(x,y)) $$

另一方面，优化目标倾向于选择$g(x)=1$的样本，即被判别器判断为属于未标注池的样本。这样能增强已标注样本集的多样性。

算法总流程如下：

![](https://pic.imgdb.cn/item/632d650616f2c2beb16ed338.jpg)

实验结果表明所提算法非常具有竞争力：

![](https://pic.imgdb.cn/item/632d658816f2c2beb16f759f.jpg)