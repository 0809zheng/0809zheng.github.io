---
layout: post
title: 'ConvMAE: Masked Convolution Meets Masked Autoencoders'
date: 2022-11-25
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6558591ec458853aefb5d830.jpg'
tags: 论文阅读
---

> ConvMAE：结合掩码卷积与掩码自编码器.

- paper：[ConvMAE: Masked Convolution Meets Masked Autoencoders](https://arxiv.org/abs/2205.03892)

**ConvMAE** 是多尺度的金字塔式架构 + 局部的归纳偏置的模型，使用 **MAE** 的 **Self-supervised Learning** 的训练方式。与 **MAE-Base** 相比，**ConvMAE-Base** 将 **ImageNet-1k** 的微调精度提高到 **85.0% (+1.4%)**，将 **Mask-RCNN COCO** 检测任务的 **AP box** 提高到 **53.2% (+2.9%)**，将 **UperNet** 的 **ADE20k** 分割任务的 **mIoU** 提高到 **51.7% (+3.6%)**。

**ConvMAE** 框架有一个 **Encoder** 和 **Decoder**。**Encoder** 是 **convolution-transformer** 混合架构，**Decoder** 是纯 **transformer** 架构。

![](https://pic.imgdb.cn/item/65585a60c458853aefbaaa0b.jpg)

**Encoder** 部分包括了**3**个 **stage**，设输入图片的尺寸$(H,W)$，每个 **stage** 输出的特征分别是$(H/4,W/4),(H/8,W/8),(H/16,W/16)$。前两个 **stage** 是卷积模块，使用 **Masked Convolutional Block** 对特征进行操作，其中的 **Depthwise Convolution** 使用**5×5**大小卷积核。在每个阶段之间，进行一次 **stride** 为**2**的卷积以进行下采样操作。最后一个 **stage** 是 **Transformer** 模块，拉大感受野，并融合所有 **patch** 的特征。另外作者发现绝对位置编码性能是最优的。

**ConvMAE** **mask** 掉 **stage3** 中一部分输出 (比如$75\%$) 之后，把这些 **mask** 分别上采样**2**倍和**4**倍得到前两个阶段的 **mask**。这些被 **mask** 掉的 **token** 在编码阶段被丢弃，并且希望经过 **Decoder** 之后能够重建出来。通过这种方式，**ConvMAE** 只需要保留至少 $25\%$ 的 **token** 用于训练。前两个阶段使用 **5×5** 的 **Depthwise Convolution** 的感受野可能大于一个 **masked patch** 的大小，因此为了确保预训练的质量，在前两个阶段采用了 **masked convolution**，确保被 **mask** 掉的部分不会参与到编码的过程。

**Decoder** 以 **Encoder** 的输出以及 **masked token** 为输入，通过一系列的 **Transformer Block** 得到最终的重建结果。**ConvMAE** 的编码器获得了多尺度特征$E_1,E_2,E_3$，分别捕捉到了细粒度和粗粒度的图像信息。为了更好地进行预训练，作者将$E_1$和$E_2$分别进行 **stride=2** 和 **stride=4** 的下采样之后与$E_3$相加，进行多尺度特征的融合。融合得到的结果再通过 **Linear Transformation** 得到最终要输入给 **Decoder** 的 **token**。

训练使用的目标函数是 **mask** 的部分的重建结果与原图的 **L1 Loss**。**ConvMAE** 经过预训练之后，**Encoder** 能够输出多尺度的特征$(H/4,W/4),(H/8,W/8),(H/16,W/16)$，它们可以被用于后续的检测分割任务里面。

![](https://pic.imgdb.cn/item/65585d06c458853aefc500e5.jpg)


为了验证本文所提出方法的有效性，作者进行了几组消融实验。

### ⚪ 预训练 Epoch 数的影响

作者对 **ConvMAE-Base** 进行预训练了**200**、**400**、**800**和**1600**个 **Epoch** ，以测试对 **ConvMAE** 的影响。结果如下图所示，可以看到随着预训练 **Epoch** 数的增加，分类任务的 **Accuracy** 在不断上升，同时 **COCO** 检测任务和 **ADE20K** 分割任务性能也在不断提升，证明了预训练 **Epoch** 数对于模型的性能有积极影响。

![](https://pic.imgdb.cn/item/65585d6bc458853aefc6d72d.jpg)

### ⚪ Mask 方式以及卷积核大小的影响

如下图所示，作者把 **block-wise** 的 **mask** 策略换回到 **random mask** 策略，发现 **ImageNet** 性能下降；把卷积核大小从**5×5**增加到**7×7**或者**9×9**几乎不会影响精度。

![](https://pic.imgdb.cn/item/65585db9c458853aefc82180.jpg)


### ⚪ 多尺度 Decoder 特征融合的影响

如下图所示，作者在训练 **200 Epoch** 和 **1600 Epoch** 这两种情况下测试了多尺度 **Decoder** 对于 **Conv MAE** 性能的影响，结果表明融合多尺度特征更容易得到好的图像表征。

![](https://pic.imgdb.cn/item/65585e14c458853aefc9abe9.jpg)
