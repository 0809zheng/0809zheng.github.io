---
layout: post
title: 'Adversarial Active Learning for Deep Networks: a Margin Based Approach'
date: 2022-08-11
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/631e8f6216f2c2beb1e65951.jpg'
tags: 论文阅读
---

> DFAL：一种基于决策边界的对抗主动学习方法.

- paper：[Adversarial Active Learning for Deep Networks: a Margin Based Approach](https://arxiv.org/abs/1802.09841)

本文作者提出了一种基于决策边界的对抗主动学习策略，在采样时选择靠近决策边界的样本进行优先标注。衡量样本到决策边界的距离比较困难，因此引入对抗样本。对抗样本能够提供输入空间分布的信息，以近似到决策边界的距离。

下图给出了几种不同的基于决策边界的主动学习方法。

![](https://pic.imgdb.cn/item/631e92e016f2c2beb1e9c88d.jpg)

- 图a通过查询样本到决策边界的投影距离来决定是否对其标注，距离边界越近表明样本的不确定性越大；然而样本和边界之间的距离较难计算。
- 图b计算样本到与其具有不同预测类别的最近样本之间的距离，距离越小表明该样本的分类类别不确定性越大，则对其进行标注。
- 图c计算样本到其对抗样本之间的距离；对抗攻击的出发点便是寻找最小的扰动以跨越决策边界。
- 图d为作者提出的对抗主动学习方法，在寻找到标注样本后对原样本和对抗样本同时进行标注(共用标签)。

作者选用**Deep-Fool**方法作为对抗攻击方法，该方法不依赖样本标签，不需要指定额外的超参数，运行速度快，并且攻击效果较好。**Deep-Fool**方法采用迭代过程，在原样本附近的分类器的局部线性近似与该样本的更新之间交替，使其穿过局部线性决策区域。当更新后的样本称为原样本的有效对抗样本时，算法停止。

![](https://pic.imgdb.cn/item/631e9d0116f2c2beb1f374f4.jpg)

作者在三个图像分类数据集上进行实验，以体现方法的有效性：

![](https://pic.imgdb.cn/item/631e9df616f2c2beb1f466f3.jpg)
