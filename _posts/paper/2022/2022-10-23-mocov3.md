---
layout: post
title: 'An Empirical Study of Training Self-Supervised Vision Transformers'
date: 2022-10-23
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63db8228ac6ef860169fbf4c.jpg'
tags: 论文阅读
---

> MoCo v3：训练自监督视觉Transformer的经验性研究.

- paper：[An Empirical Study of Training Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.02057)

**MoCo v3**是对[<font color=blue>MoCo v2</font>](https://0809zheng.github.io/2022/10/22/mocov2.html)方法的技术性改进，把矩对比方法应用到视觉**Transformer**的自监督训练中。

**MoCo v3**没有采取**MoCo**中的队列设计，而是从批次样本中构造正负样本对，这要求样本批量比较大。此外在编码器和映射头后引入预测头(**prediction head**)，用查询表示$q=f_q(Aug_1(x_q))$预测键表示$k=f_k(Aug_2(x_q))$。键表示的矩编码器$f_k(\cdot)$的参数$\theta_k$通过编码器$f_q(\cdot)$的参数$\theta_q$更新：

$$ \theta_k \leftarrow m \theta_k + (1-m) \theta_q $$

给定一批样本$x$，分别做两次数据增强得到$x_1,x_2$，通过编码器构造$q_1,q_2$，通过矩编码器构造$k_1,k_2$。则对比损失对称地构造为：

$$ \mathcal{L}_{\text{MoCov3}} = -\log \frac{\exp(q_1 \cdot k_2^+/\tau)}{\sum_{i=0}^{N}\exp(q_1 \cdot k_2^i/\tau)}-\log \frac{\exp(q_2 \cdot k_1^+/\tau)}{\sum_{i=0}^{N}\exp(q_2 \cdot k_1^i/\tau)}  $$

![](https://pic.imgdb.cn/item/63db8566ac6ef86016a57458.jpg)

作者研究了视觉**Transformer**的自监督训练中的不稳定因素，实验结果表明较大的学习率和较大的批量均会导致训练过程的不稳定。

![](https://pic.imgdb.cn/item/63db9517ac6ef86016c3f6e8.jpg)

为了进一步探究训练过程中的不稳定性，对网络第一层和最后一层的梯度范数进行可视化。结果表明在网络较浅层首先出现了较大的梯度脉冲，并逐渐传递给更深层，进而造成训练的不稳定。

![](https://pic.imgdb.cn/item/63db9569ac6ef86016c4a4d5.jpg)

为缓解训练的不稳定，在网络的第一层之前阻断梯度，即对图像块的嵌入层进行梯度停止操作，此时图像块嵌入始终为随机初始化的取值。该技巧能够显著地缓解训练过程的不稳定性。

![](https://pic.imgdb.cn/item/63db9986ac6ef86016cd7aaf.jpg)