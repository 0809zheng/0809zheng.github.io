---
layout: post
title: 'Temporal Ensembling for Semi-Supervised Learning'
date: 2022-09-03
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63ba3b0abe43e0d30e6ce3c2.jpg'
tags: 论文阅读
---

> 半监督学习的时序集成.

- paper：[Temporal Ensembling for Semi-Supervised Learning](https://arxiv.org/abs/1610.02242)

在监督学习中，对有标签数据的利用过程为：
1. 已经获得数据的标签；
2. 通过网络的预测值和标签值构造一个损失函数；
3. 通过迭代训练不断使该函数趋于一个更小的值。

对于无标签数据，上述过程无法实现，主要原因就是没有可以直接使用的数据标签。

本文作者提出了一个一致性约束假设：对于无标签数据，若对模型或数据加入一定的扰动，则预测结果应该是一致的。基于此可以构造一种无监督损失函数：

$$ \min f(x) - f^*(x^*) $$

# 1. $\Pi$-Model

[<font color=blue>$\Pi$-Model</font>](https://0809zheng.github.io/2022/09/02/pimodel.html)的无监督损失旨在最小化一个数据样本两次经过同一个带随机变换(如随即增强或**dropout**)的网络后预测结果的差异：

$$ \mathcal{L}_u^{\Pi} = \sum_{x \in \mathcal{D}} \text{MSE}(f_{\theta}(x),f_{\theta}'(x)) $$

![](https://pic.imgdb.cn/item/63ba3633be43e0d30e6683fa.jpg)

$\Pi$-**Model**的主要缺点是每个数据样本会进行两次前向传播，导致计算成本加倍。

# 2. Temporal Ensembling

**时序集成**方法是指对每个数据样本$x_i$的预测结果$z_i$存储一个指数滑动平均值$$\tilde{z}_i$$：

$$ \tilde{z}_i^{(t)} = \frac{\alpha \tilde{z}_i^{(t-1)}+(1-\alpha)z_i}{1-\alpha^t} $$

由于滑动平均值$$\tilde{z}_i$$初始化为$0$，因此采取与[Adam](https://0809zheng.github.io/2020/12/09/adam.html#--%E5%88%9D%E5%A7%8B%E5%8C%96%E5%81%8F%E5%B7%AE%E4%BF%AE%E6%AD%A3--initialization-bias-correction)类似的偏差修正。则无监督损失旨在最小化当前预测结果与指数滑动平均的差异：

$$ \mathcal{L}_u^{(t)} = \sum_{x \in \mathcal{D}} \text{MSE}(f^{(t)}_{\theta}(x),\tilde{z}_i^{(t)}) $$

![](https://pic.imgdb.cn/item/63ba3e9cbe43e0d30e715ef3.jpg)


![](https://pic.imgdb.cn/item/63ba3ec4be43e0d30e718a2d.jpg)