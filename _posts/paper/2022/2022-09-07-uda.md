---
layout: post
title: 'Unsupervised Data Augmentation for Consistency Training'
date: 2022-09-07
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63bbe4ffbe43e0d30e4cf951.jpg'
tags: 论文阅读
---

> 一致性训练的无监督数据增强.

- paper：[Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848)

**无监督数据增强 (Unsupervised Data Augmentation, UDA)**旨在使模型对一个无标签样本及其增强样本预测相同的输出，重点关注增强噪声的质量将会如何影响半监督学习方法的一致性训练表现。**UDA**采用比较先进的数据增强策略生成有意义和高效的噪声样本，而好的增强策略应能提供有效的(不改变样本标签)、多样性的噪声，并引入有目标的归纳偏置。

![](https://pic.imgdb.cn/item/63bbf895be43e0d30e769e1b.jpg)

在计算无监督损失时，**UDA**采用了以下技巧：
- 低置信度遮挡(**low confidence masking**)：丢弃预测置信度低于阈值$\tau$的样本；
- 锐化预测分布(**sharpening prediction distribution**)：在**softmax**中引入温度系数$T$；
- 域内数据过滤(**in-domain data filtration**)：为了在域外数据集中提取更多域内数据，训练一个分类器预测域标签，并保留域内分类置信度高的样本。

**UDA**的损失函数为：

$$ \mathcal{L}_u^{UDA} = \sum_{x \in \mathcal{D}} \Bbb{I} [\mathop{\max}_c f_{\theta}^c(x) > \tau] \cdot \text{D}[\text{sg}(f_{\theta}(x;T)),f_{\theta}(\hat{x})] $$

其中$$\hat{x}$$是应用数据增强的样本，$$\text{sg}(\cdot)$$表示不计算梯度，$$\Bbb{I}$$是示性函数，$$\text{D}$$是距离函数，对于分类任务常取KL散度；温度$T$用于调整**softmax**计算：

$$ f_{\theta}^i(x;T) = \frac{\exp(z_i / T)}{\sum_j \exp(z_j / T)} $$

对于图像任务，**UDA**采用[**RandAugment**](https://0809zheng.github.io/2021/11/28/randaug.html)，该方法随机均匀地从**PIL**提供的图像增强策略中采样增强方式，不需要学习或优化过程，因此是一种高效的自动增强策略。

![](https://pic.imgdb.cn/item/63bc1552be43e0d30eb5b815.jpg)

在**CIFAR-10**和**SVHN**分类数据集上，监督学习的**Wide-ResNet-28-2**和**PyramidNet**分别报告了$5.4$和$2.7$的错误率，而半监督学习方法的错误率为：

![](https://pic.imgdb.cn/item/63bc1406be43e0d30eb3047e.jpg)

对于语言任务，**UDA**采用**反向翻译(back-translation)**和基于**TF-IDF**的单词替换。反向翻译保留了高级语义信息但不会保持精确的单词，**TF-IDF**词替换丢弃了具有较低**TF-IDF**得分的信息量较小的单词。

![](https://pic.imgdb.cn/item/63bc1571be43e0d30eb5eac8.jpg)

结果表明**UDA**能够作为语言领域中迁移学习和表示学习的补充：

![](https://pic.imgdb.cn/item/63bc152cbe43e0d30eb5769f.jpg)