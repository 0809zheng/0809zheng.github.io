---
layout: post
title: 'Inverse scaling can become U-shaped'
date: 2022-12-10
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67fcd25988c538a9b5d0c0d0.png'
tags: 论文阅读
---

> 逆向缩放可能会变成 U 形.

- paper：[Inverse scaling can become U-shaped](https://arxiv.org/abs/2211.02011)

# 0. TL; DR

本文研究了语言模型在特定任务上表现出的“逆向缩放”现象（**inverse scaling**），即模型性能随着模型规模的增加而下降。研究发现，当模型规模进一步扩大时，这种逆向缩放现象可能会转变为 **U** 形缩放，即性能先下降后上升。此外，研究还发现，通过提供单个示例（**1-shot**）和链式思考（**chain-of-thought, CoT**）提示，可以进一步缓解这种不理想的缩放模式。

![](https://pic1.imgdb.cn/item/67fcd39888c538a9b5d0c1a3.png)

# 1. 背景介绍

近年来，语言模型的规模不断扩大，从数十亿到数千亿参数不等。这些基于 **Transformer** 架构的自回归语言模型在多种任务上表现出色，包括零样本、少样本和微调等评估协议。然而，随着模型规模的增加，是否所有任务的性能都会持续提升？实际上，一些任务可能会表现出“逆向缩放”现象，即模型性能随着模型规模的增加而下降。这种现象揭示了模型训练数据或目标函数中的潜在问题。

为了识别这些逆向缩放任务，**Inverse Scaling Prize** 比赛被设立，旨在找出那些随着模型规模增加而表现越来越差的任务。比赛收到了超过 **80** 个独特的提交，其中 **11** 个任务被授予三等奖，这些任务的数据集已经公开发布。这些任务涵盖了多种类型，包括问答、逻辑推理和文本生成等。

# 2. 方法介绍

本文对 **11** 个逆向缩放任务进行了重新评估，使用了不同的预训练语言模型，其参数数量从 **1B** 到 **540B** 不等。实验设置使用相同的提示和评分标准。所有答案选项都被评分，选择概率最高的选项作为预测结果。

![](https://pic1.imgdb.cn/item/67fcd4d188c538a9b5d0c356.png)

实验结果显示，只有 4 个任务在 **PaLM 540B** 上仍然表现出逆向缩放，而 6 个任务转变为 **U** 形缩放，1 个任务（**Repetitive Algebra**）表现出正向缩放。这种 U 形缩放现象表明，逆向缩放曲线可能不会延续到更大规模的模型上，因为性能可能会在某个点后开始增加。

![](https://pic1.imgdb.cn/item/67fcd4ff88c538a9b5d0c392.png)

为了缓解逆向缩放现象，本文探索了两种提示策略：**1-shot** 演示和链式思考（**CoT**）提示。

### 1-shot 演示

**1-shot** 演示是通过在提示中加入一个示例来引导模型。实验发现，这种简单的提示策略可以将所有 4 个仍然表现出逆向缩放的任务转变为 U 形或平坦缩放。

![](https://pic1.imgdb.cn/item/67fcd52e88c538a9b5d0c3bb.png)

### 链式思考（CoT）提示

**CoT** 提示通过在提示中加入逐步推理过程来引导模型。实验发现，**CoT** 提示可以进一步改善 U 形缩放任务的性能，甚至将一些任务转变为正向缩放。

![](https://pic1.imgdb.cn/item/67fcd56588c538a9b5d0c3f0.png)
![](https://pic1.imgdb.cn/item/67fcd5b588c538a9b5d0c469.png)
