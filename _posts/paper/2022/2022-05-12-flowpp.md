---
layout: post
title: 'Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design'
date: 2022-05-12
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/62a9b66d094754312936bb6f.jpg'
tags: 论文阅读
---

> Flow++：通过变分解量化和结构设计改进流模型.

- paper：[Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design](https://arxiv.org/abs/1902.00275v2)

# 1. 流模型
**流模型**(**flow-based model**)是一种从观测变量$x$到简单隐变量$z$的可逆变换$z=f(x)$，该变换可以通过叠加多个简单的可逆变换构造$f(x) = f_1 ◦ \cdots ◦ f_L(x)$，由于每个变换$f_i$可逆且容易求**Jacobian**行列式，因此采样过程也容易实现$f^{-1}(z) = f^{-1}_L ◦ \cdots ◦ f^{-1}_1(z)$。

根据[概率密度的变量替换公式](https://0809zheng.github.io/2022/04/30/variable.html)和链式法则，观测变量$x$的分布为：

$$ p(x) = p(z)\cdot |\det \prod_{i=1}^{L} \frac{\partial f_i}{\partial f_{i-1}}| $$

其对数似然函数为：

$$ \log p(x) = \log  p(z) + \sum_{i=1}^{L} \log |\det  \frac{\partial f_i}{\partial f_{i-1}}| $$

此时不需要显式地计算分布$p(x)$的概率密度函数，而是通过初始分布$p(z)$的概率密度(常取标准正态分布)以及映射过程产生的**Jacobian**行列式计算即可。

# 2. Flow++
作者认为，流模型的建模效率较低，主要存在三个问题：
1. 为输入增加均匀噪声是次优的解量化选择，影响训练损失和泛化能力；
2. 仿射耦合层的表达能力不足；
3. 耦合层网络中的卷积层特征提取能力不强。

针对这三点问题，作者设计了**Flow++**，进行了如下改进：
1. 引入基于变分的解量化；
2. 使用逻辑混合**CDF**耦合层；
3. 耦合层网络中使用自注意力机制。

## (1) 通过变分推断进行解量化

图像等数据是将连续信号**量化(quantized)**为离散的表示。若直接使用离散数据拟合连续密度模型会产生退化问题，即将所有概率集中在离散的数据点上。该问题的常见解决方案是**解量化(dequantization)**，即首先将离散数据分布转换为连续分布，然后使用连续密度模型对构造的连续分布进行建模。

### ⚪ 均匀解量化 

之前的工作通过向离散数据添加均匀噪声来实现解量化：比如包含$D$个像素的图像数据$x$的每个分量取$(0,1,2,...,255)$中的值，则解量化数据为$y=x+u$，其中$u$~$[0,1)^D$。

$$ P_{model}(x) = \int_{[0,1)^D} p_{model}(x+u)du $$

在解量化数据$y$上训练一个连续密度模型$p_{model}$相当于在离散数据$x$上最大化离散模型$P_{model}$的对数似然下界：

$$ \begin{aligned} \Bbb{E}_{y \text{~} p_{data}} [\log p_{model}(y)] &= \sum_{x} P_{data}(x) \int_{[0,1)^D} \log p_{model}(x+u)du \\ &\leq  \sum_{x} P_{data}(x) \log \int_{[0,1)^D} p_{model}(x+u)du \\ & =  \Bbb{E}_{x \text{~} p_{data}} [\log P_{model}(x)] \end{aligned} $$

均匀解量化能够防止连续密度模型$p_{model}$退化为离散数据点上的混合模型，因为最大化连续模型的对数自然会受到离散模型的对数似然的约束。

### ⚪ 变分解量化 

均匀解量化要求为数据$x$均匀地增加超立方体的噪声$[0,1)^D$，这对于神经网络等平滑函数近似器是不合适的。作者提出了一种通过变分推断进行解量化的方法。

同样使用连续密度模型$p_{model}$近似离散数据$x$的离散模型$P_{model}$：

$$ P_{model}(x) = \int_{[0,1)^D} p_{model}(x+u)du $$

引入解量化噪声分布$q(u\|x)$，则有以下变分下界：

$$ \begin{aligned} \Bbb{E}_{x \text{~} p_{data}} [\log P_{model}(x)] &= \Bbb{E}_{x \text{~} p_{data}} [\log \int_{[0,1)^D} q(u|x) \frac{p_{model}(x+u)}{q(u|x)}du] \\ &\geq  \Bbb{E}_{x \text{~} p_{data}} [\int_{[0,1)^D} q(u|x) \log \frac{p_{model}(x+u)}{q(u|x)}du]\\ & =  \Bbb{E}_{x \text{~} p_{data}} \Bbb{E}_{u \text{~} q(\cdot | x)}[\log \frac{p_{model}(x+u)}{q(u|x)}] \end{aligned} $$

把噪声分布$q$本身建模为流模型$u=q_x(\epsilon)$，其中$\epsilon$~$$p(\epsilon)=\mathcal{N}(0,I)$$。则$q(u\|x) = p(q_x^{-1}(u))\cdot \|\partial q_x^{-1}/\partial u\|$。此时目标函数为：

$$ \Bbb{E}_{x \text{~} p_{data}} [\log P_{model}(x)] \geq \Bbb{E}_{x \text{~} p_{data},\epsilon \text{~} \mathcal{N}(0,I)} [\log \frac{p_{model}(x+q_x(\epsilon))}{p(\epsilon)\cdot |\partial q_x/\partial \epsilon|^{-1}}] $$

因此目标函数变为同时优化模型$p_{model}$和$q_x$，这两个模型都被设计为流模型。注意到当$q_x$为均匀分布时，上述目标退化为$$\Bbb{E}_{y \text{~} p_{data}} [\log p_{model}(y)]$$，即均匀解量化的情况。噪声分布$q(u\|x)$允许为数据$x$更灵活地分布超立方体噪声$[0,1)^D$，从而改善模型的训练过程和泛化能力。


## (2) 改进耦合层

仿射耦合层是流模型中常用的可逆结构，并且具有容易计算的**Jacobian**行列式。该结构把输入$x$拆分成两部分$x_1$和$x_2$，然后分别计算$y_1$和$y_2$：

$$ \begin{aligned}  y_1&=x_1 \\ y_2 &= x_2 \cdot \exp(a_{\theta}(x_1)) + b_{\theta}(x_1) \end{aligned} $$

其中$a_{\theta},b_{\theta}$是用神经网络实现的。仿射耦合层的逆变换及对数**Jacobian**行列式计算如下：

$$ \begin{aligned}  x_1&=y_1 \\ x_2 &=   (y_2-b_{\theta}(y_1))\cdot \exp(-a_{\theta}(y_1)) \\ \log |\frac{\partial y}{\partial x}| & = 1^Ta_{\theta}(x_1) \end{aligned} $$

作者认为对于$y_2=f(x_2)$通过使用更复杂的非线性变换可以提高模型的建模性能，具体地，通过使用$K$个**logistic**分布的累计分布函数(**cumulative distribution function, CDF**，由混合概率$\pi$,均值$\mu$,对数尺度$s$建模)，再应用逆**sigmoid**和仿射变换：

$$ \begin{aligned} x \to \sigma^{-1}(\text{MixLogCDF}(x;\pi,\mu,s))\cdot \exp(a) + b \\ \text{MixLogCDF}(x;\pi,\mu,s) = \sum_{i=1}^{K} \pi_i \sigma((x-\mu_i)\cdot \exp(-s_i)) \end{aligned} $$

其中参数$\pi_{\theta},\mu_{\theta},s_{\theta},a_{\theta},b_{\theta}$均用神经网络建模，作者是通过卷积层和自注意力机制实现的。改进的耦合层表示为：

$$ \begin{aligned}  y_1=&x_1 \\ y_2 =& \sigma^{-1}(\text{MixLogCDF}(x_2;\pi_{\theta}(x_1),\mu_{\theta}(x_1),s_{\theta}(x_1))) \\ & \cdot \exp(a_{\theta}(x_1)) + b_{\theta}(x_1) \end{aligned} $$

## (3) 实验分析

实验结果表明，**Flow++**在非自回归模型中实现了最先进的性能，并且与自回归模型相比也具有竞争力。

![](https://pic.imgdb.cn/item/62ab165209475431294a4a82.jpg)

作者对所提改进方法进行消融实验：

![](https://pic.imgdb.cn/item/62ab16d009475431294b6a46.jpg)