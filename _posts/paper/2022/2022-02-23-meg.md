---
layout: post
title: 'Maximum Entropy Generators for Energy-Based Models'
date: 2022-02-23
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/634e03cb16f2c2beb1a3bf95.jpg'
tags: 论文阅读
---

> MEG：基于能量模型的最大熵生成器.

- paper：[Maximum Entropy Generators for Energy-Based Models](https://arxiv.org/abs/1901.08508)

# 1. 能量模型

能量模型是指使用如下概率模型拟合一批真实数据$x_1,x_2,\cdots,x_n$~$p(x)$：

$$ q_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} $$

其中$U_{\theta}(x)$是带参数的能量函数；$Z_{\theta}$是配分函数(归一化因子)：

$$ Z_{\theta} = \int e^{-U_{\theta}(x)}dx $$

上述概率形式被称为能量分布，对应物理学中的玻尔兹曼分布。玻尔兹曼分布基于[最大熵原理](https://0809zheng.github.io/2021/07/20/me.html#2-%E6%9C%80%E5%A4%A7%E7%86%B5%E5%8E%9F%E7%90%86-the-maximum-entropy-principle)，其形式容易处理，是一种比较常用的能量分布。比如**softmax**函数就是基于玻尔兹曼分布假设。

直观地，真实数据分布在能量函数中势最小的位置，从能量模型中构造生成数据$\hat{x}_1,\hat{x}_2,\cdots \hat{x}_n$旨在使其势尽可能小。

![](https://pic1.imgdb.cn/item/634e13f716f2c2beb1b9d59f.jpg)

# 2. 正相-负相分解

能量模型的目标函数为能量分布的负对数似然：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [- \log q_{\theta}(x)]  $$

计算目标函数的梯度：

$$ \begin{aligned} \nabla_{\theta} L_{\theta} & =  \Bbb{E}_{x \text{~} p(x)} [- \nabla_{\theta}\log q_{\theta}(x)] = \Bbb{E}_{x \text{~} p(x)} [- \nabla_{\theta}\log \frac{e^{-U_{\theta}(x)}}{Z_{\theta}}]\\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+ \nabla_{\theta}\log Z_{\theta}] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+\frac{1}{Z_{\theta}} \nabla_{\theta} Z_{\theta}] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)+\frac{1}{Z_{\theta}} \nabla_{\theta} \int e^{-U_{\theta}(x)}dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)-\frac{1}{Z_{\theta}} \int e^{-U_{\theta}(x)}  \nabla_{\theta}U_{\theta}(x) dx]  \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)- \int \frac{e^{-U_{\theta}(x)}}{Z_{\theta}}  \nabla_{\theta}U_{\theta}(x) dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)- \int q_{\theta}(x) \nabla_{\theta}U_{\theta}(x) dx] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[\nabla_{\theta}U_{\theta}(x) ]] \\ & = \Bbb{E}_{x \text{~} p(x)} [ \nabla_{\theta} U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[\nabla_{\theta}U_{\theta}(x) ] \\ & = \nabla_{\theta}(\Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[U_{\theta}(x) ]) \end{aligned} $$

因此目标函数可以等价地表示为：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[U_{\theta}(x) ] $$

上式称为**正相-负相分解**，表示能量函数$U_{\theta}(x)$在真实分布和能量分布下的均值之差。

# 3. 从能量的角度理解GAN

能量模型的目标函数写作：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} q_{\theta}(x)}[U_{\theta}(x) ] $$

注意到上式需要从能量分布$$q_{\theta}(x)=\frac{e^{-U_{\theta}(x)}}{Z_{\theta}}$$中采样，这个步骤通常是不可解的(考虑到配分函数的复杂性)。因此引入一个新的分布$q_{\phi}(x)$近似能量分布$q_{\theta}(x)$，该分布可以由一个生成器$G_{\phi}(z),z$~$q(z)$构造。此时目标函数为：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[U_{\theta}(x) ] $$

上式仅仅评估了真实样本和生成样本的能量差异，与此同时真实样本应该落在能量函数的极小值点附近，因此引入梯度惩罚项：

$$ L_{\theta} = \Bbb{E}_{x \text{~} p(x)} [  U_{\theta}(x)]-  \Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[U_{\theta}(x) ] + \lambda \Bbb{E}_{x \text{~} p(x)} [ || \nabla_x U_{\theta}(x) ||^2 ] $$

能量函数$U_{\theta}(x)$使用一个判别器$D_{\theta}(x)$构造，则上式等价于判别器的目标函数：

$$ \mathop{ \min}_{D} \Bbb{E}_{x \text{~} p(x)} [  D_{\theta}(x)]-  \Bbb{E}_{z \text{~} q(z)}[D_{\theta}(x) ] + \lambda \Bbb{E}_{x \text{~} p(x)} [ || \nabla_x D_{\theta}(x) ||^2 ] $$

上式表示对真实样本进行以$0$为中心的梯度惩罚，形式上等价于[<font color=Blue>WGAN-GP</font>](https://0809zheng.github.io/2022/02/06/wgangp.html)的目标函数。

与此同时，生成分布$q_{\phi}(x)$与能量分布$q_{\theta}(x)$应该足够接近，使用**KL**散度衡量两者差异：

$$ \begin{aligned} D_{KL}[q_{\phi}(x) || q_{\theta}(x)] &= \int q_{\phi}(x) \log \frac{q_{\phi}(x)}{q_{\theta}(x)} dx \\ &= \int q_{\phi}(x) \log q_{\phi}(x) dx - \int q_{\phi}(x) \log q_{\theta}(x) dx \\ &= -H_{\phi}(x)- \int q_{\phi}(x) \log \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} dx \\ &= -H_{\phi}(x)+\Bbb{E}_{x \text{~} q_{\phi}(x)}[U_{\theta}(x) ] + \log Z_{\theta} \end{aligned} $$

上式第一项$H_{\phi}(x)$表示生成样本的熵，希望熵越大越好(样本多样性越大)；第二项表示生成样本的势能，希望势越小越好(接近真实样本)；第三项是一个常数。通过上式可以构造生成器的目标函数：

$$ \mathop{ \min}_{G} -H(G_{\phi}(z))+\Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[D_{\theta}(x) ] $$

至此，在能量模型的角度下，**GAN**的目标函数写作：

$$ \begin{aligned} & \mathop{ \min}_{D} \Bbb{E}_{x \text{~} p(x)} [  D_{\theta}(x)]-  \Bbb{E}_{z \text{~} q(z)}[D_{\theta}(x) ] + \lambda \Bbb{E}_{x \text{~} p(x)} [ || \nabla_x D_{\theta}(x) ||^2 ] \\& \mathop{ \min}_{G} -H(G_{\phi}(z))+\Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[D_{\theta}(x) ] \end{aligned} $$

# 4. 使用互信息估计$H(x)$

本节讨论如何计算生成样本的熵$H_{\phi}(x)=H(G_{\phi}(z))$，其定义如下：

$$ H_{\phi}(x)= -\int q_{\phi}(x) \log q_{\phi}(x) dx $$

其中$q_{\phi}(x)$是指从随机噪声$q(z)$中采样，并通过生成器构造的样本：

$$ z\text{~}q(z), x= G_{\phi}(z) $$

此时$q_{\phi}(x)$的理论表达式为：

$$ q_{\phi}(x) = \int \delta(x-G_{\phi}(z))q(z)dz $$

直接计算生成样本的熵$H_{\phi}(x)$是相当困难的。一种可行的解决措施是将熵转换为**互信息**，然后计算互信息的**下界**。

### ⚪ 最大熵 $\to$ 互信息

考虑随机变量$x,z$之间的互信息：

$$ \begin{aligned} I_{\phi}(x,z) &= \iint  q_{\phi}(x|z) q(z) \log \frac{q_{\phi}(x|z)}{q_{\phi}(x)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log q_{\phi}(x|z)dxdz - \iint  q_{\phi}(x|z) q(z) \log q_{\phi}(x)dxdz \\ &= \int q(z) (\int q_{\phi}(x|z)  \log q_{\phi}(x|z)dx)dz - \iint   q_{\phi}(x,z) \log q_{\phi}(x)dxdz \\ &= -H_{\phi}(x|z) +H_{\phi}(x) \end{aligned} $$

其中$H_{\phi}(x\|z)$表示随机变量$x,z$的条件熵。根据$q_{\phi}(x)$的理论表达式，当$z$给定时，$x$的取值唯一($G_{\phi}(z)$)。因此条件熵$H_{\phi}(x\|z) \to 0$，从而得到：

$$ I_{\phi}(x,z) ≈ H_{\phi}(x) $$

因此可以把能量模型角度下**GAN**的目标函数中的熵$H_{\phi}(x)$替换为互信息$I_{\phi}(x,z)$：

$$ \begin{aligned} & \mathop{ \min}_{D} \Bbb{E}_{x \text{~} p(x)} [  D_{\theta}(x)]-  \Bbb{E}_{z \text{~} q(z)}[D_{\theta}(x) ] + \lambda \Bbb{E}_{x \text{~} p(x)} [ || \nabla_x D_{\theta}(x) ||^2 ] \\& \mathop{ \min}_{G} -I_{\phi}(x,z)+\Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[D_{\theta}(x) ] \end{aligned} $$

### ⚪ 寻找互信息的下界

互信息仍然是难以直接处理的。不妨寻找互信息的一个下界：

$$ \begin{aligned} I_{\phi}(x,z) &= \iint  q_{\phi}(x|z) q(z) \log \frac{q_{\phi}(x|z)}{q_{\phi}(x)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{q_{\phi}(z|x)}{q(z)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)q_{\phi}(z|x)}{p(z|x)q(z)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)}{q(z)}dxdz+ \iint  q_{\phi}(x|z) q(z) \log \frac{q_{\phi}(z|x)}{p(z|x)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)}{q(z)}dxdz+ \iint  q_{\phi}(z|x) q_{\phi}(x) \log \frac{q_{\phi}(z|x)}{p(z|x)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)}{q(z)}dxdz+ \int  q_{\phi}(z|x)  \log \frac{q_{\phi}(z|x)}{p(z|x)}dz \\ &= \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)}{q(z)}dxdz+ D_{KL}[q_{\phi}(z|x)||p(z|x)] \\ &\geq \iint  q_{\phi}(x|z) q(z) \log \frac{p(z|x)}{q(z)}dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log p(z|x)dxdz - \iint  q_{\phi}(x|z) q(z) \log q(z)dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log p(z|x)dxdz - \int  q(z) \log q(z)dz \\ &= \iint  q_{\phi}(x|z) q(z) \log p(z|x)dxdz + Const. \end{aligned} $$

最大化互信息等价于最大化互信息的一个下界。其中$p(z\|x)$可以任意指定，不妨取正态分布$p(z\|x)$~$$\mathcal{N}(z;E(x),\sigma^2)$$，其中$E(x)$是一个带参数的**编码器**。此时互信息的下界表示为：

$$ \begin{aligned} I_{\phi}(x,z) &\geq  \iint  q_{\phi}(x|z) q(z) \log p(z|x)dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log \mathcal{N}(z;E(x),\sigma^2)dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log  \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{||z-E(x)||^2}{2\sigma^2}} dxdz \\ &= \iint  q_{\phi}(x|z) q(z) \log  \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{||z-E(x)||^2}{2\sigma^2}} dxdz \\ & \leftrightarrow - \Bbb{E}_{z \text{~} q(z)}[||z-E(G_{\phi}(z))||^2] \end{aligned} $$

至此，能量模型角度下**GAN**的目标函数最终可写作：

$$ \begin{aligned} & \mathop{ \min}_{D} \Bbb{E}_{x \text{~} p(x)} [  D_{\theta}(x)]-  \Bbb{E}_{z \text{~} q(z)}[D_{\theta}(x) ] + \lambda \Bbb{E}_{x \text{~} p(x)} [ || \nabla_x D_{\theta}(x) ||^2 ] \\& \mathop{ \min}_{G,E} \Bbb{E}_{z \text{~} q(z)}[||z-E(G_{\phi}(z))||^2]+\Bbb{E}_{x \text{~} G_{\phi}(z),z \text{~} q(z)}[D_{\theta}(x) ] \end{aligned} $$

# 5. $z$的MCMC采样

随机噪声$q(z)$可以预设正态分布，一种更好的方法是从$z$的能量分布$q_{\theta}(G_{\phi}(z))$中采样，对应$z$的能量函数为$U_{\theta}(G_{\phi}(z))$。实验也验证这种采样方式能够提高采样后的生成质量。

根据[MCMC方法](https://0809zheng.github.io/2022/10/17/sampling.html)，构造以下随机过程：

$$ z_{t+1} = f(z_t,\alpha) $$

其中$\alpha$是一个容易实现的随机过程，比如从正态分布中采样；若该随机过程的静态分布为$q_{\theta}(G_{\phi}(z))$，从$z_0$出发采样得到的序列$\{z_1,z_2,\cdots,z_t\}$服从$q_{\theta}(G_{\phi}(z))$分布。

特别地，考虑**Langevin**方程：

$$ z_{t+1} = z_t - \frac{1}{2}\epsilon \nabla_zU_{\theta}(G_{\phi}(z_t)) + \sqrt{\epsilon} \alpha, \quad \alpha \text{~} \mathcal{N}(0,1) $$

上述随机微分方程当$\epsilon \to 0$时的静态分布恰为$z$的能量分布：

$$ q_{\theta}(G_{\phi}(z)) = \frac{e^{-U_{\theta}(G_{\phi}(z))}}{Z_{\theta}} $$

因此给定能量函数$U(G_{\phi}(z))$后，按照上述形式可以实现从$z$的能量分布中采样。

上述采样过程效率比较低，因此采用**Metropolis-adjusted Langevin**算法（**MALA**）。引入一个筛选过程：

$$ \begin{aligned} & \tilde{z}_{t+1} = z_t - \frac{1}{2}\epsilon \nabla_zU_{\theta}(G_{\phi}(z_t)) + \sqrt{\epsilon} \alpha, \quad \alpha \text{~} \mathcal{N}(0,1) \\ & z_{t+1} = \begin{cases} \tilde{z}_{t+1}, &\text{if }\beta < \gamma \\ z_t, & \text{others} \end{cases}, \quad \beta \text{~} U[0,1] \\ & \gamma = \min \{ 1, \frac{q(\tilde{z}_{t+1})q(z_t|\tilde{z}_{t+1})}{q(\tilde{z}_{t})q(\tilde{z}_{t+1}|z_t)} \} \end{aligned} $$

其中：

$$ \begin{aligned} q(z) &∝e^{-U_{\theta}(G_{\phi}(z))} \\ q(\tilde{z}|z) &∝e^{-\frac{1}{2\epsilon}||\tilde{z}-z+\epsilon \nabla_zU_{\theta}(G_{\phi}(z))||^2}  \end{aligned} $$

上式表示采样时以概率$\gamma$接受新的$z$，以概率$1-\gamma$保持不变。该算法能够让采样过程有机会采样到高概率的样本，从而能够生成更多真实样本。

