---
layout: post
title: 'Improving Variational Inference with Inverse Autoregressive Flow'
date: 2022-05-11
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/629c98a10947543129fe8359.jpg'
tags: 论文阅读
---

> IAF：使用逆自回归流改进变分推断.

- paper：[Improving Variational Inference with Inverse Autoregressive Flow](https://arxiv.org/abs/1606.04934)

# 1. 标准化流 normalizing flow

**normalization flow**是指用一系列可逆映射$x^k=f_k(x^{k-1}):\Bbb{R}^d\to \Bbb{R}^d$将一个分布类型较为简单的随机变量$x^0~q(x)$转换成分布比较复杂的随机变量$x^K=f(x^0)$：

$$ x^0 \leftrightarrow x^1 \leftrightarrow x^2 \leftrightarrow \cdots  \leftrightarrow  x^{K-1}  \leftrightarrow  x^{K} $$

根据[概率密度的变量替换公式](https://0809zheng.github.io/2022/04/30/variable.html)和链式法则，新变量变量$x^K$的分布为：

$$ q(x^K) = q(x^0)|\det \prod_{k=1}^{K} \frac{d f_k}{d x^{k-1}}|^{-1} $$

其对数似然函数为：

$$ \log q(x^K) = \log  q(x^0) - \sum_{k=1}^{K}|\det  \frac{d f_k}{d x^{k-1}}| $$

此时不需要显式地计算分布$q(x^K)$的概率密度函数，而是通过初始分布$q(x^0)$的概率密度以及映射过程产生的**Jacobian**行列式计算即可。

# 2. 自回归流 autoregressive flow

一般函数的**Jacobian**行列式计算复杂。如果**Jacobian**矩阵$\frac{d f_k}{d x^{k-1}}$为三角矩阵，则其行列式比较容易计算，等于各对角元素的乘积。

**自回归流**通过假设变量$z$的第$i$个维度的生成只依赖于前面的维度$x_{1:i-1}$，从而构造三角形式的**Jacobian**矩阵。具体地，把随机变量建模为自回归模型：

$$ p(x) = \prod_i p(x_i|x_{1:i-1}) $$

若记输入变量为$u=[u_1,u_2,\cdots u_D]$，输出变量为$x=[x_1,x_2,\cdots x_D]$，则自回归流的双射函数$x=f(u)$为：

$$ x_i = u_i \cdot \exp(\alpha_i) + \mu_i \\ \mu_i = g_{\mu_i}(x_{1:i-1}),\alpha_i = g_{\alpha_i}(x_{1:i-1}) $$

该函数包括尺度变换和平移变换，这些变换的因子依赖输出变量前面的维度，可以用神经网络拟合。

![](https://pic.imgdb.cn/item/629c90e90947543129f4d179.jpg)

自回归流模型的训练过程$u=f^{-1}(x)$比较快，因为当给定真实数据$x$时，基础分布$u$的每一个维度计算是独立的，可以并行计算。而该模型的数据生成过程$x=f(u)$比较慢，因为只有计算出$x_{1:i-1}$才能计算$x_i$，该过程无法并行进行。


# 3. 逆自回归流 Inverse Autoregressive Flow
**逆自回归流**是指建立自回归模型：

$$ p(x) = \prod_i p(x_i|u_{1:i-1}) $$

对应的双射函数$x=f(u)$为：

$$ x_i = u_i \cdot \exp(\alpha_i) + \mu_i \\ \mu_i = g_{\mu_i}(u_{1:i-1}),\alpha_i = g_{\alpha_i}(u_{1:i-1}) $$

![](https://pic.imgdb.cn/item/629c9a7e094754312900ddbe.jpg)

逆自回归流的平移变换和尺度变换操作，其输入是前面时刻的噪声变量$u_{1:i-1}$，而不是前面时刻的数据采样$x_{1:i-1}$。

该模型的数据生成过程$x=f(u)$比较快，当给定噪声变量$u$时，真实数据$x$的每一个维度计算是独立的，可以并行计算。

该模型的训练过程$u=f^{-1}(x)$比较慢，因为只有计算出$u_{1:i-1}$才能计算$u_i$，该过程无法并行进行。

