---
layout: post
title: 'Dual Contrastive Learning for Unsupervised Image-to-Image Translation'
date: 2022-06-30
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63e457634757feff33828227.jpg'
tags: 论文阅读
---

> SimDCL：无监督图像到图像翻译的对偶对比学习.

- paper：[Dual Contrastive Learning for Unsupervised Image-to-Image Translation](https://arxiv.org/abs/2104.07689)

本文作者使用两个[<font color=Blue>CUT</font>](https://0809zheng.github.io/2022/05/10/cut.html)模型构造了对偶结构的图像到图像翻译模型**SimDCL**。

![](https://pic.imgdb.cn/item/63e457cb4757feff33833266.jpg)

**SimDCL**训练了两个**CUT**模型（包括两个生成器和两个判别器）。$$G_{X→Y}$$实现从类型$X$转换成类型$Y$，$$G_{Y→X}$$实现从类型$Y$转换成类型$X$；$$D_{X}$$判断图像是否属于类型$X$；$$D_{Y}$$判断图像是否属于类型$Y$。

生成器的损失函数采用基于对比学习的**PatchNCE**损失。把输入图像$X$和生成图像$Y$通过生成器$$G_{X→Y}$$的编码部分提取特征，然后使用多层感知机$H_X,H_Y$对特征进行变换。此时特征的每个像素位置对应原始图像的一个图像块；则两个图像相同位置的图像块对应的特征向量为正样本对，其余位置的特征向量为负样本。基于此可以构造对比损失：

$$ \mathcal{L}(v,v^+,v^-) = -\log [\frac{\exp(v \cdot v^+/ \tau)}{\exp(v \cdot v^+/ \tau)+
\sum_{n=1}^N \exp(v \cdot v^-_n/ \tau)}] $$

在此基础上引入恒等损失(**identity loss**)，即目标域图像$Y$经过生成器$$G_{X→Y}$$后图像风格应该保持不变。在实践中通过构造目标域图像$Y$与其生成图像$$G_{X→Y}(Y)$$之间的**L1**损失实现。

$$ \mathcal{L}_{identity}(G_{X→Y},G_{Y→X}) = \Bbb{E}_{x \text{~} X}[||G_{Y→X}(x)-x||_1] +  \Bbb{E}_{y \text{~} Y}[||G_{X→Y}(y)-y||_1] $$

为了缓解训练过程中的模式崩溃问题，额外引入相似度损失(**similarity loss**)。对于属于同一数据模态的样本$X_1,X_2$，经过上述特征嵌入后再应用多层感知机$H_{X1},H_{X2}$对特征进行变换，并构造两个特征之间的**L1**损失。

$$ \begin{aligned} &\mathcal{L}_{sim}(G_{X→Y},G_{Y→X},H_X,H_Y,H_{X1},H_{X2},H_{Y1},H_{Y2}) \\ =& \Bbb{E}_{x \text{~} X,y \text{~} Y}[||H_{X1}(H_X(G_{X→Y}^{Enc}(x)))-H_{X2}(H_X(G_{X→Y}^{Enc}(G_{Y→X}(y))))||_1] \\ +&  \Bbb{E}_{x \text{~} X,y \text{~} Y}[||H_{Y1}(H_Y(G_{Y→X}^{Enc}(y)))-H_{Y2}(H_Y(G_{Y→X}^{Enc}(G_{X→Y}(x))))||_1] \end{aligned} $$

作者进行了一系列消融实验：
- **Ⅰ**：在**PatchNCE**损失中加入**RGB**图像(即输入层特征)，该层特征仅对应一个像素，缺乏局部语义信息；
- **Ⅱ**：不使用额外的负样本，即**PatchNCE**损失中负样本只取输入图像的特征；
- **Ⅲ**：使用共享的编码器部分和嵌入层；
- **Ⅳ**：加入循环一致性损失；
- **Ⅴ**：移除对偶设置。

![](https://pic.imgdb.cn/item/63e460594757feff33926881.jpg)