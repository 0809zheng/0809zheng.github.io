---
layout: post
title: 'Learning Loss for Active Learning'
date: 2022-08-04
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6318564d16f2c2beb1ea7e0d.jpg'
tags: 论文阅读
---

> 主动学习中的损失预测.

- paper：[Learning Loss for Active Learning](https://arxiv.org/abs/1905.03677)

**损失预测(loss prediction)**的基本思想是预测给定未标注样本的损失，更高的损失意味着该样本学习更困难、更值得标注。损失预测可以通过一个损失预测模块实现：

![](https://pic.imgdb.cn/item/63187c8c16f2c2beb1173b98.jpg)

损失预测模块采用带**dropout**的多层感知机实现，选择多个网络隐藏层的特征作为输入，将它们通过全局平均池化后处理并连接起来，再进行损失回归：

![](https://pic.imgdb.cn/item/63187d5c16f2c2beb118139d.jpg)

为了学习损失，可以在总损失函数中增加一项真实损失$l$和预测损失$\hat{l}$之间的误差项，比如均方误差$(l-\hat{l})^2$。然而在训练过程中损失函数是不断变化的，直接学习较为困难。

作者提出根据样本对之间的预测损失的比较来构造优化目标。步骤如下：
- 把一个批次中的$B$个样本拆分成$B/2$个样本对；
- 对于每个样本对，预测两个样本的损失$\hat{l}_i,\hat{l}_j$；
- 通过**hinge**损失比较两个样本的预测损失，要求两个预测损失之间的距离不应小于$\xi$。

损失预测损失定义如下：

$$ \begin{aligned} L_{loss}(\hat{l},l) = &\max(0,-\Bbb{I}(l_i,l_j)\cdot (\hat{l}_i-\hat{l}_j)+\xi) \\ &\text{s.t.  } \Bbb{I}(l_i,l_j)=\begin{cases} +1, & \text{if } l_i>l_j \\ -1, &\text{otherwise} \end{cases} \end{aligned} $$

在三种视觉任务上，损失预测方法的表现均超过其他方法：

![](https://pic.imgdb.cn/item/631885ac16f2c2beb1213138.jpg)