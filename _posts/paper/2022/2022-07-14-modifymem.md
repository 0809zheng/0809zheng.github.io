---
layout: post
title: 'Modifying Memories in Transformer Models'
date: 2022-07-14
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67f8d5f088c538a9b5cac952.png'
tags: 论文阅读
---

> 修正Transformer模型中的记忆.

- paper：[Modifying Memories in Transformer Models](https://arxiv.org/abs/2012.00363)


# 0. TL; DR
本文提出了一项新任务：在不降低**Transformer**模型对未修改事实性能的前提下，显式修改模型中特定的事实性知识。研究者们构建了基于**T-REx**和**zsRE**数据集的基准测试，并探索了多种方法来实现这一目标。实验表明，对**Transformer**模型的特定层进行约束微调是一种简单而有效的方法。此外，研究还发现，即使在具有显式记忆模块的模型中，修改事实性知识也并非总是更容易。

# 1. 背景介绍
**Transformer**模型在自然语言处理（**NLP**）领域取得了巨大成功，尤其是在编码事实性知识方面表现出色。然而，随着知识的不断更新和变化，如何让**Transformer**模型“忘记”旧知识并“记住”新知识成为一个亟待解决的问题。例如，体育运动员更换球队、用户希望更新模型中存储的个人信息等场景都需要模型具备修改记忆的能力。此外，模型可能需要删除无意中存储的敏感信息或消除训练数据中的偏见。这些需求促使研究者们探索如何高效地修改**Transformer**模型中的事实性知识。

# 2. 方法介绍

研究者们定义了一个新的任务：修改**Transformer**模型中隐式存储在参数中的特定知识片段，同时保留其他知识。具体来说，给定一个预训练的**Transformer**模型，其参数为$θ_0$，存储了一系列事实$F$。目标是将$F$中的一小部分事实$S$替换为新的事实$M$，得到新的模型参数$θ^{new}$，使其存储$F^′ = (F \backslash S) ∪ M$。理想情况下，新模型不仅存储了修改后的知识，还保留了对未修改知识的性能。

研究者们首先探讨了几种自然的基线方法：
- **重新训练模型**：更新所有训练数据以反映新事实，然后重新训练模型。这种方法虽然可靠，但成本过高，且不适用于仅修改少量知识的场景。
- **仅在修改后的事实上进行微调**：这种方法虽然在修改后的事实上取得了高准确率，但会导致对未修改事实的遗忘（灾难性遗忘）。
- **在修改和未修改事实上混合微调**：这种方法试图通过在每个小批量中包含修改和未修改的事实来平衡优化轨迹，但仍然无法有效避免灾难性遗忘。

为了在修改知识的同时保留未修改知识的性能，研究者们提出了一种约束优化方法。具体来说，他们将问题定义为：

$$
\begin{aligned}
\min_{\theta \in \Theta} \quad  &\frac{1}{m} \sum_{x \in D_M} L(x; \theta) \\
\text{subject to} \quad &\frac{1}{n} \sum_{x' \in D_{F \backslash S}} |L(x'; \theta) - L(x'; \theta_0)| \leq \delta
\end{aligned}
$$

其中，$D_M$是支持修改事实的证据集，$D_{F \backslash S}$是支持未修改事实的证据集，$L(x; θ)$是损失函数，$δ$是一个小的正数常量。

为了简化约束，研究者们使用参数空间的$ℓ_∞$范数来近似约束：

$$
\begin{aligned}
\min_{\theta \in \Theta} \quad  & \frac{1}{m} \sum_{x \in D_M} L(x; \theta) \\
\text{subject to} \quad & \|\theta - \theta_0\|_\infty \leq \delta
\end{aligned}
$$

这种方法通过投影梯度下降（**Projected Gradient Descent, PGD**）求解，具体算法如下：
1. 使用预训练模型初始化参数$θ_0$。
2. 在每个迭代中，计算梯度并更新参数。
3. 将更新后的参数投影到约束集合内，确保参数变化不超过$δ$。

研究者们发现，仅对**Transformer**模型的特定层进行微调比对整个模型进行微调更为有效。例如，对**BERT**模型的第**0**层或最后一层（第**11**层）进行微调可以更好地适应修改后的事实，同时保留对未修改事实的性能。

# 3. 实验分析

研究者们基于**T-REx**和**zsRE**数据集构建了两个基准测试。**T-REx**数据集包含**34,039**个事实，每个事实由多个自然语言证据支持；**zsRE**数据集包含**147,905**个事实，同样由多个证据支持。为了构建修改后的事实，研究者们随机选择一小部分事实，并将其对象替换为其他具有相同关系的事实对象。

![](https://pic1.imgdb.cn/item/67f8d87588c538a9b5cad23c.png)

为了评估模型在修改后的事实和未修改的事实上的性能，研究者们使用了平均准确率（$\bar{A}$）作为指标：

$$
\bar{A} = \frac{A_M + A_{F \backslash S}}{2}
$$

其中，$A_M$是修改后的事实的准确率，$A_{F \backslash S}$是未修改的事实的准确率。

实验表明，无约束微调（即$δ = ∞$）会导致灾难性遗忘。例如，在**T-REx**基准测试中，**BERT-Base**模型在仅对修改后的事实进行微调时，虽然在修改后的事实上取得了较高的准确率（**75.00%**），但在未修改的事实上的准确率却降至**0.30%**。

![](https://pic1.imgdb.cn/item/67f8d96088c538a9b5cad505.png)

约束微调方法在保留未修改事实的性能方面表现出色。例如，对**BERT-Base**模型的第**0**层进行约束微调时，可以在修改后的事实上达到**71.25%**的准确率，同时在未修改的事实上保持**46.47%**的准确率。此外，随着修改的事实数量增加，最佳微调层从最后一层（第**11**层）变为第一层（第**0**层）。

![](https://pic1.imgdb.cn/item/67f8d97f88c538a9b5cad561.png)

混合微调方法（在每个小批量中包含修改和未修改的事实）虽然在理论上可以平衡优化轨迹，但在实践中效果有限。例如，在**BERT-Base**模型上，混合微调仅将未修改事实的准确率提高到**18.51%**，而修改后的事实的准确率降至**73.31%**。

![](https://pic1.imgdb.cn/item/67f8d9b688c538a9b5cad619.png)


研究者们还测试了具有显式记忆模块的**FaE**模型。实验表明，仅修改**FaE**模型的符号记忆模块无法有效更新知识。例如，仅修改符号链接时，**FaE**模型在修改后的事实上仅达到**46.88%**的准确率，而在未修改的事实上准确率保持不变。然而，对**FaE**模型的特定层进行约束微调后，可以在修改后的事实上达到**75.00%**的准确率，但未修改事实的准确率会下降**3.00%**。

![](https://pic1.imgdb.cn/item/67f8d9e588c538a9b5cad696.png)