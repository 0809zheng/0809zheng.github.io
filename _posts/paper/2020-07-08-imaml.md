---
layout: post
title: 'Meta-Learning with Implicit Gradients'
date: 2020-07-08
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f057f1a14195aa594028595.jpg'
tags: 论文阅读
---

> iMAML：使用L2正则化增加内部梯度更新次数.

- paper：Meta-Learning with Implicit Gradients
- arXiv：[link](https://arxiv.org/abs/1909.04630)

**MAML**是用来自动选择初始化参数的元学习算法。

假设最优的初始化参数（称为**meta-parameter**）为$θ$，则目标函数为：

$$ θ_{ML}^* = \mathop{\arg \min}_{θ \in Θ} F(θ) $$

$$ F(θ) = \frac{1}{M} \sum_{i=1}^{M} {L(Alg(θ,D_i^{tr}),D_i^{test})} $$

- 对于**outer-level**的目标函数，希望在给定的$M$个任务上测试损失最小；
- 对于**inner-level**的目标函数，希望每个任务的训练损失最小，即找到最优的**model-parameter** $φ$。

对于第$i$个训练任务，模型从初始化参数$θ$开始，通过一步或多步梯度下降更新参数；在**first-order MAML**中使用一次梯度下降：

$$ φ_i = Alg(θ,D_i^{tr}) = θ - α \nabla_θ L((θ,D_i^{tr})) $$

这种方法在更新参数时把模型在每个任务上的当前梯度更新方向作为初始化参数的梯度更新方向，当只进行了一次梯度更新时这种线性假设近似成立。实际上**first-order MAML**只进行一次梯度更新，相当于**early stopping**，减少了过拟合的风险；但是可能得到优化比较差的结果。

如果在每个任务上训练时进行了多次梯度更新，则会引入下列问题：
- 更新次数增加，可能过拟合；
- 每次更新需要存储参数、更新参数，计算量大；
- 随着梯度更新次数的增加，**model-parameter** $φ$ 对**meta-parameter** $θ$ 的依赖减小。

![](https://pic.downk.cc/item/5f05d01a14195aa59420c8d4.jpg)

**iMAML**算法在每个任务上训练时进行了多次梯度更新，为了解决上述问题，引入了正则化方法。引入一些记号：

$$ L_i(φ) = L(φ, D_i^{test}) $$

$$ \hat{L}_i(φ) = L(φ, D_i^{tr}) $$

$$ Alg_i(θ) = Alg(θ, D_i^{tr}) $$

**iMAML**的优化问题可以写作：

$$ θ_{ML}^* = \mathop{\arg \min}_{θ \in Θ} F(θ) $$

$$ F(θ) = \frac{1}{M} \sum_{i=1}^{M} {L_i(Alg_i^*(θ))} $$

$$ Alg_i^*(θ) = \mathop{\arg \min}_{φ' \in Φ} \hat{L}_i(φ') + \frac{λ}{2} \mid\mid φ'-θ \mid\mid^2 $$

其中正则化项限制了参数$φ$的更新不能和初始化参数$θ$偏差太大。

下面求初始化参数$θ$的更新方向，即求$$ d_θF(θ) $$:

$$ d_θF(θ) = \frac{1}{M} \sum_{i=1}^{M} {d_θL_i(Alg_i(θ))} $$

$$ d_θL_i(Alg_i(θ)) = \frac{dAlg_i(θ)}{dθ} \nabla_ φ L_i(φ) \mid_{φ=Alg_i(θ)} $$

因此初始化参数$θ$的更新可表示成：

$$ θ = θ-η \frac{1}{M} \sum_{i=1}^{M} {\frac{dAlg_i^*(θ)}{dθ} \nabla_ φ L_i(φ) \mid_{φ=Alg_i^*(θ)}} $$

$$\nabla_ φ L_i(φ) \mid_{φ=Alg_i^*(θ)}$$表示模型在每一个任务上训练完之后在参数$φ$处的梯度，容易计算；下面计算$$\frac{dAlg_i^*(θ)}{dθ}$$（即$\frac{dφ}{dθ}$）：

注意到$$ Alg_i^*(θ) = \mathop{\arg \min}_{φ \in Φ} \hat{L}_i(φ) + \frac{λ}{2} \mid\mid φ-θ \mid\mid^2 $$，因此有下式：

$$ \frac{d}{dφ} \hat{L}_i(φ) + \frac{λ}{2} \mid\mid φ-θ \mid\mid^2 = \nabla_φ \hat{L}_i(φ) + λ(φ-θ) = 0 $$

上式再次对$θ$求梯度：

$$ \nabla_θ (\nabla_φ \hat{L}_i(φ) + λ(φ-θ)) = 0 $$

$$ \frac{dφ}{dθ}\nabla_φ^2 \hat{L}_i(φ) + λ(\frac{dφ}{dθ}-I) = 0 $$

$$ \frac{dφ}{dθ} = (I+\frac{1}{λ}\nabla_φ^2 \hat{L}_i(φ))^{-1} $$

完整的**iMAML**算法如下：

![](https://pic.downk.cc/item/5f05ced914195aa59420404d.jpg)

实际使用时需要注意的两点：
- 模型在每个任务上并不直接训练到最优值，只要参数$φ$足够接近最优值即可：

$$ \mid\mid φ_i - Alg_i^*(θ) \mid\mid ≤ δ $$

- 求参数$θ$的更新梯度时，可以用数值解法求逆矩阵及其乘积：

$$ \mid\mid g_i - (I+\frac{1}{λ}\nabla_φ^2 \hat{L}_i(φ))^{-1} \nabla_ φ L_i(φ) \mid_{φ=Alg_i^*(θ)} \mid\mid ≤ δ' $$

![](https://pic.downk.cc/item/5f05d0e914195aa5942120b8.jpg)

实验证明，**iMAML**很好地权衡了误差率、内存大小和运行时间。
