---
layout: post
title: 'Language Models are Open Knowledge Graphs'
date: 2021-07-01
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60dd22da5132923bf889139c.jpg'
tags: 论文阅读
---

> 使用预训练的语言模型生成知识图谱.

- paper：Language Models are Open Knowledge Graphs
- arXiv：[link](https://arxiv.org/abs/2010.11967)

**知识图谱(knowledge graph)**是一种结构化的图结构，用于表示知识及其之间的关系。知识图谱中一般存储两种知识，第一种是**实体(entity)**，如人名地名这类的名词；另一种是**关系(relation)**，表示实体间的联系，如出生地、职业等。实体一般表示为图中的**结点(node)**，关系一般表示为图中的**边(edge)**。开放知识图谱一般用**三元组(triple)**（起始实体，关系，结束实体）表示。

本文提出了一种使用预训练的语言模型(如**BERT**,**GPT-2**)自动生成知识图谱的方法。首先使用预训练语言模型从清洗过的语料库中提取三元组，再将这些三元组映射为知识图谱。模型的整体结构如下图所示，由于该模型主要包括**match**和**map**两部分，因此也被称为**MaMa**。

![](https://pic.imgdb.cn/item/60dd26a75132923bf8a21f6c.jpg)

## step 1: match

**match**这一步是自动抽取三元组。语料库选用**WiKi**百科，预训练模型选用直接发布的模型而不进行微调。由于实体抽取的技术已经相当成熟，因此给定语料库中的段落，先用开源的实体抽取工具提取段落中的所有实体，构成所有可能建立的关系候选。任选其中两个实体，依据在句子中出现的关系分别看作起始实体(头实体)和结束实体(尾实体)。之后使用预训练的语言模型提取实体间的关系，这一步是通过预训练模型中的注意力权重实现的。

对于任意(起始实体,结束实体)对，使用**beam search**的方法生成一个从起始实体到结束实体的序列。对于每一个**token**，关注注意力矩阵中该**token**与其后所有**token**之间的注意力得分，每次选取得分最大的**token**与该**token**匹配。通过搜索便可以获得三元组。

![](https://pic.imgdb.cn/item/60dd26bc5132923bf8a2afc0.jpg)

通过搜索获得的三元组可能不是合适的关系三元组，因此作者设置了一些过滤三元组的条件：
1. 只保留注意力权重之和超过阈值的三元组序列，保证提取的三元组对实体有特殊意义；
2. 提取出来的关系必须在整个语料库中出现足够多的次数，防止出现过于细节和冷门的关系；
3. 关系序列必须是句子中出现的连续**token**，防止提取出没有意义的关系。

## step 2: map
将生成的三元组映射为知识图谱已经有比较成熟的方法，因此作者直接使用**实体链接(entity linking)**和**关系映射(relation maping)**方法生成最终的知识图谱。

## 实验分析
为了与其他方法对比，作者将该模型生成的开放知识图谱对应到已有的数据集上，与其他模型进行比较。该模型在准确率和召回率上均超过其他方法。值得一提的是这些模型的召回率普遍较低，这是因为很难穷尽所有关系。

![](https://pic.imgdb.cn/item/60dd26d55132923bf8a35326.jpg)

除了可以被对应到人造数据集中的关系外，该模型还能够发现没有被预定义的关系。如下图中蓝色的关系是预定义的，黄色的关系(占$33\%$)是模型额外生成的。比如**Dylan**和其他歌手曾经合作过、曾经是某个乐队的成员等，这样的信息是人工定义的关系中所没有的，但对于歌手来说却很重要。

![](https://pic.imgdb.cn/item/60dd27065132923bf8a49120.jpg)
