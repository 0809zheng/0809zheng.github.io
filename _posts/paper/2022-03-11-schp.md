---
layout: post
title: 'Self-Correction for Human Parsing'
date: 2022-03-11
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/61a1dc792ab3f51d9111e89d.jpg'
tags: 论文阅读
---

> 人体解析中的自校正.

- paper：[Self-Correction for Human Parsing](https://arxiv.org/abs/1910.09777)

为细粒度的语义分割任务(如人体解析)标记像素级的掩码是一项具有挑战性的项目，不同语义部分之间的模糊边界会在标签中引入标签噪声。

人体解析是一个细粒度语义分割任务，旨在将人体图像的每个像素分配到一个语义类别，下图展示了人体解析中几种常见的标签噪声：

![](https://pic.imgdb.cn/item/622aa1055baa1a80ab947eb8.jpg)

本文提出了一种净化标签噪声的方法，即人体解析的自校正(**Self-Correction for Human Parsing, SCHP**)。模型训练从具有噪声的标签出发，通过循环学习对标签进行逐步校正。**SCHP**包括模型聚合和标签细化两个步骤。通过聚合当前模型和前一个最优模型来推断更可靠的伪标签，并用这些更正的标签训练更鲁棒的模型。下图展示了迭代训练过程中每轮伪标签的迭代情况：

![](https://pic.imgdb.cn/item/622aa7b85baa1a80ab98ca8d.jpg)

# 1. 模型设计

网络的主体结构采用**CE2P**。**CE2P**结合了人体的边缘检测和解析，包括解析(**parsing**)分支、边缘(**edge**)分支和融合(**fusion**)分支。解析分支用于生成人体不同部位的热图，边缘分支用于生成人体边缘，融合分支用于将部位热图和边缘结合起来生成细化的解析结果。

![](https://pic.imgdb.cn/item/622af6945baa1a80abcfabd4.jpg)

对于解析分支，使用交叉熵损失衡量部位热图的预测结果。假设共有$K$个部位，热图包含$N$个像素，则分割损失为：

$$ \mathcal{L}_{cls} = -\frac{1}{N}\sum_{k}^{}\sum_{n}^{} \hat{y}^n_k \log p(y_k^n) $$

作者进一步引入了**mIoU**损失提高模型表现，则解析分支的损失记为：

$$ \mathcal{L}_{parsing} =\mathcal{L}_{cls} + \mathcal{L}_{miou} $$

对于边缘分支，也使用交叉熵损失$\mathcal{L}_{edge}$衡量边缘的分割结果。

对于融合分支，希望部位的解析结果尽可能匹配边缘的预测结果。因此显式地增加约束项来惩罚部位和边界预测的不一致性：

$$ \mathcal{L}_{consistent} = \frac{1}{|N^+|}\sum_{n \in N^+}^{} |\tilde{e}^n-e^n| $$

其中$e^n$是边缘分支的边缘映射，$\tilde{e}^n$是从解析分支生成的的边缘映射。

模型的总损失函数定义为：

$$ \mathcal{L} =\lambda_1 \mathcal{L}_{edge} + \lambda_2 \mathcal{L}_{parsing} + \lambda_3 \mathcal{L}_{consistent} $$

下表展示了不同损失的消融实验结果：

![](https://pic.imgdb.cn/item/623199be5baa1a80abe60784.jpg)

# 2. 模型训练

模型训练使用一种自校正机制。通过模型和标签的聚合过程，循环学习$T$个周期得到更准确的模型和标签。对于每个周期，预设初始学习率$\eta_{max}$和最终学习率$\eta_{min}$，则学习率采用带热重启的余弦退火形式：

$$ \eta = \eta_{min} + \frac{1}{2}(\eta_{max}-\eta_{min})(1+\cos(\frac{T_{cur}}{T}\pi)) $$

![](https://pic.imgdb.cn/item/6231958a5baa1a80abe25d05.jpg)

循环自校正包括模型聚合和标签聚合两个过程。对于模型聚合，记录当前轮数的训练权重$\hat{w}$与之前训练的最优权重$\hat{w}_{m-1}$，得到融合权重并更新历史最优权重：

$$ \hat{w}_m = \frac{m}{m+1}\hat{w}_{m-1} + \frac{1}{m+1}\hat{w} $$

标签的更新类似，通过融合当前预测结果$\hat{y}$和前一轮标签$\hat{y}_{m-1}$获得类别关系更明确的新标签：

$$ \hat{y}_m = \frac{m}{m+1}\hat{y}_{m-1} + \frac{1}{m+1}\hat{y} $$

自校正训练的算法流程如下：

![](https://pic.imgdb.cn/item/623198a15baa1a80abe4f4fb.jpg)

下表展示了模型聚合和标签聚合的消融结果：

![](https://pic.imgdb.cn/item/623199dc5baa1a80abe62d43.jpg)

# 3. 实验分析

在**LIP**数据集上的实验结果表明，该方法获得最好的效果：

![](https://pic.imgdb.cn/item/62319c405baa1a80abe7f79a.jpg)
