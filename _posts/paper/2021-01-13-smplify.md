---
layout: post
title: 'Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image'
date: 2021-01-13
author: 郑之杰
cover: 'https://img.imgdb.cn/item/5ffe475b3ffa7d37b385f792.jpg'
tags: 论文阅读
---

> 从单张图像中建立三维SMPL模型.

- paper：Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image
- arXiv：[link](https://arxiv.org/abs/1607.08128)
- website：[link](http://smplify.is.tuebingen.mpg.de/)

作者提出了一个从单张图像中估计$3D$人体姿态的方法：**SMPLify**。该方法首先从图像中估计$2D$人体关节；再使用**SMPL**人体模型从$2D$关节估计$3D$姿态和形状。**SMPL**模型是一个高质量的三维人体生成模型。它经过训练可以捕捉人体形状变化和不同姿态的统计参数。该模型适用于少量数据的情况，因为它捕捉了大量的人体形状信息。

![](https://img.imgdb.cn/item/5ffe48f63ffa7d37b386d39d.jpg)

模型的整体流程如上图所示。首先使用**DeepCut**模型从单张图像中估计$2D$人体关节点$J_{est}$，其中的每个关节点$i$对应一个置信度$w_i$。之后通过最小化一个鲁棒的加权误差将$2D$人体关节点映射到$3D$人体模型。

$3D$人体模型定义为$M(\beta, \theta, \gamma)$。其中$\beta$表示形状(**shape**)参数，$\theta$表示姿态(**pose**)参数，$\gamma$表示转换(**translation**)参数。模型的输出是包含$6890$个顶点的三角曲面$M$。**SMPL**模型定义了**male**和**female**两类，作者额外定义了**gender-neutral**类。

**形状参数**$\beta$是一个低维形状空间的系数，从训练集中学习得到。**姿态参数**$\theta$表示部位之间相对旋转的轴角表示。预先定义人体的$23$个关节点，记$J(\beta)$为从形状参数$\beta$中预测$3D$关节点位置的函数。在**SMPL**模型中，关节点是表面顶点的稀疏线性组合，或者等价地是形状参数$\beta$的函数。通过全局刚性变换$R_{\theta}$，可将关节点映射到任意姿态中。具有姿态信息的$3D$关节点位置表示为$R_{\theta}(J(\beta))$。

![](https://img.imgdb.cn/item/5ffe4d7a3ffa7d37b3893345.jpg)

作者使用一系列**胶囊(capsule)**模拟人体表面，如上图所示。每个胶囊都有一个半径参数和一个轴长参数。通过这种代理几何学的模拟可以计算人体表面的碰撞，避免出现**渗透(interpenetration)**等“穿模”问题。具体地，将除了手指和脚趾的每个身体部位设置$20$个胶囊。通过交叉验证的岭回归将形状参数$\beta$映射为胶囊的半径参数和轴长参数。

建立模型优化的目标函数：

$$ E_J(\beta , \theta ; K, J_{est}) + \lambda_{\theta}E_{\theta}(\theta) + \lambda_{a}E_{a}(\theta) + \lambda_{sp}E_{sp}(\theta ; \beta) + \lambda_{\beta}E_{\beta}(\beta) $$

其中$K$为相机参数，$\lambda_{\theta}$,$\lambda_{a}$,$\lambda_{sp}$,$\lambda_{\beta}$是权重系数。其中每一项的含义和具体计算如下：

**基于关节点的数据项(joint-based data term)** $E_J(\beta , \theta ; K, J_{est})$惩罚估计的$2D$关节点坐标$J_{est}$和对应的**SMPL**坐标映射之间的$2D$加权距离。计算如下：

$$ E_J(\beta , \theta ; K, J_{est}) = \sum_{\text{joint }i}^{} w_i \rho(\Pi_K(R_{\theta}(J(\beta))_i)-J_{est,i}) $$

其中$\Pi_K$根据相机参数$K$得到的$3D$到$2D$的映射。将**DeepCut**模型计算的置信度$w_i$作为权重，$\rho$表示鲁棒可微**Geman-McClure**惩罚函数。

**姿态先验(pose prior)** $E_{a}(\theta)$对肘部(**elbow**)和膝盖(**knee**)的弯曲程度进行惩罚。计算如下：

$$ E_{a}(\theta) = \sum_{i}^{} exp(\theta_i) $$

其中$i$遍历与膝盖和肘部弯曲对应的姿态参数$\theta$。负弯曲是自然的，因此指数惩罚较小；正的弯曲是不自然的，受到严重的惩罚。

**姿态先验(pose prior)** $E_{\theta}(\theta)$对人体姿态的优先程度进行惩罚（一些姿态比另一些姿态更容易出现）。使用**CMU**数据集作为姿态先验的数据集，建立高斯混合模型，并优化其负对数。计算如下：

$$ E_{\theta}(\theta) = -log\sum_{j}^{} (g_jN(\theta; \mu_{\theta,j}, \Sigma{\theta,j})) \\ ≈ -log(\mathop{\max}_{j} (cg_i N(\theta; \mu_{\theta,j}, \Sigma{\theta,j}))) = \mathop{\min}_{j} (-log (cg_i N(\theta; \mu_{\theta,j}, \Sigma{\theta,j}))) $$

其中为简化计算，使用最大值算子近似求和算子。$g_j$表示$J=8$的混合高斯的权重，$c$是一个正常数。通过学习到的高斯混合模型计算当前姿态参数$\theta$出现的概率，概率越大表示该姿态越自然，越容易出现。

胶囊的**渗透误差项(interpenetration error term)** $E_{sp}(\theta ; \beta)$由自然姿态中本不应该相交的胶囊之间的的相交体积计算。将胶囊简化为具有中心$C(\theta, \beta)$和半径$r(\beta)$的球体，将每个球体看作$3D$各向同性的高斯模型，且$\sigma(\beta) = \frac{r(\beta)}{3}$。将惩罚项定义为高斯积分的缩放版本，计算如下：

$$ E_{sp}(\theta ; \beta) = \sum_{i}^{} \sum_{j \in I(i)}^{} exp(\frac{||C_i(\theta , \beta)-C_j(\theta , \beta)||^2}{\sigma_i^2(\beta) + \sigma_j^2(\beta)}) $$

其中$i$表示所有胶囊，$I(i)$表示与胶囊$i$不相容的胶囊集合。该项并不用来优化人体形状，否则会将形状变瘦来避免不相容。

**形状先验(shape prior)** $E_{\beta}(\beta)$计算如下：

$$ E_{\beta}(\beta) = \beta^T \Sigma_{\beta}^{-1} \beta $$

其中对角矩阵$\Sigma_{\beta}^{-1}$是通过主成分分析从**SMPL**的训练集形状中估计得到的平方奇异值。形状参数$\beta$是零均值的。


