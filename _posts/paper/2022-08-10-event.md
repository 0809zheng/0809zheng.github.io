---
layout: post
title: 'When Deep Learners Change Their Mind: Learning Dynamics for Active Learning'
date: 2022-08-10
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/631b223616f2c2beb1c4493d.jpg'
tags: 论文阅读
---

> 基于遗忘事件的主动学习.

- paper：[When Deep Learners Change Their Mind: Learning Dynamics for Active Learning](https://arxiv.org/abs/2107.14707)

# 1. 遗忘事件 Forgetting Event

神经网络具有遗忘之前学习到的信息的趋势。若在模型训练阶段记录每个样本的模型预测结果，并统计样本预测类别的变化情况，则样本可以划分为：
- 可遗忘(**forgettable**)样本：也称为冗余样本，是指在训练阶段预测类别不断变化的样本。
- 不可遗忘(**unforgettable**)样本：是指在训练阶段预测类别不变的样本，这类样本一旦学习过便不会被遗忘。

在训练过程中存在大量一旦学习过便不会遗忘的不可遗忘样本；而可遗忘样本大多是标签存在噪声或具有不常见特征的样本。实验结果表明将这些不可遗忘样本移除训练集后模型的表现不会有明显程度的下降。

遗忘事件可以作为主动学习的采样依据，如果模型在训练过程中改变预测结果则表明模型对该样本的不确定性较大，因此在采样时选择可遗忘样本。

# 2. 标签分散度 Label Dispersion

然而对于未标记的样本，真实标签是未知的，因此很难衡量样本的可遗忘性。作者提出了衡量无标签样本的可遗忘性的指标：**标签分散度(label dispersion)**。

记$c^{\*}$是样本$x$在训练过程中最常出现的预测标签，则标签分散度衡量训练过程中模型的预测类别不是$c^{\*}$的比例：

$$ Dispersion(x) = 1-\frac{f_x}{T} \\ f_x = \sum_{t=1}^T \Bbb{I}[\hat{y}_t=c^*], c^* = \mathop{\arg \max}_{c=1,...,C} \sum_{t=1}^T [\hat{y}_t=c] $$

如果模型不停地为同一个样本预测相同的类别，则标签分散度比较低；如果预测类别经常改变，则标签分散度比较高，对应预测的不确定性较大。

![](https://pic.imgdb.cn/item/6320392116f2c2beb16a9e53.jpg)

实验结果给出了逐渐为标签分散度更大的样本进行标记后的训练结果。结果表明人工标记标签分散度较小的样本无法提供有效的信息。

![](https://pic.imgdb.cn/item/6320397816f2c2beb16afd8e.jpg)