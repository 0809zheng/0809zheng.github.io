---
layout: post
title: 'Barlow Twins: Self-Supervised Learning via Redundancy Reduction'
date: 2022-10-16
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63d7968fface21e9ef09ea56.jpg'
tags: 论文阅读
---

> Barlow Twins：通过冗余度消除实现自监督学习.

- paper：[Barlow Twins: Self-Supervised Learning via Redundancy Reduction](https://arxiv.org/abs/2103.03230)

**Barlow Twins**把数据样本的两个增强版本喂入同一个神经网络以提取特征表示，并使得两组输出特征的互相关矩阵(**cross-correlation matrix**)接近单位矩阵。该目标使得同一个样本的不同增强版本对应的特征向量相似，并最小化这些向量之间的冗余度。

![](https://pic.imgdb.cn/item/63d797e3face21e9ef0c7486.jpg)

记任意样本$x$的两次数据增强结果为$x_i,x_j$，对应的特征向量为$z_i,z_j$，则一批样本的特征向量对应的互相关矩阵$$\mathcal{C}$$中的元素计算为:

$$ \mathcal{C}_{ij} = \frac{\sum_bz^A_{b,i}z^B_{b,j}}{\sqrt{\sum_b(z_{b,i}^A)^2}\sqrt{\sum_b(z^B_{b,j})^2}} $$

**Barlow Twins**的损失函数构造为：

$$ \mathcal{L}_{\text{BT}} = \sum_i (1-\mathcal{C}_{ii})^2 + \lambda \sum_i \sum_{j\neq i} \mathcal{C}_{ij}^2 $$

![](https://pic.imgdb.cn/item/63d7b3f4face21e9ef4053e7.jpg)

**Barlow Twins**在自监督学习领域与一些**SOTA**方法具有竞争力，但并未达到当时的最高水平。

![](https://pic.imgdb.cn/item/63d7d40fface21e9ef835c6a.jpg)

通过实验证明，**Barlow Twins**对批量大小的设置具有鲁棒性。

![](https://pic.imgdb.cn/item/63d7d433face21e9ef83b0d8.jpg)

此外实验表明**Barlow Twins**对特征映射头的映射维度比较敏感，需要更大的特征头以获得较好的性能。

![](https://pic.imgdb.cn/item/63d7d48aface21e9ef849134.jpg)