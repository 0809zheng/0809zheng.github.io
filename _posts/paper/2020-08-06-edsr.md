---
layout: post
title: 'Enhanced Deep Residual Networks for Single Image Super-Resolution'
date: 2020-08-06
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f487fba160a154a67994401.jpg'
tags: 论文阅读
---

> EDSR：增强的深度超分辨率网络.

- paper：Enhanced Deep Residual Networks for Single Image Super-Resolution
- arXiv：[link](https://arxiv.org/abs/1707.02921)

# 1. 研究背景
作者通过改进残差网络结构训练了一个增强版本的超分辨率卷积网络。分析对比现有的残差结构：

![](https://pic.downk.cc/item/5f48b42d160a154a67a6a99c.jpg)

作者认为**ResNet**等残差网络的提出是针对图像分类等**high-level**任务（更关注图像的语义特性），而不适合直接用于超分辨率等**low-level**任务（更关注图像的像素特性）。

相较于最初的**ResNet**，作者进行了如下改进：
- 去除了残差块之间的**ReLU**激活函数，仅在残差块内部使用；
- 去除了**BatchNorm**，作者认为其破坏了网络的**range flexibility**；这一步相比于**SRResNet**降低了训练时$40\%$的内存使用率。

# 2. 模型结构
作者提出了两种网络结构，分别是单尺度模型**enhanced deep super-resolution network (EDSR)**和多尺度模型**multi-scale
deep super-resolution system (MDSR)**。

### EDSR

![](https://pic.downk.cc/item/5f48b753160a154a67a76559.jpg)

通常网络层数为$B$、特征通道数为$F$的卷积神经网络需要$O(BF)$内存和$O(BF^2)$参数量。

作者设置$$B = 32, F = 256$$训练网络的残差连接部分。对于不同分辨率的要求，只需要对网络最后的上采样部分进行修改，可以共用网络残差部分的参数；这样可以加快模型的训练速度。

为了使训练更稳定，作者使用了**residual scaling**，对每个残差块的残差路径最后乘以(**Mult**)因子$0.1$。

### MDSR

![](https://pic.downk.cc/item/5f48b93c160a154a67a7f4e7.jpg)

作者还提出一个多尺度模型，可同时训练不同放大倍率的图像。

# 3. 实验分析
实验设置：
- 训练集：DIV2K
- 测试集：Set5, Set14, Urban100, B100
- 评估指标：PSNR, SSIM

作者使用了**self-ensemble**策略，测试时通过翻转和旋转测试图像，总共得到$8$张测试图像，将其喂入网络后再通过反向翻转和旋转得到$8$张高分辨率图像，最终结果取其平均值。

模型的实验结果如下：

![](https://pic.downk.cc/item/5f48b267160a154a67a64051.jpg)

![](https://pic.downk.cc/item/5f48b28d160a154a67a64c64.jpg)