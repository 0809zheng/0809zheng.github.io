---
layout: post
title: 'Emerging Properties in Self-Supervised Vision Transformers'
date: 2022-10-29
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63e4480c4757feff33670a21.jpg'
tags: 论文阅读
---

> DINO：自监督视觉Transformer的新特性.

- paper：[Emerging Properties in Self-Supervised Vision Transformers](https://arxiv.org/abs/2104.14294)

**Self-distillation with no labels (DINO)**是一种为视觉**Transformer**设计的对比学习方法。该方法没有使用负样本，而是采用一种自蒸馏策略。

![](https://pic.imgdb.cn/item/63e44bd84757feff336e3d20.jpg)

使用学生网络$f_s$和教师网络$f_t$从图像$x$的两个增强版本$x_1,x_2$中提取特征$f_s(x_1),f_t(x_2)$，教师网络$f_t$的参数$\theta_t$为学生网络参数$\theta_s$的滑动平均值$\theta_t \leftarrow m \theta_t + (1-m)\theta_s$。

为防止训练过程的模式崩溃(即学生网络和教师网络预测完全一致的结果)，为教师网络的预测特征引入**centering**操作，即特征减去历史特征的滑动平均值：

$$ \begin{aligned} c &\leftarrow m c + (1-m)f_t(x_2) \\ f_t(x_2) &\leftarrow f_t(x_2)-c \end{aligned} $$

把特征$f_s(x_1),f_t(x_2)$通过**softmax**函数映射为概率分布：

$$ \begin{aligned} p_s(x_1)^{i} = \frac{\exp(f_s(x_1)^i/\tau_s)}{\sum_k \exp(f_s(x_1)^k/\tau_s)} \\ p_t(x_2)^{i} = \frac{\exp(f_t(x_2)^i/\tau_t)}{\sum_k \exp(f_t(x_2)^k/\tau_t)}  \end{aligned} $$

则损失函数构建为两个概率分布的交叉熵（设计为对称形式）：

$$ \mathcal{L}_{\text{DINO}} = -p_t(x_2) \log p_s(x_1) -p_t(x_1) \log p_s(x_2) $$

**DINO**的完整流程如下：

![](https://pic.imgdb.cn/item/63e451da4757feff33786cde.jpg)

**DINO**中的映射头结构设计如下：

![](https://pic.imgdb.cn/item/63e4531f4757feff337a5811.jpg)

作者汇报了**DINO**方法的消融实验：

![](https://pic.imgdb.cn/item/63e453754757feff337ae0be.jpg)

实验结果表明，对教师网络的特征同时应用**centering**操作和较小的$\tau_t$(对应锐化操作)能够有效地防止模型崩溃。

![](https://pic.imgdb.cn/item/63e453db4757feff337b9550.jpg)