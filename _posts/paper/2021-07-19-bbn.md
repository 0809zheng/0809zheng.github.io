---
layout: post
title: 'BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition'
date: 2021-07-19
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60f508195132923bf8403c92.jpg'
tags: 论文阅读
---

> BBN：通过累积学习进行长尾分类的双分支网络.

- paper：BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition
- arXiv：[link](https://arxiv.org/abs/1912.02413)

作者认为训练分类模型的过程可以被解耦为**表示学习(representation learning)**和**分类器学习(classifier learning)**两部分，且上述两部分是同时进行的，因此提出了一种**累积学习(Cumulative Learning)**的双分支网络**Bilateral-Branch Network(BBN)**。

作者首先进行了一系列对比实验。将分类模型拆分成两阶段，第一阶段进行表示学习，第二阶段固定特征提取部分，微调分类器(最后一层全连接层)。在每个阶段的训练中，分别使用分类交叉熵损失**CE**、重加权方法**RW**和重采样方法**RS**进行训练，并对比不同方法组合的错误率，结果如下：

![](https://pic.imgdb.cn/item/60f50deb5132923bf86c80f9.jpg)

从上述结果中不难得出，当分类器学习采用相同的学习策略时(即横向比较)，特征学习引入重加权或重采样方法均使得错误率提升，这表明重加权或重采样方法会影响模型学习到较好的特征表示。当特征学习采用相同的学习策略时(即纵向比较)，分类器学习引入重加权或重采样方法均使得错误率降低，这表明重加权或重采样方法会帮助分类部分通过平衡类别获得更好的表现。

本文提出的**BBN**具有两个分支，即进行特征学习的**conventional learning**分支和进行分类器学习的**re-balancing**分支。**conventional learning**分支使用正常的采样方法(即按照原始分布进行采样，类别的样本数量越多则采样到的样本越多)，而**re-balancing**分支使用**reversed sampling**，即控制重采样时每个类别$j$被采样的概率与该类别样本数量成反比例(类别的样本数量越多则采样到的样本越少)：

$$ p_j^{Re} = \frac{w_j}{\sum_{j=1}^{C}w_j}, \quad w_j=\frac{n_{max}}{n_j} $$

![](https://pic.imgdb.cn/item/60f50e0e5132923bf86d95e7.jpg)

**调整器(adaptor)**通过累积学习策略使用$\alpha$控制网络的两个分支在训练过程中的权重：

$$ \alpha = 1-(\frac{T}{T_{max}})^2 $$

$\alpha$表示特征提取分支对预测结果的影响，随训练轮数不断减小。即在训练时，首先侧重于在类别不平衡的原始数据集中学习到通用的特征表示，再侧重于在重采样后的类别平衡数据集上学习到适用于分类任务的特征。若记两个分支输出的**logits**分别是$f_c$和$f_r$，则最终的**logits**计算为：

$$ z=\alpha W_c^Tf_c+(1-\alpha)W_r^Tf_r $$

最终的损失函数计算为：

$$ \mathcal{L}=\alpha E(\hat{p},y_c)+(1-\alpha)E(\hat{p},y_r), \quad \hat{p}=\text{softmax}(z) $$

![](https://pic.imgdb.cn/item/60f5189b5132923bf8c06117.jpg)

作者通过消融实验选择了不同的权重$\alpha$设置方式：

![](https://pic.imgdb.cn/item/60f519225132923bf8c4b0bd.jpg)

实验对比不同方法在长尾分布数据集上的错误率，**BBN**取得最好的效果：

![](https://pic.imgdb.cn/item/60f50e465132923bf86f4d46.jpg)

