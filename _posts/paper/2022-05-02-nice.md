---
layout: post
title: 'NICE: Non-linear Independent Components Estimation'
date: 2022-05-02
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6298552b0947543129ee1849.jpg'
tags: 论文阅读
---

> NICE：非线性独立成分估计.

- paper：[NICE: Non-linear Independent Components Estimation](https://arxiv.org/abs/1410.8516)

# 1. 问题建模

本文讨论对数据集的复杂高维概率密度进行建模的方法。由于具有良好的表示会使数据具有易于建模的分布，因此参数化数据的非线性变换，将其映射到隐空间，以使变换后的数据符合给定的分布。

若已有数据集的概率密度函数为$p_X(x)$，给定参数化变换$z=f(x)$，根据概率密度的变量替换定理 (**Change of Variable Theorem**):

$$ p_X(x) = p_Z(f(x))\cdot |\det[\frac{\partial f(x)}{\partial x}]| $$

其中$[\frac{\partial f(x)}{\partial x}]$是函数$f$在$x$上的**Jacobian**矩阵。通过选择合适的$f$使得**Jacobian**矩阵的行列式容易计算。变换$h=f(x)$的逆变换也应容易获得，此时可以实现从$p_X(x)$中采样：

$$ z~p_Z(h), x = f^{-1}(z)$$

若将隐变量$z$的先验分布$p_Z(z)$预设为各分量独立的标准正态分布：

$$ p_Z(z) = \frac{1}{(\sqrt{2\pi})^D}e^{-\frac{1}{2}||z||^2} $$

则概率密度函数$p_X(x)$表示为：

$$ p_X(x) = \frac{1}{(\sqrt{2\pi})^D}e^{-\frac{1}{2}||f(x)||^2} \cdot |\det[\frac{\partial f(x)}{\partial x}]| $$

优化目标为最大化对数似然，进一步写作：

$$ \log p_X(x) = -\frac{D}{2}\log (2\pi) -\frac{1}{2}||f(x)||^2 + \log |\det[\frac{\partial f(x)}{\partial x}]| $$

# 2. 加性耦合层

为了使得**Jacobian**矩阵的行列式容易计算，并且变换$h=f(x)$的逆变换容易实现，作者设计了一种**加性耦合层(Additive Coupling Layer)**。

把$D$维输入变量$x$拆分成两部分$x_1$和$x_2$，取如下变化：

$$ \begin{aligned} h_1&= x_1 \\ h_2&=x_2+m(x_1) \end{aligned} $$

其中$m$是任意函数，可以用多层感知机实现。$x_1$和$x_2$是$x$的某种划分，不失一般性地假设$x_1=x_{1:d}$，$x_2=x_{d+1:D}$。该变换的**Jacobian**矩阵是下三角阵：

$$ [\frac{\partial h}{\partial x}] = \begin{pmatrix} I_d & 0 \\ \frac{\partial m}{\partial x_1} & I_{d:D} \end{pmatrix} $$

上述**Jacobian**矩阵的行列式为$1$，同时该变换是可逆的：

$$ \begin{aligned} x_1&= h_1 \\ x_2&=h_2-m(h_1) \end{aligned} $$

# 3. 流模型

上述变换比较简单，特征表示能力不强。可以通过复合多个简单变换以增强非线性拟合能力，其中每个变换都采用一次加性耦合层，模型整体像流水一样积少成多，因此也称为**流(flow)**模型。

$$ x = h^{(0)} \leftrightarrow h^{(1)} \leftrightarrow  h^{(2)} \leftrightarrow \cdots  \leftrightarrow  h^{(n-1)}  \leftrightarrow  h^{(n)} =z $$

**Jacobian**矩阵可以根据链式法则计算：

$$ [\frac{\partial z}{\partial x}] = [\frac{\partial h^{(n)}}{\partial h^{(0)}}]=[\frac{\partial h^{(n)}}{\partial h^{(n-1)}}][\frac{\partial h^{(n-1)}}{\partial h^{(n-2)}}]\cdots [\frac{\partial h^{(1)}}{\partial h^{(0)}}] $$

而矩阵乘积的行列式等于矩阵行列式的乘积：

$$ \det [\frac{\partial z}{\partial x}] = \det [\frac{\partial h^{(n)}}{\partial h^{(n-1)}}]\det [\frac{\partial h^{(n-1)}}{\partial h^{(n-2)}}]\cdots \det [\frac{\partial h^{(1)}}{\partial h^{(0)}}] = 1 $$

注意到加性耦合层中存在一部分平凡的恒等变换$x_1=h_1$，如果直接堆叠多层加性耦合层，则第一部分仍然是平凡的$h_1^{(0)}= h_1^{(n)}$。

![](https://pic.imgdb.cn/item/62985e820947543129fb09bd.jpg)

为了增强模型的表示能力，可以在每个加性耦合层之前互换两个部分的位置，使得信息充分混合：

$$ \begin{aligned} h_1^{(i)}&= h_1^{(i-1)} \\ h_2^{(i)}&=h_2^{(i-1)}+m(h_1^{(i-1)}) \end{aligned} \quad \to \quad \begin{aligned} h_1^{(i+1)}&= h_1^{(i)}+m(h_2^{(i)}) \\ h_2^{(i+1)}&=h_2^{(i)} \end{aligned} $$

![](https://pic.imgdb.cn/item/62985fe90947543129fcbf1a.jpg)

# 4. NICE

**NICE**模型是由多个加性耦合层组成的流模型。
加性耦合层需要将输入分为两部分，**NICE**采用交错分区，即下标为偶数作为第一部分，下标为奇数作为第二部分；而每个$m(x)$采用全连接层（$5$个隐藏层，每层$1000$节点，**relu**激活）。在**NICE**中一共耦合了$4$个加性耦合层。在耦合之前，需要反转输入的维度，使得信息充分混合。

由于流模型构造的变换$z=f(x)$是可逆的，因此输入样本$x$与输出编码$z$具有相同的尺寸。若输入数据为$D$维流形，则编码结果也是$D$维流形，从而产生严重的维度浪费问题。比如**MNIST**图像虽然有$784$个像素维度，但有些像素取值始终为$0$，因此**MNIST**图像的编码维度应该小于$784$。

**NICE**在最后引入了一个**尺度变换层**，起到压缩流形的作用。对输出编码中每个维度的特征进行尺度变换$z=s \otimes h^{(n)}$，其中$s=(s_1,s_2,\cdots s_D)$为可学习非负参数，表示每个特征维度的重要程度。尺度变换层的**Jacobian**矩阵是对角阵：

$$ [\frac{\partial z}{\partial h^{(n)}}] = \text{diag}(s) $$

其行列式为$\prod_d^D s_d$。

将**NICE**模型$z=s \otimes f(x)$带入对数自然，得到优化目标：

$$ \log p_X(x) ~ -\frac{1}{2}||s \otimes f(x)||^2 + \log \prod_d^D s_d $$

### ⚪ 讨论：尺度变换层的作用

若将隐变量$z$的先验分布$p_Z(z)$预设为各分量独立的带方差的正态分布：

$$ p_Z(z) = \frac{1}{(\sqrt{2\pi})^D\prod_d^D \sigma_d}e^{-\frac{1}{2}\sum_d^D \frac{z_d^2}{\sigma_d^2}} $$

则概率密度函数$p_X(x)$表示为：

$$ p_X(x) = \frac{1}{(\sqrt{2\pi})^D\prod_d^D \sigma_d}e^{-\frac{1}{2}\sum_d^D \frac{f_d^2(x)}{\sigma_d^2}} \cdot |\det[\frac{\partial f(x)}{\partial x}]| $$

如果模型由加性耦合层组成，则**Jacobian**矩阵的行列式为$1$，优化目标为：

$$ \log p_X(x) ~  -\log\prod_d^D \sigma_d -\frac{1}{2}\sum_d^D \frac{f_d^2(x)}{\sigma_d^2}  $$

对比该式与**NICE**模型的优化目标，发现尺度变换层等价于带方差的隐变量先验，且$s_d = \frac{1}{\sigma_d}$。某个特征维度的方差$\sigma_d^2$越小(对应$s_d$越大)，表明该维度特征的不确定性越小，所包含的信息也越小。特别地，当$\sigma_d=0$时该维度为固定值，直接删除掉也不会影响结果。

# 5. 实验分析

**NICE**模型的输入图像像素压缩为0～1之间，然后增加[−0.01,0]的均匀分布噪声。噪声的加入能够有效地防止过拟合，提高生成图片的质量。噪声也能够增加图像的等效维度，从而缓解维度浪费问题。

由于加入噪声后，理论上的生成图像也会带有噪声，因此通过加入负噪声，使得最终生成图像的像素值稍微偏向负区间，便可以通过**clip**操作人为去掉一部分噪声。下面展示**NICE**模型在**MNIST**数据集上的生成结果：

![](https://pic.imgdb.cn/item/62986be609475431290cbe12.jpg)