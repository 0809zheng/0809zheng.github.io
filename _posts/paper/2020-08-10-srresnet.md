---
layout: post
title: 'Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network'
date: 2020-08-10
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f55af37160a154a6745b6be.jpg'
tags: 论文阅读
---

> SRResnet/SRGAN：使用生成对抗网络进行图像超分辨率.

- paper：Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network
- CVPR：[link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8099502)

直接使用**MSE**损失函数训练的超分辨率模型，在**PSNR**和**SSIM**等评价指标上能够得到较高的结果，但图像细节显示依旧较差。作者利用生成对抗网络的方法得到视觉特性较好的结果。

![](https://pic.downk.cc/item/5f55b61b160a154a6747142d.jpg)

如上图所示，在图像空间中存在若干结构相似的图像，使用**MSE**损失将会生成这些图像的平均值，忽略图像的细节；而使用**GAN**的方法则会接近某张真实图像，从而保留较好的真实表现。

本文的主要贡献在于：
- 建立了使用**PSNR**和**SSIM**为评价标准的**SRResNet**，对图像放大$4$倍，取得了最好的测试结果;
- 提出了**SRGAN**网络，该网络结构根据对抗网络网络结构提出了一种新的**感知损失函数(perceptual loss)**,利用**VGG**的网络特征作为**内容损失函数(content loss)**,代替了之前的**MSE**损失函数。
- 对生成的图像进行**MOS（mean opinion score）**评价。

# 1. 模型结构

![](https://pic.downk.cc/item/5f55b92d160a154a6747a298.jpg)

作者提出的生成对抗网络结构如图所示。
- 生成器结构参考了**ResNet**，输入低分辨率图像得到高分辨率图像，这一部分可作为**SRResNet**单独使用。
- 判别器结构参考了**VGG**，输入真实图像和生成的高分辨率图像，对二者进行分类。

# 2. 损失函数
模型的训练按照生成对抗网络的损失进行：

$$ \mathop{\min}_{θ_G} \mathop{\max}_{θ_D} E_{I^{HR} \text{~} p_{train}(I^{HR})}[logD_{θ_D}(I^{HR})] + E_{I^{LR} \text{~} p_{G}(I^{LR})}[log(1-D_{θ_D}(G_{θ_G}(I^{LR})))] $$

![](https://pic.downk.cc/item/5f55bd5c160a154a67486a19.jpg)

作者提出了**感知损失函数(perceptual loss)**$l^{SR}$，由**内容损失函数(content loss)**$l_X^{SR}$和**对抗损失函数(adversarial loss)**$l_{Gen}^{SR}$组成。

**内容损失函数(content loss)**$l_X^{SR}$基于一个预训练的**VGG19**网络，通过比较生成图像和真实图像的网络中特征差异进行定义。其中$Φ_{i,j}$表示**VGG19**网络中第$i$个池化层之前的第$j$个卷积层(在激活函数之后)的特征图。

**对抗损失函数(adversarial loss)**$l_{Gen}^{SR}$试图使判别器无法正确的分类生成器获得的结果。

# 3. 实验分析
作者进行了主观打分实验，选择$26$人对不同模型的图像质量进行打分（$1$至$5$分），并用得分均值作为评估结果：

![](https://pic.downk.cc/item/5f55c099160a154a674910e9.jpg)

作者比较了不同模型上$4X$超分辨率得到的客观和主观评价指标：

![](https://pic.downk.cc/item/5f55bf46160a154a6748ca31.jpg)

