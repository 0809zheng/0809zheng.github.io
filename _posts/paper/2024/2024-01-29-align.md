---
layout: post
title: 'Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision'
date: 2024-01-29
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67b5821ad0e0a243d400b847.png'
tags: 论文阅读
---

> 利用噪声文本监督扩大视觉语言表示学习.

- paper：[Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision](https://arxiv.org/abs/2102.05918)

## 0. TL; DR

本文提出了一种利用大规模噪声图像-文本对进行视觉和视觉-语言表示学习的方法，名为**ALIGN（A Large-scale ImaGe and Noisy-text embedding）**。通过使用超过**10**亿对图像和噪声文本数据，**ALIGN**在图像-文本检索、零样本图像分类等任务上取得了显著的性能提升，超越了现有的视觉-语言模型。该方法的核心在于利用简单的双编码器架构和对比损失函数，通过大规模数据弥补噪声数据的不足，展示了数据规模在表示学习中的重要性。

## 1. 背景介绍

在自然语言处理（**NLP**）领域，预训练表示已经成为许多任务的核心，而这些预训练模型通常基于大规模的原始文本数据，无需人工标注。然而，在视觉和视觉-语言领域，预训练表示仍然依赖于经过精心策划和标注的数据集，如**ImageNet、Conceptual Captions**等。这些数据集的创建需要大量的人力和专业知识，限制了数据集的规模，进而阻碍了模型的扩展性。

为了解决这一问题，本文提出了一种利用大规模噪声图像-文本对进行视觉和视觉-语言表示学习的方法。这种方法借鉴了**NLP**中使用大规模未标注文本的思路，通过简单的频率过滤，从超过**10**亿对图像和噪声文本数据中学习视觉和语言表示，避免了复杂的数据清洗和标注过程。

## 2. ALIGN 模型

**ALIGN**模型的核心是利用一个简单的双编码器架构，将图像和文本表示对齐到一个共享的潜在嵌入空间。模型由一个图像编码器和一个文本编码器组成，通过对比损失函数进行优化，使得匹配的图像-文本对的嵌入更接近，而不匹配的对则更远离。

![](https://pic1.imgdb.cn/item/67b5837bd0e0a243d400b8cf.png)

图像编码器使用**EfficientNet**，通过全局池化提取图像特征；文本编码器使用**BERT**，将文本嵌入到与图像相同的嵌入空间中。

模型通过对比损失函数进行优化，具体公式如下：
- 对于图像到文本的分类损失：

$$
L_{i2t}=-\frac{1}{N}\sum_{i}\log\frac{\exp(x_i^Ty_i/\sigma)}{\sum_{j=1}^{N}\exp(x_i^Ty_j/\sigma)}
$$

- 对于文本到图像的分类损失：

$$
L_{t2i}=-\frac{1}{N}\sum_{i}\log\frac{\exp(y_i^Tx_i/\sigma)}{\sum_{j=1}^{N}\exp(y_i^Tx_j/\sigma)}
$$

其中，$x_i$ 和 $y_i$ 分别是第 $i$ 对图像和文本的归一化嵌入，$N$ 是批次大小，$σ$ 是温度参数，用于缩放**logits**。

作者使用超过**18**亿对噪声图像-文本对进行预训练，数据来源于**Conceptual Captions**数据集的扩展。对图像和文本分别进行简单的过滤，例如去除色情图像、重复文本等，避免了复杂的清洗步骤。


## 3. 实验分析

对于图像-文本检索：**ALIGN**在**Flickr30K**和**MSCOCO**数据集上取得了显著的性能提升。在零样本设置下，图像到文本检索任务的**R@1**指标比之前的最佳方法**CLIP**提高了超过**7%**。在微调后，**ALIGN**在所有指标上均超越了现有的方法。

![](https://pic1.imgdb.cn/item/67b58486d0e0a243d400b92b.png)

对于零样本图像分类：**ALIGN**在**ImageNet**零样本分类任务中达到了**76.4%**的**Top-1**准确率，与**CLIP**相当，并在**ImageNet**的变体（如**ImageNet-R、ImageNet-A**）上表现出良好的鲁棒性。

![](https://pic1.imgdb.cn/item/67b5850ed0e0a243d400b95f.png)

对于视觉分类任务：**ALIGN**的图像编码器在**ImageNet**分类任务中达到了**88.64%**的**Top-1**准确率，与**BiT**和**ViT**等模型相当。

![](https://pic1.imgdb.cn/item/67b5852ad0e0a243d400b965.png)

