---
layout: post
title: 'Sigmoid Loss for Language Image Pre-Training'
date: 2024-02-29
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67b5c3b8d0e0a243d400cb83.png'
tags: 论文阅读
---

> 语言图像预训练的Sigmoid损失.

- paper：[Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343)

## 0. TL; DR

本文提出了一种基于**Sigmoid**的损失函数（**Sigmoid Loss**），用于语言-图像预训练（**Language-Image Pre-training, LIP**）。与传统的基于**Softmax**的对比学习方法相比，**Sigmoid Loss**无需全局归一化，能够显著提高训练效率，并且在小批量和大批量训练场景下均表现出色。

## 1. 背景介绍

随着对比学习技术的发展，基于图像-文本对的弱监督预训练逐渐成为获取通用计算机视觉模型的主流方法。传统的预训练方法依赖于大规模标注数据集，而近年来的研究（如**CLIP**和**ALIGN**）表明，利用网络上获取的图像-文本对进行对比学习可以取得更好的效果。这些方法通过学习图像和文本的对齐表示空间，使得匹配的图像-文本对在嵌入空间中更接近，而不匹配的对则更远离。然而，现有的对比学习方法大多采用基于**Softmax**的**InfoNCE**损失，这种方法在计算上较为复杂，且对批量大小的依赖较强。

本文提出了一种简化的**Sigmoid**损失函数，用于替代传统的**Softmax**损失。**Sigmoid**损失函数直接作用于图像-文本对，无需全局归一化，从而简化了分布式训练的实现，并显著提高了效率。此外，**Sigmoid**损失函数在小批量训练场景下表现优于**Softmax**损失，并且在大批量训练场景下也能达到类似的效果。

## 2. SigLIP 模型

**Sigmoid**损失函数的核心在于将图像-文本对的相似性评分转化为一个二分类问题：匹配的对为正样本（标签为$1$），不匹配的对为负样本（标签为$-1$）。具体来说，对于一个包含图像-文本对的小批量数据 $$B=\{(I_i,T_i)\}$$，**Sigmoid**损失函数的目标是最小化以下目标函数：

$$
L = -\frac{1}{\mid B \mid} \sum_{i=1}^{\mid B \mid} \sum_{j=1}^{\mid B \mid} \log\frac{1}{ 1 + e^{z_{ij} (-t x_i \cdot y_j + b)} }
$$

其中$x_i$和$y_j$分别是图像和文本的归一化嵌入向量；$t$是温度参数，控制相似性评分的缩放；$b$是偏置项，用于缓解负样本占主导的情况；$z_{ij}$是标签，匹配对为$1$，不匹配对为$-1$。

![](https://pic1.imgdb.cn/item/67b5c697d0e0a243d400cc32.png)

**Sigmoid**损失函数的一个显著优势是其计算效率高，尤其是在分布式训练中。与**Softmax**损失需要全局归一化不同，**Sigmoid**损失可以独立处理每一对图像-文本对，避免了全局通信和大规模矩阵运算。具体来说，作者提出了一种“分块”实现方法，通过在设备间交换负样本，逐步计算损失，从而显著减少了内存占用和计算开销。

![](https://pic1.imgdb.cn/item/67b5c6c2d0e0a243d400cc39.png)

作者通过实验对比了**Sigmoid**损失和**Softmax**损失在不同批量大小下的性能。结果表明：
- 在小批量训练（如**16k**以下）时，**Sigmoid**损失明显优于**Softmax**损失；
- 随着批量大小的增加，两者性能逐渐接近；
- 在合理的批量大小（如**32k**）下，**Sigmoid**损失即可达到最优性能，进一步增加批量大小的收益有限。
- 此外，**Sigmoid**损失在多语言预训练方面也表现出色，显示出其在实际应用中的潜力。

![](https://pic1.imgdb.cn/item/67b5c715d0e0a243d400cc48.png)

## 3. 实验分析

**WebLI**数据集用于单语言预训练，包含大量英语图像-文本对；**mSigLIP**模型则使用完整的**WebLI**数据集，包含超过**100**种语言。主要使用零样本分类（**Zero-shot Classification**）和零样本检索（**Zero-shot Retrieval**）任务来评估模型性能。零样本分类任务在**ImageNet**数据集上进行，而零样本检索任务则在**COCO**和多语言**XM3600**数据集上进行。

**SigLiT**模型基于预训练的图像编码器和从头开始训练的文本编码器。实验表明：
- 在小批量训练（如**16k**以下）时，**Sigmoid**损失显著优于**Softmax**损失，零样本分类准确率更高；
- 随着批量大小的增加，两者性能逐渐接近，但**Sigmoid**损失在大批量训练时仍表现出更高的效率；
- 在极端大批量训练（如**100**万）时，模型性能趋于饱和，表明合理的批量大小（如**32k**）已足够。

https://pic1.imgdb.cn/item/67b5c819d0e0a243d400cc67.png

**SigLIP**模型从头开始训练图像编码器和文本编码器。实验结果表明**Sigmoid**损失同样表现出色，比如零样本检索任务的平均召回率显著提高。

![](https://pic1.imgdb.cn/item/67b5c862d0e0a243d400cc85.png)

**mSigLIP**模型在包含超过**100**种语言的**WebLI**数据集上进行预训练。实验结果表明：
- 在多语言场景下，合理的批量大小（如**32k**）已足够，进一步增加批量大小会导致性能下降；
- **mSigLIP**在多语言零样本检索任务上达到了新的最佳性能，显著优于之前的模型。

![](https://pic1.imgdb.cn/item/67b5c8f9d0e0a243d400ccc1.png)

作者还研究了负样本比例对训练的影响。实验表明：
- 随机移除负样本会降低性能；
- 保留最难的负样本对训练最为有效；
- 负样本的不平衡并不是主要问题，但高效的负样本挖掘方法可能进一步提升性能。

![](https://pic1.imgdb.cn/item/67b5c920d0e0a243d400ccd0.png)

**Sigmoid**损失在对抗数据噪声方面表现出色。实验通过在训练数据中引入噪声（如随机替换图像或文本、打乱对齐关系）来测试模型的鲁棒性。结果表明，使用**Sigmoid**损失的模型在各种噪声条件下均优于**Softmax**损失的模型。

![](https://pic1.imgdb.cn/item/67b5c94bd0e0a243d400cced.png)