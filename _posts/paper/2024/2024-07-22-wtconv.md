---
layout: post
title: 'Wavelet Convolutions for Large Receptive Fields'
date: 2024-07-22
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/681c4e2158cb8da5c8e4dc87.png'
tags: 论文阅读
---

> 大感受野的小波卷积.

- paper：[Wavelet Convolutions for Large Receptive Fields](https://arxiv.org/abs/2407.05848)

# 0. TL;DR

本文提出了一种名为**WTConv**的新型卷积层，通过小波变换（**WT**）实现大感受野，同时避免了过参数化问题。**WTConv**可作为现有架构中的深度可分离卷积的即插即用替代品，能够有效提升**CNN**在多频率响应、形状偏置和鲁棒性等方面的表现，并在图像分类、语义分割和目标检测等任务中取得了显著的性能提升。

# 1. 背景介绍
在过去的十年中，卷积神经网络（**CNN**）在计算机视觉领域取得了巨大的成功。然而，随着**Vision Transformers（ViTs）**的出现，**CNN**面临着激烈的竞争。**ViTs**的核心优势在于其多头自注意力机制，能够实现全局特征混合，而传统的卷积操作则局限于局部特征混合。为了缩小**CNN**与**ViTs**之间的性能差距，研究者们尝试通过增加卷积核的大小来扩大**CNN**的感受野。然而，这种简单地增加卷积核大小的方法很快达到了性能瓶颈，且在达到全局感受野之前就出现了过参数化的问题。

在这种背景下，本文提出了一种基于小波变换（**WT**）的解决方案。**WT**是一种强大的信号处理工具，能够在保留空间分辨率的同时对输入信号进行多频率分解。通过利用**WT**，本文设计了一种新型的卷积层**WTConv**，能够在不显著增加参数数量的情况下实现大感受野，并且能够更好地捕捉输入中的低频信息。

# 2. WTConv 模型

本文采用的是[**Haar**小波变换](https://0809zheng.github.io/2025/04/22/wavelet.html)，它是一种简单而高效的小波变换方法。对于一个输入图像$X$，一维**Haar**小波变换可以通过深度可分离卷积实现，使用两个卷积核$[1, 1]/\sqrt{2}$和$[1, -1]/\sqrt{2}$，然后进行下采样操作。

二维**Haar**小波变换则是通过在两个空间维度上分别进行一维**Haar**小波变换来实现的，具体来说，使用以下四个卷积核：

$$
f_{LL} = \frac{1}{2}
\begin{bmatrix}
1 & 1 \\
1 & 1
\end{bmatrix}, \quad
f_{LH} = \frac{1}{2}
\begin{bmatrix}
1 & -1 \\
1 & -1
\end{bmatrix} \\
f_{HL} = \frac{1}{2}
\begin{bmatrix}
1 & 1 \\
-1 & -1
\end{bmatrix}, \quad
f_{HH} = \frac{1}{2}
\begin{bmatrix}
1 & -1 \\
-1 & 1
\end{bmatrix}
$$

其中，$f_{LL}$是低通滤波器，而$f_{LH}$、$f_{HL}$和$f_{HH}$是高通滤波器。对于每个输入通道，卷积操作的输出包括四个通道，分别是低频分量$X_{LL}$和三个高频分量$X_{LH}$、$X_{HL}$和$X_{HH}$。通过递归地对低频分量进行小波分解，可以得到不同层次的频率分解结果。

**WTConv**层的核心思想是先对输入进行小波变换，将输入分解为不同频率的分量，然后在这些分量上分别进行小卷积核的深度可分离卷积，最后通过逆小波变换将结果重构。具体来说，**WTConv**的操作可以表示为：

$$
Y = \text{IWT}(\text{Conv}(W, \text{WT}(X)))
$$

其中，$X$是输入张量，$W$是卷积核的权重张量。通过这种方式，**WTConv**层不仅能够将卷积操作分离到不同的频率分量上，还能够让小卷积核在更大的输入区域内操作，从而扩大其感受野。

![](https://pic1.imgdb.cn/item/681c50f258cb8da5c8e4e836.png)

为了进一步扩展**WTConv**层的能力，本文采用了多级小波分解。具体来说，对于每一级小波分解，首先对低频分量进行小波变换，然后在不同频率分量上分别进行卷积操作，最后通过逆小波变换将结果逐级累加。通过这种方式，**WTConv**层能够在不同层次上捕捉输入的不同频率信息，从而实现更有效的特征提取。

![](https://pic1.imgdb.cn/item/681c513d58cb8da5c8e4e964.png)

**WTConv**层具有两个主要的技术优势。首先，每一级小波分解都能以较小的参数增加量扩大层的感受野。具体来说，对于一个$k \times k$的卷积核，**WTConv**层的参数数量仅与小波分解的层次数线性相关，而感受野则呈指数增长。其次，**WTConv**层能够更好地捕捉低频信息。这是因为通过多次对输入的低频分量进行小波分解，**WTConv**层能够强调这些低频分量，从而提高对低频信息的响应能力。这一特性使得**WTConv**层在形状偏置和鲁棒性等方面具有显著优势。

在计算成本方面，**WTConv**层的浮点运算次数（**FLOPs**）主要由小波变换、卷积操作和逆小波变换三部分组成。对于一个输入大小为$N_W \times N_H$、卷积核大小为$K_W \times K_H$、小波分解层次为$\ell$的**WTConv**层，其**FLOPs**可以表示为：

$$
C \cdot K_W \cdot K_H \cdot \left( N_W \cdot N_H + \sum_{i=1}^{\ell} 4 \cdot \frac{N_W}{2^i} \cdot \frac{N_H}{2^i} \right)
$$

其中，$C$是输入通道数。与传统的深度可分离卷积相比，**WTConv**层在保持较小参数数量的同时，能够实现更大的感受野，从而在计算效率和性能之间取得了良好的平衡。

# 3. 实验分析
## 3.1 图像分类实验
本文在**ImageNet-1K**数据集上对**WTConv**层进行了广泛的实验验证。实验中，作者将**WTConv**层集成到**ConvNeXt**架构中，替换了原有的7×7深度可分离卷积。

实验结果表明，**WTConv**层在保持参数数量和计算量较小的情况下，显著提高了模型的分类准确率。例如，在120轮训练中，**WTConvNeXt-T**模型的**Top-1**准确率达到了81.7%，比原始的**ConvNeXt-T**模型提高了0.7个百分点，同时参数数量仅增加了1.72M。在300轮训练中，**WTConvNeXt-B**模型的**Top-1**准确率达到了84.1%，比原始的**ConvNeXt-B**模型提高了0.3个百分点，参数数量仅增加了4M。

![](https://pic1.imgdb.cn/item/681c524058cb8da5c8e4eda0.png)
![](https://pic1.imgdb.cn/item/681c524f58cb8da5c8e4eddf.png)

此外，作者还与其他大卷积核方法进行了比较，如**RepLK**和**SLaK**。**WTConv**在参数效率和性能提升方面均优于这些方法。例如，**RepLK**在使用31×31卷积核时，参数数量达到了3.84M，而**WTConv**仅使用2.04M参数就实现了更好的性能。这表明**WTConv**在扩大感受野的同时，能够更有效地利用参数，避免了过参数化的问题。

## 3.2 语义分割和目标检测实验
在语义分割任务中，作者将**WTConvNeXt**作为**UperNet**的骨干网络，在**ADE20K**数据集上进行了评估。实验结果表明，**WTConvNeXt**在语义分割任务中也表现出色。例如，在120轮预训练和80K迭代微调的设置下，**WTConvNeXt-T**模型的**mIoU**达到了45.4%，比原始的**ConvNeXt-T**模型提高了0.8个百分点。在300轮预训练和160K迭代微调的设置下，**WTConvNeXt-S**模型的mIoU达到了49.0%，比原始的**ConvNeXt-S**模型提高了0.3个百分点。这些结果表明，**WTConv**层不仅在图像分类任务中有效，还能够显著提升语义分割任务的性能。

在目标检测任务中，作者将**WTConvNeXt**作为**Cascade Mask R-CNN**的骨干网络，在**COCO**数据集上进行了评估。实验结果表明，**WTConvNeXt**在目标检测任务中也取得了显著的性能提升。例如，在120轮预训练和1x微调的设置下，**WTConvNeXt-T**模型的**APbox**和**APmask**分别达到了47.9%和41.5%，比原始的**ConvNeXt-T**模型分别提高了0.6和0.4个百分点。在300轮预训练和3x微调的设置下，**WTConvNeXt-S**模型的**APbox**和**APmask**分别达到了52.6%和45.6%，比原始的**ConvNeXt-S**模型分别提高了0.7和0.6个百分点。这些结果表明，**WTConv**层能够显著提高目标检测模型的性能，尤其是在处理复杂场景和小目标时。

![](https://pic1.imgdb.cn/item/681c52ec58cb8da5c8e4efb3.png)

## 3.3 WTConv层的进一步分析
### 3.3.1 可扩展性分析
为了验证**WTConv**层的可扩展性，作者在**ImageNet-50/100/200**数据集上进行了实验，使用**MobileNetV2**作为基础架构，并替换了其中的深度可分离卷积。实验结果表明，**WTConv**在扩大感受野的同时，能够更好地保持性能。这表明**WTConv**在扩大感受野时，能够更有效地利用参数，避免了过参数化的问题。

![](https://pic1.imgdb.cn/item/681c536358cb8da5c8e4efe1.png)

### 3.3.2 鲁棒性分析
为了验证**WTConv**层的鲁棒性，作者在多个数据集上进行了实验，包括**ImageNet-C、ImageNet-R、ImageNet-A**和**ImageNet-Sketch**。实验结果表明，**WTConv**层能够显著提高模型在面对各种干扰时的鲁棒性。例如，在**ImageNet-C**数据集上，**WTConvNeXt-T**模型的平均干扰误差为52.0，比原始的**ConvNeXt-T**模型降低了1.2个百分点。这些结果表明，**WTConv**层能够显著提高模型在面对各种干扰时的鲁棒性，尤其是在处理低频信息时。

![](https://pic1.imgdb.cn/item/681c53b258cb8da5c8e4eff3.png)

### 3.3.3 形状偏置分析
为了验证**WTConv**层的形状偏置能力，作者使用了**modelvshuman**基准测试。实验结果表明，**WTConv**层能够显著提高模型的形状偏置能力。例如，**WTConvNeXt-T**模型的形状决策比例为29.2%，比原始的ConvNeXt-T模型提高了7.5个百分点。**WTConvNeXt-B**模型的形状决策比例为35.3%，比原始的**ConvNeXt-B**模型提高了10.8个百分点。这些结果表明，**WTConv**层能够显著提高模型对形状信息的敏感性，从而更好地模拟人类视觉系统的感知能力。

![](https://pic1.imgdb.cn/item/681c53f358cb8da5c8e4f003.png)

### 3.3.4 有效感受野分析
实验结果表明，**WTConv**层能够显著扩大模型的有效感受野。例如，在**ConvNeXt-T**模型中，**WTConv**层的有效感受野几乎达到了全局范围，尽管其参数数量仅为2.04M，远小于其他大卷积核方法。这表明**WTConv**层能够在不显著增加参数数量的情况下，有效地扩大模型的感受野，从而更好地捕捉输入图像中的全局信息。

![](https://pic1.imgdb.cn/item/681c54e558cb8da5c8e4f04d.png)

### 3.3.5 消融研究

为了进一步验证**WTConv**层的设计合理性，作者进行了消融研究。

实验结果表明，增加小波分解的层次和卷积核的大小通常能够提高模型的性能。例如，在使用5级小波分解和5×5卷积核时，**WTConvNeXt-T**模型的Top-1准确率达到了81.75%，比使用3级小波分解和3×3卷积核时提高了0.51个百分点。

此外，实验还表明，同时使用低频和高频分量进行卷积操作能够显著提高模型的性能。例如，在仅使用低频分量时，**WTConvNeXt-T**模型的Top-1准确率为81.46%，仅使用高频分量时为81.24%，而同时使用低频和高频分量时则达到了81.75%。

这些结果表明，**WTConv**层的设计能够充分利用输入图像的不同频率信息，从而提高模型的性能。

![](https://pic1.imgdb.cn/item/681c553858cb8da5c8e4f070.png)
