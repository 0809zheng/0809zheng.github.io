---
layout: post
title: 'Recovering Human Pose and Shape From Through-the-Wall Radar Images'
date: 2024-06-06
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/67518b52d0e0a243d4de4c18.png'
tags: 论文阅读
---

> 从穿墙雷达图像中恢复人体姿态和形状.

- paper：[Recovering Human Pose and Shape From Through-the-Wall Radar Images](https://ieeexplore.ieee.org/document/9741729)


# 1. 背景介绍

由于穿墙雷达系统的成像空间分辨率较低，人眼很难直接从雷达图像中捕捉细粒度的人体信息。利用卷积神经网络强大的自适应特征提取能力，可以从穿墙雷达图像中获取人体关节点与轮廓等更详细的人体姿态信息。

一个完整的人体参数化模型通常是由人体姿态参数和形状参数共同决定的，因此实现穿墙雷达人体姿态估计的关键是从穿墙雷达数据中同时提取人体关节点与轮廓信息。提取人体关节点和形状轮廓并不是两个独立的任务，这对应于计算机视觉领域中的关节点定位任务和语义分割任务，如图所示。

![](https://pic.imgdb.cn/item/67518c51d0e0a243d4de4c32.png)

通常关节点定位任务依赖于局部高语义的人体特征，因为需要进行关节点的定位和分类；而轮廓分割任务依赖于全局低语义的人体特征，以区分任意点是否属于人体轮廓。由于这两个任务共享部分人体信息，受多任务学习（**Multi-Task Learning，MTL**）技术启发，共同学习这两项任务。在定位人体关节点时，形状轮廓可以帮助提前粗略地定位人体；在提取人体轮廓时，人体关节点可以确保形状的连通性。同时学习两个任务可以提高人体信息恢复的准确性，从而获得完整的姿态和形状恢复结果。

# 2. 方法介绍

## （1）网络结构设计

一个高效的多任务网络，不仅需要提取不同任务的领域差异特征，又需要提取任务间共享的通用泛化特征。这项工作采用一种硬权重共享的多任务网络结构设计，如图所示，其主体部分共模型权重，并针对不同任务使用不同的预测结构。通过在不同任务上学习泛化的通用特征，能够缓解模型在单个任务上过拟合的问题。

![](https://pic.imgdb.cn/item/67518c87d0e0a243d4de4c3e.png)

采用跨模态数据标注方法，将任务分解为关节点定位任务和轮廓提取任务后，需要分别选择对应的计算机视觉预训练模型生成伪标签。本工作使用预训练的**Hourglass**模型作为关节点定位任务的跨模态监督模型，使用预训练的**UNet**模型作为轮廓提取任务的跨模态监督模型。它们都是相关视觉任务中流行的方法，尽管有许多后续工作对这些方法进行改进，但模型的基本框架并没有太大变化。

通过设计卷积神经网络来处理穿墙雷达图像，可以实现关节点定位任务和轮廓提取任务。所设计卷积神经网络的预测结果应该尽可能接近预训练模型提供的伪标签。一种简单的设计是分别使用新的**UNet**模型和新的**Hourglass**模型来处理这些穿墙雷达图像。然而关节点定位任务和轮廓提取任务都是对人体姿态的描述，共享一些人体特征，因此通过设计一个任务共享的特征提取网络，可以从雷达图像中提取包含这些人体信息的特征。此时网络对一项任务的学习也会对另一项任务产生影响，因此网络倾向于选择在两项任务中都表现良好的特征，这间接促进了每个任务的学习。并且设计任务共享的网络可以避免使用两个独立的网络来分别解决关节点定位任务和轮廓提取任务，减少特征冗余，并进一步减少不必要的计算负担和内存消耗。

通过分析**UNet**模型和**Hourglass**模型的结构，不难发现它们的整体拓扑结构具有相似性，这进一步证实了用于人体关节点定位任务和轮廓提取任务的部分特征是共享的。**UNet**模型和**Hourglass**模型的基本结构都可以分解为下采样部分和上采样部分，如图所示。每个部分都使用多个采样层进行特征提取或重建。在每个对应的下采样层和上采样层之间建立残差连接，以保持特征细节并改进梯度传播。

https://pic.imgdb.cn/item/67518cd4d0e0a243d4de4c49.png

除了相似性之外，**UNet**模型和**Hourglass**模型的结构也有一些差异，这决定它们对不同信息水平的特征的关注。通常来说，由于关节点需要定位和分类，关节点定位任务更关注局部高层次语义信息；而人体形状需要更多的全局低层次语义信息来区分该点是否属于人体。两种网络结构之间的差异导致了它们对不同信息的归纳偏置，两个模型的主要差异可以归结为三点：
1. 对称性：**Hourglass**模型采用不对称结构，在下采样部分使用更多的卷积层来提取更多的局部语义信息，而上采样部分使用较少的卷积层。**UNet**模型的结构是对称的，通过一系列下采样层和上采样层保持信息的平等传输；
2. 卷积：**Hourglass**模型使用残差模块来增强特征，残差模块由三个卷积层和一个局部残差连接组成，这有助于提取高层次语义信息。**UNet**模型使用标准卷积层恢复轮廓和边缘，从而提取更多的空间纹理信息。
3. 深度：较浅的卷积层可以提取具有低级别语义信息的特征，而较深的卷积层可以提取具有高级别语义信息的特征。**Hourglass**模型由多组网络堆叠而成，因此它可以从图像中提取每个人体关节点的高级别语义信息。**UNet**模型只采用一组网络，因为它主要从图像中获得像素级的低级别语义信息。

对比**UNet**模型和**Hourglass**模型结构的差异，本工作设计了一个特征提取网络，旨在以最小修改的情况下从穿墙雷达图像中同时提取关节点定位任务的局部高层次语义特征和形状分割任务的全局低层次语义特征。该网络可以被视为**UNet**模型和**Hourglass**模型的变体，并且比这两种网络都能更好地同时提取包含关节点和形状信息的人体特征。特征提取网络的结构如图。其中每个卷积层后都添加了批量归一化（**Batch Normalization，BN**）和**ReLU**激活函数，下采样层采用最大池化层，上采样层采用转置卷积层。

![](https://pic.imgdb.cn/item/67518d1fd0e0a243d4de4c5e.png)

所设计的特征提取网络采用对称的网络结构，以确保采样过程中信息传输的平等性。使用残差模块代替基本卷积层来增强特征提取能力，并可以堆叠更多层。通过这种方式，该网络可以平衡高层次语义信息（如人体关节点的位置和类别）和像素级信息（如人体轮廓）的提取能力。

特征提取网络从穿墙雷达图像中提取的特征图将会被进一步解码为人体姿态的相关预测结果。在这项工作中指定两种预测结果，即人体关节点和轮廓，两种结果均以热图的形式存储。预先定义人体的$K$个关节点，因此关节点热图的形状是$(H,W,K)$，其中$H$和$W$分别表示输入图像的高度和宽度，热图的$K$个通道分别提供$K$个关节点的位置概率分布。轮廓热图的形状是$(H,W,1)$，其中每个像素位置存储该点是否属于人体轮廓的概率。

注意到关节点热图是稀疏的，而轮廓热图是密集的。这意味着轮廓热图的更多输出神经元被激活，而关节点热图的多数输出神经元被抑制。因此使用解耦的关节点回归头和轮廓分割头从特征图中分别预测关节点热图和轮廓热图，以进一步减少这两个任务学习过程之间的冲突。两个输出头都由一个卷积核大小为$3\times 3$的二维卷积层组成。虽然这两个热图是单独预测的，但它们的损失函数可以联合优化。

## （2）损失函数设计

从穿墙雷达图像的特征图中预测关节点热图和轮廓热图都属于像素级预测任务，这些与人体姿态估计相关的像素级任务通常具有相似的特性，这些相似性可以通过构造多任务损失函数来进行挖掘与学习。

关节点热图$$\boldsymbol{p}_{\text{joint}}\in \mathbb{R}^{H\times W \times K}$$及其标签$$\boldsymbol{y}_{\text{joint}}\in \mathbb{R}^{H\times W \times K}$$是多通道的稀疏特征，对于每个通道特征，通常只有少数像素取值非零，用以定位对应的关节点空间位置。使用均方误差损失作为预测关节点热图的损失函数$$\mathcal{L}_{\text{joint}}$$：

$$
    \mathcal{L}_{\text{joint}} = \frac{1}{HWK} \sum_{h=1}^H\sum_{w=1}^W\sum_{k=1}^K\left\| \boldsymbol{p}_{\text{joint}}^{h,w,k}-\boldsymbol{y}_{\text{joint}}^{h,w,k} \right\|_2^2
$$

轮廓热图$$\boldsymbol{p}_{\text{contour}}\in \mathbb{R}^{H\times W \times K}$$及其标签$$\boldsymbol{y}_{\text{contour}}\in \mathbb{R}^{H\times W \times K}$$是单通道的密集特征，热图中每个像素存储对应位置是否属于人体轮廓的概率。使用二元交叉熵损失作为预测轮廓热图的损失函数$$\mathcal{L}_{\text{contour}}$$：

$$
    \mathcal{L}_{\text{contour}} = \frac{1}{HW} \sum_{h=1}^H\sum_{w=1}^W\left[ -\boldsymbol{y}_{\text{contour}}^{h,w} \log \boldsymbol{p}_{\text{contour}}^{h,w}-\left(1-\boldsymbol{y}_{\text{contour}}^{h,w} \right)\log \left(1- \boldsymbol{y}_{\text{contour}}^{h,w}\right)\right]
$$

将多任务损失函数$$\mathcal{L}_{\text{total}}$$构造为预测关节点热图的损失函数$$\mathcal{L}_{\text{joint}}$$与预测轮廓热图的损失函数$$\mathcal{L}_{\text{contour}}$$的[同方差不确定度加权损失](https://0809zheng.github.io/2021/09/05/uncertainty.html)：

$$
    \mathcal{L}_{\text{total}} = \frac{1}{2\sigma_K^2} \mathcal{L}_{\text{joint}} + \frac{1}{2\sigma_M^2} \mathcal{L}_{\text{contour}} + \log \sigma_K + \log \sigma_M
$$

## （3）泛化性增强

当部署穿墙雷达系统检测人体目标时，受不同的墙体等障碍物材料和传感器参数影响，在不同环境中采集到的雷达信号通常具有不同的数据分布。将采集训练数据集的场景视为源域，并将采集测试数据集的场景视为目标域；由于不同域的数据分布存在差异，在源域训练的方法直接应用于目标域时很难保持相当的精度，产生域偏移问题。尽管在目标域进行微调训练能够改善性能，但是在目标域的重复训练将消耗额外的时间和计算资源。迁移学习的目的是自适应地提取域不变的特征，以消除域偏移的影响，并在不进行监督微调的前提下在目标域上也能够保持较高的精度。如果能把源域的信息以较低的成本迁移到目标域中，便可以实现具有场景泛化性的穿墙雷达人体感知。

由于不同域之间的分布不同，源域提取的特征和目标域提取的特征通常具有较大差异。通过对抗学习的方法，引入判别器进行自适应的域调整，使得特征提取网络从不同域提取的特征落入相近的特征空间中。通过在有标签的源域数据集上的监督训练，该模型便可以在未标注的目标域数据集中实现人体感知任务。

![](https://pic.imgdb.cn/item/67518ea2d0e0a243d4de4caa.png)


# 3. 实验分析

## （1）实现细节

使用自研穿墙雷达系统构造一个穿墙雷达人体关节点定位与轮廓提取数据集。雷达系统以1 m的中心高度工作，检测场景的高度向范围为-1.5 m至1.5 m，方位向范围为-2.5 m至2.5 m，距离向范围为0至5 m。为了抵消个体差异，收集了五个目标的数据。训练集总共包括9301对雷达-光学图像对，以9:1的比例随机划分为训练子集和验证子集。训练子集用于模型训练，验证子集用于性能评估（采用10折交叉验证）。在域外场景中采集相同人体目标的数据作为测试集，以验证所提方法对于不同测试环境的泛化性，测试集总共包括2313对雷达-光学图像对。

直接构造人体目标的三维轮廓标签较为困难，因此这项工作着眼于二维人体姿态信息的恢复。将原始三维雷达图像沿着距离向维度求和得到二维雷达图像，并将雷达图像和光学图像的尺寸同时调整为$(224, 224)$，从而尽可能地表示一致的空间场景。通过预训练的**Hourglass**模型和**UNet**模型处理光学图像得到对应的人体关节点热图与轮廓热图，并作为雷达图像的跨模态标签。

数据批量大小和总训练轮数分别设置为2和200。使用AdamW优化器训练模型，权重衰减率设置为0.01。初始学习率设置为$0.001$，每50个训练轮数减少$10\%$。所有实验均在**Nvidia RTX3090 GPU**上进行加速。特征提取网络堆叠了两组网络来平衡特征提取能力和模型复杂度，模型的整体结构细节如表所示。

![](https://pic.imgdb.cn/item/67518fa6d0e0a243d4de4cf5.png)

## （2）评估指标

使用平均精度（**Average Precision，AP**）和平均**AP**（**mean Average Precision，mAP**）来评估人体关节点定位的准确性。**AP**指标是基于目标关节点相似性（**Object Keypoint Similarity，OKS**）来计算的。**OKS**测量所有预定义目标关节点的平均定位质量，计算为：

$$
    \text{OKS}(y_K, \hat{y}_K) = \frac{\sum_{i} e^{-\frac{\left\|y_K-\hat{y}_K\right\|^2_2}{2s^2k_i^2}} \mathbb{1}(C_i>0)}{\sum_{i} \mathbb{1}(C_i>0)}
$$

其中$y_K$和$$\hat{y}_K$$分别表示人体关节点坐标的标签值和预测值，$C_i$是第$i$个关节点的预测置信度，$s$和$k_i$是缩放偏差的常数，$$\mathbb{1}$$是示性函数，当条件满足时为1否则为0。给定一个阈值$a$，AP@a是指满足OKS$\geq a$的关节点的比例，通常在整个数据集上按每个关节点分别计算。

**mAP**指标通过设置不同阈值$a$来进一步计算。给定一组阈值$(a_1,a_2,...,a_m)$，计算每个阈值处的**AP**指标并求平均值，可以得到**mAP**指标：

$$
\text{mAP}=\frac{1}{m}\sum_{i=1}^{m}\text{AP@}a_i
$$

使用交并比（**Intersection over Union，IoU**）和平均交并比（**mean Intersection over Union，mIoU**）来评估人体轮廓提取的准确性。**IoU**指标度量预测像素集合和标签像素集合之间的相似性。预先指定阈值$b$以衡量将像素分配给正类别（人体轮廓）的最低置信度，并进一步对预测的轮廓热图进行二值化。统计真阳性、假阳性和假阴性像素的数量，则阈值$b$下的**IoU**指标计算为：

$$
    \text{IoU@}b=\frac{\text{TP}_b}{\text{TP}_b+\text{FP}_b+\text{FN}_b}
$$

**mIoU**指标通过设置不同阈值$b$来进一步计算。给定一组阈值$(b_1,b_2,...,b_n)$，计算每个阈值处的**IoU**指标并求平均值，可以得到**mIoU**指标：

$$
\text{mIoU}=\frac{1}{n}\sum_{j=1}^{n}\text{IoU@}b_j
$$

## （3）结果分析

对于关节点定位任务，将**Hourglass**模型和**RF-Pose**模型设置为对照模型，并额外评估所提方法在单独训练人体关节点定位任务时的性能。计算阈值集$[0.5:0.95;0.05]$下的**AP**指标和**mAP**指标，并将评估结果列于表中。结果表明，**Hourglass**模型的**mAP**指标为0.782，由于该模型已经在大量数据集上进行了预训练，因此在没有使用本实验中收集的图像数据集进行微调的情况下仍然能够预测准确的人体关节点坐标。在没有应用多任务学习的情况下，所提方法的**mAP**指标为0.689。由于雷达的成像空间分辨率通常低于光学系统，这阻碍了完整人体信息的精细恢复，因此所提方法和**Hourglass**模型的结果之间存在明显的差距。**RF-Pose**模型的总体结果略好于所提方法，这是因为它使用**OpenPose**模型进行特征提取，这是一种为人体关节点定位任务精心设计的模型。而所提方法采用的特征提取网络被设计自适应地同时获得关节点和轮廓信息，这减少了关节点定位任务的归纳偏差，从而限制了其在特定任务上的性能。当应用多任务学习时，由于关节点定位和轮廓提取任务共享相似的人体结构特征，轮廓提取任务可以帮助更好地定位人体关节点，因此所提方法的**mAP**指标提高到0.745，这与基于光学的**Hourglass**模型更接近。

![](https://pic.imgdb.cn/item/67518fe6d0e0a243d4de4d13.png)

从上表中进一步看出，当阈值相对较低时（如≤70%），所提方法甚至优于**Hourglass**模型。这是因为雷达系统可以获取探测区域的三维信息，并且穿墙雷达图像沿着距离向维度携带更多的深度信息，这有利于丰富人体特征。另一方面，当阈值相对较高时（如≥75%），所提方法的性能不如**Hourglass**模型。在这种情况下，只有具有较高置信度的预测结果才会被保留，而穿墙雷达图像的较低空间分辨率阻碍了置信度更高的关节点定位。

下图显示了所提方法对于14个人体关节点（头部、胸部、肩部、肘部、腕部、臀部、膝部和踝部）的**mAP**指标。所提方法在定位靠近人体躯干的关节点上（如头部和胸部）表现更好，在定位远离躯干的肢体关节点上（如手腕和脚踝）表现不佳。这是因为人体躯干部分具有更大的反射面积，比四肢部分更容易被雷达检测到。此外雷达系统对环境照明等噪声不敏感，这为在定位人体主要关节点上超越基于光学的方法提供了机会。

![](https://pic.imgdb.cn/item/6751900dd0e0a243d4de4d18.png)

对于轮廓提取任务，将**UNet**模型和**PersonWiFi**模型设置为对照模型，并额外评估所提方法在单独训练人体轮廓提取任务时的性能。计算阈值集$[0.5:0.95;0.05]$下的IoU指标和mIoU指标，并将评估结果列于表中。

![](https://pic.imgdb.cn/item/67519025d0e0a243d4de4d1a.png)

结果显示**UNet**模型和所提方法的**mIoU**指标分别为0.701和0.615。在没有多任务学习的情况下，**PersonWiFi**模型和所提方法的总体结果是接近的，同时所提方法对阈值的变化更不敏感。这表明所提方法使用的特征提取网络增强了提取高级语义信息的能力。由于整个数据集共享高级信息，因此通过预测更高的置信度来抵抗阈值的变化。当引入多任务学习时，所提方法的**mIoU**提高到0.671。这进一步验证了多个相关任务的协同训练可以有效地提高每个任务的性能。

从表中进一步看出，当阈值较低时（如≤60%），所提方法优于**UNet**模型。由于轮廓提取是一种密集型热图预测任务，因此结果更容易受到假阳性像素的影响。光学系统可能受到照明和传感器噪声的影响，这会产生更多的假阳性像素。当检测阈值较低时，这些噪声像素不会被滤除。随着阈值的增加，所提方法的性能下降得更快，这是由雷达成像的低空间分辨率导致的。

光学系统部署在墙壁遮挡场景中时无法工作，但雷达系统仍然可以捕捉人体目标；这是所提方法相对于计算机视觉方法的优势。当穿透墙壁时，雷达信号的功率有所衰减，但信号的主体结构保持不变。由于卷积神经网络的空间不变性，所提方法在充分训练后仍然可以从未知场景的雷达图像中提取人体特征。通过这种方式，可以恢复墙壁遮挡等未知场景中的目标姿态信息。下面分析一些实际测试场景中的人体关节点定位与轮廓提取结果。

下图显示了墙壁遮挡场景中的关节点定位与轮廓提取结果。结果表明尽管测试集中的穿墙雷达数据从未参与训练过程，所提方法仍然对于不同目标表现良好。

![](https://pic.imgdb.cn/item/67519062d0e0a243d4de4d22.png)

下图显示了目标位于不同距离时的关节点定位与轮廓提取结果。结果验证了所提方法对目标距离和雷达分辨率变化具有适应性。由于卷积神经网络在训练数据集中学习人体特征的全局统计信息，因此可以补充和估计不同分辨率和目标距离对应雷达图像中的人体姿态。

![](https://pic.imgdb.cn/item/6751906ed0e0a243d4de4d24.png)

下图显示了目标在不同角度下的关节点定位与轮廓提取结果。当人体目标不面向雷达时，雷达图像的质量将变差。卷积神经网络的平移不变性可以在一定程度上抵消这种影响，并且在角度偏移较小时仍然可以给出完整的预测结果。当角度偏离过大时，人体姿态的恢复质量必然会下降。

![](https://pic.imgdb.cn/item/67519077d0e0a243d4de4d25.png)

下图显示了多目标场景中的关节点定位与轮廓提取结果，这相当于是不同距离和不同角度的组合。通过在生成雷达图像时尽可能减少目标之间的相互干扰，能够获得完整的多目标关节点定位与轮廓提取结果。

![](https://pic.imgdb.cn/item/67519081d0e0a243d4de4d2a.png)

由于未知场景中所收集的穿墙雷达图像的数据分布发生变化，所提方法的性能将不可避免地下降。引入穿墙雷达数据泛化性增强算法以增强方法的泛化能力。为了进一步说明穿墙雷达数据泛化性增强算法的有效性，将应用泛化性增强算法前后的预测结果显示在图中。在复杂的穿墙探测环境中，一些远离人体的关节点定位缺失，而人体躯干的主要关节点定位仍然准确。由于描述人体关节点的特征主要是跨域不变的全局高层次特征，尽管受到墙壁的干扰，这些特征仍然存储在雷达信号的主体结构中。相反，人体轮廓的提取结果受到明显干扰，尤其是轮廓边缘和四肢。这是因为人体轮廓是由图像中的所有像素勾勒出来的，对墙体的干扰比较敏感。通过数据泛化性增强算法，可以在不同的实际环境中获得更完整的人体关节点定位与轮廓提取结果。有趣的是，结果中存在一些几乎不可能出现在雷达图像中的细节（比如鞋子的轮廓）。这是因为在跨模态训练期间，这些轮廓存在于由光学系统提供的监督信号中，导致模型的过拟合。通常这些细节信息不影响穿墙雷达人体姿态估计的实际理解，并且有助于保持人体轮廓的完整性，因此对其不进行额外处理。

![](https://pic.imgdb.cn/item/675190a3d0e0a243d4de4d30.png)

下表列出了不同方法的每秒浮点运算次数（**Floating Point Operations per second，FLOPs**）和参数量。**FLOPs**用于估计模型的推理速度，参数量用于估计模型的内存占用成本。结果表明，尽管所提方法的**FLOPs**比两种计算机视觉模型都要高一些，但它比分别使用两个模型处理这两项任务要高效得多。

![](https://pic.imgdb.cn/item/675190bbd0e0a243d4de4d31.png)

一些错误的实验预测结果如图所示。错误结果1预测了人体的完整轮廓，但缺少一些关节点。错误结果2定位了所有人体关节点，但部分轮廓丢失。受反射效应的影响，较小的人体部位不容易被雷达信号捕获，并且可能淹没在其他信号中。中心频率为1 GHz的雷达信号具有大约0.3 m的波长，导致尺度小于0.3 m的物体可能会在其信号的直接传播路径中被绕过。这项工作使用的雷达系统具有4个发射天线和8个接收天线，因此信号的大量传播路径和反射路径能够提供更多捕捉较小人体部位的机会。错误结果3属于重心靠近地面的下蹲目标，此时发射信号在人体和地面之间多次反射，这影响了接收信号的质量；导致轮廓提取结果混淆了下肢和背景。

![](https://pic.imgdb.cn/item/675190ccd0e0a243d4de4d32.png)

为了进一步分析所提方法对穿墙雷达图像的语义理解程度，使用引导反向传播算法来构建输入雷达图像的显著性特征图，结果如图所示。由于成像空间分辨率较低和杂波的干扰，尽管原始穿墙雷达图像中可以区分人体的几个主要部分，但很难直接从中捕捉到完整的人体轮廓。显著性特征图中较亮的区域表示该区域在特征提取时的重要性较高。结果表明，所提方法能够有效地聚焦于雷达图像中具有丰富人体信息的区域，自适应地忽略杂波的干扰。尽管单个雷达图像携带的人体结构信息不足，但从统计学角度来看，实验收集的雷达图像数据集包含了足够的人体信息。通过在该数据集上同时学习携带关节点和轮廓信息的通用人体特征表示，最终获得相对完整的人体姿态估计结果。

![](https://pic.imgdb.cn/item/675190f5d0e0a243d4de4d36.png)

尽管所提方法的性能在一些较低的阈值上略优于计算机视觉方法，但基于光学的方法和基于雷达的方法之间仍存在明显的性能差距。考虑到**Hourglass**模型和**UNet**模型是用大量光学图像训练的，因此基于雷达的方法也可以通过更大的数据集和更高质量的手动标注来提高性能。