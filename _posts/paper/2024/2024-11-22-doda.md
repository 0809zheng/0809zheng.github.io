---
layout: post
title: 'DODA: Diffusion for Object-detection Domain Adaptation in Agriculture'
date: 2024-11-22
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/67404754d29ded1a8ccf529c.png'
tags: 论文阅读
---

> DODA：农业中目标检测领域自适应的扩散模型.

- paper：[DODA: Diffusion for Object-detection Domain Adaptation in Agriculture](https://openreview.net/forum?id=KUpUO7aSSg)

## TL; DR

本文提出了一种名为**DODA（Diffusion for Object-detection Domain Adaptation in Agriculture）**的统一框架，利用扩散模型为多种农业场景生成高质量、特定领域的检测数据。**DODA**结合了外部域嵌入和改进的布局到图像（**L2I**）方法，允许它在没有额外训练的情况下为新域生成高质量的检测数据。本文在全球麦穗检测数据集**GWHD**上展示了**DODA**的有效性，其中对**DODA**生成的数据进行微调的检测器在多个领域产生了显著的改进（最大**+15.6 AP**）。

![](https://pic.imgdb.cn/item/67404db4d29ded1a8cd5dc46.png)

## 1. 背景介绍

在农业领域，目标检测面临诸多挑战，如环境多样性、作物生长阶段差异、采集设备和时间的不同等。这些因素导致现有检测模型难以在不同农业环境中实现稳定的性能。

领域自适应（**Domain Adaptation, DA**）是迁移学习的一个分支，旨在提高模型在未见过的领域中的泛化能力。通过域自适应，模型可以利用源领域的知识来适应目标领域，从而减少对目标领域大量标注数据的依赖。

现有方法大多依赖于大量标注数据，且在处理农业领域的复杂变化时效果不佳。此外，传统方法通常只关注单一领域的自适应，缺乏跨领域的通用性。这就提出了一个问题：如何利用扩散模型为特定领域生成高质量的检测数据？


## 2. 方法介绍

**DODA**的目标是通过将领域信息集成到**L2I**扩散中来实现领域感知图像的生成。首先将布局表示为图像，然后使用预训练的布局编码器提取特征作为域嵌入，最后通过特征加法融合整合到**L2I**扩散中，作者将这种方法称为**LI2I （layout-image-to-image）**。

![](https://pic.imgdb.cn/item/674051e4d29ded1a8cda4c4a.png)

边界框可能会彼此重叠，为了使布局编码器区分实例，将重叠的实例分配给不同的颜色通道。具体地，将每个图像中边界框的重叠关系表示为邻接矩阵，并使用下列算法对这些框进行排列。

![](https://pic.imgdb.cn/item/67405277d29ded1a8cdb000e.png)

布局编码器具有简单的结构，由一堆时间相关的残差层和下采样层组成。每一残差层的输出为$f_{res}(a, t) + a$，这里$a$是上一层的输出，$t$是时间步长。

作者观察到，浅层的**U-Net**层会产生有噪声的局部特征。随着层的依赖，特征变得越来越抽象和整体，逐渐形成图像的整体布局。因此建议将布局嵌入与更深层（**U-Net**解码器中的层）的特征合并，以更好地传达布局信息。

![](https://pic.imgdb.cn/item/6740530dd29ded1a8cdbaff8.png)


## 3. 实验分析

作者采用全球小麦检测数据集**GWHD**进行实验，**GWHD**数据集是最大的农业检测数据集之一，专门用于近距离麦穗检测。它由47个子域组成，每个子域都有一定的差异，如位置、成像流程、采集时间、小麦发育阶段和小麦品种。**GWHD**数据集分为训练集、验证集和测试集，分别包含18、11和18个子域。

用**COCO**预训练初始化一个**YOLOX-L**，在**GWHD**训练集上训练它，并将其作为基线。对于训练集每个域，使用**DODA**生成一个包含200张图像的数据集对**YOLOX-L**进行一轮微调。结果表明，利用**DODA**合成的特定领域数据对检测器进行微调后，这些领域的识别率提高了，表明所提方法有效地帮助检测器适应农业领域的新场景，弥补了受限的人工注释与复杂多变的农业环境之间的差距。

![](https://pic.imgdb.cn/item/674057bfd29ded1a8ce01ba1.png)

作者进一步在**COCO**数据集上进行了实验，以证明所提方法的有效性。**COCO**包含多个类别，因此作者改进了布局编码方法，同一类别的目标以相同的色调描绘，但亮度较弱，并按面积降序绘制每个目标的边界框。

结果表明，**LI2I**方法在可控性（**mAP**）方面明显优于所有以前的**L2I**方法，同时保持高图像质量（**FID**）和多样性（**IS**）。此外与将布局表示为文本的方法（**LayoutDiffusion, Layoutdiffuse, GeoDiffusion**）相比，布局图像克服了基于文本的布局的限制，允许更精确和详细的控制，包括以前具有挑战性的小目标。

![](https://pic.imgdb.cn/item/674058b8d29ded1a8ce0cbeb.png)