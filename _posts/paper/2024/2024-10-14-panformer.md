---
layout: post
title: 'PanFormer: a Transformer Based Model for Pan-sharpening'
date: 2024-10-14
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/673da58dd29ded1a8ccb5174.png'
tags: 论文阅读
---

> PanFormer：基于Transformer的全色锐化模型.

- paper：[PanFormer: a Transformer Based Model for Pan-sharpening](https://arxiv.org/abs/2203.02916)

## TL; DR

本文提出了一种基于**Transformer**的全色锐化模型，称为**PanFormer**。该模型通过设计双流网络和使用自注意力机制提取提取全色图像（**PAN**）和多光谱图像（**MS**）的模态特定特征，并应用交叉注意力模块来合并光谱和空间特征，从而生成全色锐化图像。实验结果表明，**PanFormer**在**GaoFen-2**和**WorldView-3**数据集上表现优异，优于许多现有的基于**CNN**的方法。

## 1. 背景介绍

高质量的高分辨率遥感图像在地理、土地测量和环境监测等许多实际应用中都有需求。大多数遥感传感器提供一对模态的图像：多光谱图像和其对应的全色图像。**MS**图像具有丰富的光谱信息但空间分辨率较低，而**PAN**图像具有高空间分辨率但只有一个波段。为了结合这两种模态的优势，全色锐化任务的重点是从**PAN**和**MS**图像中合并互补信息并创建高分辨率**MS**（**HR MS**）图像。

近年来，深度学习在各种计算机视觉任务中取得了巨大的成功，这促使研究人员开发利用深度神经网络的全色锐化方法。**PNN**等研究借鉴了超分辨率网络的思想，设计了3层CNN来解决全色锐化问题。然而，这些方法大多从图像超分辨率的角度来解决全色锐化问题，即学习从联合**PAN-MS**空间到目标**HR MS**空间的非线性映射，其中**PAN**图像被视为输入的一个通道。但考虑到**PAN**和**MS**图像之间的区别，捕获它们之间的相关性并将其纳入融合过程对于减少**HR MS**的光谱失真至关重要。然而很少有工作考虑到这一点。

本文用一种新的基于**Transformer**的网络来解决这个问题。本文的方法引入了一种新颖的交叉注意力块，能够建模**PAN**和**MS**模态之间的冗余和互补信息。本文首先构建了一个具有**Transformer**架构的编码器，分别从**PAN**和**MS**图像中提取模态特定特征。然后，提出了一种交叉注意力操作来促进两个模态之间的信息交换。交叉注意力模块能够捕获**PAN**和**MS**之间的复杂相关关系，这对于实现最佳融合性能至关重要。在头部应用了一个恢复模块来生成最终的全色锐化图像。

## 2. 方法介绍

**PanFormer**是一个基于**Transformer**的模型，用于全色锐化任务。它包含三个模块：模态特定编码器、跨模态融合模块和图像恢复模块。

![](https://pic.imgdb.cn/item/673da72cd29ded1a8ccccb10.png)

### （1）模态特定编码器
本文构建了一个双路径编码器用于模态特定特征提取，其中每个路径处理一个模态。图像首先被分割成非重叠的补丁，然后输入到网络中，并通过线性嵌入投影到隐藏维度。对于**PAN**图像，补丁大小设置为**2×2**。每个补丁被视为一个标记，以形成序列，并由一系列自注意力块处理。

由于**PAN**和**MS**是不同的模态，因此必须使用不同的编码器从它们中提取特征。每个编码器由堆叠的自注意力块组成，以产生模态特定特征。每个模态通过**4**个自注意力块（**SAB**）来提取模态特定特征。

对于**PAN**路径，本文在中间插入了一个额外的补丁合并层，以合并补丁以达到与**MS**路径相同的大小。受**Swin Transformer**的启发，本文构建了具有基于窗口的自注意力的**SAB**，其中注意力是在局部窗口内计算的。

### （2）跨模态融合模块
**PAN**和**MS**图像高度相关但包含互补信息。因此对它们之间的跨模态关系进行建模非常重要。为了实现这一点，本文开发了一个交叉注意力块（**CAB**）并逐步融合这两个模态。交叉注意力块的输出是不同注意力的结果的拼接，从而形成包含来自不同模态的信息的融合表示，并将其输入到下一个模块。

### （3）图像恢复模块
图像恢复模块旨在基于跨模态融合模块中的融合表示生成最终的全色锐化图像，是通过卷积神经网络实现的。


## 3. 实验分析

本文在**GaoFen-2**和**WorldView-3**数据集上进行了实验。为了生成真实图像，本文首先将原始的**PAN**和**MS**图像下采样到较低的尺度，以便原始的**MS**图像可以作为真实图像。具体来说，使用高斯滤波器对原始图像对进行模糊处理，并以**4**的缩放因子对它们进行下采样以形成测试和训练补丁。最后，本文用大小为**256×256×1**的**PAN**图像、大小为**64×64×4**的低分辨率**MS**图像和大小为**256×256×4**的真实高分辨率**MS**图像训练模型。在测试阶段，**PAN**、低分辨率**MS**和高分辨率**MS**图像的大小分别为**400×400×1**、**100×100×4**和**400×400×4**。

本文首先测试了**PanFormer**中不同融合模块实现的性能。实验结果表明，跨模态融合模块确实提高了最终全色锐化图像的质量。

![](https://pic.imgdb.cn/item/673da905d29ded1a8cce5b14.png)

然后本文将其方法与包括**PNN**、**MSDCNN**、**Pan-Net**、**PSGAN**、**DRPNN**和**SCC**在内的6种最先进的深度学习方法进行了比较。在**GaoFen-2**数据集上，**PanFormer**的**SAM**、**ERGAS**和**SCC**值优于其他基于**CNN**的模型。当在**WorldView-3**数据集上进行评估时，由于**WorldView-3**捕获的图像包含更多的**MS**波段（**8**个波段），并且训练集中可用的数据较少，因此所有基于深度学习的方法的性能都有所下降。然而，**PanFormer**仍然取得了比其他方法更好的结果。

![](https://pic.imgdb.cn/item/673da9a0d29ded1a8cceffd3.png)

本文还可视化了一些不同卫星的示例来评估模型在实际应用中的性能。在**GaoFen-2**数据集上，传统方法**BDSD**和**GS**生成的结果包含大量噪声。基于深度学习的方法**PanNet**、**DRPPN**和**GPPNN**存在颜色失真。**PNN**和**MSDCNN**从残差图中可以看出产生了更多的差异。而本文的方法产生了最接近真实图像的结果，具有最小的空间或光谱失真。

![](https://pic.imgdb.cn/item/673da9d9d29ded1a8ccf32d5.png)
![](https://pic.imgdb.cn/item/673daa3dd29ded1a8ccfa8b4.png)

在推理时间和模型大小方面，本文的方法与**DRPNN**和**PSGAN**具有相似的参数数量。然而，由于注意力计算相比卷积更耗时，因此本文的方法比那些基于**CNN**的方法更慢。

![](https://pic.imgdb.cn/item/673daa26d29ded1a8ccf8d3a.png)


