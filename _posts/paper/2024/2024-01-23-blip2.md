---
layout: post
title: 'BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models'
date: 2024-01-23
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67a1f6b4d0e0a243d4fbce8a.png'
tags: 论文阅读
---

> BLIP-2：使用冻结图像编码器和大语言模型的引导式语言-图像预训练.

- paper：[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)

## 0. TL; DR

**BLIP-2** 是一种高效的视觉语言预训练方法，通过利用现成的冻结预训练图像编码器和大型语言模型（**LLM**），显著降低了预训练成本。**BLIP-2** 通过一个轻量级的 **Querying Transformer（Q-Former）**桥接视觉和语言模态，分为两个阶段进行预训练：第一阶段从冻结的图像编码器中引导视觉语言表示学习；第二阶段从冻结的 **LLM** 中引导视觉到语言的生成学习。**BLIP-2** 在多个视觉语言任务上取得了 **SOTA** 性能，同时在零样本学习场景下展现出强大的能力。

## 1. 背景介绍

视觉语言预训练（**VLP**）近年来取得了显著进展，但随着模型规模的增大，预训练成本也急剧上升。大多数现有的 **VLP** 方法采用端到端训练，这不仅计算成本高昂，而且难以利用现有的单模态预训练模型（如大型语言模型和图像编码器）。为了降低计算成本并充分利用这些单模态模型，**BLIP-2** 提出了一种新的预训练策略，通过冻结的图像编码器和 **LLM** 来引导视觉语言学习。

## 2. BLIP-2 模型

**BLIP-2** 的核心是一个轻量级的 **Querying Transformer（Q-Former）**，它通过一组可学习的查询向量从冻结的图像编码器中提取视觉特征。**Q-Former** 作为图像编码器和 **LLM** 之间的信息瓶颈，将最有用的视觉信息传递给 **LLM**，从而减少 **LLM** 学习视觉语言对齐的负担。

**Q-Former** 包含两个 **Transformer** 子模块：
- 图像 **Transformer**：与冻结的图像编码器交互，提取视觉特征。
- 文本 **Transformer**：既可以作为文本编码器，也可以作为文本解码器。

**Q-Former** 的输出是一个固定数量的查询向量，这些向量通过一个全连接层投影到与 **LLM** 输入维度相同的特征空间中。

![](https://pic1.imgdb.cn/item/67a1f75fd0e0a243d4fbce96.png)

**BLIP-2** 的预训练分为两个阶段：

**① 视觉语言表示学习阶段：**

- 图像-文本对比学习（**ITC**）：通过对比学习对齐图像和文本特征。
- 图像引导的文本生成（**ITG**）：训练 **Q-Former** 生成文本，给定输入图像。
- 图像-文本匹配（**ITM**）：学习图像和文本之间的细粒度对齐。

**② 视觉到语言生成学习阶段：**

将 **Q-Former** 的输出连接到冻结的 **LLM**，训练 **Q-Former** 使其输出的视觉特征能够被 **LLM** 解释。

![](https://pic1.imgdb.cn/item/67a1f90dd0e0a243d4fbceca.png)

## 3. 实验分析

**BLIP-2** 在多个视觉语言任务上进行了评估，包括：
- 视觉问答（**VQA**）：使用 **VQAv2** 数据集，评估指标为准确率。
- 图像标题生成：使用 **COCO** 和 **NoCaps** 数据集，评估指标为 **BLEU@4、CIDEr** 和 **SPICE**。
- 图像-文本检索：使用 **COCO** 和 **Flickr30K** 数据集，评估指标为 **Recall@1、Recall@5** 和 **Recall@10**。

主要实验结果：
- 视觉问答：**BLIP-2** 在 **VQAv2** 数据集上取得了 **65.0%** 的准确率，显著优于 **Flamingo80B（56.3%）**，尽管 **BLIP-2** 的可训练参数少了 **54** 倍。
- 图像标题生成：**BLIP-2** 在 **NoCaps** 数据集上取得了 **121.6** 的 **CIDEr** 分数，展现出强大的泛化能力。
- 图像-文本检索：**BLIP-2** 在 **Flickr30K** 数据集上取得了 **SOTA** 性能，**Recall@1** 分别达到了 **TR 97.6%** 和 **IR 89.7%**。

![](https://pic1.imgdb.cn/item/67a1fa57d0e0a243d4fbcef7.png)

**BLIP-2** 能够根据自然语言指令生成图像描述，展现出多种能力，包括视觉知识推理、视觉常识推理、视觉对话等。

![](https://pic1.imgdb.cn/item/67a1faadd0e0a243d4fbcf11.png)