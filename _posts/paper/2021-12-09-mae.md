---
layout: post
title: 'Masked Autoencoders Are Scalable Vision Learners'
date: 2021-12-09
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/61b16fba2ab3f51d919ca6a8.jpg'
tags: 论文阅读
---

> MAE: 掩码自编码器是可扩展的视觉学习者.

- paper：Masked Autoencoders Are Scalable Vision Learners
- arXiv：[link](https://arxiv.org/abs/2111.06377)

本文设计了一种应用于计算机视觉的自监督学习方法，掩码自编码器(**masked autoencoder, MAE**)。**MAE**接收随机遮挡部分**patch**的图像为输入，并重构原始图像。

**MAE**的整个网络采用非对称的编码器-解码器结构。编码器只对未遮挡的图像块进行操作；解码器是轻量级的，旨在从编码特征和遮挡**token**中重建输入图像。通常对图像进行较大比例的遮挡(如$75\%$)，此时较大程度地减少了计算量和内存消耗，并降低预训练时间。

![](https://pic.imgdb.cn/item/61b171a22ab3f51d919d9984.jpg)

编码器采用**ViT**结构，只输入未遮挡的图像块序列，因此能够使用有限的内存和计算训练非常大的编码器。编码器的特征和用于表示遮挡图像块的遮挡**token**组合后作为解码器的输入，通过一组轻量级的**Transformer**模块重构原始图像。预训练完成后，解码器可以被丢弃，只使用编码器提取图像特征用于下游任务。

解码器输出的每一个元素表示一个遮挡图像块的像素值向量，损失函数计算原始图像和重构图像上遮挡部分的像素的均方误差。作者指出首先对图像进行标准化后再计算能够提高特征表示的质量。

在实际实现时，通过线性映射和位置编码为每一个图像块生成一个**token**，对**token**序列随机打乱(记住打乱顺序)后，根据掩码率删除序列的最后一部分，其保留的部分便是未遮挡的图像块序列，用作编码器的输入。下面展示一些恢复结果：

![](https://pic.imgdb.cn/item/61b171bc2ab3f51d919da73f.jpg)

作者针对不同的掩码率进行了实验。有趣的是，对图像进行约$75\%$的遮挡能够获得最好的效果，这和自然语言处理中使用的较低掩码率不同(**BERT**约$15\%$)。这可能是因为较大的遮挡使得模型必须学习有用的通用表示，而不是简单地通过线条或纹理来完成任务。

![](https://pic.imgdb.cn/item/61b172c72ab3f51d919e28a3.jpg)

作者进一步进行了一些消融实验，其中**fit**表示对模型进行端到端的微调；**lin**表示仅微调输出端的线性层。
表(**a**)和(**b**)调整了解码器的深度和宽度；
表(**c**)测试了编码器输入是否使用遮挡**token**；
表(**d**)测试了不同的重构目标；
表(**e**)测试了不同的数据增强；
表(**f**)测试了不同的掩码采样方法，包括随机采样、按块采样和网格采样。

![](https://pic.imgdb.cn/item/61b173292ab3f51d919e5020.jpg)

![](https://pic.imgdb.cn/item/61b173612ab3f51d919e6ee8.jpg)

作者比较了**MAE**和其他自监督模型的表现：

![](https://pic.imgdb.cn/item/61b1742f2ab3f51d919ee411.jpg)