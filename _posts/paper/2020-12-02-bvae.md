---
layout: post
title: 'β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework'
date: 2020-12-02
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fc740c0394ac5237895ee10.jpg'
tags: 论文阅读
---

> β-VAE：学习变分自编码器隐空间的解耦表示.

- paper：β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework
- website：[link](https://openreview.net/forum?id=Sy2fzU9gl)

**β-VAE**的出发点是对特征空间进行**解耦(disentanglement)**，即使得隐变量空间$Z$的每一个维度作为一个**factor**，每一个**factor**表示独立的特征，而不影响其他**factor**表示的特征。

如一个在人脸数据集上训练的**VAE**，训练后隐空间中的每一个**factor**可以表示性别、肤色、表情...而不互相影响。

与**VAE**类似，模型希望最大化生成真实数据的概率，同时使得真实和估计的后验分布距离小于常数$\delta$：

$$ \mathop{\max}_{\theta,\phi} \mathbb{E}_{x \text{~} D} [\mathbb{E}_{q_{\phi}(z|x)} [\log p_{\theta}(x | z)]] \\ \text{subject to } D_{KL}(q_{\phi}(z|x)||p_{\theta}(z))<\epsilon $$

引入拉格朗日乘子$\beta$，问题转换成最大化拉格朗日函数：

$$ \mathcal{F}(\theta,\phi,\beta) = \mathbb{E}_{q_{\phi}(z|x)} [\log p_{\theta}(x | z)] - \beta (D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) - \epsilon) \\ = \mathbb{E}_{q_{\phi}(z|x)} [\log p_{\theta}(x | z)] - \beta D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) + \beta\epsilon \\ ≥ \mathbb{E}_{q_{\phi}(z|x)} [\log p_{\theta}(x | z)] - \beta D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) $$

因此**β-VAE**的损失函数定义为：

$$ L(\theta,\phi,\beta) = -\mathbb{E}_{q_{\phi}(z|x)} [\log p_{\theta}(x | z)] + \beta D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) $$

当$\beta = 1$时，模型和**VAE**相同。当$\beta > 1$时，引入了信息瓶颈，限制了隐变量的表示能力，但增加了模型的解耦能力。
