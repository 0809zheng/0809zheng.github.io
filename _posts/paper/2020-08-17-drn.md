---
layout: post
title: 'Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution'
date: 2020-08-17
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f39ee6114195aa594846a53.jpg'
tags: 论文阅读
---

> DRN：一种闭环的图像超分辨率模型.

- paper：Closed-loop Matters: Dual Regression Networks for Single Image Super-Resolution
- arXiv：[link](https://arxiv.org/abs/2003.07018)
- code：[github](https://github.com/fengye-lu/DRN-master)

# 问题阐述

图像**超分辨率（Super Resolution，SR）**旨在通过神经网络学习一个从**低分辨率（low-resolution，LR）**图像到**高分辨率（high-resolution。HR）**图像的非线性映射。目前的超分辨率方法尚存两个限制：
1. 学习非线性映射是一个**不适定问题(ill-posed problem)**，存在许多**HR**可以下采样到相同的**LR**；这导致模型的解空间非常大；
2. 模型训练往往需要成对的**LR-HR**图像数据，这在真实世界中是受限的。


# 模型介绍

![](https://pic.downk.cc/item/5f39f69914195aa594863ee6.jpg)

作者提出了一种对偶回归方法，在寻找**LR**到**HR**映射的同时，建立了从**HR**到**LR**重构的路径，形成闭环，通过增加约束减少了解空间的大小；由于闭环的存在，模型训练不必依赖成对的图像数据，可以直接从**LR**数据中学习。

# 算法分析

![](https://pic.downk.cc/item/5f39f99914195aa5948700ac.jpg)

定义$x \in \Bbb{X}$为**LR**图像，$y \in \Bbb{Y}$为**HR**图像，则模型任务可拆分成：
1. 寻找一个函数映射$P:X→Y$，使得预测结果$P(x)$和**HR**图像$y$足够接近；
2. 寻找一个函数映射$D:Y→X$，使得预测结果$D(y)$和**LR**图像$x$足够接近。

模型的损失函数定义如下，$λ$控制两个损失的权重：

![](https://pic.downk.cc/item/5f39fa6e14195aa594873e12.jpg)

记有标签的数据为$S_P$（成对的**LR-HR**），没有标签的数据为$S_U$（仅有**LR**），训练时：
- 更新原模型$P$时，考虑有标签的数据的**HR**重构损失和所有数据的**LR**重构损失；
- 更新对偶模型$D$时，考虑所有数据的**LR**重构损失。

# 模型结构

![](https://pic.downk.cc/item/5f3a026914195aa594896597.jpg)

**DRN**模型包括原网络和对偶网络两部分。原网络结构受**U-Net**网络的启发，在下采样和上采样部分分别包括$log_2(s)$个基础块，其中$s$是超分辨率倍数。对偶网络结构简单，用卷积实现。

# 测试实验
作者在**DIV2K**和**Flickr2K**数据集上训练，在**SET5**,**SET14**,**BSDS100**,**UR-BAN100**和**MANGA109**五个数据集上测试结果。测试指标选择**PSNR**和**SSIM**。

![](https://pic.downk.cc/item/5f3a54cb14195aa5949f9751.jpg)

# 消融实验
作者通过消融实验验证了对偶网络的重要性：

![](https://pic.downk.cc/item/5f3a55d614195aa5949ffe5f.jpg)

作者通过消融实验对损失函数的权重进行选择：

![](https://pic.downk.cc/item/5f3a55f214195aa594a0062f.jpg)

定义$ρ$为训练数据中无标签数据（仅有**LR**）的比例，以下是不同的$ρ$对应的模型性能：

![](https://pic.downk.cc/item/5f3a563314195aa594a01493.jpg)