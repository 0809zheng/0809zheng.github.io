---
layout: post
title: 'YOLOX: Exceeding YOLO Series in 2021'
date: 2021-08-01
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/61075a215132923bf858aa8e.png'
tags: 论文阅读
---

> YOLOX：Anchor-free的YOLO检测器.

- paper：YOLOX: Exceeding YOLO Series in 2021
- arXiv：[link](https://arxiv.org/abs/2107.08430)

作者针对**YOLO**系列检测器进行经验性改进，构造了**YOLOX**模型，将**YOLO**调整为**anchor-free**的形式并集成了一些检测技巧，取得**SOTA**的性能：
1. **YOLOX-L**和**YOLOv4-CSP,YOLOv5-L**参数量接近，前者**AP**准确率比**YOLOv5-L**高出**1.8%**，且在单张**Tesla V100**上能达到**68.9FPS**。
2. **YOLOX-Tiny**和**YOLOX-Nano**(只有**0.91M**参数量和**1.08G FLOPs**)比对应的**YOLOv4-Tiny**和**NanoDet3**分别高出**10% AP**和**1.8% AP**。
3. 在**Streaming Perception Challenge**(**Workshop on Autonomous Driving at CVPR 2021**)只使用**YOLOX-L**模型取得第一名。
4. 源码提供了**ONNX, TensorRT, NCNN 和 Openvino**版本的推理模型。

![](https://pic.imgdb.cn/item/61075bfe5132923bf85e10f2.png)

作者使用**YOLOv3**作为**baseline**(**38.5% AP**)，采用**DarkNet53**加空间金字塔池化层**SPP**作为**backbone**。

在训练阶段使用指数滑动平均,余弦退火调整学习率,添加**IoU-aware**分支，在**COCO train2017**数据集上训练$300$轮(包括$5$轮**warm up**)，使用**SGD**算法，在$8$个**GPU**上设置**batch**为$128$，学习率设置为$0.01×\frac{\text{batch}}{64}$。

损失函数中类别**cls**和**obj**使用**BCE loss**，位置回归使用**IoU loss**。

数据增强使用了**mosaic**,**RandomHorizontalFlip**(作者发现**RandomResizedCrop**和**mosaic**有冲突,所以丢弃了**RandomResizedCrop**),**ColorJitter**和多尺度($448$以步长$32$过渡到$832$)。

在**baseline**的基础上，**YOLOX**额外使用了一些技巧，下面介绍这些技巧。

![](https://pic.imgdb.cn/item/61075fd25132923bf8696b7e.png)

### ○ Decoupled Head
**YOLO**系列使用**耦合(coupled)**检测头，即针对**COCO 80**类的检测任务，每一个**anchor**会对应产生$H×W×85$维度的预测结果，其中**cls**(区分前景和背景)占用$1$个通道，**reg**(检测框坐标)占用$4$个通道，**obj**(预测是$80$类中的哪一类)占用$80$个通道。

作者通过实验发现耦合检测头可能会损害性能，因为其中的分类任务和回归任务会产生冲突。因此作者将预测分支**解耦**(decoupled)，极大的改善收敛速度。

![](https://pic.imgdb.cn/item/610764c85132923bf878714f.png)

**YOLOX**首先使用$1×1$卷积进行降维，获得$256$通道的特征图，然后使用两个$3×3$卷积的平行分支分别进行分类和回归，同时回归分支还添加了**IoU**分支。

![](https://pic.imgdb.cn/item/610765a35132923bf87b9cc1.png)

### ○ Strong Data Augmentation
作者使用了**Mosaic**和**MixUp**数据增强，但在最后**15 epochs**时关闭，防止数据增强过度。

使用强大的数据增强后，**ImageNet**预训练模型无益，因此所有后续模型都是随机初始化权重并从头开始训练。

在训练比较小的模型时候，例如**YOLOX-S, YOLOX-Tiny,YOLOX-Nano**网络，剔除**mixup**，弱化**mosaic**效果，会有更好的表现。

### ○ Anchor-Free
**YOLO**系列是基于**anchor**的检测器，**anchor**机制增加了检测头的复杂度，使得每张图具有较多的预测数量，如**COCO**数据集中**YOLOv3**使用尺寸为$416×416$的图像推理， 会产生$3×(13×13+26×26+52×52)×85=5355$个预测结果。

使用**anchor**时，为了调优模型，通常需要对数据集的目标框进行聚类分析，确定最优的**anchor**设置，而这一步缺乏泛化性。
使用**anchor-free**可以减少调整参数的数量，减少引入的特殊技巧。

**YOLOX**从原有特征图的每一个栅格位置预测$3$组**anchor**减少为只预测$1$个目标，从而可以直接预测目标框的$4$个值(左上角**xy**坐标和**box**高宽)，从而减少了参数量和**GFLOPs**，使速度更快，且表现更好。

### ○ 标签分配

特征图的每一个栅格位置预测$1$个目标，即对该位置设置一个预测**正样本**(positives)。作者在正样本选择时做过以下几个尝试：
1. 只将物体中心点所在的位置认为是正样本，即一个目标最多只会有一个正样本(**42.9% AP**)。
2. **Multi positives**：将物体中心$3×3$区域认为是正样本，即一个目标具有$9$个正样本(**45.0% AP**)。
3. **simOTA**：对预测正样本进行标签分配，采用**OTA(Optimal Transport Assignment)**方法。作者改进了简化版的**simOTA**，能够自动决定每个**gt**标签对应的正样本位置和数量(**47.3% AP**)。

**simOTA**的主要流程如下：
1. 对每个**gt**标签确定正样本的候选区域(属于哪个特征图)；
2. 计算每个**anchor**与该**gt**的交并比**IoU**，并进一步计算**cost**；
3. 为该**gt**取**cost**排名最小的前**dynamic_k**个**anchor**作为正样本，其余为负样本；
4. 根据正负样本计算损失。


### ○ 更多实验
除了**DarkNet53**，作者还选取了其他**backbone**如**CSPNet**进行实验(**CSPNet**是**YOLOv5**中的版本，包括**CSPNet**,**SiLU**激活函数和**PAN**检测头)，仅需较少的额外推理时间，获得性能的提升：

![](https://pic.imgdb.cn/item/61076c1b5132923bf898f3b3.png)