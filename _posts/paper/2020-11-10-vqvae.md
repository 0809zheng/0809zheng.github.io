---
layout: post
title: 'Neural Discrete Representation Learning'
date: 2020-11-10
author: 郑之杰
cover: 'https://pic.downk.cc/item/5faa375c1cd1bbb86baea34c.jpg'
tags: 论文阅读
---

> VQ-VAE：向量量化的变分自编码器.

- paper：Neural Discrete Representation Learning
- arXiv：[link](https://arxiv.org/abs/1711.00937)

# 研究背景
生成模型是一种无监督学习方法，旨在学习数据的分布或生成属于分布的新样本，广泛应用于图像生成任务。作者提出了一种向量量化的变分自编码器，将编码后的隐空间离散化，并采用自回归的方法在隐空间进行分布估计，实现对高清图片的生成。

### 1. 自编码器 AutoEncoder
**自编码器(AutoEncoder, AE)**模型包含两部分，**编码器(Encoder)**和**解码器(Decoder)**。

编码器将高维输入图像$x$压缩成低维的隐变量$z$，解码器将隐变量$z$解码重构图像$x$。通过计算重构误差并反向传播，即可更新网络参数。

从概率角度，编码器学习到给定输入$x$得到隐变量$z$的条件概率分布$P(z \| x)$，解码器学习到给定隐变量$z$得到输入$x$的条件概率分布$P(x \| z)$。

自编码器只能求得编码器和解码器，无法直接得到输入数据的概率分布$P(x)$，从而无法直接采样获得新的数据样本。由**Bayes**公式：

$$ P(x | z) = \frac{P(z | x)P(x)}{P(z)} $$

要想获得输入数据的概率分布$P(x)$，需要知道隐变量$z$的概率分布$P(z)$。

### 2. 变分自编码器 Variational AutoEncoder
**变分自编码器(Variational AutoEncoder,VAE)**对隐变量$z$加上了先验知识，将其看作满足$z \text{~} N(0,1)$的先验分布；训练完成后抽样得到潜在表示$z$，使用解码器$P(x | z)$可以生成新样本。

具体实现时，在重构误差之外增加编码分布和先验分布的**KL**散度，是模型学习满足正态分布的$z$。优化**置信下界(evidence low bound,ELBO)**：

$$ ELBO(\theta, \phi) = E_{z \text{~} q_{\phi}(z | x)}[logp_{\theta}(x | z)]-KL(q_{\phi}(z | x) || p(z)) $$

### 3. 自回归 AutoRegressive
**自回归(AutoRegressive)模型**(如**PixelCNN**)是一种逐像素生成的图像生成模型，通过概率的**chain rule**可以表示输入数据的概率分布$P(x)$：

$$ P(x) = P(x_0)P(x_1 | x_0)P(x_2 | x_0x_1) \cdot\cdot\cdot P(x_N | x_0x_1x_2 \cdot\cdot\cdot x_{N-1}) $$

具体抽样过程是先从$P(x_0)$抽样$x_0$, 然后根据条件概率依次抽取剩余像素数值。当图片尺寸较大时，自回归模型的计算需求极大。

### 4. VQ-VAE：Vector Quantised Variational AutoEncoder
作者将变分自编码器和自回归模型的特点结合起来，提出了**VQ-VAE**模型。

自回归模型在图像比较大的情况下因计算需求暴增而失效，如果能将图像压缩到低维空间，在低维空间训练自回归网络，再解码回高维空间即可。

作者对编码后的隐变量$z$建立自回归模型，得到结构化的全局语义概率分布：

$$ P(z) = P(z_0)P(z_1 | z_0)P(z_2 | z_0z_1) \cdot\cdot\cdot P(z_m | z_0z_1z_2 \cdot\cdot\cdot z_{m-1}) $$

变分自编码器的隐变量$z$每一维度都是连续值，如果将其离散化为整数，更符合自然界的模态，不需要学习特别细节的东西。如图像中类别的概念是离散的，两个不同类别的中间值没有意义。

将$z$离散化的关键是**向量量化(vector quatization,VQ)**。首先建立一个字典存储一系列编码表，在这个字典中找到和隐变量最接近(比如欧氏距离最近)的一个编码，用这个编码的**index**来代表这个隐变量。

# 模型结构

![](https://pic.downk.cc/item/5faa39301cd1bbb86baf022b.jpg)

**VQ-VAE**的模型结构如上图所示。

将尺寸为$H \times W \times c$的输入图像$x$通过卷积网络构成的编码器，得到尺寸为$H' \times W' \times D$的特征映射(隐变量)$z_e(x)$，该特征映射的每一个空间位置是一个$D$维向量。

构建一个字典$$\{e_1,e_2, \cdot\cdot\cdot e_K\},e_k \in \Bbb{R}^D$$，将$H' \times W'$个$D$维向量映射到字典中最近的向量$e_i$，用其**index**表示，就可以把隐变量量化为$q(z \| x)$，这是一个$H' \times W'$的整数矩阵，实现了离散型编码。

把$z_e(x)$的向量替换为对应的向量$e_i$，就可以得到最终的编码结果$z_q(x)$。将$z_q(x)$喂入解码器，重构最终图像$p(x \| z_q)$。

在实验中，设置输入图像的尺寸为$H \times W \times c = 256 \times 256 \times 3$，离散编码的尺寸为$H' \times W' = 32 \times 32$，字典长度为$K = 53$。字典编码采用**one-hot**形式。

# 损失函数
对于自编码器，损失函数考虑重构误差：

$$ ① || x - p(x | z_e) ||_2^2 $$

但在**VQ-VAE**模型中，重构图像使用的是$z_q$而不是$z_e$，应该用下列重构误差：

$$ ② || x - p(x | z_q) ||_2^2 $$

但是$z_q$的构建过程无法求导（包含**argmin**），无法直接对②式进行优化；而直接优化①式又不是直接的优化目标。作者使用**Straight-Through Estimator**的方法，优化下面的重构误差：

$$ || x - p(x | z_e + sg[z_q-z_e]) ||_2^2 $$

其中$sg$表示**stop gradient**，即在反向传播时不计算其梯度。因此在前向传播时使用$z_q$计算误差，在反向传播时使用$z_e$计算梯度，便可以同时更新编码器和解码器。

在计算损失函数时，还希望编码向量$z_e$和字典向量$e$足够接近，即：

$$ || z_e - e ||_2^2 $$

作者将上式分解为两个损失，分别更新字典向量和编码向量：

$$ || sg[z_e] - e ||_2^2 + || z_e - sg[e] ||_2^2 $$

整个模型的损失函数可以写作：

$$ || x - p(x | z_e + sg[z_q-z_e]) ||_2^2  +  || sg[z_e] - e ||_2^2  +  \beta || z_e - sg[e] ||_2^2 $$

# 建模先验分布
**VQ-VAE**训练完成后，可以在先验分布$p(z)$上采样，通过解码器生成图像。

如果独立地采样$H' \times W'$个离散值，再通过字典映射为维度是$H' \times W' \times D$的$z_q(x)$，那么生成的图像在每个空间位置上都是独立的。

为了建立不同空间位置之间的联系，建立自回归模型，具体地，使用**PixelCNN**：$p(z_1,z_2,z_3, \cdot\cdot\cdot) = p(z_1)p(z_2 \| z_1)p(z_3 \| z_1z_2) \cdot\cdot\cdot$，其中联合概率$p(z_1,z_2,z_3, \cdot\cdot\cdot)$就是先验分布。通过对其采样，可以得到互相关联的$H' \times W'$个整数。

