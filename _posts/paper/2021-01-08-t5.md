---
layout: post
title: 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer'
date: 2021-01-08
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60ed21125132923bf834851a.jpg'
tags: 论文阅读
---

> T5：编码器-解码器结构的预训练语言模型.

- paper：[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)

本文介绍**Google**提出的预训练语言模型**T5(text-to-text-transfer-transformer)**，该模型使用标准的编码器-解码器结构，构建了无监督+有监督的文本生成预训练任务(将预训练任务都看作**Seq2Seq**任务)，并在大量自然语言处理任务中取得最好的成绩。

## 1. 预训练任务

**T5**的预训练包含**无监督**和**有监督**两部分。无监督部分使用**Google**构建的$800$G语料库**C4**，训练任务采用和**BERT**一样的**mask**语言建模，但将其改成了**Seq2Seq**版本，即采用编码器-解码器结构，将**masked**序列输入编码器，解码器以自回归的方式顺序生成**masked token**。

![](https://pic.imgdb.cn/item/60ed23435132923bf846986a.jpg)

有监督部分则收集了多种不同的自然语言处理监督任务数据，并也统一转化为**Seq2Seq**任务来训练：

![](https://pic.imgdb.cn/item/60ed23105132923bf844f375.jpg)

值得一提的是，微调**T5**模型时的学习率要比微调**BERT**大$10$倍以上才行(即$10^{−4}$级别，**BERT**一般是$10^{−5}$级别)，这是两者模型架构差异决定的。

## 2. 相对位置编码

作者在**T5**模型中使用了一种特殊的相对位置编码。通常对于使用绝对位置编码的自注意力机制运算如下：

$$ \begin{aligned} q_i &= (x_i+p_i) W^Q , k_j = (x_j+p_j) W^K ,v_j = (x_j+p_j) W^V  \\ \alpha_{ij} &= \text{softmax}\{(x_i+p_i)W^Q ( (x_j+p_j)W^K)^T \} \\ &=  \text{softmax}\{ x_iW^Q (W^K)^T x_j^T+x_iW^Q (W^K)^T p_j^T+p_iW^Q (W^K)^T x_j^T+p_iW^Q (W^K)^T p_j^T \} \\ z_i &= \sum_{j=1}^{n} \alpha_{ij}(x_jW^V+p_jW^V)  \end{aligned} $$

其中注意力运算这一步骤可以分解成输入-输入($x_i,x_j$)、输入-位置($x_i,p_j$)、位置-输入($p_i,x_j$)、位置-位置($p_i,p_j$)四项注意力的组合。作者假设输入信息与位置信息应该是独立（解耦）的，则它们之间不应该有交互，因此删掉了注意力运算中的输入-位置($x_i,p_j$)和位置-输入($p_i,x_j$)交互项。

此外位置-位置($p_i,p_j$)项得到的结果是依赖于相对位置$(i,j)$的一个标量，将其设置为可训练参数$r_{i,j}$，并移除值向量的位置编码。最终得到的相对位置编码表示为：

$$ \begin{aligned}  \alpha_{ij} &=  \text{softmax}\{ x_iW^Q (W^K)^T x_j^T+r_{i,j} \} \\ z_i &= \sum_{j=1}^{n} \alpha_{ij}x_jW^V  \end{aligned} $$

对于$r_{i,j}$，作者设置了一种分桶截断的方法$r_{i,j}=f(i-j)$，即比较邻近的位置需要精细比较，所以分别分配一个独立的位置编码；至于稍远的位置不用区分得太清楚，所以共用一个位置编码；距离越远，共用范围就越大，直到达到指定范围后进行截断。

![](https://pic.imgdb.cn/item/62c538ee5be16ec74a03087c.jpg)

## 3. 超参数选择

除了在多个自然语言处理任务中取得最好的结果，**T5**还对整个训练流程中的可调的超参数进行了讨论，比如模型架构是采用标准的编码器-解码器结构还是**UniLM**结构，无监督预训练任务是采用**mask**语言建模还是其他方式，随机**mask**的比例应该是多少等，并给出了如下表格：

![](https://pic.imgdb.cn/item/60ed23905132923bf8491a3a.jpg)

