---
layout: post
title: 'V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation'
date: 2021-06-05
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60dad6375132923bf88d4630.jpg'
tags: 论文阅读
---

> V-Net：用于三维医学图像分割的全卷积网络.

- paper：V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation
- arXiv：[link](https://arxiv.org/abs/1606.04797)

临床诊断中很多医学数据都是三维的，作者提出了一种基于全卷积神经网络的三维图像分割方法**V-Net**，实现了磁共振成像(**MRI**)数据中前列腺体积的分割。

**V-Net**结构与**UNet**类似，主要不同在于将卷积替换为$3d$卷积，卷积核尺寸为$5 \times 5 \times 5$。此外下采样过程没有使用池化，而是选用尺寸为$2 \times 2 \times 2$,步长为$2$的卷积，使得每次下采样时体积都减小为原来的$2$倍。上采样时使用尺寸为$2 \times 2 \times 2$,步长为$2$的转置卷积。最终输出两组通道特征，应用**softmax**函数分别转换为前景和背景区域的概率分割。

![](https://pic.imgdb.cn/item/60dad6a55132923bf88ff6c9.jpg)

作者计算了模型每一层的感受野，在分割不明显的解剖结构时，更大的感受野能够感知整个感兴趣的解剖结构，提高模型的性能。

![](https://pic.imgdb.cn/item/60dadb065132923bf8ab237f.jpg)

作者提出了一种新的损失函数**Dice loss**，用于处理前景体素和背景体素之间存在类别严重不平衡的情况。在数据中感兴趣的区域一般仅占据很小的扫描区域，这通常会使网络的预测结果强烈地倾向于背景，使得前景区域经常丢失或仅被部分检测。之前常用的损失函数是交叉熵损失，尽管其简单易实现，但与语义分割中常用的指标**Dice coefficient**并不匹配。直接将该指标作为模型的优化函数通常是一个更好的选择(类比于目标检测中选用**IoU**损失代替交叉熵损失)。对于两个集合$P$和$G$，其**Dice coefficient**定义为：

$$ D = \frac{2|P ∩ G|}{|P|+|G|} $$

若$p_i \in P$代表预测结果，$g_i \in G$代表真实标签，由于真实标签通常用$0,1$表示，因此上述表达式可以写为逐元素相加的形式：

$$ D=\frac{2\sum_{i}^{N}p_ig_i}{\sum_{i}^{N}p_i^2+\sum_{i}^{N}g_i^2} $$

该损失函数对于$p_i$是可导的，因此可以用来更新梯度。

实验在[PROMISE2012](https://promise12.grand-challenge.org/)数据集上进行，通过网络设计和**Dice loss**的应用，取得最好的表现：

![](https://pic.imgdb.cn/item/60dade245132923bf8bdccf9.jpg)