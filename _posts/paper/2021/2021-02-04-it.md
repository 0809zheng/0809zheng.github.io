---
layout: post
title: 'Image Transformer'
date: 2021-02-04
author: 郑之杰
cover: 'https://img.imgdb.cn/item/601ba1763ffa7d37b355d1fe.jpg'
tags: 论文阅读
---

> 基于Transformer的图像生成自回归模型.

- paper：Image Transformer
- arXiv：[link](https://arxiv.org/abs/1802.05751)

图像生成领域的自回归模型，如**PixelRNN**和**PixelCNN**，将图像中像素的联合分布建模为条件分布的乘积。其中基于**RNN**的模型对图像按光栅顺序建模，这类模型能够捕捉长距离的信息，但需要顺序计算，并行程度低；基于**CNN**的模型对图像中的部分区域(感受野)并行计算，但缺点是不能捕捉全局信息。作者提出了基于**Transformer**的自回归模型，其能够并行计算，并捕捉较长距离的信息。

作者将真彩色图像的每一个像素值$0$~$255$编码为一个$d$维向量，将图像调整为尺寸为$(h,w·3,d)$的张量；并通过卷积调整为$(h,w,d)$的张量。引入位置编码，前$d/2$维编码行数信息，后$d/2$维编码列数信息和颜色通道信息。

自注意力的计算如下图所示：

![](https://img.imgdb.cn/item/601bf2003ffa7d37b37d9bce.jpg)

全局的自注意力计算需要每一个位置和所有位置进行交互，产生较大的计算量。受卷积网络“感受野”的启发，作者在自注意力计算中引入了**局部性**。将图像划分为**查询块(query block)**，并将每个查询块与一个包含查询块的**内存块(memory block)**关联起来。 对于给定查询块的所有**查询** $q$，模型使用相同的内存矩阵，该矩阵由来自内存块的所有位置组成。然后对所有查询块并行计算自注意力。

具体地，作者使用两种不同的方案来选择查询块及其相关的内存块邻域，即**1D Local Attention**和**2D Local Attention**，如下图所示，值得一提的是未生成像素位置的权重被屏蔽。

![](https://img.imgdb.cn/item/601bfcf33ffa7d37b38316bc.jpg)


