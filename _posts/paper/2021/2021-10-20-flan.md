---
layout: post
title: 'Finetuned Language Models Are Zero-Shot Learners'
date: 2021-10-20
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67ff14ab88c538a9b5d23d3b.png'
tags: 论文阅读
---

> 微调的语言模型是零样本学习器.

- paper：[Finetuned Language Models Are Zero-Shot Learners](https://arxiv.org/abs/2109.01652)

# 0. TL; DR
本文探讨了一种简单而有效的方法，通过**指令微调（instruction tuning）**显著提升语言模型的零样本学习（**zero-shot learning**）能力。研究者们通过对一个 **137B** 参数的预训练语言模型进行指令微调，使其在多个自然语言处理（**NLP**）任务上表现出色，甚至超越了 **175B** 参数的 **GPT-3**。实验表明，指令微调的效果随着模型规模的增大而增强，并且在未见过的任务类型上表现出色。此外，指令微调还与少样本学习（**few-shot learning**）和提示调整（**prompt tuning**）等方法具有良好的兼容性。

![](https://pic1.imgdb.cn/item/67ff194d88c538a9b5d24ae2.png)

# 1. 背景介绍
随着语言模型规模的不断扩大，其在少样本学习任务中表现出色，但在零样本学习任务中表现较差。例如，**GPT-3** 在阅读理解、问答和自然语言推理等任务上的零样本性能远低于少样本性能。这主要是因为零样本任务的提示格式与预训练数据的格式差异较大，导致模型难以适应。为了解决这一问题，本文提出了一种指令微调的方法，通过在多个 **NLP** 数据集上进行微调，使模型能够更好地理解和执行自然语言指令，从而提升其在未见过的任务上的零样本性能。

# 2. 方法介绍

指令微调的核心思想是利用自然语言指令来描述 **NLP** 任务，并通过对模型进行微调，使其能够根据这些指令执行任务。具体来说，研究者们将 **62** 个公开的 **NLP** 数据集转换为指令格式，并将它们混合在一起进行微调。这些数据集涵盖了自然语言推理、阅读理解、情感分析、翻译等多种任务类型。每个数据集都被手动编写了十个独特的指令模板，以增加任务描述的多样性。例如，对于自然语言推理任务，指令模板可以是“判断给定的前提是否支持假设”等。

![](https://pic1.imgdb.cn/item/67ff174988c538a9b5d24494.png)

为了评估模型在未见过的任务上的零样本性能，研究者们将数据集按照任务类型分为多个任务簇（**task clusters**），并在微调时保留一个任务簇作为评估集，而对其他任务簇进行微调。例如，如果评估集是自然语言推理任务，那么在微调时就不会包含任何自然语言推理任务的数据。这种设置确保了模型在评估时需要完全依赖于其对指令的理解来完成任务。

![](https://pic1.imgdb.cn/item/67ff16d188c538a9b5d24345.png)

对于分类任务，模型需要从多个选项中选择一个正确答案。为了帮助模型更好地理解任务要求，研究者们在指令的末尾添加了一个“选项后缀”，明确列出所有可能的输出类别。例如，在情感分析任务中，指令可以是“判断这条电影评论的情感是正面还是负面？选项：正面、负面”。这种设计使得模型能够更清晰地识别任务目标，并在生成答案时更加准确。

![](https://pic1.imgdb.cn/item/67ff16ad88c538a9b5d242d4.png)

在实验中，研究者们使用了一个 **137B** 参数的预训练语言模型 **LaMDA-PT**。该模型是一个密集的、左到右的解码器语言模型，预训练数据包括网页文档、对话数据和维基百科等。微调过程中，所有数据集的训练样本数量被限制在 **30k** 以内，并采用按比例混合的策略进行采样。模型使用 **Adafactor** 优化器进行训练，学习率为 3e-5，输入和目标序列长度分别为 1024 和 256。整个微调过程在 128 核的 **TPUv3** 上进行了 30k 次梯度更新，耗时约 60 小时。

# 3. 实验分析

研究者们在多个任务簇上对指令微调后的模型**FLAN**进行了评估，包括自然语言推理、阅读理解、封闭式问答、翻译、常识推理、指代消解和结构化数据到文本生成等。为了确保评估的公正性，每个任务簇都使用了不同的模型检查点进行评估。此外，研究者们还报告了使用最佳开发集模板时的测试集性能，以展示模型在典型自然语言指令下的预期性能。

实验结果表明，**FLAN** 在大多数任务上的零样本性能都显著优于未微调的 **LaMDA-PT** 模型，并且在 25 个评估任务中的 20 个任务上超越了 **GPT-3** 的零样本性能。特别是在自然语言推理、阅读理解和封闭式问答等任务上，**FLAN** 的表现尤为突出。部分任务上，**FLAN** 的零样本性能甚至超过了 **GPT-3** 的少样本性能。

![](https://pic1.imgdb.cn/item/67ff181788c538a9b5d24744.png)

研究者们通过消融实验发现，随着微调任务簇数量的增加，模型在未见过的任务上的零样本性能也随之提高。这表明指令微调能够有效地提升模型对新任务的泛化能力。然而，当任务簇数量达到一定规模后，性能提升的幅度逐渐减小，这可能意味着模型在微调过程中已经学习到了足够的任务知识，进一步增加任务簇数量的收益有限。

![](https://pic1.imgdb.cn/item/67ff185788c538a9b5d247e8.png)

实验还发现，指令微调的效果与模型规模密切相关。对于 **100B** 参数以上的大型模型，指令微调能够显著提升其零样本性能；而对于 **8B** 及以下的小型模型，指令微调反而会降低其在未见过的任务上的性能。这可能是因为小型模型的容量有限，微调过程中学习到的大量任务知识会占据模型的大部分容量，导致其在新任务上表现不佳。而对于大型模型，指令微调不仅能够提升其对任务的理解能力，还能在剩余的容量中保留足够的知识来泛化到新任务。

![](https://pic1.imgdb.cn/item/67ff188788c538a9b5d24899.png)


为了验证指令在微调过程中的重要性，研究者们进行了对比实验。他们分别使用了无指令（仅输入输出对）和仅任务名称（在输入前添加任务名称）的微调方法，并与 **FLAN** 的指令微调方法进行了比较。结果表明，无指令和仅任务名称的微调方法在零样本任务上的性能远低于 **FLAN**，这表明指令微调对于提升模型的零样本性能至关重要。

![](https://pic1.imgdb.cn/item/67ff18c588c538a9b5d2495c.png)

研究者们进一步探索了指令微调与少样本学习的结合效果。他们发现，在指令微调的基础上添加少样本示例，能够进一步提升模型在所有任务簇上的性能。少样本示例对于那些输出空间较大或较复杂的任务（如结构化数据到文本生成、翻译和封闭式问答）尤其有效，因为它们可以帮助模型更好地理解输出格式。此外，少样本示例还降低了模型对提示工程的敏感性，使得模型在不同提示下的性能更加稳定。

![](https://pic1.imgdb.cn/item/67ff18e588c538a9b5d249a1.png)

除了少样本学习，研究者们还研究了指令微调与提示调整的结合效果。提示调整是一种通过优化连续提示向量来提升模型性能的方法。实验结果表明，指令微调后的模型 **FLAN** 在提示调整过程中表现更好，能够更好地响应连续输入。这进一步证明了指令微调能够提升模型对自然语言指令的理解能力，使其在多种提示下都能更好地完成任务。

![](https://pic1.imgdb.cn/item/67ff191d88c538a9b5d24a40.png)