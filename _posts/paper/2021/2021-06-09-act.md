---
layout: post
title: 'Action Tubelet Detector for Spatio-Temporal Action Localization'
date: 2021-06-09
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/60ef95bd5132923bf88a9241.jpg'
tags: 论文阅读
---

> ACT-detector：检测tubelet的时空动作检测器.

- paper：Action Tubelet Detector for Spatio-Temporal Action Localization
- arXiv：[link](https://arxiv.org/abs/1705.01861)

目前的时空动作检测算法是在每一帧上进行目标检测，得到目标的空间位置，再连接每一帧上的检测结果得到时间上的定位。这些算法把每一帧作为独立的输入，没有考虑视频帧的时间连续性，容易造成检测结果的模糊。如下图仅从单帧图像上是无法分辨目标是坐下还是站起来。

![](https://pic.imgdb.cn/item/60ef96c05132923bf8904287.jpg)

本文提出了**Action Tubelet detector (ACT-detector)**，即每次输入多帧连续视频帧，输出待预测的行为在连续帧上的多个**bbox**构成的**anchor cuboids**，然后对每个**bbox**进行精修得到待预测行为的**tubelets**。由于**ACT-detector**考虑到多个视频帧的连续性特征，从而能够减少行为预测的模糊性，同时提高定位准确率。

![](https://pic.imgdb.cn/item/60ef97855132923bf894bd2e.jpg)

给定$K$帧的连续帧视频序列，使用共享权重的卷积神经网络**backbone**(本文采用**SSD**)从每帧图像上提取不同层次的特征图。由于**backbone**预设了**ahchor**，因此对于同一个**anchor**在连续的$K$帧视频序列上构成了**anchor cuboids**。将$K$帧连续图像上的同一个**anchor cuboids**的特征图堆叠起来，通过两个卷积层分别预测动作类别得分和预测框回归结果。其中分类层预测**anchor cuboids**对于$C+1$个类别的得分，回归层输出$4K$个坐标用于对预测框进行调整。

![](https://pic.imgdb.cn/item/60ef98805132923bf89a578a.jpg)

模型每一次的预测结果是$K$帧图像序列对应的一系列**tubelets**，需要将整个视频中的**tubelets**连接起来。所使用的**link**算法如下：
对于每次输入采取帧步长为$1$，即前一个连续$K$帧图像序列和后一个连续$K$帧图像序列有$K-1$帧重叠。通过非极大值为每个类别保留置信度最大的$N$个**tubelets**，将重叠的**tubelets**合并为同一个**tubelet links**，
最后对**tubelet links**在时间上进行平滑(在每一帧上对所有预测求平均值)，得到最终的检测框坐标。

作者提出了增强版的**Two-stream ACT-detector**。即同时训练两个检测器，其中一个输入连续的$K$帧图像序列，另一个输入连续$K$帧光流图；两个检测器都输出**tubelets**。之后对两个**tubelets**进行融合，具体地，有两种融合方法：
- **union**：对两个**tubelets**进行合并
- **late**：对两个模型的**anchor cuboids**置信度取平均，但只使用输入**RGB**图像的**anchor cuboids**调整的**tubelets**

通过对比，引入光流处理后的模型性能得到提高：
![](https://pic.imgdb.cn/item/60efcd025132923bf8db28c7.jpg)

作者对输入连续帧的长度$K$进行了消融实验，并选定$K=6$:

![](https://pic.imgdb.cn/item/60efcce65132923bf8da4d3c.jpg)

对于每一帧的预测结果，除了预测正确的情况，作者针对预测错误的情况划分成五种常见的误差类型，并分析模型在$K=1$和$K=6$时所犯错误的比例：
1. 定位错误$E_L$：动作类别预测正确，但定位错误(**IoU**$<0.5$)
2. 分类错误$E_C$：定位正确(**IoU**$≥0.5$)，但动作类别预测错误
3. 时间错误$E_T$：检测到正确的动作类别，但该帧中不包含这个动作
4. 其他错误$E_O$：在没有动作的帧中检测到结果
5. 漏检错误$E_M$：没有检测到真实存在的动作

![](https://pic.imgdb.cn/item/60ef9beb5132923bf8ae2e72.jpg)

作者对比了在不同数据集上几种模型的帧**mAP(frame-mAP)**，即只考虑每一帧中预测结果的(空间)质量，不考虑不同帧之间的连接(时间)质量。

![](https://pic.imgdb.cn/item/60ef9b425132923bf8aa4258.jpg)

作者对比了在不同数据集上几种模型的视频**mAP(video-mAP)**，即同时考虑预测结果的空间质量(每一帧上的检测结果)和时间质量(不同帧之间的连接结果)。

![](https://pic.imgdb.cn/item/60ef9b8d5132923bf8abfea4.jpg)
