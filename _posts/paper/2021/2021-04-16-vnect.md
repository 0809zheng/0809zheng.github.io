---
layout: post
title: 'VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera'
date: 2021-04-16
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/64a538391ddac507cc7bda1a.jpg'
tags: 论文阅读
---

> VNect：使用单张RGB图像进行实时3D人体姿态估计.

- paper：[VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera](https://arxiv.org/abs/1705.01583)

在人体姿态估计任务中，如果将**3D**姿态视为**2D**姿态的隐变量，则会产生空间的歧义性问题。因为**2D**位置稀疏序列失去了空间的前后性，如四肢的前后方向（手往前和往后在**2D**序列中表现的位置是一样的），这样在模糊前提下的估计会导致错误的估计。

为了解决这种问题，作者提出从图像特征中直接学习**3D**姿态隐特征的判别方法**VNect**。通过全卷积网络在图像中联合训练**2D**和**3D**姿态。网络预测一个热图(**heatmap**)及位置图(**location map**)。位置图存储关节点相对于根关节的三维坐标，实际上就是$X, Y, Z$三个方向的坐标图。找到关键点的过程为从热图中寻找关节的最大值$(x, y)$，则在对应的$X, Y, Z$位置图中找到对应位置的点，组成相对根节点的**3D**坐标。

![](https://pic.imgdb.cn/item/64a628ee1ddac507cc293eee.jpg)

**VNect**的输入是连续的单目**RGB**图像（实际上每次输入是一张**RGB**图像），第**t**帧的输出为全局**3D**骨骼位置$P^G_t$。**CNN**联合训练**2D**关节点位置$K_t$和相对根关节的**3D**关节点位置$P_t^L$。最后将**2D**和**3D**关节点预测位置结合起来，估计出一个平滑的、时间连续的姿态$P^G_t(\theta, d)$，其中$d$是相机空间的全局位置，$\theta$是运动学骨架的关节点角度。$J$表示关节点的数量。由于这种**3D**姿态估计是通过单帧进行的，无法考虑前后信息，无法在视频时间上保持动作的一致性，所以需要一系列的后处理。

![](https://pic.imgdb.cn/item/64a629991ddac507cc2aa652.jpg)

### ⚪ VNect结构

![](https://pic.imgdb.cn/item/64a62c581ddac507cc313aea.jpg)

**VNect**设计的卷积网络模型如上图所示。骨干网络为**ResNet50**，从**res5a**层开始修改结构，最终目标是预测**2D**热图$H$和**3**个位置图$X, Y, Z$。通过使用额外的**3**个位置图将**2D**热图扩展成**3D**，方式为找到关节点$j$对应热图的最大值位置，依据最大值位置在$X, Y, Z$中找到对应的$x_j, y_j, z_j$存为$$P^L=\{x, y, z\}$$，其中$x\in R^{1*J}$。训练损失如下，其中$\odot$表示**Hadamard**乘积，实际操作为元素对应乘积:

$$
Loss(x_j)=\| H^{GT}_j \odot (X_j - X_j^{GT}) \|
$$

除输入和输出外，**VNect**的中间还加入了和相对于根关节的位置图$X_j, Y_j, Z_j$相似的运动学父相对位置图(**kinematic parent-relative location-map**) $\Delta X_j, \Delta Y_j, \Delta Z_j$，然后用于计算骨骼长度图(**bone length-map**):

$$
BL_j=\sqrt {\Delta X_j \odot \Delta X_j + \Delta Y_j \odot \Delta Y_j + \Delta Z_j \odot \Delta Z_j}
$$

作者想通过结合中间预测和中间特征，给网络额外增加骨骼长度的明确概念，以自适应特征对象躯干。

在训练的时候加入中间监督。随着迭代的加深，逐步减少中间损失的权重。中间监督从 **res4d** 和 **res5a** 预测 **2D heatmaps** 和 **3D location maps**。**2D pose**使用**MPII**和**LSP**进行预训练，**3D pose**使用**MPI-INF-3DHP**和**Human3.6m**。**huamn3.6**数据集除了**S9**和**S11**都用于训练，**MPI-INF-3DHP**使用全部。

### ⚪ 后处理

在视频中，逐帧姿态估计不能充分利用运动的时间一致性，小的姿态误差会导致时间上的抖动，所以在后处理时做时域滤波和平滑。

平滑时同时利用**2D**姿态和**3D**姿态，最后得到的骨骼关节角度$\theta$和根关节点在相机空间的坐标$d$由最小化下面公式的能量所得

$$
\begin{aligned}
E_{total}(\theta,d) =& E_{IK}(\theta,d) + E_{proj}(\theta,d) \\
&+ E_{smooth}(\theta,d) + E_{depth}(\theta,d)
\end{aligned}
$$

$E_{IK}$是**3D**逆运动像，与**3D CNN**的输出$P_t^L$的相关性来决定整体的姿态；$E_{proj}$决定全局姿态$d$，通过**2D**检测结果来校正**3D pose**；$E_{smooth}$衡量时间稳定度；为抵消单目重建中的不确定性，对深度的大变化进行补偿$E_{depth}$。

$$
\begin{aligned}
E_{IK}(\theta,d) &= ||(P_t^G-d)-P^L_t||_2 \\
E_{proj}(\theta,d) &= ||\Pi(P_t^G)-K_t||_2 \\
E_{smooth}(\theta,d) &= ||\hat{P_t^G}||_2 \\
E_{depth}(\theta,d) &= ||[\tilde{P_t^G}]_Z||_2 \\
\end{aligned}
$$
