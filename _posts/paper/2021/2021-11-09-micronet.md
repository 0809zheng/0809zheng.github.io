---
layout: post
title: 'MicroNet: Towards Image Recognition with Extremely Low FLOPs'
date: 2021-11-09
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6189dfd32ab3f51d91e3e2cb.jpg'
tags: 论文阅读
---

> MicroNet：极低FLOPs的图像识别网络.

- paper：[MicroNet: Towards Image Recognition with Extremely Low FLOPs](https://arxiv.org/abs/2011.12289)

作者提出了**MicroNet**，在**ImageNet**分类任务上实现了$6$**M FLOPs**模型。为了缓解小模型的性能下降问题，采用了两个设计原则。第一，通过降低节点的连接来避免网络宽度的减少。第二，通过引入更复杂的非线性来补偿网络深度的减少。

![](https://pic.imgdb.cn/item/6189e2bf2ab3f51d91ea59c2.jpg)

## 1. Micro-Factorized Convolution
网络宽度定义为通道数量，输入输出节点之间的连接性定义为每个输出节点的连接数。网络连接性为输出通道数量与节点连接性的乘积。若总计算代价一定，则通道数量与连接性冲突。作者设计了**微因子卷积**(**micro-factorized conv**)，用以平衡通道数量和输入输出的连接性。

### ① 微因子逐点卷积
假设卷积的输入与输出通道数$C$相同，每一个输出通道由所有输入通道计算得到，则逐点卷积($1\times 1$卷积)的卷积核可以表示为$C\times C$的矩阵$W$。

作者提出使用自适应组卷积(**group-adaptive conv**)对逐点卷积进行分解：

$$ W=P\Phi Q^T $$

其中矩阵$Q \in \Bbb{R}^{C \times \frac{C}{R}}$按比例$R$压缩通道，矩阵$P \in \Bbb{R}^{C \times \frac{C}{R}}$按比例$R$扩张通道，两者均为$G$块的分块对角矩阵，每块相当于组卷积的一组。
矩阵$\Phi \in \Bbb{R}^{\frac{C}{R} \times \frac{C}{R}}$是一个置换矩阵，用于打乱通道。

![](https://pic.imgdb.cn/item/61920b132ab3f51d911de0f5.jpg)

定义输入输出通道之间的连接性为$E$。每个输出通道连接$\frac{C}{RG}$个中间层通道，每个中间层通道又连接$\frac{C}{G}$个输入通道，因此连接性$E=\frac{C^2}{RG^2}$。

总计算复杂度为$\mathcal{O}=2\times \frac{C}{R} \times \frac{C}{G}=\frac{2C^2}{RG}$，则网络宽度(通道数$C$)和连接性$E$表示为：

$$ C=\sqrt{\frac{\mathcal{O}RG}{2}},\quad  E=\frac{\mathcal{O}}{2G} $$

![](https://pic.imgdb.cn/item/61920ec32ab3f51d911f2e0d.jpg)

当通道数$C$等于连接性$E$时，组数$G$和通道减少率$R$应满足关系：

$$ G=\sqrt{\frac{C}{R}} $$

此时每个输出通道连接所有输入通道，导致卷积核矩阵$W$可以$G\times G$分块，每个子矩阵的秩为$1$。

### ② 微因子深度
把$k\times k$的深度卷积分解为$k\times 1$卷积与$1\times k$卷积。

![](https://pic.imgdb.cn/item/61920fe82ab3f51d911f90c1.jpg)


## 2. Dynamic Shift-Max
当网络层数减少时，网络性能会下降；通过改善每一层的非线性可以补偿网络深度的减少。
作者提出了**Dynamic Shift-Max**激活函数，用于增强网络非线性。

假设输入向量$x$具有$C$个通道，划分为$G$组。则每个组具有$\frac{C}{G}$个通道。定义$x$中第$i$个通道的$N$通道循环移位表示为(即第$i+N$个通道)：

$$ x_N(i)=x_{(i+N) \text{ mod } C} $$

进一步可以定义组循环移位(即每个组的对应通道位置)：

$$ x_{\frac{C}{G}}(i,j)=x_{(i+j{\frac{C}{G}}) \text{ mod } C}, \quad j=0,...,G-1 $$

**Dynamic Shift-Max**结合了多个组移位，定义为：

$$ y_i= \mathcal{\max}_{1\leq k\leq K} \{\sum_{j=0}^{J-1} a_{i,j}^k(x)x_{\frac{C}{G}}(i,j)\} $$

其中超参数$a_{i,j}^k$可以通过类似**SENet**的方式计算。注意到**Dynamic Shift-Max**提高了不同通道组之间的连通性，可以作为逐点卷积的补充。下图展示了一种特殊情况，即只关注该组与下一个组的情况：

![](https://pic.imgdb.cn/item/619219ed2ab3f51d912315f9.jpg)

**Dynamic Shift-Max**共引入了$CJK$个超参数，实践中可取$J=K=2$。

## 3.  MicroNet

![](https://pic.imgdb.cn/item/61921b082ab3f51d91236d73.jpg)

作者设计了三种**Micro**块，**Micro**块具有四个超参数，卷积核大小$k$，输出通道数$C$，逐点卷积的压缩率$R$和分组数$G_1G_2=\frac{C}{R}$。
- **Micro-A**：堆叠微因子深度卷积和逐点卷积（只使用压缩部分），用在网络浅层。
- **Micro-B**：连接模块**A**和**C**，使用深度卷积和完整的逐点卷积。
- **Micro-C**：用在网络深层。

**MicroNet**的网络结构如下：

![](https://pic.imgdb.cn/item/61921d5f2ab3f51d91242f57.jpg)

实验结果如下：

![](https://pic.imgdb.cn/item/61921dfb2ab3f51d91246ee5.jpg)