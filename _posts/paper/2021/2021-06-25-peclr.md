---
layout: post
title: 'PeCLR: Self-Supervised 3D Hand Pose Estimation from monocular RGB via Equivariant Contrastive Learning'
date: 2021-06-25
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/668f7fcad9c307b7e9db1829.png'
tags: 论文阅读
---

> PeCLR：通过等变对比学习实现单目RGB自监督3D手部姿态估计.

- paper：[PeCLR: Self-Supervised 3D Hand Pose Estimation from monocular RGB via Equivariant Contrastive Learning](https://arxiv.org/abs/2106.05953)

本文基于单目RGB图片，通过对比学习的方式来做自监督3D手部姿态估计。以往的对比学习自监督任务，都是通过对无标注数据进行数据增强，鼓励模型学习出不随数据增强变换而改变的特征表示，这种性质称为不变性（**invariance**）。手部姿态估计任务作为一个对空间信息敏感的下游任务，任何改变空间信息的几何数据增强操作都会改变手部动作，这时则会期望模型表征具有等变性（**equivariance**）。

为了应对以上姿态估计任务的独特性质，和数据标注面临的问题，本文提出了**Pose Equivariant Contrastive Learning(PeCLR)**方法，即一个具有等变性的对比学习目标函数，能在不利用任何标注信息的情况下学习到几何变换上的等变性特征，并通过实验证明，具有等变性的对比学习自监督训练，能取得比原来只有不变性的对比学习自监督更好的效果。

![](https://pic.imgdb.cn/item/668f8120d9c307b7e9dd0d07.png)

通常对比学习函数会将$N$张图片经过两种不同的数据增强$T_1$和$T_2$，对每个样本$I$而言，都有$1$个正样本和$2(N-1)$个负样本，将这些样本送入编码器提取特征，将同类样本在向量空间中互相拉近，不同类样本相互远离：

$$
L_{i,j} = - \log \frac{\exp(sim(z_i,z_j)/\tau)} {\sum_{k=1:2N,k\neq i} \exp(sim(z_i,z_k)/\tau)}
$$

手部姿态估计要求模型对于几何变换具有等变性，因为几何变换会改变关键点的位置；此时对比学习不再强迫正样本对的特征$z_i,z_j$接近，而是对这两个特征做逆变换，追求逆变换后得到的特征一样。

$$
L_{i,j} = - \log \frac{\exp(sim(T_i^{-1}(z_i),T_i^{-1}(z_j))/\tau)} {\sum_{k=1:2N,k\neq i} \exp(sim(T_i^{-1}(z_i),T_i^{-1}(z_k))/\tau)}
$$

由于几何变换本质上是一种仿射变换，可以通过矩阵乘法完成，所以逆变换是很容易得到的。值得一提的是，由于图片所在的空间跟特征所在的向量空间是不同的，而缩放、旋转等变换是与图片尺寸相关的，因此不能简单地直接把针对图片的逆变换用在特征上，在应用之前还需要根据各自的大小计算比例，进行等比例的变换。

由于自监督学习的数据增强选择会很大程度上影响模型性能，本文也从单个变换到多个变换组合递进的方式，探索了适合于手部姿态估计任务的数据增强集合。结果表明，对**PeCLR**，**scale+rotation+translation+color jittering**的组合表现最好。

![](https://pic.imgdb.cn/item/668f84cdd9c307b7e9e344eb.png)

本文首先在手部姿态数据上验证了**SimCLR**使用单个变换的表现（图a），可以看到尽管**SimCLR**不适用于姿态估计任务，但经过了自监督预训练的模型表现仍然超过随机初始化后进行监督训练的表现。接下来又对比了**PeCLR**和**SimCLR**在几何变换上的表现（图b），可以看到**PeCLR**的确在几何变换上大幅超越了**SimCLR**。

![](https://pic.imgdb.cn/item/668f853ed9c307b7e9e3db80.png)