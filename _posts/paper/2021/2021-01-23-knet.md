---
layout: post
title: 'K-Net: Towards Unified Image Segmentation'
date: 2021-01-23
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/64104e62ebf10e5d5333ff27.jpg'
tags: 论文阅读
---

> K-Net: 面向统一的图像分割.

- paper：[K-Net: Towards Unified Image Segmentation](https://arxiv.org/abs/2106.14855)

语义分割、实例分割和全景分割存在着潜在的链接，但现有的分割方法往往将其割裂开来，譬如最经典的**FCN**用于语义分割，而在实例分割中，**Mask-RCNN**则是较为经典的网络。而全景分割则是语义和实例两者的结合，要求在分割实例的情况下提供更全面的场景理解。

针对以上三个任务，**K-Net**提出了一种基于动态内核的分割模型，为每个任务分配不同的核来实现多任务统一。

对于所有细分的分割任务，其内核都是对有意义的像素进行分组，譬如语义分割将不同的类别像素分组。理论上而言，分割任务的分组是有上限的，因此可以把分组数量设置为**N** ，比如有**N**个用于语义分割的预定义语义类或图像中最多有**N**个实例对象，对于全景分割，**N**是图像中的**stuff**类和**Instance**类的总数。

因此可以使用**N**个**Kernel**将图像划分为**N**组，每个**Kernel**都负责找到属于其相应组的像素（**Kernel**与**Content**实现一对一映射）。具体而言，给定由神经网络产生的**B**张图像的输入特征映射$F∈R^{B×C×H×W}$，只需要**N**个**kernels** $K∈R^{N×C}$即可执行卷积以获得相应的的预测结果$M=\sigma(K*F)∈ R^{B×N×H×W}$。

使用$\sigma$对结果进行激活，设置对应阈值后即可得到**N**个二进制掩码**Mask**，即可得到语义分割的结果。为了实现实例分割，需要对每一个**Kernel**进行限制，也就是每个**Kernel**最多只能处理图像中一个对象，通过这种方式**K-Net**可以区分实例并同时执行分割，从而在一个特征映射中实现实例分割，而无需额外的步骤。作者将这些内核称为本文中的**语义内核**和**实例内核**，分别用于语义和实例分割。实例内核和语义内核的简单组合即可实现全景分割，该分割将像素分配给实例对象或一类东西。

![](https://pic.imgdb.cn/item/6410185df144a010073b422b.jpg)

虽然使用**Kernel**来区分语义类别是十分简单的，但是要区分实例对象就显得比较困难。因为实例内核需要区分图像内部和跨图像内外部的对象。不像语义类别具有共同和明确的特征，实例内核需要拥有比语义内核更强的判别能力。因此作者提出了一个**Kernel Update**策略，来使每一个内核对应一个像素组。**Kernel Update Head** $f_{i}$包含三个关键步骤：**group feature assembling**、**adaptive kernel update** 和 **kernel interaction**。

![](https://pic.imgdb.cn/item/641021f3ebf10e5d53e04e5e.jpg)

### ⚪ Group Feature Assembling

首先通过**Mask** $M_{i-1}$来计算聚合出一个组特征映射$F^{K}$。其中每一个组**group**都对应着一个语义类\实例对象。由于$M_{i-1}$中每个内核的掩码本质上定义了像素是否属于该内核的相关组，可以通过将特征映射$F$乘$M_{i-1}$作为新的组装特征$F^K$:

$$
F^K=\sum_u^H \sum_v^W M_{(i-1)}(u, v) \cdot F(u, v), F^K \in R^{B \times N \times C}
$$

### ⚪ Adaptive Feature Update

经过**Group Feature Assembling**之后，$F^{K}$内的每一个组都将会被用来更新内核$K_{i-1}$。但考虑到**mask** $M_{i-1}$可能不够准确，可能包含了其他组被误分类进来的噪音，因此设计了一个自适应的内核更新策略，首先在$F^K$和$K_{i-1}$之间执行元素乘法($\phi_1,\phi_2$为线性变换)：

$$
F^G=\phi_1\left(F^K\right) \otimes \phi_2 K_{i-1}, F^G \in R^{B \times N \times C}
$$

随后，计算两个门控**gates**，$G^F$和$G^K$：

$$
G^K=\sigma\left(\Phi_1\left(F^G\right)\right), G^F=\sigma\left(\Phi_2\left(F^G\right)\right)
$$

再由这两个**gates**计算出一组新的**kernels** $\tilde{K}$:

$$
\tilde{K}=G^F \otimes \Phi_3\left(F^K\right)+G^K \otimes \Phi_4\left(K_{i-1}\right)
$$

其中，$\Phi_n$函数均为**Fully connected layers**（全连接层）+ **Layer Norm**（层归一化）。计算结果$\tilde{K}$则将用于**Kernel Interaction**中。

### ⚪ Kernel Interaction

内核$K_{i-1}$进行交互，互相能够提供上下文信息以对全局特征图进行建模，获得新的内核$K_{i}$。**Kernel Interaction**可以使不同的**kernel**之间互相信息流通，也就是能够提供上下文信息，这些信息允许**kernel**隐式利用图像**group**之间的关系。

为了从上述计算出来的$\tilde{K}$中计算出一组新的**kernels** $K_i$，作者采用了**Multi-Head Self-Attention+Feed-Forward Neural Network**的形式来输出一组新的$K_i$。最后，使用$K_{i}$对特征图**F**进行卷积，得到预测结果更加精确的**Mask**：$M_i=g_i(K_i)*F$， 这里的$g_i$为 **FC−LN−ReLU** 操作。

### ⚪ K-Net

![](https://pic.imgdb.cn/item/641022b6ebf10e5d53e1fc94.jpg)

**K-Net**通过一个**BackBone**和**Neck**（作者这里使用了**FPN**）来生成一组特征图**F**。由于语义分割和实例分割所要求的特征图有所差异，所以作者通过两个独立的卷积分支对**F**进行处理生成$F^{ins}$和$F^{seg}$，这里使用的卷积核为初始化的$K_0^{ins}$和$K_0^{seg}$，这样就生成了一组新的**Mask**：$M_0^{ins}$、$M_0^{seg}$。

对于全景分割，由于$M_0^{seg}$中自然而然的包括了全景分割中所需求的"**things**"和"**stuff**"（只不过没有区分实例），那么只需要从$M_0^{seg}$中将包含"**stuff**"的部分提取出来，再和$s M_0^{ins}$（区分实例）直接进行通道相加，即可得到全景分割所需要的**Mask**：$M_0$。同理，对于卷积核**Kernel**，也只需要提取对应的$K_0^{ins}$和$K_0^{seg}$组合成新的$K_0K$。而对于特征图$F$，将$F^{ins}$和$F^{seg}$简单通道相加即可（信息越多越好）。对于新得到的$K_0$、$M_0$和$F$，经过$S$次**Kernel Update Head**处理，可以得到最终的**Output**：$M_S$。

对于实例分割，只需要删除内核和掩模的串联过程即可。在这一步并不需要删除语义分割分支，因为语义信息仍然是互补的（遵循信息越多越好的原则，毕竟实例信息可以从语义信息中提取）。不过需要注意的是，在这种情况下，语义分割分支不使用额外的真实标签。语义结果的标签是通过将实例掩码转换为相应的类标签来构建的。训练**Instance Kernels**的损失函数选择了**Dice Loss**，原因是局部细节使用交叉熵的话容易导致不平衡问题；使用匈牙利算法（**Mask-based Hungarian Assignment**）来处理**Mask**配对问题。

对于语义分割，只需要简单地将**Kernel Update Head**附加到任何依赖语义内核的语义分割方法中即可执行语义分割。