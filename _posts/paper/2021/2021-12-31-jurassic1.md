---
layout: post
title: 'Jurassic-1: Technical details and evaluation'
date: 2021-12-31
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67f72f3e88c538a9b5c82a2d.png'
tags: 论文阅读
---

> Jurassic-1：技术细节与评估.

- paper：[Jurassic-1: Technical details and evaluation](https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf)


# 0. TL; DR

**Jurassic-1** 是由 **AI21 Labs** 发布的一对自回归语言模型，包括拥有 **178B** 参数的 **J1-Jumbo** 和 **7B** 参数的 **J1-Large**。它基于 **Transformer** 解码器架构，采用改进的词汇表和网络深度/宽度比，显著提高了推理速度。**Jurassic-1** 在多领域文本预测任务中优于 **GPT-3**，并在零样本和少样本学习中表现相当或更好。此外，其大词汇表设计提高了文本编码效率，使模型在少样本学习中能处理更多示例。尽管存在偏见和毒性问题，但 **Jurassic-1** 为大规模语言模型的发展提供了新的思路和实践。

# 1. 背景介绍

随着自然语言处理（**NLP**）技术的飞速发展，语言模型在理解、生成和翻译自然语言方面扮演着越来越重要的角色。近年来，自回归语言模型如 **GPT-3** 等取得了显著的成果，展示了其在多种任务中的强大能力。然而，随着模型规模的不断增大，如何在保持性能的同时提高效率和适应性成为新的挑战。

**AI21 Labs** 发布的 **Jurassic-1** 是对这一挑战的回应。该模型旨在超越单纯的规模扩张，通过创新的架构和训练方法，实现更高效、更强大的语言处理能力。**Jurassic-1** 包括两个版本：**J1-Jumbo**（**178B** 参数）和 **J1-Large**（**7B** 参数），分别对应 **GPT-3** 的 **175B** 和 **6.7B** 模型。**Jurassic-1** 在架构和训练上进行了多项改进，以实现更快的推理速度和更高的文本处理效率。

本研究的主要目标是详细介绍 **Jurassic-1** 的技术细节，包括其架构设计、训练过程以及性能评估。通过与 **GPT-3** 的对比，展示 **Jurassic-1** 在多领域文本预测、零样本学习和少样本学习中的优势，并探讨其在实际应用中的潜力和局限性。

# 2. Jurassic-1 模型

**Jurassic-1** 基于 **Transformer** 架构的解码器模块，采用了多项改进以提高性能和效率。模型的主要参数如下表所示：

![](https://pic1.imgdb.cn/item/67f730ce88c538a9b5c82cea.png)

**Jurassic-1** 在设计 **J1-Jumbo** 时，参考了关于自注意力网络深度与宽度权衡的理论。该理论指出，在给定参数预算下，存在一个最优的深度。对于 **175B** 参数的预算，理论上的最优深度约为 **80** 层，而 **GPT-3 175B** 使用了 **96** 层。**Jurassic-1** 将 **J1-Jumbo** 的层数设计为 **76** 层，同时考虑了硬件限制和训练效率。

**Jurassic-1** 采用了 **256K** 的词汇表，远大于 **GPT-2/3** 的 **50K** 词汇表。这种设计不仅提高了文本编码效率，还使模型能够更好地捕捉语义单元，包括多词表达和命名实体。例如，**Jurassic-1** 的词汇表中包含如 "**_Tony_Stark**" 和 "**_System.out.println**" 等多词表达，这使得模型在处理复杂文本时更具优势。

![](https://pic1.imgdb.cn/item/67f7319d88c538a9b5c82e44.png)
![](https://pic1.imgdb.cn/item/67f731e288c538a9b5c82eb3.png)

**Jurassic-1** 的训练面临了巨大的工程挑战，包括存储和计算资源的限制。为了高效训练，研究者采用了数据、模型和流水线并行策略，并利用 **DeepSpeed** 和 **MegatronLM** 等工具进行分布式训练。模型在 **300B** 个标记上进行了自监督训练，优化器的初始学习率分别为 1.2×10⁻⁴（**J1-Large**）和 0.6×10⁻⁴（**J1-Jumbo**），并使用了线性预热和逐步增加的批量大小。

# 3. 实验分析

**Jurassic-1** 在多个领域的文本完成任务中表现出色。研究者在 **Pile** 数据集的多个子集上测试了模型的性能，包括学术文本（**arXiv**）、小说（**Books3**）、代码（**GitHub**）等。结果显示，**Jurassic-1** 在几乎所有领域都优于 **GPT-3**。例如，在 **arXiv** 数据集上，**J1-Jumbo** 的平均对数概率为 **-0.471**，而 **GPT-3 175B** 为 **-0.581**。

![](https://pic1.imgdb.cn/item/67f7323688c538a9b5c82f43.png)

零样本学习是评估语言模型泛化能力的重要指标。**Jurassic-1** 在多个零样本任务上的表现与 **GPT-3** 相当。例如，在 **ARC-Challenge** 任务中，**J1-Jumbo** 的准确率为 **48.1%**，而 **GPT-3 175B** 为 **50.2%**。在 **BoolQ** 任务中，**J1-Jumbo** 的准确率为 **73.5%**，与 **GPT-3 175B** 的 **75.9%** 接近。这表明 **Jurassic-1** 在处理未见过的任务时具有很强的适应性。

![](https://pic1.imgdb.cn/item/67f7327a88c538a9b5c82fc3.png)

少样本学习是语言模型的另一个重要能力，尤其是在需要少量示例来引导模型生成正确答案的场景中。**Jurassic-1** 的大词汇表设计使其能够处理更长的文本，从而在少样本学习中包含更多示例。例如，在 **DBPedia-14** 文本分类任务中，**J1-Large** 能够在提示中包含更多的训练示例，从而显著提高准确率。

![](https://pic1.imgdb.cn/item/67f732c288c538a9b5c83043.png)

尽管 **Jurassic-1** 在性能上取得了显著进展，但它仍然继承了训练数据中的偏见和毒性。例如，在性别偏见方面，模型更倾向于将医生与 "**he**" 联系起来，而将护士与 "**she**" 联系起来。研究者使用 **StereoSet** 基准测试了模型的偏见程度，发现 **Jurassic-1** 在某些方面略优于 **GPT-3**，但整体差异不大。这表明，尽管 **Jurassic-1** 在技术上取得了进步，但在伦理和安全性方面仍需进一步改进。

![](https://pic1.imgdb.cn/item/67f732f088c538a9b5c83051.png)