---
layout: post
title: 'Poseur: Direct Human Pose Regression with Transformers'
date: 2021-10-15
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/679060bbd0e0a243d4f65b67.png'
tags: 论文阅读
---

> Poseur：使用Transformer直接进行人体姿态回归.

- paper：[Poseur: Direct Human Pose Regression with Transformers](https://arxiv.org/abs/2201.07412)

## TL; DR

本文提出了一种基于**Transformer**的直接人体姿态回归方法——**Poseur**。该方法将人体姿态估计问题转化为序列预测任务，通过**Transformer**网络直接从图像回归关键点坐标，避免了传统基于热图方法的复杂性。**Poseur**通过引入注意力机制，解决了以往回归方法中特征对齐问题，并显著提高了低分辨率图像上的人体姿态估计性能。实验表明，**Poseur**在**MS-COCO**和**MPII**数据集上显著优于现有的回归方法，并首次与基于热图的**SOTA**方法相媲美。

## 1. 背景介绍

人体姿态估计是计算机视觉中的一个核心问题，广泛应用于动作识别、视频增强和人机交互等领域。传统方法主要分为基于热图的方法和回归方法。基于热图的方法通过预测每个关键点的热图来定位人体姿态，虽然精度较高，但存在以下局限性：
- 热图的分辨率通常低于输入图像，导致量化误差。
- 需要手动设计和调整热图，引入噪声。
- 非可微的后处理操作（如寻找热图峰值）阻碍了端到端训练。

回归方法直接从图像回归关键点坐标，避免了热图的复杂性，但以往的回归方法性能较差。本文提出了一种新的回归框架**Poseur**，通过**Transformer**网络直接学习从图像到关键点坐标的映射，并引入注意力机制解决特征对齐问题。

## 2. Poseur模型

**Poseur**的核心思想是将人体关键点表示为查询（**queries**），每个查询对应一个关键点。通过**Transformer**的交叉注意力机制，模型能够自适应地关注与目标关键点最相关的特征，从而提高定位精度。**Poseur**框架包括以下部分：

![](https://pic1.imgdb.cn/item/6790620dd0e0a243d4f65c0d.png)

### ⚪ Backbone

**Backbone**使用卷积层提取卷积特征，经过**GAP**后用**FC**来回归坐标值。回归得到的坐标值作为粗略预测用来引导特征匹配；并且不同**stage**的特征图作为多尺度特征一起送入后面的**decoder**进行坐标预测。

### ⚪ Keypoint Encoder

本文用$K$个**query token**作为可学习的关键点**token**。关键点编码器用于初始化查询**token**。每个查询包含两个属性：位置和类别。位置属性通过将**Backbone**中粗略预测的关键点坐标转换为正弦-余弦位置嵌入来编码；类别属性通过学习可训练的类别嵌入向量来表示。最终，查询**token**通过位置和类别嵌入的逐元素相加来初始化。

### ⚪ Query Decoder

查询解码器是**Poseur**的核心部分，它通过**Transformer**解码器结构来更新查询**token**。每个查询**token**通过自注意力模块和交叉注意力模块逐步更新，最终生成每个关键点的特征表示。交叉注意力模块采用高效的多尺度变形注意力（**EMSDA**），能够自适应地从**Backbone**提供的多尺度特征图中采样与查询最相关的特征。

为了增强解码器的能力，本文设计了一个人工噪声的模块，用人工生成的随机坐标作为预测参考点送进**Decoder**一起训练，要求模型预测正确的结果；在训练结束后扔掉，推理时使用**RLE**的结果作为参考点。

### ⚪ Uncertainty Score

本文提出使用预测关键点分布的似然概率函数在均值点附近的积分来作为关键点预测的不确定性得分。用标准**Lapalce**分布作为概率密度函数的假设：

$$
f(x\mid \mu,b) = \frac{1}{2b}\exp\left(-\frac{|x-\mu|}{b}\right)
$$

则关键点预测的不确定性得分计算为：

$$
s = \int_{\mu-a}^{\mu+a} f(x\mid \mu,b)dx=1-\exp\left(-\frac{a}{b}\right)
$$

### ⚪ Loss Function

**Poseur**采用[<font color=blue>Residual Log-likelihood Estimation (RLE)</font>](https://0809zheng.github.io/2021/07/24/rle.html)来监督模型训练。模型预测每个关键点的中心位置和尺度参数，通过最大化目标位置的概率来优化网络。损失函数包括两部分：粗略预测的损失和查询解码器的损失，最终通过加权求和得到总损失。

## 3. 实验分析

实验主要在**MS-COCO**和**MPII**数据集上进行。**MS-COCO**包含约**25**万个人体实例，标注了**17**个关键点；**MPII**包含约**2.5**万张图像，标注了**16**个关键点。评估指标采用**AP**（平均精度）和**PCK**（正确关键点百分比）。

**Poseur**在使用低分辨率表示的背景网络（如**MobileNet-V2**和**ResNet**）时表现出色，且计算复杂度更低。

![](https://pic1.imgdb.cn/item/67908f11d0e0a243d4f67925.png)

**Poseur**在**MS-COCO**和**MPII**数据集上均取得了与基于热图的**SOTA**方法相当的性能。

![](https://pic1.imgdb.cn/item/67908f52d0e0a243d4f67944.png)

此外，作者进行了一系列消融实验：
- 查询初始化方法的影响：使用粗略预测的关键点坐标初始化查询比直接从可训练向量初始化查询效果更好，提升了0.6 AP。
- 噪声参考点采样策略：在训练阶段引入噪声参考点采样策略可以提高模型对粗略预测错误的鲁棒性，提升了0.6 AP。
- 概率积分作为**score**：这一策略相较于RLE提升了0.9 AP。
- 不同特征图层级的影响：使用多尺度特征图可以逐步提升性能，从单层特征图的73.6 AP提升到四层特征图的74.7 AP。
- 解码器层数的影响随着解码器层数的增加，性能逐渐提升，但在第六层时趋于饱和。

![](https://pic1.imgdb.cn/item/67908ffdd0e0a243d4f679a3.png)

