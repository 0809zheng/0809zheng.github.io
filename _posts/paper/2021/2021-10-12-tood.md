---
layout: post
title: 'TOOD: Task-aligned One-stage Object Detection'
date: 2021-10-12
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6530e289c458853aef0b2052.jpg'
tags: 论文阅读
---

> TOOD：任务对齐的单阶段目标检测方法.

- paper：[TOOD: Task-aligned One-stage Object Detection](https://arxiv.org/abs/2108.07755)

目标检测包括分类和定位两个子任务，分类任务学习的特征主要关注物体的关键或显著区域，而定位任务是为了精确定位整个对象主要关注物体的边界。由于分类和定位学习机制的不同，两个任务学习的特征的空间分布可能会不同，当使用两个独立的分支进行预测时，会导致一定程度的**misalignment**。如下图所示在检测**dining table**时，分类得分最高的**anchor**预测的**bounding box**和披萨的**IoU**更大，而和目标**IoU**最大的**anchor**分类得分却很低，反映出两个任务的**misalignment**。

![](https://pic.imgdb.cn/item/6530e353c458853aef0d26fd.jpg)

为了解决上述存在的问题，本文提出了一种任务对齐的单阶段目标检测模型**TOOD（Task-aligned One-stage Object Detection）**，通过设计一种新的**head**和**alignment-oriented**学习方法，来更准确地对齐两个任务。
- **Task-aligned head**：与传统的单阶段目标检测模型中分类和定位分别使用两个并行分支的结构不同，本文设计了一个任务对齐的**head**，以增强两个任务之间的交互，从而使它们的预测保持一致。**T-head**包括计算**task-interactive**特征，并通过新提出的**Task-Aligned Predictor（TAP）**进行预测，然后根据**task alignment learning**提供的信息对两个预测的空间分布进行对齐。
- **Task alignment learning**：为了进一步克服**misalignment**问题，作者提出了**Task Alignment Learning（TAL）**来拉近两个任务最优的**anchor**。这是通过设计了一个新的样本分配方法和任务对齐的损失函数来实现的，前者通过计算每个**anchor**的任务对齐程度来分配标签，后者在训练过程中逐步统一最适合两个任务的**anchor**。因此在推理阶段，一个分类得分最高的**anchor**同时也是定位精度最高的。

本文通过新设计的**T-head**和**TAL**来对齐两个子任务，如下图所示，两者可以协同工作以改进两个任务的对齐方式。具体来说，**T-head**首先对**FPN**特征的分类和定位进行预测，然后**TAL**计算一个对齐**metric**，这个指标用来衡量两个任务的对齐程度，最后**T-head**利用在反向传播过程中从**TAL**计算得到的对齐指标自动调整分类概率和定位预测。

![](https://pic.imgdb.cn/item/6530e480c458853aef10a23f.jpg)

## 1. Task-aligned Head

![](https://pic.imgdb.cn/item/6530f0e0c458853aef314f09.jpg)

**T-head**包括一个简单的特征提取器和两个**TAP**。为了增强分类和定位之间的**interaction**，特征提取器使用$N$个连续的卷积层和激活函数来计算**task-interactive**特征，接着这些交互特征被送进两个**TAP**进行分类和定位的对齐。

由于单一分支的设计，任务交互特征不可避免的会在两个不同任务之间引入一定程度的特征冲突，这是因为分类和定位的目标不同，因此专注于不同类型的特征，比如不同的层次和感受野。因此本文提出一种层注意力机制，通过在层级动态计算不同任务特定的特征从而进行任务分解。

在预测阶段，通过调整两个预测的空间分布进一步对齐两个任务。和之前使用**centerness**分支或**IoU**分支的模型不同，它们只能根据分类特征或定位特征对分类得分进行调整；而本文在用任务交互特征对齐两个预测时同时考虑到了两个任务，其中空间概率图$M∈R^{H×W×1}$和空间偏移图$O∈R^{H×W×8}$的学习是通过**Task Alignment Learning（TAL）**进行的。

## 2. Task Alignment Learning

从任务对齐的角度看，**TAL**基于一个单独设计的度量指标动态的挑选高质量的**anchor**。其次，它同时考虑到了**anchor**的分配和权重。具体包括一个样本分配策略和一个专门为调整这两个任务而设计的新的损失函数。

为了应对**NMS**，一个训练示例的样本分配应该满足以下的准则：一个**well-aligned**的**anchor**的分类和定位预测都应该很精确；一个**misaligned**的**anchor**预测的分类得分应该低。本文设计了一个**anchor**对齐度量指标，用来衡量**anchor**的任务对齐程度，并集成到样本分配和损失函数中，以动态的细化每个**anchor**的预测。

分类得分以及预测的**bounding box**和**gt**之间的**IoU**分别表明了两个任务的预测质量，因此作者将两者结合到一起设计了一个新的对齐衡量指标：

$$
t = s^\alpha \times u^\beta
$$

其中$s$和$u$分别表示分类得分和**IoU**，$α$和$β$是权重系数用来控制两个任务对任务对齐衡量指标的影响大小。作者将任务对齐指标引入样本分配汇总，具体来说，对每个目标，选择$t$值最大的$m$个**anchor**作为正样本，其余的作为负样本。

作者用$t$值替换正样本的二分类标签值，但是作者发现当$α$和$β$增大时，$t$变得非常小从而导致网络无法收敛，因此采用了一个**normalized**的$\hat{t}$，$\hat{t}$的最大值等于和每个对象**IoU**的最大值。和分类一样，回归损失里也加入了$\hat{t}$来进行**re-weight**。

下面是一些本文提出的**T-head+TAL**的测试图，以及和**ATSS**的对比，可以看出**T-head+TAL**可以很好的对齐两个预测，最终分类得分最高的预测同时也是**IoU**最大的。

![](https://pic.imgdb.cn/item/6530f42ac458853aef396c65.jpg)