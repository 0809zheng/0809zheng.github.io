---
layout: post
title: 'CompConv: A Compact Convolution Module for Efficient Feature Learning'
date: 2021-08-03
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/610919415132923bf824e745.png'
tags: 论文阅读
---

> CompConv：使用分治法的紧凑卷积模块.

- paper：CompConv: A Compact Convolution Module for Efficient Feature Learning
- arXiv：[link](https://arxiv.org/abs/2106.10486)


![](https://pic.imgdb.cn/item/610919e35132923bf8264a65.jpg)

卷积层可以看成是一种将特征从一个空间(输入特征空间)映射到另一个空间(输出特征空间)的操作。卷积神经网络计算成本较高，因此本文提出了一种紧凑的卷积模块**CompConv**，通过分治法降低计算复杂度，并引入恒等映射保证足够的输出通道数。

![](https://pic.imgdb.cn/item/610919d05132923bf8261f46.jpg)

**CompConv**采用的分治策略如上图所示。若要计算输出特征$X$，可以将其拆分成两部分。一部分是输入特征的恒等映射$X_A$，另一部分通过卷积运算获得中间特征$X_B$，引入特征变换矩阵$W$后将两个特征沿通道轴拼接得到最终的输出特征：

$$ X=X_A \oplus WX_B $$

进一步，对于卷积特征$X_B$，可以递归地进行计算：

$$ X_{B_i} = X_{A_{i+1}} \oplus W_{i+1}X_{B_{i+1}} $$

若进行$d$次递归，则可构造特征$$\{X_{A_{d-1}},X_{B_{d-1}},...,X_{A_{0}},X_{B_{0}}\}$$，其中$X_{A_{0}}$不是直接从输入空间获得的，而是从$X_{B_{0}}$转换得到的。这样做的原因是：
1. $X_{A_{0}}$具有较大的通道数，如果直接使用输入特征会引入较多的特征冗余；
2. 从$X_{B_{0}}$计算得到$X_{A_{0}}$既能保证获得足够多的输入特征信息，又具有较低的计算成本。

分治策略中的递归深度$d$和特征通道最小分割数$C_{prim}$影响着**CompConv**的计算效率和特征表示能力；如上图中$d=3,$$C_{prim}=2$。一般地，输出特征通道数$C_{out}$可以计算为：

$$ C_{out} = \sum_{i=1}^{d}2^iC_{prim} $$

因此可得：

$$ C_{prim} = \lceil \frac{C_{out}}{2\times(2^d-1)} \rceil $$

由上式可知特征通道最小分割数$C_{prim}$依赖于递归深度$d$，因此**CompConv**中的超参数主要是递归深度$d$。$d$越大表示压缩率越高，$d=0$表示没有压缩。作者提出了一种自适应的递归深度选择策略：

$$ d=\max (log_2(max(1,\frac{C_{in}}{C_0}))+1,3) $$

其中超参数$C_0$由模型大小和目标压缩率决定，用于平衡模型压缩率和学习能力。$C_0$越大，$d$越小，压缩率越小。递归深度$d$与输入特征通道数$C_{in}$有关，即对于网络每一层会自适应地选择合适的递归深度。对于常用的网络如**VGG,ResNet**，推荐$C_0=128$，对应的结构称为**CompConv128**。

假设输入特征和输出特征的空间尺寸都是$H\times W$，则普通卷积的计算复杂度是：

$$ \mathcal{O}_{Conv}=H\times W \times k^2 \times C_{in} \times C_{out} $$

而**CompConv**的计算复杂度是：

$$ \mathcal{O}_{CompConv}=H\times W \times k^2 \times (C_{in} \times C_{prim}+\sum_{i=1}^{d-1}(2^iC_{prim})^2+2^{d-1}C_{prim}) $$

作者使用**CompConv128**替换**ResNet**中的普通卷积层，得到实验结果如下：

![](https://pic.imgdb.cn/item/610919b45132923bf825de44.jpg)


![](https://pic.imgdb.cn/item/6109198d5132923bf825894e.jpg)