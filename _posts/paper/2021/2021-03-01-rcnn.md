---
layout: post
title: 'Rich feature hierarchies for accurate object detection and semantic segmentation'
date: 2021-03-01
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/642fdbd3a682492fcc6f496a.jpg'
tags: 论文阅读
---

> R-CNN：丰富的特征层次结构可实现精确目标检测和语义分割.

- paper：[Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524)

**R-CNN (Region-based Convolutional Neural Network)**是深度学习应用于目标检测领域最早的模型之一。该网络首先使用传统的区域[**选择搜索(Selective Search)**算法](https://0809zheng.github.io/2020/05/08/object-detection.html#-%E9%80%89%E6%8B%A9%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95-selective-search)在图像中提取大约$2000$个**候选区域(Region Proposal)**；然后对每一个候选区域通过各向异性的放缩变换到预定的尺寸，再通过卷积网络提取特征映射，之后使用支持向量机进行二分类获得每一个类别的可能性。为进一步提高精度，训练一个线性模型对目标框矩形位置进行微调，减小标注框与预测框的中心位置偏移和长宽尺寸比例。

![](https://pic.imgdb.cn/item/648678031ddac507ccd6f5f5.jpg)

**R-CNN**模型的工作流程如下：
1. 在通用的图像分类任务（如$1000$类的**ImageNet**）上预训练一个卷积神经网络（如**AlexNet, VGGNet, ResNet**）；
2. 通过选择搜索算法提取感兴趣区域(**region of interest, RoI**)，对每张图像提取约$2k$个区域，这些区域具有不同的尺寸，可能包含不同的目标；
3. 把区域尺寸调整(**warp**)到卷积神经网络的指定输入尺寸；
4. 在调整后的区域上微调$K+1$类别分类的分类网络，$K$是下游任务的类别数，并额外增加一个背景类。微调阶段应使用更小的学习率和正类别过采样，因为大部分区域都是背景；
5. 对于每个区域，使用训练后的卷积网络提取特征向量，并通过每个类别的二元支持向量机进行分类。把**IoU**大于阈值($0.3$)的区域视为正样本，其余区域视为负样本；
6. 为了减少定位误差，训练一个回归模型使用卷积网络的特征向量预测检测框的位置偏移。

**R-CNN**的速度瓶颈：
- 对每个图像都需要通过选择搜索算法提取约$2k$个区域；
- 对每个图像区域都需要通过卷积网络的前向计算提取特征向量；
- 整个过程包括三个独立的步骤，没有共享计算：卷积网络的图像分类和特征提取；支持向量机的目标识别；回归模型的边界框位置修正。

## ⚪ 边界框回归 Bounding Box Regression

给定预测边界框坐标$p=(p_x,p_y,p_w,p_h)$及其标签$g=(g_x,g_y,g_w,g_h)$，分别代表边界框的中心位置及其宽度和高度。回归器$d(\cdot)$学习中心位置的尺度不变变换以及宽度和高度的对数尺度变换：

$$
\begin{aligned}
\hat{g}_x &= p_wd_x(p) + p_x \\
\hat{g}_y &= p_hd_y(p) + p_y \\
\hat{g}_w &= p_w \exp(d_w(p)) \\
\hat{g}_h &= p_h \exp(d_h(p))
\end{aligned}
$$

![](https://pic.imgdb.cn/item/64867ddd1ddac507ccde920e.jpg)

通过采用上述变换，回归器的输出$$d_i(p),i\in \{x,y,w,h\}$$取值范围为$(-\infty,+\infty)$。回归器学习的目标为：

$$
\begin{aligned}
t_x &= (g_x-p_x)/p_w \\
t_y &= (g_y-p_y)/p_h \\
t_w &= \log (g_w/p_w) \\
t_h &= \log (g_h/p_h) \\
\end{aligned}
$$

回归器的损失函数设置为带正则化项的**L2**损失：

$$
\mathcal{L}_{reg} = \sum_{i \in \{x,y,w,h\}} (t_i-d_i(p))^2 + \lambda w_{reg}
$$

注意到并不是所有预测边界框都具有对应的标签。如果两个边界框没有重叠，则进行边界框回归是没有意义的。因此只对**IoU**超过$0.6$的预测边界框执行边界框回归。

## ⚪ 通用技巧

### （1）非极大值抑制 Non-Maximum Suppression

目标检测模型倾向于对同一个目标生成大量重复检测框，可以通过非极大值抑制避免对同一个目标的重复检测。模型获得同一个目标类的所有检测框后，按照检测置信度对边界框进行降序排序，丢弃置信度很低的检测框，并对其余检测框重复执行贪心选择：每次选择置信度最大的一个边界框，然后丢弃所有与其**IoU**超过指定阈值($0.5$)的检测框。

![](https://pic.imgdb.cn/item/6486807d1ddac507cce2cabf.jpg)

### （2）负难例挖掘 Hard Negative Mining

把没有目标的预测边界框视为负样本（即假阳性样本）。通常在目标检测中会生成大量负样本，每个负样本的识别难度不同。比如一个样本中只包含纯背景，则该样本被视为简单的负样本(**easy negative**)；如果样本中包含带噪声的纹理或部分目标，则较难识别，被视为负难例(**hard negative**)，负难例容易被误分类为正样本。可以在训练过程中主动找到这些负难例样本，并将它们包含在训练数据中，以改进分类器。
