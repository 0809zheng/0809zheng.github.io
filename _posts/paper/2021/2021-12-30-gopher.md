---
layout: post
title: 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher'
date: 2021-12-30
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67f733aa88c538a9b5c830c4.png'
tags: 论文阅读
---

> 扩展语言模型：训练 Gopher 的方法、分析和见解.

- paper：[Scaling Language Models: Methods, Analysis & Insights from Training Gopher](https://arxiv.org/abs/2112.11446)


# 0. TL; DR

本文介绍了 **DeepMind** 开发的 **Gopher**，这是一个拥有 **2800** 亿参数的 **Transformer** 解码器架构语言模型。**Gopher** 在多个任务上取得了显著的性能提升，尤其是在阅读理解、事实核查和常识理解等领域。研究还探讨了模型规模对性能的影响，发现规模越大，模型在某些任务上的表现越好，但在逻辑和数学推理任务上提升有限。此外，**Gopher** 在生成有毒内容和性别偏见方面表现出了一定的倾向，但同时也展示了更强的毒性检测能力。研究还讨论了如何通过对话提示和微调来优化模型在对话场景中的表现。

# 1. 背景介绍

自然语言处理（**NLP**）是人工智能的一个重要分支，它使计算机能够理解和生成人类语言。近年来，随着深度学习技术的发展，尤其是 **Transformer** 架构的出现，**NLP** 领域取得了巨大的进展。**Transformer** 架构通过自注意力机制，能够处理长距离的依赖关系，从而在语言建模、机器翻译、问答系统等任务上取得了显著的成果。

随着模型规模的不断扩大，语言模型的性能也在不断提升。例如，**OpenAI** 的 **GPT-3** 拥有 **1750** 亿参数，展示了强大的语言生成能力。然而，更大的模型是否总是更好的？它们在不同任务上的表现如何？是否存在一些任务对模型规模不敏感？这些问题促使 **DeepMind** 开发了 **Gopher**，一个 **2800** 亿参数的语言模型，以探索大规模语言模型的性能边界。

本文的主要目标是：
- 探讨模型规模对语言模型性能的影响。
- 在多种任务上评估 **Gopher** 的性能，包括语言建模、阅读理解、常识理解、事实核查等。
- 分析 **Gopher** 在生成有毒内容和偏见方面的表现，并探讨如何缓解这些问题。
- 研究 **Gopher** 在对话场景中的表现，并探索对话提示和微调的效果。

# 2. Gopher 模型

**Gopher** 基于 **Transformer** 解码架构，采用了相对位置编码和 **RMSNorm**。模型的主要参数如下表所示：

![](https://pic1.imgdb.cn/item/67f734a088c538a9b5c831a5.png)

**Gopher** 在 **3000** 亿个标记上进行了训练，使用了 **Adam** 优化器和余弦退火学习率调度。训练数据来自 **MassiveText**，这是一个包含多种数据源的大型文本数据集，包括网页、书籍、新闻文章和代码。**MassiveText** 的数据经过了严格的预处理，包括内容过滤、文本提取、质量过滤、重复内容移除和文档去重。

**MassiveText** 数据集的构建过程如下：
1. 内容过滤：移除非英语文档和显式内容。
2. 文本提取：从网页中提取纯文本，保留格式化信息。
3. 质量过滤：移除低质量文档，如自动生成的内容、重复内容等。
4. 重复内容移除：使用 **MinHash** 算法检测和移除近似重复的文档。
5. 测试集过滤：移除与测试集高度相似的训练文档，以避免数据泄露。

![](https://pic1.imgdb.cn/item/67f734e188c538a9b5c831d9.png)

# 3. 实验分析

**Gopher** 在多个语言建模任务上进行了评估，结果显示，**Gopher** 在大多数任务上都取得了优于现有语言模型的性能。在阅读理解任务中，**Gopher** 也取得了显著的性能提升。**Gopher** 在多个常识理解任务上的表现优于 **GPT-3**，但与人类水平仍有较大差距。在事实核查任务中，**Gopher** 的准确率优于 **GPT-3**。


![](https://pic1.imgdb.cn/item/67f734fb88c538a9b5c831e7.png)
![](https://pic1.imgdb.cn/item/67f7353b88c538a9b5c8321d.png)

研究还探讨了模型规模对性能的影响。结果显示，模型规模越大，其在大多数任务上的表现越好。然而，在逻辑和数学推理任务上，模型规模的提升对性能的贡献有限。这表明，某些任务可能需要更复杂的推理能力，而不仅仅是模型规模的增加。

![](https://pic1.imgdb.cn/item/67f7365788c538a9b5c8332a.png)

**Gopher** 在生成有毒内容和毒性分类方面进行了评估。结果显示，**Gopher** 在生成有毒内容时，其毒性水平与提示的毒性水平相关。此外，**Gopher** 在毒性分类任务上也表现出色，准确率达到了 **76.0%**。

![](https://pic1.imgdb.cn/item/67f736a588c538a9b5c8334f.png)