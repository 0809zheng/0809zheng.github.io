---
layout: post
title: 'Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection'
date: 2021-05-26
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/65337db5c458853aef80fa00.jpg'
tags: 论文阅读
---

> Generalized Focal Loss V2：学习密集目标检测中可靠的定位质量估计.

- paper：[Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection](https://arxiv.org/abs/2011.12885)

[<font color=blue>Generalized Focal Loss (GFL)</font>](https://0809zheng.github.io/2021/05/21/gfl.html)提出了对边界框进行一般化的分布表示建模。对于非常清晰明确的目标边界，学习到的分布都很尖锐；而模糊定义不清的边界（如背包的上沿和伞的下沿）它们学习到的分布基本上会平下来，而且有的时候还经常出现双峰的情况。

![](https://pic.imgdb.cn/item/6533819cc458853aef8e737b.jpg)

既然分布的形状和真实的定位质量非常相关，可以用能够表达分布形状的统计量去指导最终定位质量的估计。对**GFLV1**做一些统计分析，具体把预测框的分布的**top-1**值和其真实的**IoU**定位质量做了一个散点图：

![](https://pic.imgdb.cn/item/65338225c458853aef905993.jpg)

可以看出整个散点图有一个明显地倾向于$y=x$的趋势的，也就是说，在统计意义上，观察得出的“分布的形状与真实的定位质量具有较强的相关性”这个假设是基本成立的。基于这个分析，可以采用学习到的分布的形状来帮助（协助指导）定位质量估计，从而提升检测的整体性能。

本文采用了一个非常简单的做法来刻画分布的形状，即直接取学习到的分布（分布是用离散化的多个和为$1$的回归数值表示的）的**Topk**数值。因为所有数值和为**1**，如果分布非常尖锐的话，**Topk**这几个数通常就会很大；反之**Topk**就会比较小。选择**Topk**还有一个重要的原因就是它可以使得特征与对象的**scale**尽可能无关。

![](https://pic.imgdb.cn/item/653382dfc458853aef92cefc.jpg)

**Distribution-Guided Quality Predictor**部分把**4**条边的分布的**Topk concat**在一起形成一个维度非常低的输入特征向量，用这个向量再接一个非常小的全连接层（通常维度为$32$、$64$），最后再变成一个**Sigmoid**之后的**scalar**乘到原来的分类表征中。

![](https://pic.imgdb.cn/item/6533834dc458853aef943e01.jpg)

得益于输入（分布的统计量）和输出（定位质量）是非常相关的，所以网络设计也只需要非常的轻量就能够达到很不错的效果。这个模块的引入并不会对训练和测试带来额外的负担，几乎保持了网络训练和测试的效率，同时还能提**1~2**个**AP**点。

![](https://pic.imgdb.cn/item/653383e8c458853aef963d95.jpg)

可视化**GFLV2**是如何利用好更好的定位质量估计来保障更精准的结果的（给出了**NMS**前后的所有框，并列出了**NMS score**排前**4**的框和它们的分数）。结果表明，其他算法里面也有非常准的预测框，但是它们的**score**通常都排到了第**3**第**4**的位置，而**score**排第一的框质量都比较欠佳。相反，**GFLV2**也有预测不太好的框，但是质量较高的框都排的非常靠前。

![](https://pic.imgdb.cn/item/6533858bc458853aef9ba656.jpg)