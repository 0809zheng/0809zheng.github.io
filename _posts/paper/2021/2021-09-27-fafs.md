---
layout: post
title: 'Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification'
date: 2021-09-27
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/62dd32e0f54cd3f937323195.jpg'
tags: 论文阅读
---

> 多任务网络中的全自适应特征共享及其在目标属性分类中的应用.

- paper：[Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification](https://arxiv.org/abs/1611.05377)


# 1. 初始模型

初始模型使用**VGG-16**网络，对其网络宽度（每层特征通道数）进行缩小，称之为**thin-**$w$模型。**thin-**$w$模型中卷积层的通道数设置为$w$与原通道数之间的最小值，全连接层的宽度设置为$2w$。下图展示了一个$w=32$的模型。

![](https://pic.imgdb.cn/item/62e0f0abf54cd3f93781d234.jpg)

使用预训练模型的权重可以加快训练速度并提高模型泛化能力。由于**thin-**$w$模型相比于原模型权重数量更小，因此作者设计了一种权重提取的初始化方法。记$W^{p,l}$为预训练模型第$l$层的参数，其卷积核数量是$d$；对于**thin-**$w$模型，其第$l$层的参数$W^{p,l}_{w:}$为从预训练参数$W^{p,l}$中挑选出的$d'=\|w\|$个卷积核。希望选定的参数能够最小化以下目标：

$$ A^*, w^* (l) = \mathop{\arg \max}_{A \in \Bbb{R}^{d \times d'},|w| = d'} ||W^{p,l} - AW^{p,l}_{w:}||_F $$

上述问题是一个**NP-hard**问题，作者使用贪心的联立正交匹配追逐(**simultaneous orthogonal matching pursuit, SOMP**)算法计算近似解：

![](https://pic.imgdb.cn/item/62e0f463f54cd3f93796ce33.jpg)

# 2. 自上而下的层级模型加宽

训练算法的核心是以分层的方式逐步扩大当前结构。网络中的连接点是将网络拆分为若干个独立子网络(分支)的点；每个分支执行一个预测任务的子集。模型加宽只在分支点处进行。考虑第$k$层将输入$x^l$预测为$d$个输出$$\{y_i^l\}_{i=1}^d$$，每个输出都是$d$个子网络之一的输入，对每个子层内执行：

$$ y^l = \sigma_l(\mathcal{P}(W_i^l)x^l), \text{  for }i \in [d] $$

为了将第$l$层加宽$c$倍，对第$l-1$层构造$c$个输出：

$$ y^{l-1} = \sigma_{l-1}(\mathcal{P}(W_j^{l-1})x^{l-1}), \text{  for }j \in [c] $$

初始多任务网络的输出层具有$T$个输出结点，每个输出结点用于一个任务预测。加宽操作从输出层$l$开始，将$T$个结点聚类为$t$组，从而在$l-1$层构造了$t$个分支。该操作以自上而下的方式向下层递归执行。输出层的任务和分支之间存在一一对应关系，在较低的层将会有任务共享分支。

![](https://pic.imgdb.cn/item/62e0fbe4f54cd3f937c0e54b.jpg)

# 3. 基于并发难易样本概率的任务分组

作者观察到，一个任务的简单样本通常是另一个任务的困难样本，因此将一对任务之间的亲和力定义为从训练数据的随机样本中同时观察基本任务对的简单或困难样本的概率。将任务$i$的困难样本的指标变量定义为$e_i^n=1_{m_i^n \geq\Bbb{E}[m_i]}$，则任务$i,j$之间的亲和力$A(i,j)$定义为：

$$ \begin{aligned} A(i,j) &= \Bbb{P} (e_i^n=1,e_j^n=1)+\Bbb{P} (e_i^n=0,e_j^n=0) \\ &= \Bbb{E}[e_i^ne_j^n+(1-e_i^n)(1-e_j^n)] \end{aligned} $$

为了减少计算量，通过计算批内样本平均值的指数加权平均值来估计上述期望值。通过该亲和度估计的任务相关性可以直接用于输出层的聚类。

在较低层中，由于映射是多对一的，因此一个分支可能与多个任务相关联，所以需要计算任务组之间的相关性。

记$k,l$是当前层的两个分支，$i_k,j_l$是每个分支相关联的第$i,j$个任务。这两个分支的亲和力定义为：

$$ \tilde{A}_b(k,l) = \mathop{\text{mean}}_{i_k} (\mathop{\min}_{j_l} A(i_k,j_l)) \\ \tilde{A}_b(l,k) = \mathop{\text{mean}}_{j_l} (\mathop{\min}_{i_k} A(i_k,j_l)) \\ A_b(k,l) = \frac{\tilde{A}_b(k,l) + \tilde{A}_b(l,k)}{2}  $$

# 4. 复杂度感知的宽度选择

创建的分支数决定了加宽操作后网络的宽度。若上一层具有$c$个分支，通过谱聚类构造分组函数$g_d:[d]\to [c]$将新创建的分支与旧分支相关联，并通过以下损失函数平衡复杂度与任务分离程度：

$$ L^l(g_d) = (d-1)L_02^{p_l}+\alpha L_s(g_d) $$

上式中前一项是创建分支的惩罚项，后一项是任务分离的惩罚项。$p_l$是第$l$层中包含池化层的数量，$L_0$是创建分支的单位成本。第一项随分支数量线性增大。

分离项的惩罚则是通过分支亲和力矩阵$A_b$定义的：

$$ \begin{aligned} L^i_s(g_d) &= 1 - \mathop{\text{mean}}_{k \in g^{-1}(i)} (\mathop{\min}_{l \in g^{-1}(i)} A_b(k,l)) \\ L_s(g_d) &= \frac{1}{d} \sum_{i \in [d]} L^i_s(g_d) \end{aligned} $$

# 5. 实验分析

作者给出了在**CelebA**人脸属性分类和**DeepFashion**衣物属性分类任务上的模型表现：

![](https://pic.imgdb.cn/item/62e106cbf54cd3f937fa171f.jpg)

![](https://pic.imgdb.cn/item/62e106daf54cd3f937fa5d04.jpg)

作者对**Branch-32-2.0**模型最后两层的实际任务归类情况进行可视化：

![](https://pic.imgdb.cn/item/62e1070cf54cd3f937fb52ee.jpg)