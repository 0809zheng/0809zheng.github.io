---
layout: post
title: 'Removing the Bias of Integral Pose Regression'
date: 2021-05-02
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/64d19cdf1ddac507cced5673.jpg'
tags: 论文阅读
---

> 移除积分姿态回归中的偏差.

- paper：[Removing the Bias of Integral Pose Regression](https://openaccess.thecvf.com/content/ICCV2021/papers/Gu_Removing_the_Bias_of_Integral_Pose_Regression_ICCV_2021_paper.pdf)

[<font color=blue>Integral Pose Regression</font>](https://0809zheng.github.io/2021/04/25/softargmax.html)(**IPR**)方法是对特征图进行归一化后求期望来获得坐标值的方法，是对**Heatmap-based**方法后处理时**Argmax**不可导问题的一个解决方案，将**Argmax**软化为可微分的**Soft-Argmax**，进而实现了端到端训练，使得坐标值可以直接监督网络训练。

**Heatmap-based**方法是一种检测任务：网络输出的是二维平面上的概率分布，在标准的做法里，这个概率分布图的解码方式是通过**Argmax**操作来进行的：

$$
\boldsymbol{J}_k = \arg \max_{\boldsymbol{p}} \boldsymbol{H}_k(\boldsymbol{p})
$$

由于**Argmax**操作不可导，使得训练无法端到端进行，网络的输出还需要进行后处理。**IPR**通过**Soft-Argmax**替换了**Argmax**，通常会对网络输出的**Heatmap**经过一次**Softmax**归一化，然后计算期望：

$$
\boldsymbol{J}_k = \int_{\boldsymbol{p} \in \Omega} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}_k(\boldsymbol{p}) = \int_{\boldsymbol{p} \in \Omega} \boldsymbol{p} \cdot \frac{e^{\boldsymbol{H}_k(\boldsymbol{p})}}{\int_{\boldsymbol{q} \in \Omega}e^{\boldsymbol{H}_k(\boldsymbol{q})}}
$$

**Softmax**后计算期望能够得到一个非常近似**Argmax**的值，由于期望并不一定是整数，**Soft-Argmax**甚至能避开**Argmax**方法由于输出特征图尺寸过小带来的量化误差影响。然而一旦输出分辨率够高，**Soft-Argmax**性能就远远不如**Argmax**了。

本文作者指出，**Softmax**的一个性质是倾向于让每一项的值都**非零**。对于一个非常尖锐的分布（比如**one-hot**），**Softmax**会将其软化，变成一个渐变的分布，原本取值为**0**的项会被赋上一个非零的值。当计算概率分布的期望时，这些原本为**0**、现在非零的项，也会参与期望值的计算。这会导致最后计算得到的期望值会不准确。只有响应值足够大，分布足够尖锐的时候，期望值才接近**Argmax**结果，一旦响应值小，分布平缓，期望值会趋近于中心位置。

为解决上述问题，可以在**Softmax**的计算中引入一个温度参数$\beta$控制**Softmax**输出的分布的尖锐与否，只要$\beta$足够大，能够让期望估计值重新回到准确。

$$
\boldsymbol{J}_k = \int_{\boldsymbol{p} \in \Omega} \boldsymbol{p} \cdot \frac{e^{\beta \boldsymbol{H}_k(\boldsymbol{p})}}{\int_{\boldsymbol{q} \in \Omega}e^{\beta \boldsymbol{H}_k(\boldsymbol{q})}}
$$

![](https://pic.imgdb.cn/item/64d1a1c21ddac507ccf72e15.jpg)

然而随着$\beta$取值越来越大，当趋近无穷大时，**Softmax**就会收敛到**Argmax**形式，函数就变成不可导了。并且随着它增大，远离中心点的像素上的梯度也会变小，直到消失。 因此在实际应用中，需要精心挑选最优的参数值。

既然**Soft-Argmax**方法不准是因为响应值不够大时，期望值趋近于中央；则可以预先计算出非目标区域的期望值，并在总期望值中将其减去，以进行偏差修正。

假设响应值是符合高斯分布的，不失一般性地假设响应点位于图像左上方，把特征图划分成四个区域：

![](https://pic.imgdb.cn/item/64d1a3731ddac507ccfb3e92.jpg)

对于$\Omega_1$区域，由于响应值正处于区域的中央，因此不论响应值大小，该区域的估计期望值都会是准确的。假设$\Omega_2,\Omega_3,\Omega_4$区域的响应值都为$0$。记整个区域的归一化因子为：

$$
C = \sum_{\boldsymbol{p} \in \Omega} e^{\beta \boldsymbol{H}(\boldsymbol{p})}
$$

划分区域后的**Softmax**结果可以表示成：

$$
\tilde{\boldsymbol{H}}(\boldsymbol{p}) = \begin{cases}
\frac{1}{C}e^{\beta\boldsymbol{H}(\boldsymbol{p})}, & \boldsymbol{p} \in \Omega_1 \\
\frac{1}{C}, & \boldsymbol{p} \in \{\Omega_2,\Omega_3,\Omega_4\} \\
\end{cases}
$$

按照**Soft-Argmax**的计算公式带入，期望值的计算可以表示为：

$$
\boldsymbol{J} = \int_{\boldsymbol{p} \in \Omega} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}(\boldsymbol{p}) = \sum_{\boldsymbol{p} \in \Omega_1} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}(\boldsymbol{p}) + \sum_{\boldsymbol{p} \in \{\Omega_2,\Omega_3,\Omega_4\}} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}(\boldsymbol{p}) \\
= \sum_{\boldsymbol{p} \in \Omega_1} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}(\boldsymbol{p}) + \frac{1}{C}\sum_{\boldsymbol{p} \in \{\Omega_2,\Omega_3,\Omega_4\}} \boldsymbol{p} 
$$

注意到$$\int_a^bxdx = \frac{(a+b)}{2}\cdot(b-a)$$，因此$$\sum_{\boldsymbol{p} \in \Omega_2} \boldsymbol{p}$$的计算结果为该区域的中心点坐标乘以该区域的面积。假设$\Omega_1$区域中心点坐标为$(x_0,y_0)$，那么剩下三个区域中心点坐标为$(x_0,y_0+w/2),(x_0+h/2,y_0),(x_0+h/2,y_0+w/2)$。因此有：

$$
\begin{aligned}
\frac{1}{C}\sum_{\boldsymbol{p} \in \Omega_2} \boldsymbol{p} &=\frac{2x_0(w-2y_0)}{C} \begin{bmatrix} x_0 \\ y_0+\frac{w}{2} \end{bmatrix} \\
\frac{1}{C}\sum_{\boldsymbol{p} \in \Omega_3} \boldsymbol{p} &=\frac{2(h-2x_0)y_0}{C} \begin{bmatrix} x_0+\frac{h}{2} \\ y_0 \end{bmatrix} \\
\frac{1}{C}\sum_{\boldsymbol{p} \in \Omega_4} \boldsymbol{p} &=\frac{(h-2x_0)(w-2y_0)}{C} \begin{bmatrix} x_0+\frac{h}{2} \\ y_0+\frac{w}{2} \end{bmatrix} \\
\end{aligned}
$$

注意到$\Omega_1$区域是关于中心点$(x_0,y_0)$中心对称的，因此有：

$$
\sum_{\boldsymbol{p} \in \Omega_1} \boldsymbol{p} \cdot \tilde{\boldsymbol{H}}(\boldsymbol{p}) = \sum_{\boldsymbol{p} \in \Omega_1} \tilde{\boldsymbol{H}}(\boldsymbol{p}) \begin{bmatrix} x_0 \\ y_0 \end{bmatrix}
$$

注意到$$\sum_{\boldsymbol{p} \in \Omega} \tilde{\boldsymbol{H}}(\boldsymbol{p})=1$$，因此有：

$$
\begin{aligned}
\sum_{\boldsymbol{p} \in \Omega_1}\tilde{\boldsymbol{H}}(\boldsymbol{p}) &= \sum_{\boldsymbol{p} \in \Omega} \tilde{\boldsymbol{H}}(\boldsymbol{p}) - \sum_{\boldsymbol{p} \in \{\Omega_2,\Omega_3,\Omega_4\}} \tilde{\boldsymbol{H}}(\boldsymbol{p}) \\
&= 1-\sum_{\boldsymbol{p} \in \{\Omega_2,\Omega_3,\Omega_4\}} \frac{1}{C} \\
&= 1-\frac{2x_0(w-2y_0)}{C}-\frac{2(h-2x_0)y_0}{C} -\frac{(h-2x_0)(w-2y_0)}{C}
\end{aligned}
$$

综合上式可得：

$$
\begin{aligned}
\boldsymbol{J} &= \begin{bmatrix} x_J \\ y_J \end{bmatrix} = \begin{bmatrix} x_0 + \frac{2(h-2x_0)y_0}{C}\frac{h}{2}+\frac{(h-2x_0)(w-2y_0)}{C}\frac{h}{2} \\ y_0 + \frac{2(h-2x_0)y_0}{C}\frac{w}{2}+\frac{(h-2x_0)(w-2y_0)}{C}\frac{w}{2} \end{bmatrix}
=\begin{bmatrix} x_0 - \frac{hw}{C}x_0 + \frac{hw}{C}\frac{h}{2} \\ y_0 - \frac{hw}{C}y_0 + \frac{hw}{C}\frac{w}{2}\end{bmatrix}
\end{aligned}
$$

对上式变形可得：

$$
\begin{aligned}
\begin{bmatrix} x_0  \\ y_0  \end{bmatrix}= \begin{bmatrix} \frac{C}{C-hw}x_J-\frac{h^2w}{2(C-hw)} \\ \frac{C}{C-hw}y_J-\frac{hw^2}{2(C-hw)} \end{bmatrix}
\end{aligned}
$$

其中$(x_J,y_J)$值可以很容易通过对整张图计算**Soft-Argmax**得到，这一步相当于将原本多余的长尾从期望值中减去，能得到准确的第一区域中心点坐标$(x_0,y_0)$。当$C$足够大（等价于$\beta$设置得足够大）时，$(x_J,y_J)$和$(x_0,y_0)$趋于相等。

实际实现如下：

```python
def soft_argmax(features, debias=True):
    B, N, H, W = features.shape

    features = features.reshape(B, N, H*W)
    heatmaps = F.softmax(features, dim=2)
    heatmaps = heatmaps.reshape(B, N, H, W)

    accu_x = heatmaps.sum(dim=2) # [B, N, W]
    accu_y = heatmaps.sum(dim=3) # [B, N, H]

    accu_x = accu_x * torch.arange(1, W+1)[None, None, :]
    accu_y = accu_y * torch.arange(1, H+1)[None, None, :]

    accu_x = accu_x.sum(dim=2, keepdim=True) -1
    accu_y = accu_y.sum(dim=2, keepdim=True) -1

    if debias:
        C = features.exp().sum(dim=2)
        accu_x = C / (C - H*W) * (accu_x - H ** 2 * W / (2 * C))
        accu_y = C / (C - H*W) * (accu_y - H * W ** 2 / (2 * C))

    coord_out = torch.cat((accu_x, accu_y), dim=-1)
    return coord_out
```

本文还对数据集进行了进一步的精细化分，按照关键点个数、遮挡率、输入尺寸等多个角度来评估不同方法的表现。从该实验结果可以得出以下结论：
- **Heatmap-based**方法在输入尺寸大、遮挡少的情况下表现更佳
- **Regression-based**方法在输入尺寸小、遮挡多的情况表现更佳
- 当对象被画面截断时，画面中出现的关键点数少时，**Heatmap-based**方法更有优势

![](https://pic.imgdb.cn/item/64d1b4f91ddac507cc228ed1.jpg)

加入本文提出的修正方法后，在任何情况下模型均能取得更好的表现：

![](https://pic.imgdb.cn/item/64d1b51c1ddac507cc22e3f0.jpg)