---
layout: post
title: 'DeepFace: Closing the Gap to Human-Level Performance in Face Verification'
date: 2020-05-09
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63c4d2dabe43e0d30e4ad207.jpg'
tags: 论文阅读
---

> DeepFace: 实现人类水平的人脸验证与识别.

- paper：[DeepFace: Closing the Gap to Human-Level Performance in Face Verification](https://openaccess.thecvf.com/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf)

**DeepFace**实现了人类水平的深度**人脸识别Face Recognition**方法，其主要步骤：
1. 人脸检测**Face Detect**：从一张图像中检测出人脸；
2. 人脸对齐**Face Align**：对检测到的人脸进行矫正；
3. 人脸表示**Face Represent**：对校正后的人脸提取特征；
4. 人脸分类**Face Classify**：用特征进行识别。

**DeepFace**采用已有的人脸检测方法，在此基础上设计了人脸对齐和表示学习方法；下面分别进行介绍。

# 1. Face Align

![](https://pic.downk.cc/item/5eb133bec2a9a83be5c702e9.jpg)

**DeepFace**提出的**Alignment**方法：

(a) 使用$LBP$ $Histograms$和$SVR$的方法检测出$6$个**初始基准点 initial fiducial points**:两个眼睛中心、鼻尖和嘴的位置；

(b) 拟合一个对基准点的**变换**(缩放$scale$、旋转$rotate$、平移$translate$)对图像进行**裁剪**；

(c) 用$SVR$对裁剪后的图像定位$67$个**基准点**，进行**三角剖分 Delaunay triangulation**，在人脸的轮廓上添加三角形避免**不连续性 discontinuities**；

(d) 用$3D$人脸库**USF Human-ID**构建一个平均$3D$人脸模型，手工标注$67$个**基准点**；

(e) 用**generalized least squares**学习$3D$人脸和$2D$人脸之间的**映射**，并对三角形进行可视化，颜色越深代表越不可见；

(f) 根据学习到的映射把原$2D$图像中的基准点转换成$3D$图像中的基准点；

(g) 得到**端正 frontalized**的人脸图像；

(h) 把最终图像转换成$3D$模型(not used in this paper)。

# 2. Face Represent

**DeepFace**使用卷积神经网络进行人脸表示的特征提取：

![](https://pic.downk.cc/item/5eb13b9bc2a9a83be5cf4f77.jpg)

C1：卷积层，输入通道数$3$，输出通道数$32$，卷积核大小$11×11$；

M2：最大池化层；

C3：卷积层，输入通道数$32$，输出通道数$16$，卷积核大小$9×9$；

L4：局部卷积层，输入通道数$16$，输出通道数$16$，卷积核大小$9×9$；

L5：局部卷积层，输入通道数$16$，输出通道数$16$，卷积核大小$7×7$；

L6：局部卷积层，输入通道数$16$，输出通道数$16$，卷积核大小$5×5$；

F7：全连接层，输出未标准化的4096维人脸特征向量；

F8：全连接层，$Softmax$分类，用来进行$Face$ $recognition$，4300维是数据库中的人数。

- **局部卷积层**：卷积核参数不共享，基于人脸的不同区域会有不同的统计特征假设；局部卷积层会导致更大的参数量，需要更多的数据支持。

如何训练这个网络呢？使用**孪生网络 Siamese Network**。

对于一张人脸的图像$$x^{(1)}$$，使用网络得到一个特征向量$$f(x^{(1)})$$；

对于另一张人脸的图像$$x^{(2)}$$，喂入具有同样参数的网络，得到特征向量$$f(x^{(2)})$$；

![](https://pic.downk.cc/item/5eb15059c2a9a83be5e7a20e.jpg)

训练的目标是，若两张图像是同一个人，则两个特征向量越接近越好；否则差别越大越好；使用一种**相似度度量 metric**衡量这种差异。

**DeepFace**使用**Weighted χ2 distance**。选取两张人脸图像，计算出特征向量之后进行二分类，判断这两个图像是否代表同一个人：

记两张人脸图像$$x^{(i)}$$和$$x^{(j)}$$，得到的特征向量为$$f(x^{(i)})$$和$$f(x^{(j)})$$，特征向量为$k$维，使用$χ^2$**相似度**进行分类：

$$ \hat{y} = σ(W\frac{(f(x^{(i)})-f(x^{(j)}))^2}{f(x^{(i)})+f(x^{(j)})} + b) $$

![](https://pic.downk.cc/item/5eb15453c2a9a83be5ec1087.jpg)


# 3. Face Classify
训练好模型之后，就可以实现人脸验证和识别。

在实际使用中，预先存储已知人脸数据集的人脸对应特征向量；对于一张新的人脸图像，先提取特征再进行比较。