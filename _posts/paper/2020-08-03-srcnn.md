---
layout: post
title: 'Image Super-Resolution Using Deep Convolutional Networks'
date: 2020-08-03
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f44653b160a154a67d2ee79.jpg'
tags: 论文阅读
---

> SRCNN：图像超分辨率的开山之作.

- paper：Image Super-Resolution Using Deep Convolutional Networks
- arXiv：[link](https://arxiv.org/abs/1501.00092)

# 模型介绍
作者先把低分辨率图像**LR**通过非线性变换（如bicubic插值）调整到高分辨率图像**HR**的尺寸，此时仍是较低的分辨率，记为$Y$。

使用一个卷积神经网络，将$Y$映射为超分辨率图像；其结构如下：

![](https://pic.downk.cc/item/5f44679f160a154a67d54f8d.jpg)

作者将卷积网络分成三个部分，分别是：
1. **Patch extraction and representation**：从图像$Y$中抽取patch，每一个卷积核能够将patch表示成一个标量，多个卷积核将patch表示成高维向量；具体地，使用$9×9×64$的卷积核，并设置了same padding。
2. **Non-linear mapping**：将高维特征向量通过非线性映射表示为另一个高维特征向量；具体地，使用$1×1×32$的卷积核。
3. **Reconstruction**：将高维特征向量恢复成超分辨率图像；具体地，使用$5×5×1$的卷积核，并设置了same padding。

作者将卷积神经网络类比为稀疏编码的过程，并用稀疏编码对这一过程进行解释：
1. **Patch extraction and representation**：类似于稀疏编码中的将图像patch映射到低分辨率字典中。
2. **Non-linear mapping**：类似于字典学习中的找到图像patch对应的高分辨率字典。
3. **Reconstruction**：类似于字典学习中的根据高分辨率字典进行图像重建。

![](https://pic.downk.cc/item/5f446af0160a154a67d8a753.jpg)

# 实验分析
作者在实验中把图像转变为$$YCbCr$$格式，在卷积网络中只使用亮度通道($Y$)。网络的输出合并已插值的$CbCr$通道，输出最终彩色图像。作者认为选择这一步骤是因为感兴趣的不是颜色变化(存储在$CbCr$通道中的信息)而只是其亮度($Y$通道);根本原因在于相较于色差，人类视觉对亮度变化更为敏感。

作为对比，作者实验了不同的训练策略，其中pre-train表示先在单通道上预训练，然后在全部通道上微调：

![](https://pic.downk.cc/item/5f4470a7160a154a67de6af2.jpg)

实验设置：
- 训练集：ImageNet
- 测试集：Set5, Set14, BSD200
- 评估指标：PSNR, SSIM
- 训练尺寸：裁剪33×33

在Set5测试集上，SRCNN方法超过了一些传统的超分辨率算法：

![](https://pic.downk.cc/item/5f446fd5160a154a67dd99d7.jpg)

![](https://pic.downk.cc/item/5f447016160a154a67dddd26.jpg)

作者对比了不同模型精度和运行速度的折中：

![](https://pic.downk.cc/item/5f44719e160a154a67df64c0.jpg)

作者展示了学习到的部分卷积滤波器和特征映射：

![](https://pic.downk.cc/item/5f446f7c160a154a67dd3d27.jpg)

![](https://pic.downk.cc/item/5f44714e160a154a67df1872.jpg)
