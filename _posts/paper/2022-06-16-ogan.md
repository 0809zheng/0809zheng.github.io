---
layout: post
title: 'O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks'
date: 2022-06-16
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63a26e99b1fccdcd36074af8.jpg'
tags: 论文阅读
---

> O-GAN：把GAN的判别器修改为编码器.

- paper：[O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks](https://arxiv.org/abs/2106.12423)

在**GAN**的训练中，训练完成后判别器通常是没有用的。因为理论上越训练，判别器越退化（趋于一个常数）。本文作者提出了正交**GAN(Orthogonal GAN, O-GAN)**，通过对判别器的正交分解操作，把判别器变成一个编码器，从而让**GAN**同时具备生成能力和编码能力，并且几乎不会增加训练成本。

一般的**GAN**具有损失函数：

$$ \begin{aligned}  & \mathop{ \max}_{D} \Bbb{E}_{x \text{~} P_{data}(x)}[\log D(x)] + \Bbb{E}_{z \text{~} P_{Z}(z)}[\log(1-D(G(z)))]  \\  &  \mathop{ \max}_{G}  \Bbb{E}_{z \text{~} P_{Z}(z)}[\log D(G(z))] \end{aligned} $$

生成器$G$把输入隐编码$z$转换为生成图像$x$，判别器$D$区分真实图像和生成图像；判别器的结构和编码器类似，只不过编码器输出一个向量而判别器输出一个标量，因此可以把判别器$D$写成复合函数：

$$ D(x) = T(E(x)) $$

其中编码部分$E(\cdot)$把输入图像进行编码，判别部分$T(\cdot)$用于进一步判断图像的真假。判别器的主要参数量位于编码部分，因此能够充分地利用参数，在训练完成后只丢弃参数量少的判别部分$T(\cdot)$。进一步地，判别部分$T(\cdot)$还可以被省略为$T(\cdot) = \text{avg}(\cdot)$：

$$ D(x) = T(E(x)) = \text{avg}(E(x)) $$

**O-GAN**的目标函数为：

$$ \begin{aligned} \mathop{\max}_{E}& \Bbb{E}_{x \text{~} P_{data}(x)}[\log \text{avg}(E(x))] + \Bbb{E}_{z \text{~} P_{Z}(z)}[\log(1-\text{avg}(E(G(z))))] \\ & + \lambda \Bbb{E}_{z \text{~} P_{Z}(z)}[\rho(z,E(G(z)))] \\ \mathop{ \max}_{G}&  \Bbb{E}_{z \text{~} P_{Z}(z)}[\log \text{avg}(E(G(z)))] + \lambda \Bbb{E}_{z \text{~} P_{Z}(z)}[\rho(z,E(G(z)))] \end{aligned} $$

损失函数中额外引入了**Pearson**相关系数：

$$ \rho(z,\hat{z}) = \frac{\sum_i^{n_z}(z_i-\mu(z))(\hat{z}_i-\mu(\hat{z}))/n_z}{\sigma(z)\times\sigma(\hat{z})} = \cos(\frac{z-\mu(z)}{\sigma(z)},\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})}) $$

引入**Pearson**相关系数是为了使得隐编码$z$及其重构编码$\hat{z}=E(G(z))$尽可能相关。不使用**MSE**重构损失$\|\|z-\hat{z}\|\|^2$的原因是，编码部分$E(\cdot)$输出一个$n_z$维向量，具有$n_z$个自由度；后续判别部分$T(\cdot)$至少需要一个自由度进行真假判别(输出一个标量)。**MSE**重构损失会强迫重构编码完全等于输入隐编码，此时$n_z$个自由度全部被占用，没有多余的自由度用于判别真假。而**Pearson**相关系数跟输入向量的均值$\mu$和方差$\sigma^2$无关，至少留出两个自由度进行真假判别。

在训练时隐编码$z$是从标准正态分布$N(0,I)$中采样。训练完成后隐编码$z$~$N(0,I)$对应一张逼真的图像$G(z)$；如果编码部分$E(\cdot)$成功训练，则重构编码$\hat{z}=E(G(z))$也应该近似服从$N(0,I)$。对于**MSE**重构损失，把$z$和$\hat{z}$的均值看作常数，则有：

$$ \begin{aligned} ||z-\hat{z}||_2^2 &\propto ||\frac{z-\mu(z)}{\sigma(z)}-\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})}||_2^2 \\ & = ||\frac{z-\mu(z)}{\sigma(z)}||_2^2+ ||\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})}||_2^2 - 2||\frac{z-\mu(z)}{\sigma(z)}||\cdot ||\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})}|| \cdot \cos(\frac{z-\mu(z)}{\sigma(z)},\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})})\\ & = 2 - 2 \cos(\frac{z-\mu(z)}{\sigma(z)},\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})}) \\ & \propto - \cos(\frac{z-\mu(z)}{\sigma(z)},\frac{\hat{z}-\mu(\hat{z})}{\sigma(\hat{z})} \\ & = -\rho(z,\hat{z}) \end{aligned} $$

因此将损失设置为**Pearson**相关系数等价于已经均值$\mu=0$和方差$\sigma^2=1$的两个向量的**MSE**重构损失。

$\rho(z,E(G(z)))$可以理解为$z$和$G(z)$的互信息下界，最大化**Pearson**相关系数也等价于最大化$z$和$G(z)$的互信息，即最大化$G(z)$的熵，能够增加生成图像的多样性，防止**mode collapse**的出现。