---
layout: post
title: 'Orthogonal-Padé Activation Functions: Trainable Activation functions for smooth and faster convergence in deep networks'
date: 2021-10-25
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6178adf02ab3f51d919a4868.jpg'
tags: 论文阅读
---

> OPAU：基于正交Padé近似的可训练激活函数.

- paper：[Orthogonal-Padé Activation Functions: Trainable Activation functions for smooth and faster convergence in deep networks](https://arxiv.org/abs/2106.09693v1)

作者提出了基于正交**Padé**近似的可训练激活函数，称为正交**Padé**激活单元(**Orthogonal-Padé Activation Unit, OPAU**)，使用给定阶数的有理分式实现对任意函数的通用近似，其分子分母均采用正交多项式基。

# 1. Padé近似

给定任意函数$f(x)$，**Padé**近似是指使用给定阶数的有理分式$F(x)$对其进行近似。给定有理函数分子$P$和分母$Q$的阶$m$和$n$，近似表达式为：

$$ F(x) = \frac{P(x)}{Q(x)} = \frac{\sum_{j=0}^{m}a_jx^j}{1+\sum_{k=1}^{n}b_kx^k} \\ = \frac{a_0+a_1x+a_2x^2+...+a_mx^m}{1+b_1x+b_2x^2+...+b_nx^n} $$

一种安全的**Padé**近似，能够保证分母的值不小于$1$：

$$ F(x) = \frac{P(x)}{Q(x)} = \frac{\sum_{j=0}^{m}a_jx^j}{1+\sum_{k=1}^{n}|b_k||x|^k} \\ = \frac{a_0+a_1x+a_2x^2+...+a_mx^m}{1+|b_1||x|+|b_2||x|^2+...+|b_n||x|^n} $$

# 2. 正交Padé近似

正交**Padé**近似是指在**Padé**近似中使用的有理函数分子$P$和分母$Q$均采用正交多项式$$\{f_1,f_2,...,f_n\}$$：

$$ G(x) = \frac{P(x)}{Q(x)} = \frac{\sum_{i=0}^{k}c_if_i(x)}{1+\sum_{j=1}^{l}d_jf_j(x)} \\ = \frac{c_0+c_1f_1(x)+c_2f_2(x)+...+c_kf_k(x)}{1+d_1f_1(x)+d_2f_2(x)+...+d_lf_l(x)} $$

为了避免函数拟合极值点，采用如下安全的正交**Padé**近似：

$$ G(x) = \frac{P(x)}{Q(x)} = \frac{\sum_{i=0}^{k}c_if_i(x)}{1+\sum_{j=1}^{l}|d_j||f_j(x)|} \\ = \frac{c_0+c_1f_1(x)+c_2f_2(x)+...+c_kf_k(x)}{1+|d_1||f_1(x)|+|d_2||f_2(x)|+...+|d_l||f_l(x)|} $$

考虑六种常用的正交多项式基：

![](https://pic.imgdb.cn/item/6178b4fe2ab3f51d919eeda0.jpg)

使用正交多项式基具有更快的运行时间。实践中使用**Leaky ReLU**初始化正交**Padé**。

# 3. 实验分析
下表展示了在不同数据集上不同激活函数的性能：

![](https://pic.imgdb.cn/item/6178ba3e2ab3f51d91a2fd1e.jpg)