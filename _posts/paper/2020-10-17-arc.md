---
layout: post
title: 'On the Measure of Intelligence'
date: 2020-10-17
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f8a75231cd1bbb86bf6f535.jpg'
tags: 论文阅读
---

> 测试人工智能的抽象推理能力.

- paper：On the Measure of Intelligence
- arXiv：[link](https://arxiv.org/abs/1911.01547)

# 1. Context and history

## 1.1 定义人工智能
“人工智能”尚未获得公认而准确的定义。

### （1）Intelligence as a collection of task-specific skills
一些学者认为人工智能应能解决一系列具体任务。**Marvin Minsky**对其做如下定义：
- AI is the science of making machines capable of performing tasks that would require intelligence if done by humans.
- 如果机器能够完成通常需要人类智能才能完成的任务，则认为其具有智能。

### （2）Intelligence as a general learning ability
另一些学者认为人工智能应具有通用的学习能力。**Hernandez-Orallo**对其做如下定义：
- AI is the science and engineering of making machines do tasks they have never seen and have not been prepared for beforehand.
- 如果机器能够完成之前从未见过或没有准备过的任务，则认为其具有智能。

**Legg**和**Hutter**总结了对人工智能的若干定义，并将其归纳为：
- Intelligence measures an agent’s ability to achieve goals in a wide range of environments.
- 智能衡量了代理在不同环境下实现目标的能力。

## 1.2 评估人工智能
可以从如下角度评估人工智能：
- 狭义地：基于技能（**skill-based**）
- 广义地：通用性（**generalization**）

### （1）Skill-based, narrow AI evaluation
狭义地评估人工智能系统是从实现任务的角度出发，并没有统一的评估标准。目前应用较为成功的一些方法包括：
1. 人类评审：如图灵测试，常用于有人类参与的系统中（如聊天机器人）；
2. 白盒分析：常用于能够给出所有可能的输入情况（如解决“旅行商人问题”的算法）；
3. 同行对抗：常用于系统能够和其他系统或人类比赛的场合（如围棋）；
4. 基准测试：常见于各领域的**benchmarks**。

上述各种评估方式通常过度关注某一具体的任务，并且不关心系统实现的过程，常常导致在某个任务中表现出色的系统在另一个任务中表现较差。

### （2）The spectrum of generalization
广义地评估人工智能系统是从泛化能力的角度出发，具体地有两种泛化类型：
1. 以系统为中心的泛化（**System-centric**）：系统能够处理之前没有见过的情况，如测试集；
2. 关注开发者的泛化（**Developer-aware**）：考虑开发者的先验知识，系统能够处理完全未知的情况。

作者定义了泛化的不同程度：
- **Absence**：系统专门针对某一类问题而设计，不具备泛化能力，如排序问题；
- **Local**：系统能够处理某一任务中已知数据分布的新数据，此时称系统具有**robustness**；
- **Broad**：系统能够处理一系列相关领域的任务，此时称系统具有**flexibility**，如自动驾驶；
- **Extreme**：系统具备能够处理未知领域和任务的能力，即通用人工智能；
- **Universal**：系统能够解决不局限于人类提出的任务（目前认为这个阶段的意义不大）。

![](https://pic.downk.cc/item/5f8a753c1cd1bbb86bf6fa90.jpg)


# 2. A new perspective

## 2.1 考虑人类先验
作者认为在衡量人工智能系统时应考虑人类的先验知识，因为只有**human-centric**才是有意义的。

人类在不断进化中获取的核心先验知识（**Core Knowledge**）包括：
- 物质性和基础物理
- 代理性和目标导向
- 自然计数和基本运算
- 基础的几何和拓扑

作者认为应将上述先验知识通过硬编码提供给人工智能系统，在此基础上测试系统是否具备智能；但测试时不能依赖额外的先验（如人类语言）。

## 2.2 定义智能
基于之前的分析，作者对系统的智能性给出如下定义：
- The intelligence of a system is a measure of its skill-acquisition efficiency over a scope of tasks, with respect to priors, experience, and generalization difficulty.
- 系统的智能性是衡量其在一定范围内的任务中技能获取效率（通过先验、经验和泛化难度）的一种度量。

![](https://pic.downk.cc/item/5f8a95c61cd1bbb86bfe17d0.jpg)

作者引入算法复杂度作为衡量系统智能的工具。记$H(s)$为模型获得结果$s$的复杂度，记$H(s_1 \mid s_2)$为模型在已知结果$s_2$下获得结果$s_1$的相对复杂度。

### （1）Generalization Difficulty
记$GD_{T,C}^{θ}$为在给定任务$T$、总训练集$C$和验证阈值$θ$下的**泛化难度**指标。其计算可表示为：

$$ GD_{T,C}^{θ} = \frac{H(Sol_{T}^{θ} \mid TrainSol_{T,C}^{opt})}{H(Sol_{T}^{θ})} $$

其中$Sol_{T}^{θ}$表示在验证集上得到指标至少为$θ$的结果，$TrainSol_{T,C}^{opt}$表示在训练集$C$上优化得到的结果。

上式理解为在训练集上训练模型泛化到验证集的难度。当训练集结果对验证集泛化没有帮助时，其值为$1$；当训练集结果完全泛化于验证集时，其值为$0$。

引入系统的初始状态$IS_{t=0}$的影响，泛化难度可计算为：

$$ GD_{IS,T,C}^{θ} = \frac{H(Sol_{T}^{θ} \mid TrainSol_{T,C}^{opt},IS_{t=0})}{H(Sol_{T}^{θ})} $$

当系统的初始状态能降低获得满足验证集精度的解的复杂度时，泛化难度会降低。

### （2）Priors
记$P_{IS,T}^{θ}$为在给定任务$T$、系统状态$IS$和验证阈值$θ$下的**先验**指标。其计算可表示为：

$$ P_{IS,T}^{θ} = \frac{H(Sol_{T}^{θ}) - H(Sol_{T}^{θ} \mid IS_{t=0})}{H(Sol_{T}^{θ})} $$

其中$Sol_{T}^{θ}$表示在验证集上得到指标至少为$θ$的结果，$IS_{t=0}$表示系统的初始状态。

上式理解为系统的初始状态能够对系统带来多大的帮助。系统的初始状态即为先验知识，当其对获得目标结果没有帮助时，其值为$0$；当其能完全确定目标结果时，其值为$1$。

### （3）Experience
记$E_{IS,T,t}^{θ}$为在给定任务$T$、某一训练集$t$、系统状态$IS$和验证阈值$θ$下的**经验**指标。其计算可表示为：

$$ E_{IS,T,t}^{θ} = H(Sol_{T}^{θ} \mid IS_{t}) - H(Sol_{T}^{θ} \mid IS_{t}, data_t) $$

其中$Sol_{T}^{θ}$表示在验证集上得到指标至少为$θ$的结果，$IS_{t}$表示在当前训练集下系统的状态。

上式理解为该训练数据集能够给系统带来的帮助。考虑总训练集$C$，可计算平均的**经验**指标：

$$ E_{IS,T,C}^{θ} = \frac{1}{H(Sol_{T}^{θ})} \sum_{t}^{} {E_{IS,T,t}^{θ}} $$

### （4）Defining intelligence
记$I_{IS,scope}^{θ_T}$为在给定系统状态$IS$、任务范围$scope$和每一任务$T$的验证阈值$θ_T$下的系统的智能。其计算可表示为：

$$ I_{IS,scope}^{θ_T} = \mathop{Avg}_{T \in scope} [\omega_T \cdot \theta_T \sum_{C \in Cur_{T}^{θ_T}}^{} {[P_C \cdot \frac{P_{IS,T}^{θ_T} + E_{IS,T,C}^{θ_T}}{GD_{IS,T,C}^{θ_T}}]} ] $$

上式在需要解决的任务范围内取各自结果的平均值，其中$\omega_T \cdot \theta_T$表示每一个任务的指标修正因子，防止不同任务的指标值差距过大。$P_C$表示每一个任务的出现概率。

当系统使用的先验和经验程度越高时，其智能程度越低；当系统解决的问题泛化难度越大时，其智能程度越高。


# 3.  A benchmark proposal: the ARC dataset
作者提出了一个通用的人工智能测试基准：**Abstraction and Reasoning Corpus (ARC)**用于衡量人工智能系统的抽象推理能力。

**ARC**的设计参考了如下顶层设计目标：
- 和人类的智力测试问题类似，对于没有实践或培训过的人类是可解的；
- 更加关注开发者的泛化，评估集对于开发者是未知的；
- 更加关注**broad**的泛化能力，增加任务的多样性；
- 量化控制训练提供的经验，每个任务提供的训练集都很少；
- 显式描述先验，接近人类先天的先验知识。

**ARC**包括一个训练集和一个评估集。训练集包括$200$种不同的任务；评估集包括$600$种不同的任务，其中$200$种任务不对外开放。每个任务平均包括$3.3$个训练样本和大多数为$1$个测试样本。每个样本是由尺寸为$1 \times 1$到$30 \times 30$之间的栅格组成的。栅格的每个位置包括$10$种不同的符号或颜色。

下面是数据集中的一些任务展示：
- 图像色块推理
![](https://pic.downk.cc/item/5f8aaee11cd1bbb86b0665a9.jpg)
- 去噪
![](https://pic.downk.cc/item/5f8aaf0f1cd1bbb86b066f96.jpg)
- 目标移动
![](https://pic.downk.cc/item/5f8aaf231cd1bbb86b0673d3.jpg)
- 光线反射
![](https://pic.downk.cc/item/5f8aaf381cd1bbb86b0679a5.jpg)
- 连线
![](https://pic.downk.cc/item/5f8aaf521cd1bbb86b06800e.jpg)
- 最大频率模式
![](https://pic.downk.cc/item/5f8aaf701cd1bbb86b06863d.jpg)
- 模式对称
![](https://pic.downk.cc/item/5f8aaf9b1cd1bbb86b06902e.jpg)