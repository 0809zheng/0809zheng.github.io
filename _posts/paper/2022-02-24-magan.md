---
layout: post
title: 'MAGAN: Margin Adaptation for Generative Adversarial Networks'
date: 2022-02-24
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/634f99b216f2c2beb12834b3.jpg'
tags: 论文阅读
---

> MAGAN：自适应调整EBGAN的能量边界.

- paper：[MAGAN: Margin Adaptation for Generative Adversarial Networks](https://arxiv.org/abs/1704.03817)

# 1. EBGAN

[<font color=Blue>EBGAN</font>](https://0809zheng.github.io/2022/02/16/ebgan.html)是一种基于能量模型的**GAN**，其生成器为标准的**GAN**生成器，判别器采用自编码器的形式，且能量函数采用样本的重构损失：

$$ U(x) = ||D(x)-x|| = ||Dec(Enc(x))-x|| $$

注意到**EBGAN**的能量函数由均方误差构造，因此能量最小值为$0$。在实践中，通常限制生成样本的能量不超过$m$。则**EBGAN**的目标函数为：


$$ \begin{aligned} D^* &\leftarrow \mathop{ \min}_{D} \Bbb{E}_{x \text{~} P_{data}(x)} [  D(x)]+  \Bbb{E}_{x \text{~} P_G(x)}[\max(0, m-D(x)) ] \\ G^* &\leftarrow \mathop{ \min}_{G} \Bbb{E}_{x \text{~} P_G(x)}[D(x) ] \end{aligned} $$

![](https://pic1.imgdb.cn/item/634f9a6e16f2c2beb1294242.jpg)

上图报告了训练过程中真实图像和生成图像的能量(均方误差)变化情况。真实图像的能量不断减小，但是生成图像的能量几乎不变，且接近预设的$m$值。

本文作者指出，应该随着训练过程自适应地降低$m$值，在保持学习过程的稳定性和收敛性的同时减少生成图像的能量，从而使生成图像更接近真实图像。

# 2. MAGAN

作者设计了**Margin Adaptation**方法，在训练过程中自适应地调整$m$值。

在每轮更新中计算真实样本的总能量和生成样本的总能量：

$$ S_{data}^{t} =\sum_i D(x_i) \\ S_{G}^{t} = \sum_i D(G(z_i)) $$

记总样本数为$N$，当满足以下条件：

$$ S_{data}^{t}/N < m_t \\ S_{data}^{t} < S_{G}^{t} \\ S_{G}^{t} > S_{G}^{t-1} $$

更新$m$值：

$$ m_{t+1} =  S_{data}^{t}/N $$

直观地，只有当生成样本的总能量大于真实样本的总能量，并且生成样本的总能量变大时才会更新$m$值，且$m$值更新为真实样本的平均能量。

至于$m$值的初始值，使用真实样本对判别器(自编码器)进行预训练后，选用真实样本的平均能量。

**MAGAN**的完整训练过程如下：

![](https://pic1.imgdb.cn/item/634f9ec016f2c2beb12f1e51.jpg)

