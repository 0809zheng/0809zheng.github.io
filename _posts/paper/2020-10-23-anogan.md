---
layout: post
title: 'Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery'
date: 2020-10-23
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f92786c1cd1bbb86bef4b85.jpg'
tags: 论文阅读
---

> AnoGAN：使用生成对抗网络进行异常检测.

- paper：Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery
- arXiv：[link](https://arxiv.org/abs/1703.05921)

作者提出了一种使用生成对抗网络（**GANs**）进行图像异常检测的方法。该方法的主要流程如下：

![](https://pic.downk.cc/item/5f9278531cd1bbb86bef45d0.jpg)

首先使用预处理后的正常图像训练一个常规的**GAN**，使其能够从隐空间中采样得到正常图像。

在检测新图像时，先在隐空间中找到与该新图像匹配度最高的隐变量，将其通过**GAN**的生成器获得生成图像，通过对比新图像与其对应的生成图像之间的差异判断其是否为异常图像。

## 通过GAN表示正常图像
作者使用**DCGAN**作为正常图像的生成模型，学习从隐空间到真实图像的映射。

![](https://pic.downk.cc/item/5f927a551cd1bbb86befa9b6.jpg)

## 映射新图像到隐空间
由于**GAN**没有显式地提供从真实图像到隐空间的映射，因此无法直接将一幅新图像映射到隐空间中，

**GAN**学习得到的隐空间数据分布具有平滑性，即距离接近的两个隐向量生成的图像也是接近的。因此如果能够在隐空间中找到对应生成图像与新图像足够接近的隐向量，可将其近似看作新图像的隐向量。

为了寻找合适的隐向量，作者先从隐空间中随机采样一个$z_{\gamma}$，将其喂入训练好的**GAN**得到生成图像$G(z_{\gamma})$，定义损失函数，通过生成图像与新图像的差异进行反向传播，对隐向量进行梯度更新。

作者将总损失$L(z_{\gamma})$分为两个损失：残差损失$L_R(z_{\gamma})$和判别损失$L_D(z_{\gamma})$：

$$ L(z_{\gamma}) = (1- \lambda) \cdot L_R(z_{\gamma}) + \lambda \cdot L_D(z_{\gamma}) $$

### (1)Residual Loss
残差损失表示生成图像与真实图像之间的距离：

$$ L_R(z_{\gamma}) = \sum_{}^{} {\mid x - G(z_{\gamma}) \mid} $$

### (2)Discrimination Loss
判别损失表示生成图像被**GAN**判别为真实图像的损失：

$$ L_D(z_{\gamma}) = \sigma (D(G(z_{\gamma})),1) $$

其中$\sigma$表示交叉熵。

作者引入**特征匹配（feature matching）**的方法对判别损失进行改进。具体地，希望生成图像与真实图像在判别器中的中间层特征$f$足够接近：

$$ L_D(z_{\gamma}) = \sum_{}^{} {\mid f(x) - f(G(z_{\gamma})) \mid} $$

## 检测异常图像
对于每张新图像$x$，计算其异常得分$A(x)$。该得分可由损失函数计算得到，其残差损失和判别损失分别作为残差得分$R(x)$和判别得分$D(x)$。

$$ A(x) = (1- \lambda) \cdot R(x) + \lambda \cdot D(x) $$

异常得分越大，表明图像更有可能是异常图像。残差图像$x_R = \mid x - G(z_{\Gamma}) \mid$可以辨识图像中的异常区域。
