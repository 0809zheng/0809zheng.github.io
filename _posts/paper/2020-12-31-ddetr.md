---
layout: post
title: 'Deformable DETR: Deformable Transformers for End-to-End Object Detection'
date: 2020-12-31
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fed30993ffa7d37b3a4350c.jpg'
tags: 论文阅读
---

> Deformable DETR：使用多尺度可变形的注意力模块进行目标检测.

- paper：Deformable DETR: Deformable Transformers for End-to-End Object Detection
- arXiv：[link](https://arxiv.org/abs/2010.04159)
- code：[github](https://github.com/facebookresearch/deit)

**DETR**将目标检测问题建模为边界框的集合预测问题，从而避免了**anchor**、**label assignment**、**NMS**等操作，实现了**end-to-end**的检测流程。但仍存在一些问题，如：
- 相比于现存的检测器，**DETR**需要更长的**训练时间**。如在**COCO**数据集上需要$500$轮才能收敛，是**Faster RCNN**的$10$~$20$倍。
- **DETR**在**小目标**上检测性能较差。现存的检测器通常使用多尺度特征融合，其中小目标物体在高分辨率特征图上进行检测。而高分辨率的特征图会对**DETR**增加不可接受的计算复杂度。

作者认为，上述问题主要是因为在初始化的自注意力计算中，**query**与所有**key**计算得到的权重几乎都是一样的（均匀分布），导致需要用较长的时间才能学习到关注稀疏且有意义的位置。作者提出应该让**query**不再与所有**key**计算相似度，而是只与有意义的**key**计算相似度，即在建模相关性的同时保持采样的稀疏性。为此，作者提出**Deformable DETR**。

具体地，作者提出了**可变形注意力模块(deformable attention module)**，对每个**query**分配固定数量的**key**。假设输入特征图$x \in \Bbb{R}^{C \times H \times W}$，查询向量$z_q$的参考点坐标为$p_q$，则其可变形注意力计算为：

$$ DeformAttn(z_q,p_q,x) = \sum_{m=1}^{M} W_m [ \sum_{k=1}^{K} A_{mqk} \cdot W_m'x(p_q+\Delta p_{mqk}) ] $$

其中$M$表示注意力**head**的数量；表示固定的**key**采样数量（$k<<HW$）；$\Delta p_{mqk}$和$A_{mqk}$表示第$m$个注意力**head**的第$q$个查询向量的第$k$个采样点的**采样偏置(sampling offset)**和注意力权重，都是通过$z_q$的线性映射得到的。

具体实现时，查询向量$z_q$通过线性映射得到通道数为$3MK$的张量。前$2MK$编码采样偏置$\Delta p_{mqk}$，剩下的$MK$通过**softmax**函数获得注意力权重$A_{mqk}$。

作者进一步引入了**多尺度(multi-scale)**特征融合的方法。同时使用$L$层卷积特征图，对其尺寸进行归一化后在每一层都采集$K$个**key**，即每个**query**都采样了$LK$个**key**。其可变形注意力计算为：

$$ MSDeformAttn(z_q,\hat{p}_q, \{ x^l \}_{l=1}^{L} ) = \sum_{m=1}^{M} W_m [ \sum_{l=1}^{L} \sum_{k=1}^{K} A_{mlqk} \cdot W_m'x^l(\phi_l(\hat{p}_q)+\Delta p_{mlqk}) ] $$

模型实现如下图所示。在输入编码器时使用固定的位置编码，为区分不同尺度的特征，额外引入可学习的**scale-level**编码$$\{ e_l \}_{l=1}^{L}$$。

![](https://pic.downk.cc/item/5fed33d13ffa7d37b3a9c7ee.jpg)

与**DETR**相比，**Deformable DETR**能够在更少的训练轮数下获得更好的性能：

![](https://pic.downk.cc/item/5fed72973ffa7d37b31897c6.jpg)

