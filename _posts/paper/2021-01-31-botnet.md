---
layout: post
title: 'Bottleneck Transformers for Visual Recognition'
date: 2021-01-31
author: 郑之杰
cover: 'https://img.imgdb.cn/item/601a98663ffa7d37b3fef384.jpg'
tags: 论文阅读
---

> BotNet：CNN与Transformer结合的backbone.

- paper：Bottleneck Transformers for Visual Recognition
- arXiv：[link](https://arxiv.org/abs/2101.11605)

本文提出一个用于图像任务的**backbone**网络：**BotNet**。该网络没有用**Transformer**完全取代卷积网络，而是把**ResNet**中的$3 \times 3$卷积替换为**Multi-Head Self-Attention (MHSA)**：

![](https://img.imgdb.cn/item/601a98e83ffa7d37b3ff1c13.jpg)

替换前后的网络结构对比(**ResNet50**和**BotNet50**)：

![](https://img.imgdb.cn/item/601a990b3ffa7d37b3ff26ca.jpg)

替换后的网络性能有所提升：

![](https://img.imgdb.cn/item/601a99663ffa7d37b3ff4987.jpg)

引入的**MHSA**层结构如下图所示，相较于**non-local**网络增加了位置编码，更接近**NLP**中的自注意力操作：

![](https://img.imgdb.cn/item/601a99d33ffa7d37b3ff73e3.jpg)

值得一提的是，考虑到自注意力机制的计算量与内存占用问题，只在最小分辨率特征阶段添加自注意力模块。实验证明这类混合模型可以同时利用卷积与自注意力的特性，取得优于纯注意力模型的效果。