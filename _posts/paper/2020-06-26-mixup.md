---
layout: post
title: 'mixup: Beyond Empirical Risk Minimization'
date: 2020-06-26
author: 郑之杰
cover: 'https://pic.downk.cc/item/5f09ac1a14195aa594471088.jpg'
tags: 论文阅读
---

> mixup：样本对插值的经验风险最小化.

- paper：[mixup: Beyond Empirical Risk Minimization](https://arxiv.org/abs/1710.09412)

大型神经网络可能对样本集过拟合，表现为对训练样本具有记忆性，并且对对抗样本非常敏感。作者提出了**mixup**作为一种数据增强方法，用于缓解以上问题。**mixup**表示为成对样本及其标签的凸组合。实验表明该方法能够有效地提高网络的通用性，减小了对训练样本的记忆，增强了模型对对抗样本的鲁棒性，并进一步提高了**GAN**的训练稳定性。

# 1. mixup的提出

神经网络的训练目标是在训练数据集上实现平均误差最小化，即经验风险最小化(**empirical risk minimization, ERM**)原则。学习理论指出如果学习器的大小(如参数量或**VC**复杂度)不随训练数据的数量增强而增加，则**ERM**的收敛性可以得到保证。然而***ERM**无法保证在与训练数据不同的测试集分布上的泛化性。这是因为**ERM**允许大型神经网络记忆训练数据，当其在训练分布之外的数据上评估时，预测结果会有大幅度的改变。

数据增强是指在类似但不同于训练数据的数据集上进行训练的方法，即邻近风险最小化(**vicinal risk minimization, VRM**)原则。**VRM**是指通过人类知识构建训练数据中每个样本附近的邻域区域，然后从训练样本的邻域分布中采样额外的样本，以扩大训练样本的分布范围。虽然数据增强能够提高模型的泛化性，但它依赖于数据集，需要一定的专家知识。此外数据增强只能产生相同类别的样本，不能建立不同类样本之间的邻近关系。

作者提出了**mixup**作为一种数据扩充方法，其先验假设是特征向量的线性插值将导致目标标签的线性插值，因此使用两个样本的凸组合构造新的样本：

$$ \hat{x} = λx_i + (1-λ)x_j $$

$$ \hat{y} = λy_i + (1-λ)y_j $$

# 2. mixup的建模

监督学习是指寻找一个函数$f \in \mathcal{F}$描述服从联合分布$P(X,Y)$的特征向量$X$和目标向量$Y$之间的关系。定义损失函数$\mathcal{l}$衡量预测结果$f(x)$和实际目标$y$之间的差异。对于数据分布$P$中的样本$(x,y)$，目标是最小化损失函数的平均值，即期望风险(**expected risk**)：

$$ R(f) = \int_{}^{} \mathcal{l}(f(x),y)dP(x,y) $$

在实践中分布$P$是未知的，因此从分布中采样训练数据$$\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n$$，通过训练样本近似$P$的经验分布(**empirical distribution**)：

$$ P_{\delta}(x,y) = \frac{1}{n}\sum_{i=1}^{n}\delta(x=x_i,y=y_i) $$

进一步可以用经验风险(**empirical risk**)代替期望风险：

$$ R_{\delta}(f) = \int_{}^{} \mathcal{l}(f(x),y)dP_{\delta}(x,y)=\frac{1}{n}\sum_{i=1}^{n}\mathcal{l}(f(x_i),y_i) $$

通过最小化上式学习函数$f$的过程即为经验风险最小化**ERM**原则。对分布$P$的近似还有其它形式，比如在邻近风险最小化**VRM**原则中，分布$P$近似为：

$$ P_{\nu}(\tilde{x},\tilde{y}) = \frac{1}{n}\sum_{i=1}^{n}\nu(\tilde{x},\tilde{y}|x_i,y_i) $$

其中$\nu$是邻近分布(**vicinity distribution**)，用于衡量样本$(\tilde{x},\tilde{y})$出现在样本$(x_i,y_i)$附近的概率。常用的邻近分布有高斯邻近$\nu(\tilde{x},\tilde{y}\|x_i,y_i)=\mathcal{N}(\tilde{x}-x_i,\sigma^2)\delta(\tilde{y}=y_i)$，即对训练样本增加高斯噪声。

从分布$P$的近似中采样训练数据$$\mathcal{D}_{\nu}=\{(\tilde{x}_i,\tilde{y}_i)\}_{i=1}^m$$，则目标为最小化经验邻近风险(**empirical vicinal risk**)：

$$ R_{\nu}(f) = \frac{1}{m}\sum_{i=1}^{m}\mathcal{l}(f(\tilde{x}_i),\tilde{y}_i) $$

这篇论文的主要贡献是提出了一种通用的邻近分布，即**mixup**：

$$ \mu(\tilde{x},\tilde{y}|x_i,y_i) = \frac{1}{n}\sum_{j}^{n}\Bbb{E}_{\lambda} [\delta(\tilde{x}=\lambda \cdot x_i+(1-\lambda) \cdot x_j,\tilde{y}=\lambda \cdot y_i+(1-\lambda) \cdot y_j)] $$

其中$\lambda\text{~Beta}(\alpha,\alpha)$。超参数$\alpha$控制两个样本的插值强度，当$\alpha=0$时$\lambda=1$，上式恢复为**ERM**。

**mixup**实现简单，计算开销少。使用**Pytorch**实现**mixup**：

```python
# y1, y2 should be one-hot vectors
for (x1, y1), (x2, y2) in zip(loader1, loader2):
    lam = numpy.random.beta(alpha, alpha)
    x = Variable(lam * x1 + (1. - lam) * x2)
    y = Variable(lam * y1 + (1. - lam) * y2)
    optimizer.zero_grad()
    loss(net(x), y).backward()
    optimizer.step()
```

作者进一步指出，构造三个及以上样本的凸组合不能再带来进一步的增益。在实践中可以使用单个数据加载器提供的一个**minibatch**，随机打乱后将**mixup**应用在相邻的样本之间，这样做能够减少**I/O**需求。实验发现，仅在相同类别的样本中使用**mixup**不能显著地提高性能。

**mixup**能够有效地减少对训练样本之外的样本预测的振荡，且复合奥卡姆剃刀的归纳偏置。
对于下图所示的样本集，绿色表示类别0，橙色表示类别1。经验风险最小化**ERM**构造了硬分类的决策边界，蓝色区域代表模型分类为1的区域；而**mixup**实现软分类的决策边界，对于中间的区域，从一个类别过渡到另一个类别，提供更平滑的不确定性估计。

![](https://pic.downk.cc/item/5f09bd5d14195aa5944cae85.jpg)

作者在相同的训练条件下分别按照**ERM**和**mixup**训练模型。左图统计了对于插值样本$x=x_i+(1-\lambda) \cdot x_j$，预测结果不属于$$\{y_i,y_j\}$$的预测遗漏统计值，结果表明**mixup**具有更少的预测遗漏。右图表示对于插值样本，**mixup**具有更小的梯度范数。结果表明**mixup**模型预测和模型训练时更稳定。

![](https://pic.imgdb.cn/item/61ea130e2ab3f51d9127f613.jpg)
