---
layout: post
title: 'Wasserstein GANs Work Because They Fail (to Approximate the Wasserstein Distance)'
date: 2022-02-13
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/6349101116f2c2beb1b8f05b.jpg'
tags: 论文阅读
---

> WGAN的表现与Wasserstein距离的近似程度没有必然联系.

- paper：[Wasserstein GANs Work Because They Fail (to Approximate the Wasserstein Distance)](https://arxiv.org/abs/2103.01678)

# 1. WGAN

在[<font color=Blue>Wasserstein GAN</font>](https://0809zheng.github.io/2022/02/04/wgan.html)中，作者采用**Wasserstein**距离构造了**GAN**的目标函数，优化目标为真实分布$$P_{data}$$和生成分布$P_G$之间的**Wasserstein**距离：

$$   \mathop{\min}_{G} \mathop{\max}_{D, ||D||_L \leq K} \{ \Bbb{E}_{x \text{~} P_{data}(x)}[D(x)]-\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)] \} $$

或写作交替优化的形式：

$$ \begin{aligned} θ_D &\leftarrow \mathop{\arg \max}_{\theta_D} \frac{1}{n} \sum_{i=1}^{n} { D(x^i)} - \frac{1}{n} \sum_{i=1}^{n} {D(G(z^i))}  \\ \theta_G &\leftarrow \mathop{\arg \min}_{\theta_G} -\frac{1}{n} \sum_{i=1}^{n} {D(G(z^i))} \end{aligned} $$

其中要求判别器$D$是$K$阶**Lipschitz**连续的，即应满足：

$$ | D(x_1)-D(x_2) | ≤K | x_1-x_2 | $$

# 2. WGAN的表现与Wasserstein距离的近似程度没有必然联系

本文作者指出，**WGAN**经过训练后并没有很好地近似**Wasserstein**距离；相反如果对**Wasserstein**距离做更好的近似，效果反而会变差。

作者首先比较了[<font color=Blue>c-transform WGAN</font>](https://0809zheng.github.io/2022/02/12/ctrans.html)和[<font color=Blue>WGAN-GP</font>](https://0809zheng.github.io/2022/02/06/wgangp.html)的实际表现，其中前者比后者能够更好地近似**Wasserstein**距离，训练曲线也能体现这一点：

![](https://pic1.imgdb.cn/item/6349121b16f2c2beb1bca9ed.jpg)

然而前者的表现却不如后者：

![](https://pic1.imgdb.cn/item/634912c816f2c2beb1bdbb47.jpg)

因此得到如下结论：
- 效果比较好的**WGAN**在训练过程中并没有精确地近似**Wasserstein**距离；
- 更好地近似**Wasserstein**距离对提升图像生成表现并没有帮助。

### ⚪ 原因1：交替训练

**WGAN**的目标函数：

$$ \begin{aligned} (D^*, G^*) & \leftarrow \mathop{ \min}_{G} \mathop{ \max}_{D,\|D\|_L \leq K} \Bbb{E}_{x \text{~} P_{data}(x)}[D(x)]-\Bbb{E}_{x \text{~} P_{G}(x)}[D(x)]  \end{aligned} $$
 
上述目标函数只有先精确完成$$\mathop{\max}_{D}$$，然后再进行$$\mathop{ \min}_{G}$$，才相当于优化两个分布的**Wasserstein**距离；在实际训练时采用交替优化，理论上不可能精确逼近分布度量。

### ⚪ 原因2：批量训练

**WGAN**在训练时采用批量训练的方法，导致目标为最小化训练集中两个批量之间的**Wasserstein**距离，该目标仍然大于一个批量与训练集平均样本之间的**Wasserstein**距离。

作者展示了真实样本、平均样本和样本聚类中心，结果显示真实样本对应的**Wasserstein**距离反而是最大的。

![](https://pic1.imgdb.cn/item/634914f416f2c2beb1c1516a.jpg)

### ⚪ 原因3：成本函数

**Wasserstein**距离定义如下：

$$ \begin{aligned} \mathcal{W}[p,q] = \mathop{\inf}_{\gamma \in \Pi[p,q]} & \int \int \gamma(x,y) d(x,y) dxdy  \end{aligned} $$

其中样本之间的距离度量函数$d(x,y)$一般选择欧氏距离$$\|x-y\|_2$$。欧氏距离在衡量两张图像的相似程度时在视觉效果上是不合理的；两张相似的图像对应的欧氏距离不一定小。

作者指出，通过精确的**Wasserstein**距离(**c-transform WGAN**)获得的结果跟**k-means**方法的聚类中心类似，而后者也是使用欧氏距离作为度量：

![](https://pic1.imgdb.cn/item/6349160716f2c2beb1c30797.jpg)

### ⚪ WGAN为什么能成功？

作者认为，**WGAN**成功的关键是引入了**Lipschitz**约束。
