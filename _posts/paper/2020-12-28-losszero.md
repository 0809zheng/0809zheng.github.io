---
layout: post
title: 'Do We Need Zero Training Loss After Achieving Zero Training Error?'
date: 2020-12-28
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/62270eb75baa1a80ab384757.jpg'
tags: 论文阅读
---

> Flooding：避免训练损失为0.

- paper：[Do We Need Zero Training Loss After Achieving Zero Training Error?](https://arxiv.org/abs/2002.08709)

过参数化的深度网络能够在训练后实现零训练误差，此时会记忆训练数据，尽管训练损失接近0，但测试精度下降。作者提出了一种正则化方法，称为**flooding**。为损失函数指定一个合理的较小值**flood level**，使其在优化时在该值附近波动，而不至于损失下降过小。此时尽管训练损失不会下降，但测试损失会进一步下降，从而具有更好的泛化性。

![](https://pic.imgdb.cn/item/6227116e5baa1a80ab3c4c54.jpg)

# 1. Flooding

**flooding**方法是对损失函数进行简单的修改。假设原来的损失函数为$\mathcal{L}(\theta)$，则修改为：

$$ \tilde{\mathcal{L}}(\theta) = |\mathcal{L}(\theta)-b| +b $$

上述修改仅用一行代码可以实现：

```python
loss = (loss-b).abs() + b
```

$b$是预先设定的较小的阈值。当损失函数$\mathcal{L}(\theta)>b$时，$\tilde{\mathcal{L}}(\theta) =\mathcal{L}(\theta)$，此时进行正常的梯度下降。当损失函数$\mathcal{L}(\theta)<b$时，$\tilde{\mathcal{L}}(\theta) =2b-\mathcal{L}(\theta)$，此时损失函数变号，执行梯度上升过程。

因此，当损失函数的数值位于$b$附近时，交替执行梯度下降和梯度上升过程。假设学习率为$\eta$，参数更新先下降一次再上升一次，则：

$$ \theta_{t} = \theta_{t-1}-\eta g(\theta_{t-1}) \\ \theta_{t+1} = \theta_{t}+\eta g(\theta_{t}) $$

其中梯度$g(\theta_{t})=\nabla_{\theta}\mathcal{L}(\theta_t)$。进一步有：

$$ \theta_{t+1} = \theta_{t-1}-\eta g(\theta_{t-1})+\eta g(\theta_{t-1}-\eta g(\theta_{t-1})) \\ ≈ \theta_{t-1}-\eta g(\theta_{t-1})+\eta [g(\theta_{t-1})-\eta \nabla_{\theta}g(\theta_{t-1}) g(\theta_{t-1})] \\ = \theta_{t-1}-\eta^2 \nabla_{\theta}g(\theta_{t-1}) g(\theta_{t-1}) \\ = \theta_{t-1}-\frac{\eta^2}{2} \nabla_{\theta}|| g(\theta_{t-1})||^2 $$

上式用到了[**Taylor**](https://0809zheng.github.io/2021/08/20/taylor.html)展开。注意到**flooding**的结果相当于损失函数为梯度惩罚项$$\|g(\theta)\|^2=\|\nabla_{\theta}\mathcal{L}(\theta)\|^2$$、学习率为$\frac{\eta^2}{2}$的梯度下降方法。

**flooding**方法相当于当损失下降到一定程度后，将目标函数调整为最小化$$\|\nabla_{\theta}\mathcal{L}(\theta)\|^2$$，推动参数向更平稳的区域移动，从而提高模型的泛化能力。

# 2. 实验分析

实验结果表明，应用**flooding**后，测试误差会出现二次下降的趋势，并最终导致更好的测试精度。

![](https://pic.imgdb.cn/item/62271a855baa1a80ab42d137.jpg)

![](https://pic.imgdb.cn/item/62271a715baa1a80ab42c2d4.jpg)