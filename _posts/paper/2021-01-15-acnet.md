---
layout: post
title: 'ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks'
date: 2021-01-15
author: 郑之杰
cover: 'https://img.imgdb.cn/item/6000eaf83ffa7d37b30d677c.jpg'
tags: 论文阅读
---

> ACNet：深度网络重参数化.

- paper：ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks
- arXiv：[link](https://arxiv.org/abs/1908.03930v1)
- code：[github](https://github.com/DingXiaoH/ACNet)

# 1. 重参数化
卷积神经网络等深度学习模型包括**学习(learn)**和**推理(inference)**两个阶段。在学习阶段(即训练阶段)通过训练集的训练获得满足精度要求的模型参数，在推理阶段(即测试阶段)根据模型参数对新的数据样本计算输出。通常的模型在这两个阶段使用同一套模型参数。

深度模型的**重参数化(re-parameterize)**是指在学习阶段使用一套模型参数进行训练，训练完成后将其等价转换为另一套模型参数进行推理。通过重参数化能够提高模型的性能。

该方法之所以可行，作者认为主要原因是深度模型的动力学特征是复杂的。两套不同的模型参数即使在前向传播中是等价的，其反向传播并不等价。用更高的学习成本学习更复杂的模型参数，在推理阶段使用其等价参数；对于模型的使用者(仅做推理)来说，在没有引入额外计算量的情况下获得性能的提升。


# 2. ACNet
作者提出了一种深度模型重参数化的应用，基于**非对称卷积块(Asymmetric Convolution Block)**的**ACNet**。具体地，作者提出了一种对$3 \times 3$卷积层进行重参数化的方法：

![](https://img.imgdb.cn/item/6000f4d43ffa7d37b311c420.jpg)

**ACNet**从宏观上分为训练阶段和推理阶段。训练阶段强化卷积的特征提取，推理阶段进行卷积核融合，而不增加任何计算量。
- **训练阶段**：$3 \times 3$卷积是大多数网络的基本组件，训练阶段将现有网络中的$3 \times 3$卷积替换成$3 \times 3$卷积＋$1 \times 3$卷积＋$3 \times 1$卷积共三个卷积层，将这三个卷积层的计算结果融合作为最终的输出。由于这一过程中引入的$1 \times 3$卷积和$3 \times 1$卷积是非对称的，所以将其称为非对称卷积块。
- **推理阶段**：对三个卷积核进行融合，将融合后的卷积核参数作为现有网络的初始化参数。在推理阶段没有增加计算量，但使得卷积核参数具有更强的特征提取能力。具体的融合是和**BatchNorm**层一起进行的，过程如下图所示：

![](https://img.imgdb.cn/item/6000f86a3ffa7d37b31391b7.jpg)

上述等价转换能够实现，是因为卷积操作具有齐次性和可加性：

$$ I * (pF) = p(I * F), \quad \forall p \in \Bbb{R} $$

$$ I * F^{(1)} + I * F^{(2)} = I * (F^{(1)}+F^{(2)}) $$

作者认为，将$3 \times 3$卷积替换成$3 \times 3$卷积＋$1 \times 3$卷积＋$3 \times 1$卷积能够增强模型对图像翻转和旋转的鲁棒性。如下图所示，训练好的$1 \times 3$卷积在图像垂直翻转后仍能提取正确的特征，而$3 \times 3$卷积提取的特征显然是不同的。同理，使用$3 \times 1$卷积能够提升模型对图像水平翻转的鲁棒性。

![](https://img.imgdb.cn/item/6000fafa3ffa7d37b3152f5d.jpg)