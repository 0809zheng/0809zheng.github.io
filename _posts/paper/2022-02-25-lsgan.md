---
layout: post
title: 'Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities'
date: 2022-02-25
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/634fa63f16f2c2beb13ab17f.jpg'
tags: 论文阅读
---

> LSGAN：损失敏感GAN.

- paper：[Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities](https://arxiv.org/abs/1701.06264)

# 1. 将能量模型引入GAN

[能量模型](https://0809zheng.github.io/2020/04/12/energy.html)是指使用如下能量分布拟合一批真实数据$x_1,x_2,\cdots,x_n$~$$P_{data}(x)$$：

$$ q_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}},Z_{\theta} = \int e^{-U_{\theta}(x)}dx $$

其中$U_{\theta}(x)$是带参数的能量函数；$Z_{\theta}$是配分函数(归一化因子)。直观地，真实数据分布在能量函数中势最小的位置。我们希望通过对抗训练使得生成数据$\hat{x}_1,\hat{x}_2,\cdots \hat{x}_n$的势也尽可能小。

![](https://pic1.imgdb.cn/item/634e13f716f2c2beb1b9d59f.jpg)

使用判别器$D(x)$拟合能量函数$U_{\theta}(x)$，使用生成器$G(x)$构造生成分布$P_G(x)$。则判别器的目标函数为最小化真实数据分布的能量，并最大化生成数据分布的能量：

$$ D^* \leftarrow \mathop{ \min}_{D} \Bbb{E}_{x \text{~} P_{data}(x)} [  D(x)]-  \Bbb{E}_{x \text{~} P_G(x)}[D(x) ] $$

与此同时生成器的目标函数为最小化生成数据分布的能量：

$$ G^* \leftarrow \mathop{ \min}_{G} \Bbb{E}_{x \text{~} P_G(x)}[D(x) ] $$

至此，在能量模型的角度下，**GAN**的目标函数写作：

$$ \begin{aligned} D^* &\leftarrow \mathop{ \min}_{D} \Bbb{E}_{x \text{~} P_{data}(x)} [  D(x)]-  \Bbb{E}_{x \text{~} P_G(x)}[D(x) ] \\ G^* &\leftarrow \mathop{ \min}_{G} \Bbb{E}_{x \text{~} P_G(x)}[D(x) ] \end{aligned} $$

# 2. Loss-Sensitive GAN (LSGAN)

上式在优化判别器的过程中容易使对于真实样本$D(x) \to -\infty$，对于生成样本$D(x) \to +\infty$，从而导致训练不稳定。

**LSGAN**提出，判别器在最小化真实图像能量的同时，不需要最大化任意生成图像的能量。如果生成图像与真实图像比较相似，则生成图像的能量可以小一些；否则就把生成图像的能量调整得大一些。

![](https://pic1.imgdb.cn/item/634fa95e16f2c2beb13f1692.jpg)

**LSGAN**的目标函数写作：

$$ \begin{aligned} D^* \leftarrow \mathop{ \min}_{D} &\Bbb{E}_{x \text{~} P_{data}(x)} [  D(x)] \\ &+  \Bbb{E}_{(x,z) \text{~}(P_{data}(x),P_z(z))}[\max \{ 0, \Delta(x,G(z))+D(x)-D(G(z)) ] \\ G^* \leftarrow \mathop{ \min}_{G} &\Bbb{E}_{x \text{~} P_G(x)}[D(x) ] \end{aligned} $$