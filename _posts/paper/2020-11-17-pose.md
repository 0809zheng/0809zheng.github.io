---
layout: post
title: 'Monocular Human Pose Estimation: A Survey of Deep Learning-based Methods'
date: 2020-11-17
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fb32b3eb18d627113f5867e.jpg'
tags: 论文阅读
---

> 单目人体姿态估计的深度学习方法综述.

- paper：Monocular Human Pose Estimation: A Survey of Deep Learning-based Methods
- arXiv：[link](https://arxiv.org/abs/2006.01423?context=cs.CV)

基于视觉的**单目人体姿态估计(Monocular Human Pose Estimation)**旨在从输入图像或视频序列中获得人体的姿态。这篇综述总结了$2014$年以来提出的基于深度学习的$2D$和$3D$人体姿态估计方法。


# ① 2D人体姿态估计 2D Human Pose Estimation
$2D$人体姿态估计通过单目图像或视频计算人体关节点(**joint**)的位置，并进一步生成$2D$人体骨架。

## 2D单人人体姿态估计 2D single person pose estimation
$2D$单人人体姿态估计可以分为**基于回归(regression-based)**的方法或**基于检测(detection-based)**的方法。
- 基于回归的方法直接将输入图像映射到**身体关节的坐标**或**人体模型的参数**。这类方法可以端到端的训练，但映射是高度非线性的，学习较为困难，且缺乏鲁棒性。
- 基于检测的方法将输入图像映射到**图像块(patch)**或关节位置的**热图(heatmap)**，将身体部位作为检测目标。这类方法鲁棒性更好，但从中估计关节点坐标的准确性较差，并且阻碍了端到端的训练。

![](https://pic.downk.cc/item/5fb3408fb18d627113fa00d6.jpg)

### (a) Regression-based methods
基于回归的方法直接预测人体各关节点的**联合坐标**。

- [Toshev, A., Szegedy, C., 2014. Deeppose: Human pose estimation via deep
neural networks]首先尝试训练类似**AlexNet**的深度神经网络，直接从完整图像中学习关节坐标。

忽略关节周围的信息会缺乏鲁棒性，同时学习**热图**和**联合坐标**可以保留两种表示的优点。
- [Luvizon, D.C., Tabia, H., Picard, D., 2017. Human pose regression by combining indirect part detection and contextual information]提出了一个**Soft-argmax**函数，将热图转换为联合坐标，从而可以将基于检测的网络转换为基于微分的回归网络。
- [Nibali, A., He, Z., Morgan, S., Prendergast, L., 2018. Numerical coordinate regression with convolutional neural networks.]设计了一个可微分的**空间数值转换(DSNT)**层，根据热图计算联合坐标，该坐标与低分辨率热图配合使用效果很好。

直接从原始输入图像中预测关节坐标非常困难，下面的方法通过改进**网络结构**或**人体模型结构**来改善方法的性能。

- [Carreira, J., Agrawal, P., Fragkiadaki, K., Malik, J., 2016. Human pose estimation with iterative error feedback]提出了一个基于**GoogleNet**的迭代错误反馈网络**(Iterative Error Feedback network)**，该网络递归地处理输入图像和输出结果的组合，最后的姿态比迭代后的初始平均姿态有所改善。
- [Sun, X., Shang, J., Liang, S.,Wei, Y., 2017. Compositional human pose regression]提出了一种基于**ResNet-50**的结构感知回归方法。不再使用关节表示人体姿态，而是通过涉及身体结构信息来设计基于骨骼的表示，实现比仅使用关节位置更稳定的结果。

下面的方法将姿态估计任务与其他和人体密切相关的任务结合，使用网络同时学习多种特征，以改善对关节坐标的预测。

- [Li, S., Liu, Z.Q., Chan, A.B., 2014. Heterogeneous multi-task learning for human pose estimation with deep convolutional neural network]采用了类似**AlexNet**的多任务框架，使用完整图像通过回归预测联合坐标，并使用滑动窗口获得图像进行身体部位检测。
- [Gkioxari, G., Hariharan, B., Girshick, R., Malik, J., 2014a. R-cnns for pose estimation and action detection]使用**R-CNN**结构同步进行人体检测、姿态估计和动作分类。
- [Fan, X., Zheng, K., Lin, Y., Wang, S., 2015. Combining local appearance and holistic view: Dual-source deep neural networks for human pose estimation]提出了一种**双源(dual-source)CNN**，以图像块和完整图像作为输入，同时输出热图和坐标。热图代表滑动窗口的联合检测结果，坐标代表联合定位结果。从两个结果的组合中获得最终的姿态估计。
- [Luvizon, D.C., Picard, D., Tabia, H., 2018. 2d/3d pose estimation and action recognition using multi-task deep learning]设计的模型可以同时处理视频序列中的$2D$/$3D$姿态估计和动作识别。 网络中间估计的姿态可以用作动作识别的参考。

### (b) Detection-based methods
基于检测的方法使用**热图**来指示关节的真实值。如下图所示，每个关键点占据一个热图通道，表示为以目标关节位置为中心的二维高斯分布。

![](https://pic.downk.cc/item/5fb37ddeb18d62711306f2a6.jpg)

- [Newell, A., Yang, K., Deng, J., 2016. Stacked hourglass networks for human pose estimation]提出了使用残差模块作为基本单元的**Hourglass**网络结构。
- [Yang, W., Li, S., Ouyang, W., Li, H., Wang, X., 2017. Learning feature pyramids for human pose estimation]设计了一个**金字塔残差模块(PRM)**来替换**Hourglass**的残差模块，通过学习不同尺度的特征来增强网络的尺度不变性。
- [Belagiannis, V., Zisserman, A., 2017. Recurrent human pose estimation]将$7$层前馈模块与递归模块组合在一起迭代地优化结果。该模型学习预测关节和肢体的定位热图。
- [Sun, K., Xiao, B., Liu, D., Wang, J., 2019. Deep high-resolution representation learning for human pose estimation]提出了一种具有多尺度特征融合的高分辨率网络。

下面的方法试图将人体结构信息进行编码并输入网络。

- [Tompson, J.J., Jain, A., LeCun, Y., Bregler, C., 2014. Joint training of a convolutional network and a graphical model for human pose estimation]训练了一个类似马尔可夫随机场的空间模型网络，学习关节之间的典型空间关系。
- [Lifshitz, I., Fetaya, E., Ullman, S., 2016. Human pose estimation using deep consensus voting]将图像离散化为以每个关节为中心的**对数极坐标箱(log-polar bins)**，并使用基于**VGG**的网络来预测对每个成对关节的置信度和关节类别。通过所有相对置信度得分，使用反卷积网络生成每个关节的最终热图。
- [Yang, W., Ouyang, W., Li, H., Wang, X., 2016. End-to-end learning of deformable mixture of parts and deep convolutional neural networks for human pose estimation]设计了一个两阶段的网络。 第一阶段是卷积神经网络，以预测热图表示中的关节位置。第二阶段是根据人体结构手动连接的消息传递模型，以最大和算法找到最佳的关节位置。
- [Gkioxari, G., Toshev, A., Jaitly, N., 2016. Chained predictions using convolutional neural networks]提出了卷积递归神经网络，按照链模型顺序输出关节位置。每一步的输出取决于输入图像和先前预测的输出。该网络可以处理具有不同连接策略的图像和视频。
- [Chu, X., Ouyang, W., Li, H., Wang, X., 2016. Structured feature learning for pose estimation]提出了通过双向树对内核进行变换，以在**树体模型(tree body model)**中的相应关节之间传递信息。
- [Chu, X., Yang, W., Ouyang, W., Ma, C., Yuille, A.L., Wang, X., 2017.Multi-context attention for human pose estimation]用更复杂的模块替换了**Hourglass**网络的残差模块。 条件随机场用于注意力图，作为学习人体结构信息的中间监督。
- [Papandreou, G., Zhu, T., Kanazawa, N., Toshev, A., Tompson, J., Bregler, C.,Murphy, K., 2017. Towards accurate multi-person pose estimation in the wild]提出了一种改进的关节位置表示方法，该方法将二进制激活热图和相应的偏移量结合在一起。
- [Ning, G., Zhang, Z., He, Z., 2018. Knowledge-guided deep fractal neural networks for human pose estimation]设计了一个分形网络引入人体先验知识来指导网络。通过使用学习的投影矩阵，将外部知识的视觉特征编码到基本网络中。
- [Ke, L., Chang, M.C., Qi, H., Lyu, S., 2018. Multi-scale structure-aware network for human pose estimation]提出了一种基于**Hourglass**网络的多尺度结构感知网络，该网络具有多尺度监督、多尺度特征组合、结构感知损失和关节掩码数据增强等特点。
- [Tang, W., Yu, P., Wu, Y., 2018a. Deeply learned compositional models for human pose estimation]设计了用于中间监督的身体部位的分层表示形式，以替换每个关节的热图。因此，网络学习自下而上/自上而下的身体结构，而不是仅学习分散的关节。
- [Tang, W., Wu, Y., 2019. Does learning specific features for related parts help human pose estimation]提出了一种基于零件的分支网络，以学习每个零件组的特定表示，而不是预测一个分支的所有联合热图。 然后通过计算关节的相互信息来分割数据驱动的零件组。

下面的方法使用**生成对抗网络**学习身体结构，或为网络训练提供对抗监督。

- [Zhou, X., Huang, Q., Sun, X., Xue, X., Wei, Y., 2017. Towards 3d human pose estimation in the wild: a weakly-supervised approach]引入了对抗学习，分别使用两个相同的**Hourglass**网络作为生成器和判别器。生成器预测每个关节的热图位置，而鉴别器则将**GT**热图与生成的热图区分开。
- [Chen, Y., Shen, C., Wei, X.S., Liu, L., Yang, J., 2017. Adversarial posenet: A structure-aware convolutional network for human pose estimation]提出了一种具有结构意识的卷积网络，该网络具有一个生成器和两个判别器，以整合人体结构的先验知识。该生成器是从**Hourglass**网络设计的，可预测关节热图和闭遮挡热图。 姿态判别器可以将合理的姿态与不合理的姿态区别开。置信度判别器显示预测的置信度得分。
- [Peng, X., Tang, Z., Yang, F., Feris, R.S., Metaxas, D., 2018. Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation]研究了如何在不寻找更多数据的情况下共同优化数据增强和网络训练。当网络从生成的增强数据中学习时，使用增强来增加网络损失，而不是使用随机数据增强。

下面的方法使用**时间信息**来增强对于单目视频序列中的人体姿态估计。

- [Jain, A., Tompson, J., LeCun, Y., Bregler, C., 2014. Modeep: A deep learning framework using motion features for human pose estimation]设计了一个包含两个分支的框架，采用多尺度**RGB**帧和光流图作为输入，在最后的卷积层之前将提取的特征串联在一起。
- [Pfister, T., Charles, J., Zisserman, A., 2015. Flowing convnets for human pose estimation in videos]使用光流图作为指导，根据视频的时间上下文对齐来自相邻帧的预测热图。
- [Luo, Y., Ren, J., Wang, Z., Sun, W., Pan, J., Liu, J., Pang, J., Lin, L., 2018. Lstm pose machines]通过使用多阶段的递归神经网络利用时间信息。

下面的方法旨在低容量的设备上进行姿态估计，在保持性能的同时减少网络参数。

- [Tang, Z., Peng, X., Geng, S., Wu, L., Zhang, S., Metaxas, D., 2018b. Quantized densely connected u-nets for efficient landmark localization]通过提出密集连接的**U-Net**和有效利用内存来改善网络结构。 该网络类似于**Hourglass**，但它利用**U-Net**作为每个组件，在每个阶段具有更优化的全局连接，从而减少了参数和模型尺寸。
- [Debnath, B., O’Brien, M., Yamaguchi, M., Behera, A., 2018. Adapting mobilenets for mobile based upper body pose estimation]通过在**MobileNets**的最后两层设计分离流架构进行姿态估计。
- [Feng, Z., Xiatian, Z., Mao, Y., 2019. Fast human pose estimation]设计了一个**Hourglass**的轻量级变体，并通过**快速姿势蒸馏(Fast Pose Distillation)**训练策略对完整的**Teacher Hourglass**网络进行训练。

## 2D多人人体姿态估计 2D multi-person pose estimation
与单人姿态估计相比，多人姿态估计需要同时完成**检测**和**估计**任务。根据完成任务的顺序不同，多人姿态估计方法分为**自上而下(top-down)**的方法和**自下而上(bottom-up)**的方法。
- 自上而下的方法先做**检测**再做**估计**。即先通过人体检测器在输入图像中检测出不同的人体，再使用单人姿态估计方法对每个人进行姿态估计。这类方法的精度依赖于人体检测的精度，当检测人数增加时运行时间成倍地增加。
- 自下而上的方法先做**估计**再做**检测**。即先在图像中估计出所有人体关节关键点，再将它们组合成不同的人体姿态。这类方法的关键在于正确组合关节点，当不同人体之间有较大遮挡时，估计效果会下降。

![](https://pic.downk.cc/item/5fb340f2b18d627113fa1cb5.jpg)

### (a) Top-down methods
自上而下的方法中两个最重要的组成部分是**人体区域检测器**和**单人姿态估计器**。大多数研究基于现有的人体检测器进行估计，如**Faster R-CNN**、**Mask R-CNN**和**FPN**。

- [Iqbal, U., Gall, J., 2016. Multi-person pose estimation with local joint-to-person associations]利用**convolution pose machine**生成初始姿势，然后应用整数线性规划获得最终姿势。
- [Fang, H., Xie, S., Tai, Y.W., Lu, C., 2017. Rmpe: Regional multi-person pose estimation]采用**spatial transformer network**、非极大值抑制和**Hourglass**网络提高姿态估计的准确性。
- [Huang, S., Gong, M., Tao, D., 2017. A coarse-fine network for keypoint localization]提出了以**Inception-v2**为骨干网络的**粗精细网络(coarse-fine network)**。 该网络在多个级别进行监督，以学习粗略和精细的预测。
- [Xiao, B., Wu, H., Wei, Y., 2018. Simple baselines for human pose estimation and tracking]在**ResNet**的最后一个卷积层后添加几个反卷积层，根据深层和低分辨率特征生成热图。
- [Chen, Y., Wang, Z., Peng, Y., Zhang, Z., Yu, G., Sun, J., 2018. Cascaded pyramid network for multi-person pose estimation]提出了一种**级联金字塔网络(cascade pyramid network)**，它利用来自不同层的多尺度特征图来从局部和全局特征中提取更多信息，并采用了在线难例挖掘方法。
- [Moon, G., Chang, J.Y., Lee, K.M., 2019. Posefix: Model-agnostic general
human pose refinement network]设计了**PoseFix**网络细化估计姿态。

通过将现有的人体检测网络和单人姿态估计网络结合起来，可以轻松实现自上而下的多人姿态估计。这类方法几乎在所有**Benchmarks**上取得了最先进的表现，但这种方法的处理速度受到检测人数的限制。

### (b) Bottom-up methods
自下而上的人体姿态估计方法的主要组成部分包括**人体关节检测**和**候选关节分组**。大多数算法分别处理这两个组件。

- [Deep-Cut（Pishchulin et al.，2016）]使用基于**Faster R-CNN**的人体部位检测器首先检测所有身体部位**proposal**并标记对应的部位类别，之后使用整数线性规划组合这些零件来构成完整的骨架。
- [DeeperCut（Insafutdinov et al.，2016）]通过使用基于**ResNet**的更强大的部位检测器和探索联合候选对象之间的几何形状和外观约束的更好的增量优化策略改进**DeepCut**。
- [OpenPose（Cao et al.，2016）]使用**convolution pose machine**来预测具有**人体部位亲和场(Part Affinity Fields,PAF)**的所有身体关节。 **PAF**可以对肢体的位置和方向进行编码，用于将估计的关节组装成不同的人体姿势。
- [Nie, X., Feng, J., Xing, J., Yan, S., 2018. Pose partition networks for multi-person pose estimation]提出了一个**姿态分割网络(Pose Partition Network)**来进行关节检测和密集回归，以实现关节分割和对具有关节分割的关节配置进行局部推断。
- [Kreiss, S., Bertoni, L., Alahi, A., 2019. Pifpaf: Composite fields for human pose estimation]设计了一个**PifPaf**网络以预测代表身体关节位置和身体关节关联的**部位强度场（PIF）**和**部位关联场（PAF）**。

以上方法都是将关节检测和关节分组分开。最近，一些方法可以在**单阶段**进行预测。

- [Newell, A., Huang, Z., Deng, J., 2017. Associative embedding: End-to-end learning for joint detection and grouping]引入了单阶段深度网络架构，以同时执行检测和分组。 该网络可以为每个关节生成检测热图，以及包含每个关节的分组标签的关联嵌入图。

一些方法采用**多任务学习**的结构。

- [Papandreou, G., Zhu, T., Chen, L.C., Gidaris, S., Tompson, J., Murphy,K., 2018. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model]提出了一种用于姿态估计和实例分割的多任务网络。基于**ResNet**的网络可以同步预测每个人所有关键点的联合热图及其相对位移。然后从最可靠的检测开始分组，该检测基于树状运动学图的贪婪解码过程。
- [Kocabas, M., Karagoz, S., Akbas, E., 2018. Multiposenet: Fast multi-person pose estimation using pose residual network]结合了具有新颖分配方法的多任务模型，可完全处理人类关键点估计、检测和语义分段任务。它的骨干网是共享关键点特征的**ResNet**和**FPN**的组合以及人体检测子网络。人体检测结果被用来限制人的空间位置。

目前，自下而上的方法处理速度非常快，有些方法可以实时运行。但是性能会受到复杂背景和人为遮挡的影响。

# ② 3D人体姿态估计 3D Human Pose Estimation
$3D$人体姿态估计通过图像或视频在$3D$空间中计算人体关节点(**joint**)的位置，并进一步生成$3D$人体骨架。与$2D$人体姿态估计相比，$3D$人体姿态估计需要估计**深度(depth)**信息。本节总结了从单目**RGB**图像和视频中估计$3D$人体姿态的深度学习方法。

## 3D单人人体姿态估计 3D single person pose estimation
根据是否应用**人体模型(human body model)**，$3D$单人姿态估计可以分为**不用模型(model-free)**的方法和**基于模型(model-based)**的方法。

![](https://pic.downk.cc/item/5fb34137b18d627113fa3261.jpg)

![](https://pic.downk.cc/item/5fb3415ab18d627113fa3aec.jpg)

### (a) Model-free methods
不用模型的方法可以分成两类。第一类是直接把图像映射成$3D$姿态；第二类是从$2D$姿态估计的结果中估计深度信息。

从图像中直接估计$3D$姿态通常包含很少的约束。

- [Li, S., Chan, A.B., 2014. 3d human pose estimation from monocular images with deep convolutional neural network]利用浅层网络直接回归$3D$关节坐标，通过滑动窗口实现身体部位检测和姿态估计的多任务学习。 
- [Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose]提出$3D$人体姿态的体积表示，并采用粗到细的预测方案来改进具有多级结构的预测。

下面的方法试图将**身体结构信息**或**人体关节之间的依赖关系**添加到深度网络中。

- [Li, S., Zhang, W., Chan, A.B., 2015b. Maximum-margin structured learning with deep networks for 3d human pose estimation]设计了一种嵌入子网络，通过学习潜在姿态结构信息来指导三维联合坐标映射。该子网络可以为具有最大边际成本函数的输入图像姿态分配匹配分数。
- [Tekin, B., Katircioglu, I., Salzmann, M., Lepetit, V., Fua, P., 2016. Structured prediction of 3d human pose with deep neural networks]预训练了一个无监督的自编码器，以学习三维姿态的高维潜在姿态表示，用于添加关于人体的隐式约束，然后使用浅层网络学习高维姿态表示。
- [Sun, X., Shang, J., Liang, S., Wei, Y., 2017. Compositional human pose regression]提出了一种结构感知回归方法。通过设计一种涉及身体结构信息的基于骨骼表示，只使用关节位置更稳定。
- [Pavlakos, G., Zhou, X., Daniilidis, K., 2018a. Ordinal depth supervision for 3d human pose estimation]通过具有额外的人类关节序数深度的网络训练为约束，二维人类数据集也可以用序数深度注释输入。

从$2D$姿态估计的结果中估计深度信息，再生成$3D$姿态估计的方法可以很容易地利用$2D$姿态数据集，并且具有$2D$姿态估计的优点。

- [Martinez, J., Hossain, R., Romero, J., Little, J.J., 2017. A simple yet effective baseline for 3d human pose estimation]设计了一个只有两个线性层的$2D$-$3D$姿态预测器。
- [Zhou, X., Huang, Q., Sun, X., Xue, X., Wei, Y., 2017. Towards 3d human pose estimation in the wild: a weakly-supervised approach]提出了一个深度回归模块，用于预测二维热图的三维姿态，并提出了二维数据的几何约束损失。
- [Tekin, B., Marquez Neila, P., Salzmann, M., Fua, P., 2017. Learning to fuse 2d and 3d image cues for monocular body pose estimation]提出了一个双分支框架预测二维热图，并从图像中提取特征。提取的特征通过可训练的融合方案与二维热图融合，以获得最终的三维联合坐标。
- [Li, C., Lee, G.H., 2019. Generating multiple hypotheses for 3d human pose estimation with mixture density network]认为$3D$姿态估计是具有多个可行解的逆问题。提出从二维姿态中产生多个三维姿态的可行假设，并通过二维再投影选择最佳假设。
- [Qammaz, A., Argyros, A., 2019. Mocapnet: Ensemble of snn encoders for 3d human pose estimation in rgb images]提出了**Mocapnet**$2D$姿态直接编码为$3D$**BVH**格式，通过整合**OpenPose**，该体系结构仅使用**CPU**处理实时估计和呈现$3D$人体姿态。

将$2D$姿态映射到$3D$姿态时，可以采用不同的策略。

- [Chen, C.H., Ramanan, D., 2017. 3d human pose estimation= 2d pose estimation+ matching]使用了一种匹配策略，用于从库中估计$2D$姿态和$3D$姿态。
- [Moreno-Noguer, F., 2017. 3d human pose estimation from a single image via distance matrix regression]将二维和三维体关节的成对距离编码成两个欧氏距离矩阵，并训练回归网络来学习这两个矩阵的映射。
- [Wang, M., Chen, X., Liu, W., Qian, C., Lin, L., Ma, L., 2018a. Drpose3d: Depth ranking in 3d human pose estimation]预测人体关节的深度排名，作为从二维姿势推断三维关节位置的线索。
- [Yang, W., Ouyang, W., Wang, X., Ren, J., Li, H., Wang, X., 2018. 3d human pose estimation in the wild by adversarial learning]设计了一个具有图像、成对几何结构和联合位置信息的多源判别器。

### (b) Model-based methods
基于模型的方法通常采用**人体参数模型**从图像中估计人的姿态和形状。

一些工作采用了**SMPL**人体模型，从图像中估计三维参数。

- [Bogo, F., Kanazawa, A., Lassner, C., Gehler, P., Romero, J., Black, M.J., 2016. Keep it smpl: Automatic estimation of 3d human pose and shape from a single image]将**SMPL**模型拟合到二维节点，并提出了一种基于优化的方法从二维节点中恢复**SMPL**参数。
- [Tan, J., Budvytis, I., Cipolla, R., 2017. Indirect deep structured learning for 3d human body shape and pose prediction]通过训练解码器来推断**SMPL**参数，用合成数据从**SMPL**参数预测轮廓，然后用训练的解码器学习图像编码器。经过训练的编码器可以从输入图像中预测**SMPL**参数。

直接学习**SMPL**的参数是困难的，一些工作预测中间线索作为约束。

- [Kanazawa, A., Black, M.J., Jacobs, D.W., Malik, J., 2018. End-to-end recovery of human shape and pose]为克服人体模型缺乏训练数据的问题，采用对抗性学习，使用生成器预测**SMPL**的参数，并使用判别器来区分真实的**SMPL**模型和预测的模型。
- [Arnab, A., Doersch, C., Zisserman, A., 2019. Exploiting temporal context for 3d human pose estimation in the wild]从探索多视图信息的视频序列中重建人体。

**运动学模型(kinematic model)**广泛应用于$3D$人体姿态估计中。

- [Mehta, D., Rhodin, H., Casas, D., Fua, P., Sotnychenko, O., Xu, W., Theobalt, C., 2017a. Monocular 3d human pose estimation in the wild using improved cnn supervision]根据运动树体模型从二维热图预测了相对关节位置。
- [Nie, B.X., Wei, P., Zhu, S.C., 2017. Monocular 3d human pose estimation by predicting depth on joints]通过**LSTM**利用运动树体模型的全局二维关节位置和局部体部图像进行关节深度估计。
- [Zhou, X., Sun, X., Zhang, W., Liang, S., Wei, Y., 2016. Deep kinematic pose regression]将运动物体模型嵌入到一般铰接物体姿态估计网络中，提供方向和旋转约束。
- [Mehta, D., Sridhar, S., Sotnychenko, O., Rhodin, H., Shafiei, M., Seidel, H.P., Xu, W., Casas, D., Theobalt, C., 2017c. Vnect: Real-time 3d human pose estimation with a single rgb camera]将时间信息和运动体模型作为平滑滤波器拟合骨架。
- [Rhodin, H., Salzmann, M., Fua, P., 2018a. Unsupervised geometry-aware representation for 3d human pose estimation]使用编解码器网络通过自监督学习潜在变量体模型，然后使用预训练的编码器来预测三维姿态。

除这些典型的人体模型外，从数据中学习到的潜在$3D$姿态模型也用于$3D$人体姿态估计。

- [Tome, D., Russell, C., Agapito, L., 2017. Lifting from the deep: Convolutional 3d pose estimation from a single image]提出了一个多级**CPM**网络，包括一个预训练的概率三维姿态模型层，它可以从二维热图中生成三维姿态。

## 3D多人人体姿态估计 3D multi-person pose estimation
$3D$多人姿态估计方法基于$3D$单人姿态估计方法。

![](https://pic.downk.cc/item/5fb341c3b18d627113fa5b67.jpg)

- [Mehta, D., Sotnychenko, O., Mueller, F., Xu, W., Sridhar, S., Pons-Moll, G., Theobalt, C., 2017b. Single-shot multi-person 3d body pose estimation from monocular rgb input]提出了一种自下而上的方法，利用二维姿态和部分亲和字段来推断人体。通过**遮挡-鲁棒姿态映射(ORPM)**提供多风格的遮挡信息，而不考虑人数。
- [Rogez, G., Weinzaepfel, P., Schmid, C., 2017. Lcr-net: Localization-classification-regression for human pose]提出了一个三阶段的**本地化分类-回归网络(LCR-Net)**。首先使用**Faster R-CNN**检测人员的位置，其次对每个姿态分配一个分类器指向**anchor**姿态，最后用回归器进行细化。
- [Zanfir, A., Marinoiu, E., Sminchisescu, C., 2018. Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints]提出了一个具有前馈和反馈后向阶段的三维多人姿态和形状估计框架。前馈过程包括身体部位的语义分割和基于**DMHS**的三维姿态估计。反馈后向阶段细化**SMPL**的姿态和形状参数。
- [Mehta, D., Sotnychenko, O., Mueller, F., Xu, W., Elgharib, M., Fua, P., Seidel, H.P., Rhodin, H., Pons-Moll, G., Theobalt, C., 2019. Xnect: Realtime multi-person 3d human pose estimation with a single rgb camera]通过三个阶段实时估计多个人体姿态。首先，**SelcSLS网络**为可见身体关节注入$2D$姿态和中间$3D$姿态编码。然后根据每个检测到的人重建完整的三维姿态。最后，细化时间稳定性和运动学骨架。

# ③ 数据集 Datasets

### （1）Datasets for 2D human pose estimation
本节介绍超过$1000$张的$2D$人体姿态估计数据集。

![](https://pic.downk.cc/item/5fb341edb18d627113fa683b.jpg)

- **Frames Labeled In Cinema (FLIC) Dataset**
- **Leeds Sports Pose (LSP) Dataset**
- **Max Planck Institute for Informatics (MPII) Human Pose Dataset**
- **Microsoft Common Objects in Context (COCO) Dataset**
- **AI Challenger Human Keypoint Detection (AIC-HKD) Dataset**

除了上述静态图像数据集，下面提到了一些具有密集注释视频帧的数据集。这些数据集包括更接近现实生活的应用场景，提供了利用时间信息的可能性，并可用于动作识别。

- **Penn Action Dataset**
- **Joint-annotated Human Motion Database (J-HMDB)**
- **BBC Pose**
- **YouTube Pose**
- **MPII Video Pose**
- **PoseTrack**

### （2）Datasets for 3D human pose estimation
本节总结了涉及**RGB**图像和三维联合坐标的$3D$人体姿态估计数据集。

![](https://pic.downk.cc/item/5fb34225b18d627113fa775e.jpg)

- **HumanEva-I&II Datasets**
- **Human3.6M Dataset**
- **TNT15 Dataset**
- **MPI-INF-3DHP**
- **TotalCapture Dataset**
- **MARCOnI Dataset**
- **Panoptic Dataset**
- **3DPW Dataset**

# ④ 评估工具 Evaluation protocol

### （1）Evaluation Metrics of 2D human pose estimation
不同的数据集具有不同的特征(如不同范围的人体大小和不同的任务要求)，因此具有不同的评价指标。

![](https://pic.downk.cc/item/5fb34209b18d627113fa6f1f.jpg)

- **Percentage of Correct Parts (PCP)**：如果肢体的两个端点距离和**GT**端点距离相比在阈值范围内，则认为肢体定位正确。该指标统计了定位正确的肢体百分比。
- **Percentage of Correct Keypoints (PCK)**：如果候选关节点位于**GT**关节点的阈值像素内，则认为关节点定位正确。
- **The Average Precision (AP)**：参考目标检测的**AP**计算方法，如果预测的关节位于**GT**关节点的阈值像素内，则将其计算为真阳性；否则为假阳性。可以进一步计算所有关节的**平均精度(mAP)**。
- **Average Precision (AP), Average Recall (AR) and their variants**：计算方法与上面类似。
- **Frame Rate, Number of Weights and Giga Floating-point Operations Per Second (GFLOPs)**：计算性能指标也非常重要。**帧速率**表示输入数据的处理速度，通常由**帧每秒(FPS)**或**秒每图像(s/Image)**表示。**权重数**和**GFLOP**显示了网络的效率，主要与网络设计和特定使用的**GPU/CPU**有关。这些指标也适用于$3D$姿态估计。

### （2）Evaluation Metrics of 3D human pose estimation

- **Mean Per Joint Position Error (MPJPE)**：是评价$3D$姿态估计性能的最广泛的方法。它计算估计的三维关节和**GT**三维关节之间的欧氏距离（以毫米为单位），并在一幅图像中的所有关节上取平均。在一组帧的情况时再在所有帧上取平均。
- **Percentage of Correct Keypoints (PCK) and Area Under the Curve (AUC)**：**PCK**记录了在一个阈值内正确关键点的百分比，**AUC**通过一系列不同的阈值计算。
- **Mean Per-vertex Error**：计算估计和**GT**网格之间的误差。
