---
layout: post
title: 'Learning Continuous Image Representation with Local Implicit Image Function'
date: 2020-12-22
author: 郑之杰
cover: 'https://pic.downk.cc/item/5fe1d1513ffa7d37b3707878.jpg'
tags: 论文阅读
---

> LIIF：学习2D图像的连续表达形式.

- paper：Learning Continuous Image Representation with Local Implicit Image Function
- arXiv：[link](https://arxiv.org/abs/2012.09161)
- code：[github](https://github.com/yinboc/liif)

对于人类视觉系统，图像是一种连续形式；对于计算机系统，图像是以$2D$矩阵的离散形式存储的。
作者提出了一种连续图像的表达形式。它在离散$2D$图像与连续$2D$图像之间构建连接，能够对图像进行分辨率调整，可以实现“无极放大”。

# 模型介绍

作者提出了一种**Local Implicit Image Function (LIIF)**表示，它采用图像坐标和$2D$深度特征作为输入，输出给定位置的**RGB**值。具体地，每张连续图像$I^{(i)}$是由$2D$特征图$M^{(i)} \in \Bbb{R}^{H \times W \times D}$表示的。所有图像共享一个**neural implicit function** $f_{\theta}$，用多层感知机**MLP**为其建模，并表示为：

$$ s = f(z,x) $$

其中$z$是特征向量；$x \in \mathcal{X}$是连续图像域中的$2D$坐标，$s \in \mathcal{S}$是预测的**RGB**值。每个特征向量$z$可以看作一个映射：$f(z, \cdot):\mathcal{X} \to \mathcal{S}$，该映射可以表示连续图像。

假设$2D$特征图$M^{(i)}$的$H \times W$个特征向量均匀分布在连续图像域空间中，如下图所示。

![](https://pic.downk.cc/item/5fe1df3b3ffa7d37b37f5970.jpg)

对于连续图像$I^{(i)}$，在坐标$x_q$处的**RGB**值定义为：

$$ I^{(i)}(x_q) = f(z^*,x_q-v^*) $$

其中$z^\*$表示距离$x_q$最近的特征向量，$v^\*$表示该特征向量对应的坐标。

为丰富特征信息，对特征进行**Feature unfolding**。即用$3 \times 3$邻域的特征丰富该点的特征：

$$ \hat{M}^{(i)}_{jk} = Concat( \{ {M}^{(i)}_{j+l,k+m} \} _{l,m \in \{ -1,0,1 \} }) $$

上述方法存在的问题是，$x_q$处的预测**RGB**值依赖于其最近的特征向量$z^\*$，当$x_q$在图像域中移动时，特征向量的选择可能会突然跳转，这导致输出图像的不连续性问题。

为解决上述问题，采用**Local ensemble**技术。其实就是用双线性插值重新计算了在坐标$x_q$处的**RGB**值：

$$ I^{(i)}(x_q) = \sum_{t \in \{ 00,01,10,11 \} }^{} \frac{S_t}{S} \cdot f(z_t^*,x_q-v_t^*) $$

作者进一步考虑到每个像素的面积信息，引入**Cell decoding**。扩充上述函数为：

$$ s = f_{cell} (z,[x,c]) $$

其中$c = \[c_h, c_w\]$包含像素的高度和宽度信息(如$64 \times 64$分辨率，则$c=\frac{1}{64}$)。当$c$趋近于$0$时，可以看作连续图像。

![](https://pic.downk.cc/item/5fe1df563ffa7d37b37f73b8.jpg)


# 模型训练

![](https://pic.downk.cc/item/5fe1df963ffa7d37b37fcc14.jpg)

对于训练图像，通过对其进行随机下采样生成输入。**Ground truth**是把训练图像表示为像素样本$x_{hr},s_{hr}$，其中$x_{hr}$表示图像域的中心坐标，$s_{hr}$是其对应的**RGB**值。

模型同时训练一个编码器$E_{\phi}$和一个**neural implicit function** $f_{\theta}$。编码器将输入图像映射成$2D$特征图，作者选择超分辨率模型**EDSR**和**RDN**实现。

# 实验分析
作者选用了**DIV2K**进行模型训练，采用**DIV2K-val**等进行验证。输入图像块大小为$48 \times 48$，训练过程中尺度在$1$-$4$之间均匀采样，**batch**$=16$；损失函数为**L1**；**LIIF**为五层**MLP**(维度为$256$)。初始学习率为$10^{-4}$，每$200$轮减半，共训练$1000$轮。

下表给出了所提方法与**Bicubic**、**MetaSR**等在**DIV2K-val**数据集上的**PSNR**指标对比。可以看出，所提方法取得全面性的超越；在超出训练尺度外，所提方法所取得优势更大。

![](https://pic.downk.cc/item/5fe1e3e93ffa7d37b3848df3.jpg)

下图给出了所提方法在$30 \times$超分上的效果对比。可以看到，所提方法生成的结果更为自然，无任何伪影问题；而**MetaSR**则存在严重的伪影问题。

![](https://pic.downk.cc/item/5fe1e3923ffa7d37b3844043.jpg)
