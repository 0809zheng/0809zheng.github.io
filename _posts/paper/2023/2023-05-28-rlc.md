---
layout: post
title: 'Towards Partial Supervision for Generic Object Counting in Natural Scenes'
date: 2023-05-28
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6684f331d9c307b7e9d14ade.png'
tags: 论文阅读
---

> 面向自然场景中通用目标计数的部分监督.

- paper：[Towards Partial Supervision for Generic Object Counting in Natural Scenes](https://arxiv.org/abs/1912.06448)

[<font color=blue>Lower-Count (LC)</font>](https://0809zheng.github.io/2023/05/27/lc.html)框架是一种低数量图像级监督的计数框架，仅需要标记出小于4个计数样本的类别。本文在此基础上提出了更低的低数量计数 **reduced lower-count(RLC)**。**RLC**框架利用类别的子集和剩下类别的 “类别-标签” 信息，能够进一步降低大量目标类别的标记成本。

**LC**框架的设置考虑到了小于4个的目标类别，但自然场景中可能存在大量的目标类别，此种情况下**LC**的标注也是非常麻烦的。因此对于目标计数来说，需要更具有挑战性的部分监督设置，即所有图像类别的标签是已知的情况下，只需要知道目标类别的一个子集上类别的少数量标注，这就是**RLC**监督的定义。

![](https://pic.imgdb.cn/item/6684f414d9c307b7e9d30474.png)

**RLC**框架使得目标计数器能够泛化到没有数量标注的类别上。**RLC**框架是在**LC**双分支框架上拓展的：首先引入一个权重调制层，能迁移标记好的计数类别知识到没有任何数量标注的类别上，同时又为了增强其泛化性(未标记的类别和不相关的类别)，在密度分支上又引入了一个类别无关的子分支，可以估计一幅图像的所有目标数量。

![](https://pic.imgdb.cn/item/6684f50bd9c307b7e9d4eac2.png)

为了解决一些类别中数量标签不提供的情况，引入权重调制层：修改分类分支卷积层的权重来产生特定类别的密度图，该密度图用于估计所有类别中特定类别的数量。调制层的结构是一个$P\times\frac{P}{2}$的全连接层+正则化的 **softmax** 非线性层+ $\frac{P}{2}\times{P}$的全连接层(相当于一个瓶颈结构)。对于标注类别训练的卷积权重$\omega_{cls}^{c}$，穿过权重调制层$\Psi$得到未标注类别的卷积$\omega_{cnt}^{c}$，以进一步获得任意类别的密度图：

$$
w_{c n t}^{c}=\Psi\left(w_{c l s}^{c}\right), \mathrm{D}^{c}=w_{c n t}^{c} * \mathrm{~F}_{\mathrm{cnt}}
$$

独立类别子分支由1个单通道$1\times 1$卷积组成，输入为 $\text{F}^{\text{cnt}}$，对输出$\text{D}^{tot}$整个区域求和可得独立类别的总数量，即$$\hat{t}_{t o t}=\sum_{i j} \mathrm{D}_{i j}^{t o t}$$。

采用带有数量标注的$S$和$\tilde S$来训练独立类别分支，其 **GT** 数量$t_{tot}$记为:

$$
t_{t o t}=\sum_{c \in S} t_{c}+(\tilde{t} \times|\tilde{S}|)
$$

独立类别分支的训练损失为：

$$
\mathcal{L}_{t o t}=\mathcal{L}_{M S E}\left(\hat{t}_{t o t}, t_{t o t}\right) [ Z=0 ]+\mathcal{L}_{r a n k}\left(\hat{t}_{t o t}, t_{t o t}\right) [ Z>0 ]
$$

其中$Z$为数量标注未提供的目标类别的总数，记为：$Z=\|\tilde{s}\|+\|{\mathcal B}\prime\|$。其中$\|{\mathcal B}\prime\|$为$\mathcal B$类别中的正样本集合。$${L}_{M S E}=\left(\hat{t}_{t o t}- t_{t o t}\right)^2$$为均方误差损失，$$\mathcal{L}_{\text {rank }}\left(\hat{t}_{\text {tot }}, t_{\text {tot }}\right)=\max \left(0, t_{\text {tot }}-\hat{t}_{\text {tot }}\right)$$为排序损失。

独立类别密度图$\text{D}^{tot}$和目标类别图$\text{M}^{c}$一起产生空间注意力图$\text{G}^{c}$：利用 **sigmoid** 激活函数得到归一化后的$\hat{\text{M}^{c}}$。类别为$c$的空间注意力图$\mathbf{G}^{c}=\hat{\mathbf{M}}^{c} \circ \mathbf{D}^{t o t}$，$\mathbf{G}^{c}$作为相应的伪标签$\text{D}^{c}$获得特定类别的密度图$\hat{\text{D}}^{c}=\mathrm{D}^{c} \circ \mathrm{G}^{c}$。

通过累积整个空间区域内的$\hat{\mathrm{D}}^{c}$，特定类别的目标总数量为$${\hat t}_{c}=\sum_{i j} \hat{\mathrm{D}}_{i j}^{c}$$，其中$i,j$为矩阵中元素的坐标。该特定类别的子分支可用 **LRC** 损失函数$$\mathcal{L}_{\text {rcount }}$$来训练：

$$
\mathcal{L}_{\text {rcount }}=\mathcal{L}_{M S E}\left(\hat{t}_{c}, t_{c}\right) [ c \in S ]+\mathcal{L}_{\text {rank }}\left(\hat{t}_{c}, \tilde{t}\right) [ c \in \tilde{S} ]
$$

需要注意的是，预测的总数${\hat t}_c$是空间注意力$\text{G}^{c}$加权给密度图$\hat{\mathrm{D}}^{c}$得到的，因此在最小化计数误差的同时，空间分布信息将会保留下来。

由于产生$\text{D}^{c}$的卷积权重$\omega_{cnt}^{c}$是根据调制层$\Psi\left(\omega_{cls}^{c}\right)$得到的，因此在最小化 **LRC** 损失$\mathcal{L}_{\text {rcount }}$时也会训练无关类别的权重调制层$\Psi$。

