---
layout: post
title: 'Towards Open-Set Object Detection and Discovery'
date: 2023-11-04
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/655c6d2bc458853aef539ec2.jpg'
tags: 论文阅读
---

> 面向开集目标检测与挖掘.

- paper：[Towards Open-Set Object Detection and Discovery](https://arxiv.org/abs/2204.05604)

在之前的 **open-set object detection (OSOD)** 方法中，除了检测识别已知物体外，还会检测一些未知类别的物体，但把所有未知的物体都归到 “未知类”。本文提出 **Open-Set Object Detection and Discovery (OSODD)**，不仅可以检测未知物体，还可以挖掘它们潜在的类别。**OSODD** 采用了两阶检测方式，先对已知物体和未知物体进行预测，然后通过无监督和半监督方式学习预测到物体的表征并进行聚类，从而挖掘出未知物体的类别。

![](https://pic.imgdb.cn/item/655c6dcbc458853aef5554c6.jpg)

在 **OSODD** 中，假设已知类为 $$C_k = \{C_1, C_2,...,C_m\}$$；未知类为 $$C_u = \{C_{m+1}, C_{m+2}, ..., C_{m+n}\}$$，$C_k$ 和 $C_u$ 没有交集。训练集只包含 $C_k$，而测试集是 $C_k$ 和 $C_u$ 的合集。模型的任务就是对所有物体进行定位和分类 $I = [c, x, y, w, h]$，已知物体归于$C_k$，未知物体则归于 $C_u$。

**OSODD** 包含两个部分，分别是 **Object Detection and Retrieval (ODR)** 和 **Object Category Discovery (OCD)**。
- **ODR** 是一个带有两个记忆缓存的开集检测器，对于已知物体，检测器预测位置信息和类别；对于未知物体，只预测其位置信息。其中已知物体和类别信息储存在 **known memory** 中，未知物体则储存在 **working memory** 中。
- **OCD** 则是主要利用 **working memory** 来挖掘未知物体的类别，包含了一个特征编码器和聚类辨别器。首先使用非监督对比学习方式，从 **known** 和 **working memory** 中训练一个编码器，在 **latent space** 中学习更好的物体表征。最后用 **constrained k-means** 来进行聚类。

![](https://pic.imgdb.cn/item/655c6f42c458853aef59a09d.jpg)

## ⚪ Object Detection and Retrieval

**ODR**主要是对所有物体进行定位，同时对已知物体进行分类，且把未知物体归到“**unknown**” 一类。文中使用了 **faster-rcnn** 作为模型的 **backbone**，利用了 **RPN** 对类别无感知的特性，把那些与 **ground-truth** 没有重叠且置信度比较高的候选框作为未知物体。为了让物体的特征更具有区别性，作者在**ROI**损失中额外引入了对比损失，也就是计算从 **ROI pooling** 中得到的特征和模板（该类别特征的滑动平均值）之间的差异：

$$
\ell_{p c l}(f_{c})=\sum_{i=0}^{c}\ell(f_{c},p_{i})\\
\ell(f_{c},p_{i})=
    \begin{cases}||f_{c},p_{i}||, &\mathrm{if~}i=c\\ \mathrm{max~}(0,\Delta-||f_{c},p_{i}||), &\mathrm{oherwise}\end{cases}
$$

## ⚪ Object Category Discovery

因为未知物体的类别是不确定的，只能通过一些方式来挖掘出这些物体潜在的类别信息，文中采用了 **DCT**，主要是通过一种特殊的无参数学习的 **k-mean** 来估计潜在的类别数目。为了更好地挖掘未知物体的潜在类别，作者在 **OCD** 中加入了一个 **encoder**，用来学习更有判别性的 **embedding**。在**encoder** 中使用 **known memory** 和 **working memory** 来进行对比学习，增大 **positive pairs** 的相似度，而减小 **negative pairs** 的相似度，这样更有益于后面的聚类操作。对比学习的 **InfoNCE loss** 为：

$$
\ell_{q,\{k\}}=-\log\frac{\exp(q\cdot k^{+}/\tau)}{\exp(q\cdot k^{+}/\tau)+\sum_{k^{-}}\exp(q\cdot k^{-}/\tau)}
$$

## ⚪ 实验分析

在实验中，作者把数据分成两种，对应着不同的 **Known / Unknown**。对于已知类物体，采用 **mAP** 作为检测评价标准，对于未知类物体，则采用 **UDR** 和 **UDP** 作为检测评价标准：

$$
\mathrm{UDR}=\frac{TP_{\mathrm{u}}+F N^*_{\mathrm{u}}}{\mathrm{TP_{\mathrm{u}}+F N_{\mathrm{u}}}}\\
\mathrm{UDP}=\frac{TP_{\mathrm{u}}}{TP_{\mathrm{u}}+F N^*_{\mathrm{u}}}
$$

因为是 **unknown class**，所以不确定具体哪个物体的类别 **ID**具体是多少，**OCD**通过 **k-mean** 来聚类。所以必须对**unknown object** 的**labe**l 进行排列组合，算出最大的**ACC**作为最终的聚类准确率：

$$
\mathrm{ACC}=\max_{p\in P_{y}}\frac{1}{N}\sum_{i=1}^{N}\mathrm{1}\left\{y_{i}=p(\hat{y}_i)\right\}
$$

对于类别挖掘的评价指标，作者还采用了归一化互信息和聚类纯度：

$$
\mathrm{NM}=\frac{I(C l,\widehat{C l})}{[H(C l)+H(\widehat{C l})]/2} \\
\mathrm{purity}=\frac{1}{N}\sum_{i=1}^{N}\max_{k}|C l_{k}\cap \widehat{C l}_i|
$$

![](https://pic.imgdb.cn/item/655c7447c458853aef68d01a.jpg)

![](https://pic.imgdb.cn/item/655c7467c458853aef692e7a.jpg)