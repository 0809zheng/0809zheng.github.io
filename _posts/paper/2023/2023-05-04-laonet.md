---
layout: post
title: 'Object Counting: You Only Need to Look at One'
date: 2023-05-04
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/667cccded9c307b7e9cd1091.png'
tags: 论文阅读
---

> 目标计数：你只需要看一个.

- paper：[Object Counting: You Only Need to Look at One](https://arxiv.org/abs/2112.05993)

本文旨在解决单次目标计数的问题，具体来说，仅采用包含一个示例样本边界框的图像作为输入，来统计出该类别所有目标的个数。单样本计数存在的主要问题：
1. 目标计数任务中包含不同的类别，甚至一张图片里面就有多个类别，而在少样本计数中，这些类别在训练和推理阶段不会重叠；
2. 在单样本计数中，模型仅仅能从单个实例中学习；
3. 目标的尺寸、形状可能差异较大。


本文提出了一种**Look At One instance(LaoNet)**网络来解决该问题。**LaoNet**主要由三个部分组成：特征提取、特征关联、密度回归。

![](https://pic.imgdb.cn/item/667cce3ad9c307b7e9cf0745.png)

单样本计数由训练数据集$$\left(I_{t},s_{t},y_{t}\in \mathcal T\right)$$和序列集$$\left(I_{q},s_{q}\in \mathcal Q\right)$$组成，而模型的输入由一幅图像$I$和一个边界框$s$组成。训练时，$y_t$作为点标注提供；推理时，单样本$s_q$和图像一起提供。

**特征提取**模块采用**VGG-19**作为**backbone**，取其最后一层输出直接展平。对于单样本，采用尺度聚合机制融合不同尺度的信息：

$$
S=\operatorname{Concat}\left(\mathcal{F}^{l}(s), \mathcal{F}^{l-1}(s), \ldots, \mathcal{F}^{l+1-\delta}(s)\right)
$$

其中，$l$为CNN的层数，$\mathcal{F}^{i}$为第$i_{th}$层的特征图，$\delta\in[1,l]$决定了聚合哪些层的特征。另外，加上位置特征以区分整合的尺度信息。

**特征关联**模块用于学习查询样本和图像特征之间的关系。首先通过**Self-Attention**模块分别学习两种图像序列的类内关系，然后通过关联注意力学习两者的类间关系，这使得网络能够对不同尺度目标更加鲁棒。

**密度回归**模块用于回归密度图，密度回归器由1个下采样层和3个带有ReLU激活的卷积层（2个1x1，1个1x1）组成。采用欧几里得距离来衡量预测的密度图与**GT**密度图之间的差异：

$$
\mathcal{L}_{E}=\left\|D^{g t}-D\right\|_{2}^{2}
$$
​
其中$D$为预测的密度图，$D^{gt}$为**GT**密度图。为了提高局部样式一致性，还采用了$\textrm{SSIM}$损失，最终总损失为：

$$
\mathcal{L}=\mathcal{L}_{E}+\lambda \mathcal{L}_{S S I M}
$$

