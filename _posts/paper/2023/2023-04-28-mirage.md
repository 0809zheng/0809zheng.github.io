---
layout: post
title: 'Are Emergent Abilities of Large Language Models a Mirage?'
date: 2023-04-28
author: 郑之杰
cover: 'https://pic1.imgdb.cn/item/67fe0b3588c538a9b5d18695.png'
tags: 论文阅读
---

> 大型语言模型的涌现能力只是海市蜃楼吗？

- paper：[Are Emergent Abilities of Large Language Models a Mirage?](https://arxiv.org/abs/2304.15004)

# 0. TL; DR

本文探讨了大型语言模型（**LLMs**）中所谓的“涌现能力”现象，即某些能力在小型模型中不存在，但在大型模型中突然出现。文章提出，这些所谓的“涌现能力”可能并非模型内在的特性，而是研究者选择的评估指标导致的。通过数学模型和实验分析，文章发现使用非线性或不连续的评估指标会导致性能的突然变化，而使用线性或连续的指标则显示性能的平滑、连续和可预测的提升。因此，文章认为所谓的“涌现能力”可能只是研究者选择的评估指标造成的幻觉。

# 1. 背景介绍

近年来，大型语言模型（**LLMs**）如**GPT、PaLM**和**LaMDA**等在自然语言处理（**NLP**）领域取得了显著进展。这些模型在某些任务上表现出所谓的“涌现能力”，即在小型模型中不存在的能力在大型模型中突然出现。这种现象引起了广泛关注，因为它表明模型的性能提升可能并非完全可预测。

“涌现能力”的两个关键特征是：
1. **突然性（Sharpness）**：能力在模型规模扩大时突然出现。
2. **不可预测性（Unpredictability）**：能力出现的模型规模无法预测。

这些特征使得“涌现能力”成为研究的热点，同时也引发了关于**AI**安全和对齐的问题。例如，如果模型突然获得某种能力，可能会带来不可预见的风险。

# 2. 方法介绍

文章提出了一个关键观点：所谓的“涌现能力”可能是由于研究者选择的评估指标导致的，而非模型内在的特性。具体来说，非线性或不连续的评估指标会导致性能的突然变化，而线性或连续的指标则显示性能的平滑、连续和可预测的提升。

假设模型的每**token**交叉熵损失（**LCE**）随模型参数数量（N）呈幂律下降：

$$
LCE(N) = \left(\frac{N}{c}\right)^\alpha
$$

其中 $c > 0$ 和 $\alpha < 0$ 是常数。

模型选择正确**token**的概率为：

$$
p(\text{single token correct}) = \exp(-LCE(N))
$$

如果研究者选择一个非线性评估指标，如准确率（**Accuracy**），则性能随目标序列长度呈几何下降(体现出涌现能力)：

$$ \text{Accuracy}(N) \approx \left(p(\text{single token correct})\right)^L
$$

而如果选择一个线性评估指标，如**token**编辑距离（**Token Edit Distance**），则性能随目标序列长度呈近似线性下降（没有体现涌现能力）：

$$
\text{Token Edit Distance}(N) \approx L \left(1 - p(\text{single token correct})\right)
$$

![](https://pic1.imgdb.cn/item/67fe0c9288c538a9b5d18847.png)


# 3. 实验分析

文章通过以下三种方式验证了这一观点：
1. 使用**InstructGPT/GPT-3**模型家族，对两个算术任务（两位数乘法和四位数加法）进行实验，验证不同评估指标下的性能变化。
2. 对**BIG-Bench**基准测试中的“涌现能力”进行元分析，验证不同评估指标下的性能变化。
3. 在多个视觉任务中，通过改变评估指标，诱导出所谓的“涌现能力”。

## 3.1 InstructGPT/GPT-3模型家族的算术任务

文章首先对**InstructGPT/GPT-3**模型家族在两个算术任务（两位数乘法和四位数加法）上进行了实验。实验结果表明：
- 当使用非线性评估指标（如准确率）时，模型性能在目标序列长度较长时表现出突然提升（图上）。
- 当使用线性评估指标（如**token**编辑距离）时，模型性能随模型规模的增加表现出平滑、连续和可预测的提升（图下）。

![](https://pic1.imgdb.cn/item/67fe0d6d88c538a9b5d18914.png)

文章进一步通过增加测试数据量，提高了性能评估的分辨率。结果表明，即使是使用非线性评估指标（如准确率），所有模型的性能也表现出平滑、连续和可预测的提升。

![](https://pic1.imgdb.cn/item/67fe0d9488c538a9b5d18945.png)

## 3.2 BIG-Bench基准测试中的“涌现能力”

文章对**BIG-Benc**h基准测试中的“涌现能力”进行了元分析，发现：
- 大多数“涌现能力”出现在特定的评估指标下，尤其是非线性和/或不连续的指标。![](https://pic1.imgdb.cn/item/67fe0dcf88c538a9b5d1899d.png)
- 改变评估指标可以消除“涌现能力”。![](https://pic1.imgdb.cn/item/67fe0de688c538a9b5d189b4.png)

## 3.3 在视觉任务中诱导“涌现能力”

文章在**CIFAR100**自然图像数据集上训练的浅层非线性自编码器中，通过定义一个不连续的评估指标（**Reconstructionc**），诱导出所谓的“涌现能力”。

![](https://pic1.imgdb.cn/item/67fe0e1488c538a9b5d189f6.png)

文章在训练自回归**Transformer**分类**Omniglot**手写字符的任务中，通过重新定义准确率为分类所有图像正确，诱导出所谓的“涌现能力”。

![](https://pic1.imgdb.cn/item/67fe0e2488c538a9b5d189fe.png)