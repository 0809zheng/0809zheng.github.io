---
layout: post
title: 'Object Counting and Instance Segmentation with Image-level Supervision'
date: 2023-05-27
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6684c1c3d9c307b7e96e351e.png'
tags: 论文阅读
---

> 使用图像级监督的目标计数与实例分割.

- paper：[Object Counting and Instance Segmentation with Image-level Supervision](https://arxiv.org/abs/1903.02494)

现有的计数方法要么依赖于实例水平的标注或者绝对的计数信息来训练出通用的目标计数器。本文引入一种低数量图像级监督的设置（仅需要标记出小于4个计数样本的类别）来减少用于通用目标计数所需的标注，提出了低数量计数 **Lower-count(LC)**框架。

**LC**框架由图像分类分支和密度分支组成，图像分类分支估计当前图像内是否存在目标类别，密度分支预测特定类别的目标数量。仅使用少数量的监督，**LC** 模块能够减少标注的成本；此外密度分支构建出密度图来预测每个目标类别的实例在空间中的分布，因此可进行图像水平的实例分割（弱监督实例分割）。

设训练图像为$I$，对应的$C$个类别的 **GT** 计数向量标签为$$t={\{}t_1,t_2,\dots,t_c,\dots,t_C{\}}$$。对于一幅图像来说，可以根据他们包含的实例数量划分为三个不重叠的集合：
- $S_0$：目标类别并未出现在图像中，即$t_c=0$；
- $S$：目标类别数量较少，$0\leq t_c \leq4$；
- $\tilde{S}$：目标类别数量较多，$t_c\geq 5$。

**LC**框架建立在 **ResNet50** 上，为了保留空间信息除去了全局平均池化层。其主干是两个输出分支：分类分支预测特定类别的目标是否出现在图像上；密度图分支预测特定类别的数量以及每个目标类别的空间分布。

这两个分支的输入都是 2048 维的特征。之后两个分支分别接上两个 $1\times1$ 卷积分开，得到 $C$ 个通道的特征，$C$是目标类别的数量。然后分别生成目标类别图用于帮助目标定位，和密度图用于评估给定区域内目标的数量。

![](https://pic.imgdb.cn/item/6684c60ed9c307b7e9767942.png)

设图像分类分支中的目标类别图为：

$$
\mathbf{M}=\left\{\mathbf{M}^{c} \in \mathbb{R}^{H \times W} \quad: c \in[1, C]\right\}
$$

由密度分支产生的特定类别密度图为：

$$
\mathbf{D}=\left\{\mathbf{D}^{c} \in \mathbb{R}^{H \times W} \quad: c \in[1, C]\right\}
$$

为了解决无点标注监督的问题，本文提出利用图像分类器的粗定位能力来产生一个空间**mask**。对目标类别图利用局部最大位置来产生空间**mask**用作训练密度分支时的伪标签：

$$
\tilde{\mathbf{M}}^{c}(i, j)= \begin{cases} M^c(i,j), & M^c(i,j)>M^c(i−r_i,j−r_j) \\ 0, & \text{otherwise} \end{cases}
$$
​
其中$-r \leq r_i,r_j \leq r$为计算局部最大值时的半径。为了训练图像分类器， 第$i$个目标类别的得分$s^c$设为$\tilde{\mathbf{M}}^{c}$上的非零元素平均值。而对于这种二分类任务，采用多标签软间隔损失函数来训练。

图像分类分支在峰值图$\tilde{\mathbf{M}}^{c}$中使用类别置信度得分可以预测出目标类别在不在图像中，而在图像类别分类分支中获得的目标类别图可以提供一个粗目标定位，为密度图提供空间上的指引。但是由于缺乏有关目标实例数量的先验信息，因此很难区分出单个目标和多个目标，这可能会导致大量的虚假正样本出现在峰值图$\tilde{\mathbf{M}}^{c}$中。因此引入了一个硬空间指导模块来利用计数信息并从峰值图$\tilde{\mathbf{M}}^{c}$中产生一个空间**mask**。

对于所有的目标类别$c\in{S}$，峰值图$\tilde{\mathbf{M}}^{c}$中的第$t_c$个最大的峰值$h_c$可以根据 **heap-max** 算法得到，之后$h_c$用来产生空间 **mask** $\text{B}^{c}$：

$$
\text{B}^{c}=u\left(\tilde{\mathbf{M}}^{c}-{h_c}\right)
$$

其中$u\left(n\right)$为单位步长函数，即$n \geq 0$时，$u\left(n\right)=1$。之后用空间**mask**作为伪标签来监督密度分支的空间损失，而这个特性也使得密度图中保留着目标的空间分布信息，从而提高了实例分割的性能。

密度分支产生特定类别的密度图$\text D^{c}$，其中的像素一方面表明了有多少个目标属于类别$c$，另一方面也可以估计出目标类别$c$的数量，同时在目标类别图$\text M^{c}M$上的像素也表明了该像素属于目标类别$c$的置信度。密度分支采用两个损失函数：$\mathcal L_{spatial}$损失确定了每个目标实例的位置，同时$\mathcal L_{global}$确定了特定类别的目标数量。

空间损失$\mathcal L_{spatial}$分为$\mathcal L_{sp+}$和$\mathcal L_{sp-}$：

$$
\mathcal {L}_{spatial}=\hat{\mathcal{L}}_{s p+}{[ c \in S ]}+\hat{\mathcal{L}}_{s p-}{[ c \in S_{0} ],}
$$

$\mathcal L_{sp+}$的作用是增强$S$类别中对应的正峰值；为了采用$\mathcal L_{spatial}$来监督密度图，本文利用了空间 **mask** $\text{B}^{c}$来作为伪监督 **GT mask**。虽然在$\text{B}^{c}$上的非零元素意味着目标的位置，但是 0 元素并不意味着该像素对应着背景。因此，可以用 **mask** 密度图$\tilde{\text D}^{c}$来排除掉密度图$\text{D}^{c}$位置上为 0 的值，该位置对应 $\text{B}^{c}$位置上为 0 的像素。同时密度图$\text{D}^{c}$上的值也可以在训练和反向传播时被除去(防止引入虚假的负样本)：

$$
\tilde{\mathrm{D}}^{c}=\mathrm{D}^{c} \odot \mathbf{B}^{c}
$$
 
$\mathcal L_{sp+}$表示为：

$$
\mathcal{L}_{s p+}\left(\tilde{\mathbf{D}}^{c}, \mathbf{B}^{c}\right)=-\sum_{\forall c \in S} \frac{\operatorname{sum}\left(\mathbf{B}^{c} \odot \log \left(\sigma\left(\tilde{\mathbf{D}}^{c}\right)\right)\right)}{|S| \cdot \operatorname{sum}\left(\mathbf{B}^{c}\right)}
$$
​
$\mathcal L_{sp-}$用于惩罚$S_{0}$类别中假的正样本峰值。对于$c\in {S}_{0}$，$\text{D}^{c}$中正的激活值意味着错误的检测，即虚假的正样本。因此一个全为 0 值的 **mask** $\mathbb 0_{H\times{W}}$可以用作 **GT** 来减少这种错误的检测：

$$
\mathcal{L}_{s p-}\left(\mathbf{D}^{c}, \mathbf{0}_{H \times W}\right)=-\sum_{c \in S_{0}} \frac{\operatorname{sum}\left(\log \left(1-\sigma\left(\mathbf{D}^{c}\right)\right)\right)}{\left|S_{0}\right| \cdot H \cdot W}
$$
 
尽管空间损失$\mathcal L_{spatial}$能保存目标的空间分布信息，但只依赖于局部信息可能会导致目标计数存在偏差，因此引入计数损失$\mathcal L_{global}$。计数损失包含排序损失$\mathcal L_{rank}$和均方误差损失$\mathcal L_{MSE}$：

$$
\mathcal{L}_{\text {count }}=\hat{\mathcal{L}}_{M S E} [ c \in S_{0}, S ]+\lambda * \hat{\mathcal{L}}_{\text {rank }} [ c \in \tilde{S} ]
$$

对于超出低数量范围的目标类别($\vee{c}\in \tilde {S}$)，采用排序损失$\mathcal L_{rank}$惩罚$\tilde{S}$中过低的目标类别计数:

$$
\mathcal{L}_{\text {rank }}\left(\hat{t_{c}}, \tilde{t}\right)=\sum_{c \in \tilde{S}} \frac{\max \left(0, \tilde{t}-\hat{t_{c}}\right)}{|\tilde{S}|}
$$

对于剩余的类别，均方误差损失$\mathcal L_{MSE}$惩罚与 **GT** 数量不匹配的特定类别的预测：

$$
\mathcal{L}_{M S E}\left(\hat{t_{c}}, t_{c}\right)=\sum_{c \in\left\{S_{0}, S\right\}} \frac{\left(\hat{t_{c}}-t_{c}\right)^{2}}{\left|S_{0}\right|+|S|}
$$
 
其中$\hat {t_c}$为类别$c$的密度图在其整个区域内的求和，即$\hat {t_c}=\text{sum}\left(\text{D}^{c}\right)$。

作者对不同损失函数进行消融：

![](https://pic.imgdb.cn/item/6684f01dd9c307b7e9caf1e0.png)