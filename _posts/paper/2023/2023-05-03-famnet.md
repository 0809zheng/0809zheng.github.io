---
layout: post
title: 'Learning To Count Everything'
date: 2023-05-03
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/667cbee2d9c307b7e9b943f6.png'
tags: 论文阅读
---

> 学习计数任意目标.

- paper：[Learning To Count Everything](https://arxiv.org/abs/2104.08391)

本文提出了一个小样本计数网络**FamNet**，相比于流行的计数网络，通用性更强。流行的计数网络多数针对单类物体，比如针对人群、动物、细胞、交通工具、植物等。该模型通用性更强，但可能对某种类别计数不如专门训练过的网络。

**FamNet**的网络结构如图所示。模型输入原图和几个标注框的位置，通过冻结的**resnet 50**的全卷积部分提取特征图，并通过**FPN**的多尺度来强化特征；然后通过**ROI pooling**将标注框的特征池化到统一大小；最后通过卷积计算**ROI**特征和全图特征的相关性，并通过密度估计模块（由5个卷积和3个下采样层组成）预测密度图。

![](https://pic.imgdb.cn/item/667cc6d2d9c307b7e9c3e8a0.png)

在训练时需要构造密度图作为**Ground Truth**。构建密度图的过程：使用适当的窗口尺寸进行高斯平滑。具体来说，首先采用点标注来估计目标的尺寸：计算每一个点和最近邻点的距离以及所有点的平均距离，这一平均距离作为高斯滑动窗口的尺寸用来产生密度图，高斯分布的标准差设为窗口尺寸的四分之一。损失采用均方误差(**MSE**)。

在推理阶段，提出一种适应损失用于提升估计模块的精度，关键在于充分利用边界框样本的位置信息（在训练阶段利用的是样本外观特征信息）。推理阶段继续迭代损失更新网络。

适应损失函数由**Min-Count loss**和**Perturbation Loss**组成：

$$
\mathcal{L}_{Adapt} = \lambda_1\mathcal{L}_{MinCount} + \lambda_2\mathcal{L}_{Per}
$$

其中**Min-Count loss**约束每个目标框对应位置的物体数量应该至少是1个，若小于1个就产生损失，大于等于1不产生损失：

$$
\mathcal{L}_{MinCount}=\sum_{b\in B}\max(0, 1-||Z_b||_1)
$$

**Perturbation Loss**是指给定一个需要跟踪的物体以及它的标注框，当一个框位于标注框的位置时有最大的响应值，当这个框偏离了标注框，它的响应值会随着干扰距离的增加而呈指数衰减，通常为高斯分布。设$G_{h\times w}$为尺寸是$h\times w$的2D高斯分布图，干扰损失计算为：


$$
\mathcal{L}_{Per} = \sum_{b\in B}||Z_b-G_{h\times w}||_2^2
$$

此外作者还开源了一个小样本物体计数的数据集**FSC147**，共有6135张图像，147类物体，主要由厨房餐具、办公文具、信纸、交通工具、动物等组成。数量从7-3731，平均每张图的物体数量是56。通常每张图只有一类物体有标注（点标注），每张图只有三个物体有额外的框标注。数据集的划分：训练集：3659张，89类；验证集：1286张，29类；测试集：1190张，29类，总计147类。

![](https://pic.imgdb.cn/item/667cc83ed9c307b7e9c6820c.png)