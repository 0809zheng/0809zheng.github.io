---
layout: post
title: 'Class-agnostic Few-shot Object Counting'
date: 2023-05-18
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/668258c8d9c307b7e9849b30.png'
tags: 论文阅读
---

> 类别无关少样本目标计数.

- paper：[Class-agnostic Few-shot Object Counting](https://openaccess.thecvf.com/content/WACV2021/papers/Yang_Class-Agnostic_Few-Shot_Object_Counting_WACV_2021_paper.pdf)

本文提出了一种有效的目标计数网络：类别无关少样本目标计数网络(**Class-agnostic Fewshot Object Counting Network, CFOCNet**)，它能够根据输入的参考图像对任意类别的目标进行计数。**CFOCNet**网络由一个双流**Resnet**编码器和一个解码器组成。编码器分别提取查询图像和参考图像的特征，通过相关操作来嵌入两个分支的信息以计算不同尺度下的匹配分数；解码器通过可训练的加权求和机制融合编码器生成的分数图，以生成预测的密度图。

![](https://pic.imgdb.cn/item/66825ae1d9c307b7e987af93.png)

编码器有两个流，一个是查询流，另一个是参考流。查询流和参考流使用了**Resnet-50**的前三个块，因为它具有强大的特征表示能力。为了计算查询图像与参考目标的匹配度，使用池化操作对编码器提取的参考图像特征进行聚合，在查询特征上使用自注意力机制促使模型关注由于重复目标的而产生的自相似性。然后通过无参数卷积计算匹配分数图，其中参考图像池化特征作为卷积核，自注意力增强的查询特征作为输入特征。

由于查询图像的尺度变化，需要一个尺度感知的融合机制。这项工作提出了一种可学习的加权求和融合机制，使模型根据编码器生成的匹配分数自动加权到期望的尺度上。为了计算三个匹配分数图的加权和，首先通过1x1卷积+求和+**Softmax**计算每个匹配分数图的权重，然后对匹配分数图进行加权融合。由于融合后特征的空间分辨率为原始图像的1/8，因此输出密度图只需通过转置卷积和双线性上采样即可生成。

作者使用**COCO**数据集进行实验评估，使用**4-fold**验证，将80个目标类别分成60/20进行训练和测试。因此，测试阶段的20类目标在训练阶段是不可见的，这可以衡量模型对新类别的泛化能力。

![](https://pic.imgdb.cn/item/66825ea5d9c307b7e98d68bf.png)