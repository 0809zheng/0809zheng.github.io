---
layout: post
title: 'Dilated-Scale-Aware Attention ConvNet For Multi-Class Object Counting'
date: 2023-05-24
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/6684b0bbd9c307b7e94ea30b.png'
tags: 论文阅读
---

> 多类别目标计数的扩张尺度感知注意力卷积网络.

- paper：[Dilated-Scale-Aware Attention ConvNet For Multi-Class Object Counting](https://arxiv.org/abs/2012.08149)

本文提出用点标注的方式进行多类别目标计数。具体来说，首先将单目标计数密度图改为多类别目标计数图。而由于所有类别的目标都采用同一特征提取器，因此目标特征会在特征空间内进行交互，所以本文设计了一种多任务结构来抑制目标之间的这种负的交互/联系。

![](https://pic.imgdb.cn/item/6684b1a4d9c307b7e950373f.png)

本文提出了一种**Dilated-Scale-Aware Attention ConvNet (DSAA)**来实现多类别目标计数。具体来说，**DSAA** 由两个模块 **Dilated-Scale-Aware Module(DSAM)** 和 **Category-Attention Module (CAM)** 组成。首先利用**VGG16**提取特征图，**DSAM** 采用不同的卷积扩张率来提取不同尺度的特征，用于融合这些特征图。由于共享特征提取器，预测的密度图彼此会进行交互，**CAM**模块用于减少不同类别密度图中的负关联。

![](https://pic.imgdb.cn/item/6684b223d9c307b7e9514206.png)

单类别目标计数方法主要采用高斯核在点标注上滑动，来产生密度图以及预测出单类别的数量。为了实现多类别计数，本文同样采用高斯核，但预测的是所有类别的密度图。

**DSAM**模块通过扩张卷积融合多尺度的特征信息，应用不同尺度的扩张卷积分别在 **stage_3,4,5** 上，之后经过下采样和拼接操作后，一个 $3\times 3$的卷积操作用于融合这些多尺度的特征。

**CAM**模块产生区分性强的密度图，主要是分别处理每个类别的空间注意力。**CAM** 仅采用 **stage_5** 上的特征图作为输入，因为该层具有更加丰富的语义信息。具体来说，首先利用距离转换将点图转化为距离图$S$：

$$
S_{(x, y)}=\min _{\left(x_{i}, y_{i}\right) \in A} \sqrt{\left(x-x_{i}\right)^{2}+\left(y-y_{i}\right)^{2}}
$$

通过使用阈值$J$将距离图$S$上的点划分为0-1来获得伪标签注意力图。之后经过多个卷积和拼接操作来联合多尺度的特征图。这里卷积指的是采用扩张因子为$1,2,3,4$的扩张卷积。空间注意力图的数量等于类别的数量。预测的空间注意力图和预测的密度图相乘获得最终的密度图，这一操作能有效减少类别间的联系。

利用$L_2$损失来衡量**GT**密度图和预测密度图之间的区别：

$$
L_{2}=\sum_{n=1}^{N} \sum_{x=1}^{W} \sum_{y=1}^{H}\left|P_{(n, x, y)}^{\prime}-P_{(n, x, y)}\right|^{2}
$$

采用相同的损失来训练 **DASM**，即$L_{2}^{\prime}$。采用 **BCE** 损失来训练 **CAM**：

$$
L_{B C E}=-\frac{1}{W \times H} \sum_{n=1}^{N} \sum_{x=1}^{W} \sum_{y=1}^{H}\left(\left(T_{(n, x, y)} \times \log R_{(n, x, y)}\right)\right.\left.+\left(1-T_{(n, x, y)}\right) \times \log \left(1-R_{(n, x, y)}\right)\right)
$$

其中$$T_{(n,x,y)}\in {\{}0,1{\}}$$表示位置$(x,y)$处第$n$个类别的伪标签注意力 **mask**。$R_{(n,x,y)}\in[0,1]$表示位置$(n,x,y)$处预测的空间注意力。

