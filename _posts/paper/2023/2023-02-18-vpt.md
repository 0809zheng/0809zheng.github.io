---
layout: post
title: 'Visual Prompt Tuning'
date: 2023-02-18
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/657a6f86c458853aef2566d0.jpg'
tags: 论文阅读
---

> 视觉提示微调.

- paper：[Visual Prompt Tuning](https://arxiv.org/abs/2203.12119)

把大模型应用于下游任务时，通常的策略是进行端到端的全面微调（**full fine-tuning**），然而这种策略需要为每个任务存储部署单独的主干参数，代价比较高。

一种简单的方法是仅微调参数的子集，如下图（a）：如分类器头部或者偏差项。之前的研究还会试着向主干添加额外的残差结构或者**adapter**。然而这些策略会在准确度上略差于执行完全微调。

本文介绍**Visual Prompt Tuning（VPT）**作为一种有效的用于大规模**Transformer**的视觉微调。它只需要在输入空间引入少量（不到$1\%$的模型参数）的可训练参数，同时冻结**backbone**。实践中，这些附加参数只是预先加入到**Transformer**每层输入序列中，并在微调时和线性头一起学习。

在**ViT**预训练微调的**24**个跨域的下游任务中，**VPT**优于其他迁移学习的**baseline**，有**20**个超过了完全微调，同时保持了为每个单独任务储存较少参数的优势。

![](https://pic.imgdb.cn/item/657bf213c458853aef2fef83.jpg)


对于一个$N$层的**ViT**，输入的图片被分为$m$个**patch** $I_j,j=1,...,m$。每一个**patch**和位置编码**embedding**连接后被嵌入到$d$维潜在空间。给定一个预先训练好的**Transformer**，在**Embed**层后的输入空间引入一组$d$维的连续**prompt**。在微调过程中，只有**prompt**会被更新，主干将会冻结。

![](https://pic.imgdb.cn/item/657bf5cbc458853aef3f9841.jpg)

根据加入**prompt**的层数量分为浅**VPT**和深**VPT**。

**VPT-Shallow**是指**Prompt**仅插入第一层。每一个**prompt token**都是一个可学习的$d$维参数。

$$
\begin{aligned}
\left[\mathbf{x}_{1},\mathbf{Z}_{1},\mathbf{E}_{1}\right]&=L_{1}\left(\left[\mathbf{x}_{0},\mathbf{P},\mathbf{E}_{0}\right]\right)\\ 
\left[\mathbf{x}_{i},\mathbf{Z}_{i},\mathbf{E}_{i}\right]&=L_{i}\left(\left[\mathbf{x}_{i-1},\mathbf{Z}_{i-1},\mathbf{E}_{i-1}\right]\right)\\ 
\mathbf{y}&=\text{Head}(\mathbf{x}_{N})
\end{aligned}
$$

**VPT-Deep**是指**Prompt**被插入每一层的输入序列。

$$
\begin{aligned}
\left[\mathbf{x}_{i},\_\_,\mathbf{E}_{i}\right]&=L_{i}\left(\left[\mathbf{x}_{i-1},\mathbf{P}_{i-1},\mathbf{E}_{i-1}\right]\right)\\ 
\mathbf{y}&=\text{Head}(\mathbf{x}_{N})
\end{aligned}
$$

**VPT**对于多个下游任务都是有帮助的，只需要为每个任务存储学习到的**prompt**和分类头，重新使用预训练的**Transformer**，从而显著降低存储成本。

作者做了关于**prompt**位置的消融实验，本文提出的**prepend**与直接在**embedding**上添加对比效果更好。除此之外，作为前置像素或者**concat**通道的效果也都在下降。

![](https://pic.imgdb.cn/item/657bf8b8c458853aef4c32cd.jpg)

作者做了关于**prompt**长度的消融实验，最佳提示长度因任务而异，即使只有一个**prompt**，深**VPT**的效果仍显著优于另外两种方法。

![](https://pic.imgdb.cn/item/657bfa3ec458853aef52a683.jpg)

作者做了关于**prompt**深度的消融实验，从上到下插入**prompt**，准确性会显著下降。这表明前面**Transformer**层的**prompt**比后面层更加重要。

![](https://pic.imgdb.cn/item/657bfa8dc458853aef53bd71.jpg)

作者做了关于输出**head**位置的消融实验，结果表明使用**CLS token**或者图像**patch**的输出特征进行预测效果最好。

![](https://pic.imgdb.cn/item/657bfb5bc458853aef56f30d.jpg)