---
layout: post
title: 'VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition'
date: 2023-04-03
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/649cf8201ddac507ccd19d5e.jpg'
tags: 论文阅读
---

> VoxNet：用于实时目标识别的3D卷积神经网络.

- paper：[VoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition](https://ieeexplore.ieee.org/document/7353481)

本文提出了一种用于快速且精确的**3D**点云数据目标识别框架**VoxNet**。**VoxNet**把点云转换为体积占用网格表示（**Volumetric Occupancy Grid representation**），并通过三维卷积神经网络进行分类。

![](https://pic.imgdb.cn/item/649cf8b11ddac507ccd27e3c.jpg)

# 1. Volumetric Occupancy Grid

**Occupancy grids**将当前的环境表示为随机变量的**3D**网格（**voxel**），并且将它们占据的空间概率估计视为数据输入和先验知识的函数。在**volumetric**表示中，每个点$(x, y, z)$都要被映射到离散的**voxel**坐标$(i, j, k)$中，该映射过程会考虑**voxel**网格的原点、方向和分辨率：
- 原点(**origin**)：通过分割算法或是检测框得到的点云输入。
- 方向(**orientation**)：网格方向的$z$轴就是重力的方向，可以使用**IUM**或是使传感器垂直实现。
- 分辨率(**resolution**)：对于**LiDAR**数据采用$0.1×0.1×0.1m^3$的分辨率，保证了各个目标间尺度信息的一致性；对于其他数据集采用$$32×32×32 \text{ voxel}^3$$的分辨率，但是目标所占用的空间应该在$$24×24×24 \text{ voxel}^3$$内。

令$$\left\{z^{t}\right\}_{t=1}^{T}$$表示所有体素的状态。本文尝试了三种体素表示：

### ⚪ Binary Occupancy Grid

对于一个体素$(i, j, k)$，假设有两个状态，分别为**occupied**（$z^{t}=1$） 或是 **unoccupied**（$z^{t}=0$）。

对于每一个体素，**occupancy**的概率估计是通过**log odds**来更新的：

$$
l_{i j k}^{t}=l_{i j k}^{t-1}+z^{t} l_{\mathrm{occ}}+\left(1-z^{t}\right) l_{\text {free }}
$$
 
$l_{\mathrm{occ}}$和$l_{\text {free }}$是这个单元的**log odds**，本文设置这些参数为$l_{\mathrm{occ}}=1.38, l_{\text {free }}=−1.38$，并且将**log odds**截断为$(-4,4)$以避免数值不稳定问题。**occupancy**最初被设置为$0.5$，$l_{i j k}^{0}=0$。

### ⚪ Density Grid

在该模型中，每个体素都被假设有一个连续的强度，对应着传感器采集而来的概率。对于所有的体素$(i, j, k)$，设置参数$\alpha_{i j k}^{t},\beta_{i j k}^{t}$，初始时$\alpha_{i j k}^{0}=\beta_{i j k}^{0}=1$。每个体素更新时都会受到$z_{t}$的影响：

$$
\begin{aligned}
α^t_{ijk}&=α^{t−1}_{ijk}+z^t \\
β^t_{ijk}&=β^{t−1}_{ijk}+(1−z^t)
\end{aligned}
$$
 

最后平均值表示为：

$$
\mu_{i j k}^{t}=\frac{\alpha_{i j k}^{t}}{\alpha_{i j k}^{t}+\beta_{i j k}^{t}}
$$
​
$\mu_{i j k}$被作为输入。

### ⚪ Hit Grid

在此模型中仅考虑**hit**，初始状态下$l_{i j k}^{0}=0$，更新过程如下：


$$
h_{i j k}^{t}=\min \left(h_{i j k}^{t-1}+z^{t}, 1\right)
$$

尽管该模型丢掉了一些潜在的变量信息，但是实验证明其性能很好。

# 2. VoxNet

**VoxNet**的结构很简单：

$$
C(32, 5, 2)−C(32, 3, 1)−P(2)−FC(128)−FC(K)
$$

其中$K$表示类别的数量。**VoxNet**对于数据进行归一化范围为$(-1,1)$，该模型有**921736**个参数，其中大多数都集中在第一层。

为了解决旋转不变性问题，在训练时使用数据增强：把每个模型旋转$360°/n$度，多增加了$n$倍的数据。在测试的时候，每个目标的输入的角度也不同，输出层的维度也要增加$n$倍，最后采取投票的方式确定到底属于哪一类。可以避免过拟合现象。

分辨率较高的**Volumetric Occupancy Grid**会得到更精细的特征，分辨率较低的**Volumetric Occupancy Grid**能够获得全局特征。本文中使用两个相同的框架处理两个分辨率不一样的**Volumetric Occupancy Grid**，为了让这两个模型进行融合，直接将两个$FC(128)$拼接，连接到**softmax**输出层。

