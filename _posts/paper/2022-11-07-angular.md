---
layout: post
title: 'Deep Metric Learning with Angular Loss'
date: 2022-11-07
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/63c7bc8cbe43e0d30e67811f.jpg'
tags: 论文阅读
---

> 通过角度损失实现深度度量学习.

- paper：[Deep Metric Learning with Angular Loss](https://arxiv.org/abs/1708.01682v1)

在深度度量学习中，[<font color=blue>Triplet Loss</font>](https://0809zheng.github.io/2022/11/02/triplet.html)为每一个样本$x_a$选择一个正样本$x_p$和一个负样本$x_n$，同时最小化正样本对之间的距离和最大化负样本对之间的距离。

$$ \mathcal{L}_{tri} =  \max(0, ||x_a-x_p||^2 -||x_a-x_n||^2 + \epsilon) $$

**Triplet Loss**对应的样本梯度为：

$$ \frac{\partial \mathcal{L}_{tri}}{\partial x_a} = 2(x_n-x_p) \\ \frac{\partial \mathcal{L}_{tri}}{\partial x_p} = 2(x_p-x_a) \\ \frac{\partial \mathcal{L}_{tri}}{\partial x_n} = 2(x_a-x_n) $$

**Triplet Loss**对尺度变化很敏感，并且不具有旋转不变性。尽管样本梯度使得正样本$x_p$接近样本$x_a$，负样本$x_n$远离样本$x_a$，但是无法保证正样本$x_p$和负样本$x_n$相互远离：

![](https://pic.imgdb.cn/item/63c7c099be43e0d30e6d1160.jpg)

本文设计了**角度损失(angular loss)**，该损失引入了三元组的三阶几何限制，具有尺度不变性和旋转不变性，提高了目标对于特征差异的鲁棒性。

为使得负样本$x_n$远离样本$x_a$和正样本$x_p$，构造样本$x_a$和正样本$x_p$的中心点$x_c=(x_a+x_p)/2$，并以其为圆心作圆；连接$x_n$与$x_c$后作垂线与圆相交于点$x_m$。若角度$n'$减小，则$x_n$同时远离样本$x_a$和正样本$x_p$。

![](https://pic.imgdb.cn/item/63c7db41be43e0d30e9cde87.jpg)

存在如下几何关系：

$$ \tan n' = \frac{||x_m-x_c||}{||x_n-x_c||} = \frac{||x_a-x_p||}{2||x_n-x_c||} $$

预定义角度$n'$的上界$\alpha$（实验设置$45^{\circ}$），则存在关系：

$$ \frac{||x_a-x_p||}{2||x_n-x_c||} \leq \tan \alpha \leftrightarrow ||x_a-x_p|| \leq 2\tan \alpha ||x_n-x_c||  $$

尽可能减小角度$n'$，等价于最小化以下损失函数：

$$ \mathcal{L}_{ang} =  \max(0, ||x_a-x_p||^2 -4 \tan^2 \alpha||x_n-x_c||^2) $$

上述损失对应的样本梯度为：

$$ \begin{aligned} \frac{\partial \mathcal{L}_{ang}}{\partial x_a} &= 2(x_a-x_p)-2 \tan^2 \alpha(x_a+x_p-2x_n) \\ \frac{\partial \mathcal{L}_{ang}}{\partial x_p} &= 2(x_p-x_a) - 2 \tan^2 \alpha(x_a+x_p-2x_n)  \\ \frac{\partial \mathcal{L}_{ang}}{\partial x_n} &= 4\tan^2 \alpha(x_a+x_p-2x_n) \end{aligned} $$

根据梯度方向观察可得，负样本$x_n$沿着$x_cx_n$方向远离样本$x_a$和正样本$x_p$，而样本$x_a$和正样本$x_p$彼此接近。

使用**PyTorch**自定义角度损失：

```python
class AngularLoss(nn.Module):
    def __init__(self, alpha=45, p=2):
        super(AngularLoss, self).__init__()
        self.alpha = alpha / 180 * np.pi
        self.p = p
        
    def forward(self, anchor, positive, negative):
        center = (anchor + positive) / 2
        pos_dist = F.pairwise_distance(anchor, positive, self.p)
        neg_dist = F.pairwise_distance(center, negative, self.p)
        loss = F.relu(pos_dist - 4 * torch.tan(self.alpha) ** 2 * neg_dist)
        return loss.mean()
```

角度损失可以从三元组形式扩展到**N-pair**形式，即考虑正样本$x_p$的同时考虑$N-1$个来自其他类别的负样本$x_n^1,...,x_n^{N-1}$。

![](https://pic.imgdb.cn/item/63c7ea53be43e0d30eb64217.jpg)

此时把**Hinge**损失中的$\max$函数替换成一个平滑上界$\log (\exp(y_1)+\exp(y_2)) \geq \max(y_1,y_2)$。对特征进行归一化($$\|x\|=1$$)，则三元组$(x_a,x_p,x_n)$的角度损失近似为：

$$ \begin{aligned} \mathcal{L}_{ang} &≈  \log(\exp(0) + \exp( ||x_a-x_p||^2 -4 \tan^2 \alpha||x_n-x_c||^2)) \\ & = \log (1+\exp( ||x_a||^2-2x_a^Tx_p + ||x_p||^2 -4 \tan^2 \alpha (||x_n||^2-(x_a+x_p)^Tx_n+\frac{||x_a+x_p||^2}{4}) )) \\ & = \log (1+\exp( 2-2x_a^Tx_p  -4 \tan^2 \alpha (1-(x_a+x_p)^Tx_n+\frac{2+2x_a^Tx_p}{4}) )) \\ & = \log (1+\exp( 2-2x_a^Tx_p  -4 \tan^2 \alpha (1-(x_a+x_p)^Tx_n+\frac{2+2x_a^Tx_p}{4}) )) \\ & \propto \log (1+\exp(4 \tan^2 \alpha (x_a+x_p)^Tx_n-2(1+\tan^2\alpha )x_a^Tx_p)) \end{aligned} $$

对于一批样本，角度损失计算为：

$$  \mathcal{L}_{ang}(\mathcal{B}) = \frac{1}{|\mathcal{B}|} \sum_{x_a \in \mathcal{B}} \log (1+\sum_{x_n \in \mathcal{B}, y_n \neq y_a,y_p} \exp(4 \tan^2 \alpha (x_a+x_p)^Tx_n-2(1+\tan^2\alpha )x_a^Tx_p)) $$