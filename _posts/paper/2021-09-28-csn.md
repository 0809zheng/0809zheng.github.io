---
layout: post
title: 'Cross-stitch Networks for Multi-task Learning'
date: 2021-09-28
author: 郑之杰
cover: 'https://pic.imgdb.cn/item/62dd3433f54cd3f93739b83e.jpg'
tags: 论文阅读
---

> Cross-stitch Network：用于多任务学习的十字绣网络.

- paper：[Cross-stitch Networks for Multi-task Learning](https://arxiv.org/abs/1604.03539)

本文作者设计了一种**十字绣网络(Cross-stitch Network)**，可以在多任务学习范式下学习共享表示和任务特定表示的最佳组合。

# 1. 分析实验

作者首先构造了一个分析实验，用于了解共享表示和任务特定表示的不同组合之间的性能权衡。具体地，分别在“属性分类与目标检测”以及“语义分割和表面法线估计”这两类相关任务上训练了**AlexNet**，并设置了不同的网络结构共享程度。

![](https://pic.imgdb.cn/item/62de3979f54cd3f93756698f.jpg)

图中最左端的网络从第一个卷积**conv2**到全连接层**fc7**的所有层都是参数共享的，只有最后一个全连接层**fc8**是特定于任务的。而最右端的网络是完全任务独立的。作者计算了不同共享程度下共享网络与独立网络之间的性能差异，

![](https://pic.imgdb.cn/item/62de399df54cd3f93757251e.jpg)

语义分割和表面法线估计任务的最佳性能是使用“**Split conv4**”架构，而属性分类与目标检测任务分别使用**Split conv2**以及**Split fc6**能获得最佳性能。这些结果表明：
1. 以多任务方式学习的网络比单任务训练的网络更具优势；
2. 多任务学习的最佳网络分割结构取决于不同的任务。

因此多任务学习的网络结构设计具有任务依赖性，缺乏探索结构的原则性方法导致列举每一组任务的所有可能结构是不切实际的。本文作者设计了一种**十字绣单元**，能够通过单个网络同时实现所有拆分的结构，并自动学习共享表示和任务特定表示的最佳组合，从而比暴力枚举和搜索发现的网络获得更好的性能。

# 2. 十字绣网络 Cross-stitch Network

十字绣网络是为具有多种不同任务标签的相同输入结构(如图像)设计的。比如使用同一个输入图像$x$解决任务$A,B$，首先分别为这两个任务训练两个网络，十字绣单元通过最两个网络的激活图进行线性组合来建模共享表示。即对激活图的任意位置$(i,j)$：

$$ \begin{bmatrix} \tilde{x}_{A}^{ij} \\ \tilde{x}_{B}^{ij} \end{bmatrix} =  \begin{bmatrix} \alpha_{AA} & \alpha_{AB} \\ \alpha_{BA} & \alpha_{BB} \end{bmatrix}  \begin{bmatrix} x_{A}^{ij} \\ x_{B}^{ij} \end{bmatrix} $$

![](https://pic.imgdb.cn/item/62de3e04f54cd3f9376e39ea.jpg)

十字绣单元的反向传播过程如下：

$$ \begin{bmatrix} \frac{\partial L}{\partial x_{A}^{ij}} \\ \frac{\partial L}{\partial x_{B}^{ij}} \end{bmatrix} =  \begin{bmatrix} \alpha_{AA} & \alpha_{BA} \\ \alpha_{AB} & \alpha_{BB} \end{bmatrix}   \begin{bmatrix} \frac{\partial L}{\partial \tilde{x}_{A}^{ij}} \\ \frac{\partial L}{\partial \tilde{x}_{B}^{ij}} \end{bmatrix} \\ \frac{\partial L}{\partial \alpha_{AA}}  = \frac{\partial L}{\partial \tilde{x}_{A}^{ij}} x_{A}^{ij} ,\frac{\partial L}{\partial \alpha_{AB}}  = \frac{\partial L}{\partial \tilde{x}_{A}^{ij}} x_{B}^{ij} \\ \frac{\partial L}{\partial \alpha_{BA}}  = \frac{\partial L}{\partial \tilde{x}_{B}^{ij}} x_{A}^{ij} ,\frac{\partial L}{\partial \alpha_{AB}}  = \frac{\partial L}{\partial \tilde{x}_{B}^{ij}} x_{B}^{ij} $$

通过改变线性组合的数值，该单元可以在共享表示和任务特定表示之间自由组合，并根据实际任务选择最合适的表示。

![](https://pic.imgdb.cn/item/62de4275f54cd3f937854565.jpg)

# 3. 实验分析

作者评估了十字绣单元中不同$\alpha$初始化值、不同学习率；以及不同网络初始化值对实验结果的影响。结果表明：
- 同一任务内的组合系数应初始化较高的值，不同任务之间的组合系数应初始化较低的值，两者可以按照凸组合进行初始化。
- 对十字绣单元使用比基本网络更高的学习率能够导致更快的收敛和更好的性能。
- 对不同任务的网络分别进行初始化的性能优于对所有网络同步初始化的性能。

![](https://pic.imgdb.cn/item/62de44aef54cd3f93790a569.jpg)

作者对不同初始化情况下网络学习到的线性组合参数进行可视化(升序排序)。其中$\alpha_S$表示同一任务内的组合系数$\alpha_{AA},\alpha_{BB}$，其值越大表明网络更倾向学习更多任务特定的特征表示；$\alpha_D$表示不同任务之间的组合系数$\alpha_{AB},\alpha_{BA}$，其值越大表明网络更倾向学习更多共享的特征表示。

结果表明，在所有初始化条件下，这两个任务都更喜欢在**pool5**学习到特定于任务的表示（$\alpha_S$较大）；曲面法线任务更喜欢学习共享的表示（$\alpha_S$和$\alpha_D$范围接近）。

![](https://pic.imgdb.cn/item/62de4709f54cd3f9379d1f49.jpg)

作者汇报了两种多任务情况下的模型性能比较，十字绣网络均取得不错的性能：

![](https://pic.imgdb.cn/item/62de47f4f54cd3f937a1f52b.jpg)

多任务学习有助于规范化共享特征的学习，这相当于一种正则化策略，能够在一些数据匮乏的类别中提高表现。作者给出了语义分割任务中不同类别的像素数量与模型的表现情况，结果表明该模型大大提高了数据匮乏的类别的性能。

![](https://pic.imgdb.cn/item/62de4896f54cd3f937a5635d.jpg)

类似地，该网络也能在属性分类任务上通过学习共享表示为数据匮乏的属性提供显著的收益。

![](https://pic.imgdb.cn/item/62de48f6f54cd3f937a759e3.jpg)