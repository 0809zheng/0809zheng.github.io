---
layout: post
title: '卷积神经网络 综述'
date: 2020-02-01
author: 郑之杰
cover: ''
tags: 深度学习
---

> Papers about Convolutional Neural Networks.

# Survey

### A Survey of the Recent Architectures of Deep Convolutional Neural Networks
- arXiv:[https://arxiv.org/abs/1901.06032](https://arxiv.org/abs/1901.06032)


# CNN History

### Receptive fields, binocular interaction and functional architecture in the cat's visual cortex
- intro:Hubel,Wiesel
- pdf:[http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf)

### Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition
- intro:neocognitron
- pdf:[https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf](https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf)


# CNN Components

### A Theoretical Analysis of Feature Pooling in Visual Recognition
- intro:pooling
- pdf:[https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf](https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf)

### Activation Functions: Comparison of trends in Practice and Research for Deep Learning
- intro:activation functions
- arXiv:[https://arxiv.org/abs/1811.03378](https://arxiv.org/abs/1811.03378)

### Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
- intro:batch norm
- arXiv:[https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)

### Dropout: A Simple Way to Prevent Neural Networks from Overfitting
- intro:dropout
- pdf:[http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)


# CNN Architectures

### Gradient-based learning applied to document recognition
- intro:LeNet5
- pdf:[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

![](https://pic.downk.cc/item/5e82aee6504f4bcb04cdd1bc.png)

### ImageNet Classification with Deep Convolutional Neural Networks
- intro:AlexNet
- keypoint:local response normalization、ReLU、dropout、group convolution
- pdf:[http://stanford.edu/class/cs231m/references/alexnet.pdf](http://stanford.edu/class/cs231m/references/alexnet.pdf)

![](https://pic.downk.cc/item/5e82af1b504f4bcb04cdfba2.png)

### Visualizing and Understanding Convolutional Networks
- intro:ZFNet
- keypoint:deconvolution、unpooling
- arXiv:[https://arxiv.org/abs/1311.2901](https://arxiv.org/abs/1311.2901)

![](https://pic.downk.cc/item/5e82af70504f4bcb04ce4445.png)

### Network In Network
- intro:NiN
- keypoint:1×1 conv、global average pooling
- arXiv:[https://arxiv.org/abs/1312.4400](https://arxiv.org/abs/1312.4400)

![](https://pic.downk.cc/item/5e816d3b504f4bcb04f28f50.png)

### Very Deep Convolutional Networks for Large-Scale Image Recognition
- intro:VGG16、VGG19
- arXiv:[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)

![](https://static.oschina.net/uploads/space/2018/0314/022939_Pl12_876354.png)

### Going Deeper with Convolutions
- intro:GoogLeNet
- keypoint:inception、split-transform-merge
- arXiv:[https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)

![](https://pic.downk.cc/item/5e8170f0504f4bcb04f4f7b5.png)
[GoogLeNet结构](https://static.oschina.net/uploads/space/2018/0317/141544_FfKB_876354.jpg)

### Highway Networks
- intro:Highway Networks
- arXiv:[https://arxiv.org/abs/1505.00387](https://arxiv.org/abs/1505.00387)

![](https://pic.downk.cc/item/5e817166504f4bcb04f546f3.png)


### Rethinking the Inception Architecture for Computer Vision
- intro:Inception-V2、Inception-V3
- arXiv:[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)

![](https://pic.downk.cc/item/5e818862504f4bcb040451fb.png)


### Deep Residual Learning for Image Recognition
- intro:ResNet
- keypoint:skip connection
- arXiv:[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)

![](https://pic.downk.cc/item/5e8172ce504f4bcb04f63231.png)


### Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- intro:Inception-V4, Inception-ResNet
- arXiv:[https://arxiv.org/abs/1602.07261v1](https://arxiv.org/abs/1602.07261v1)

Inception-V4:
![](https://pic.downk.cc/item/5e82afcf504f4bcb04ce8d19.jpg)
![](https://pic.downk.cc/item/5e82afe2504f4bcb04ce99d5.jpg)
![](https://pic.downk.cc/item/5e82aff4504f4bcb04cea61f.jpg)

Inception-ResNet:
![](https://pic.downk.cc/item/5e82b009504f4bcb04ceb33c.jpg)
![](https://pic.downk.cc/item/5e82b01a504f4bcb04cebd2f.png)

### SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size
- intro:SqueezeNet
- keypoint:fire module
- arXiv:[https://arxiv.org/abs/1602.07360](https://arxiv.org/abs/1602.07360)

![](https://pic.downk.cc/item/5e82b031504f4bcb04cecd60.png)
![](https://pic.downk.cc/item/5e82b044504f4bcb04ced960.png)

### Stacked Hourglass Networks for Human Pose Estimation
- intro:Hourglass Network
- arXiv:[https://arxiv.org/abs/1603.06937](https://arxiv.org/abs/1603.06937)

![](https://pic.downk.cc/item/5e82b057504f4bcb04cee503.png)

### Deep Networks with Stochastic Depth
- intro:Stochastic Depth
- arXiv:[https://arxiv.org/abs/1603.09382](https://arxiv.org/abs/1603.09382)

![](https://pic.downk.cc/item/5e8175b9504f4bcb04f82c8d.png)


### Wide Residual Networks
- intro:WideResNet
- arXiv:[https://arxiv.org/abs/1605.07146](https://arxiv.org/abs/1605.07146)

![](https://pic.downk.cc/item/5e8175f2504f4bcb04f851cc.png)


### Densely Connected Convolutional Networks
- intro:DenseNet
- arXiv:[https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)

![](https://pic.downk.cc/item/5e82b06c504f4bcb04cef7ae.png)


### Xception: Deep learning with depthwise separable convolutions
- intro:Xception
- keypoint:Depthwise Separable Convolution(depthwise + pointwise)
- arXiv:[https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357)

![](https://pic.downk.cc/item/5e82b07f504f4bcb04cf06e0.png)


### Deep Pyramidal Residual Networks
- intro:Pyramidal ResNet
- arXiv:[https://arxiv.org/abs/1610.02915](https://arxiv.org/abs/1610.02915)

![](https://pic.downk.cc/item/5e818246504f4bcb04008f58.png)


### Aggregated Residual Transformations for Deep Neural Networks
- intro:ResNeXt
- keypoint:cardinality
- arXiv:[https://arxiv.org/abs/1611.05431](https://arxiv.org/abs/1611.05431)

![](https://pic.downk.cc/item/5e81810c504f4bcb04ffcb7c.png)


### MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
- intro:MobileNet
- keypoint:Depthwise Separable Convolution(pointwise + depthwise)
- arXiv:[https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)

![](https://pic.downk.cc/item/5e8183cb504f4bcb04016f4b.png)


### Residual Attention Network for Image Classification
- intro:Residual Attention Network
- keypoint:trunk brunch + mask brunch
- arXiv:[https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)

![](https://pic.downk.cc/item/5e82b31f504f4bcb04d14747.png)


### ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
- intro:ShuffleNet
- keypoint:group convolution + channel shuffle
- arXiv:[https://arxiv.org/abs/1707.01083](https://arxiv.org/abs/1707.01083)

![](https://pic.downk.cc/item/5e82b098504f4bcb04cf1784.png)
![](https://pic.downk.cc/item/5e82b0ab504f4bcb04cf26dd.png)


### Squeeze-and-Excitation Networks
- intro:SENet
- arXiv:[https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)

![](https://pic.downk.cc/item/5e82b533504f4bcb04d2fbf5.png)
![](https://pic.downk.cc/item/5e82b54c504f4bcb04d30d40.png)


### MobileNetV2: Inverted Residuals and Linear Bottlenecks
- intro:MobileNetV2
- arXiv:[https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)

![]()


### Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks
- intro:cSE(即SENet)、sSE、scSE
- arXiv:[https://arxiv.org/abs/1803.02579](https://arxiv.org/abs/1803.02579)

![](https://pic.downk.cc/item/5e82b6f7504f4bcb04d478f4.png)


### A New Channel Boosted Convolutional Neural Network using Transfer Learning
- intro:Channel Boosted CNN
- arXiv:[https://arxiv.org/abs/1804.08528v4](https://arxiv.org/abs/1804.08528v4)

![]()


### CBAM: Convolutional Block Attention Module
- intro:CBAM
- arXiv:[https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)

![](https://pic.downk.cc/item/5e82b8e2504f4bcb04d628c8.png)


### Competitive Inner-Imaging Squeeze and Excitation for Residual Network
- intro:Competitive SENet
- arXiv:[https://arxiv.org/abs/1807.08920v4](https://arxiv.org/abs/1807.08920v4)

![](https://pic.downk.cc/item/5e82bbfd504f4bcb04d8bf5a.png)
![](https://pic.downk.cc/item/5e82bc12504f4bcb04d8d3ee.png)


### ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design
- intro:ShuffleNet V2
- arXiv:[https://arxiv.org/abs/1807.11164v1](https://arxiv.org/abs/1807.11164v1)

![]()


### Selective Kernel Networks
- intro:SKNet
- arXiv:[https://arxiv.org/abs/1903.06586](https://arxiv.org/abs/1903.06586)

![](https://pic.downk.cc/item/5e82bc3b504f4bcb04d8ffa8.png)


### ANTNets: Mobile Convolutional Neural Networks for Resource Efficient Image Classification
- intro:ANTNet
- arXiv:[https://arxiv.org/abs/1904.03775](https://arxiv.org/abs/1904.03775)

![]()


### Searching for MobileNetV3
- intro:MobileNetV3
- arXiv:[https://arxiv.org/abs/1905.02244](https://arxiv.org/abs/1905.02244)

![]()


### EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
- intro:EfficientNet
- keypoint:Compound Model Scaling
- arXiv:[https://arxiv.org/abs/1905.11946?context=stat.ML](https://arxiv.org/abs/1905.11946?context=stat.ML)

![](https://pic.downk.cc/item/5e81b404504f4bcb04225c0e.png)


### GhostNet: More Features from Cheap Operations
- intro:GhostNet
- arXiv:[https://arxiv.org/abs/1911.11907](https://arxiv.org/abs/1911.11907)

![](https://pic.downk.cc/item/5e82be97504f4bcb04db1b4f.png)

# CNN Benchmarks

### ImageNet Large Scale Visual Recognition Challenge
- intro:ImageNet
- arXiv:[https://arxiv.org/abs/1409.0575](https://arxiv.org/abs/1409.0575)
