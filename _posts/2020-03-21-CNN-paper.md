---
layout: post
title: '卷积神经网络 论文'
date: 2020-03-21
author: 郑之杰
cover: ''
tags: 深度学习
---

> Papers about Convolutional Neural Networks.

# Survey

### A Survey of the Recent Architectures of Deep Convolutional Neural Networks
- arXiv:[https://arxiv.org/abs/1901.06032](https://arxiv.org/abs/1901.06032)


# CNN History

### Receptive fields, binocular interaction and functional architecture in the cat's visual cortex
- intro:Hubel,Wiesel
- pdf:[http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf)

### Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition
- intro:neocognitron
- pdf:[https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf](https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf)


# CNN Components

### A Theoretical Analysis of Feature Pooling in Visual Recognition
- intro:pooling
- pdf:[https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf](https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf)

### Activation Functions: Comparison of trends in Practice and Research for Deep Learning
- intro:activation functions
- arXiv:[https://arxiv.org/abs/1811.03378](https://arxiv.org/abs/1811.03378)

### Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
- intro:batch norm
- arXiv:[https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)

### Dropout: A Simple Way to Prevent Neural Networks from Overfitting
- intro:dropout
- pdf:[http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)


# CNN Architectures

### · Gradient-based learning applied to document recognition
- intro:LeNet5
- pdf:[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

![](https://cuijiahua.com/wp-content/uploads/2018/01/dl_3_4.jpg)

### ImageNet Classification with Deep Convolutional Neural Networks
- intro:AlexNet
- keypoint:local response normalization、ReLU、dropout、group convolution
- pdf:[http://stanford.edu/class/cs231m/references/alexnet.pdf](http://stanford.edu/class/cs231m/references/alexnet.pdf)

![](http://picture.piggygaga.top/AlexNet/AlexNet.png)

### Visualizing and Understanding Convolutional Networks
- intro:ZFNet
- keypoint:deconvolution、unpooling
- arXiv:[https://arxiv.org/abs/1311.2901](https://arxiv.org/abs/1311.2901)

![](https://img-blog.csdn.net/20171229135004198)

### Network In Network
- intro:NiN
- keypoint:1×1 conv、global average pooling
- arXiv:[https://arxiv.org/abs/1312.4400](https://arxiv.org/abs/1312.4400)

![](https://pic.downk.cc/item/5e816d3b504f4bcb04f28f50.png)

### Very Deep Convolutional Networks for Large-Scale Image Recognition
- intro:VGG16、VGG19
- arXiv:[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)

![](https://static.oschina.net/uploads/space/2018/0314/022939_Pl12_876354.png)

### Going Deeper with Convolutions
- intro:GoogLeNet
- keypoint:inception、split-transform-merge
- arXiv:[https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)

![](https://pic.downk.cc/item/5e8170f0504f4bcb04f4f7b5.png)
[GoogLeNet结构](https://static.oschina.net/uploads/space/2018/0317/141544_FfKB_876354.jpg)

### Highway Networks
- intro:Highway Networks
- arXiv:[https://arxiv.org/abs/1505.00387](https://arxiv.org/abs/1505.00387)

![](https://pic.downk.cc/item/5e817166504f4bcb04f546f3.png)


### Rethinking the Inception Architecture for Computer Vision
- intro:Inception-V2、Inception-V3
- arXiv:[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)

![](https://pic.downk.cc/item/5e818862504f4bcb040451fb.png)


### Deep Residual Learning for Image Recognition
- intro:ResNet
- keypoint:skip connection
- arXiv:[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)

![](https://pic.downk.cc/item/5e8172ce504f4bcb04f63231.png)


### Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- intro:Inception-V4, Inception-ResNet
- arXiv:[https://arxiv.org/abs/1602.07261v1](https://arxiv.org/abs/1602.07261v1)

Inception-V4:
![](https://upload-images.jianshu.io/upload_images/8904720-56edb7b9edf874f1.png)
![](https://upload-images.jianshu.io/upload_images/8904720-4a80d0db07af7397.png)
![](https://upload-images.jianshu.io/upload_images/8904720-faa68bb2ea896417.png)

Inception-ResNet:
![](https://upload-images.jianshu.io/upload_images/8904720-b0714348b3e54802.png)
![](https://upload-images.jianshu.io/upload_images/8904720-2f86302e81da93df.png)


### Stacked Hourglass Networks for Human Pose Estimation
- intro:Hourglass Network
- arXiv:[https://arxiv.org/abs/1603.06937](https://arxiv.org/abs/1603.06937)

![](https://upload-images.jianshu.io/upload_images/2189093-7a07d4386633c753.png)

### Deep Networks with Stochastic Depth
- intro:Stochastic Depth
- arXiv:[https://arxiv.org/abs/1603.09382](https://arxiv.org/abs/1603.09382)

![](https://pic.downk.cc/item/5e8175b9504f4bcb04f82c8d.png)


### Wide Residual Networks
- intro:WideResNet
- arXiv:[https://arxiv.org/abs/1605.07146](https://arxiv.org/abs/1605.07146)

![](https://pic.downk.cc/item/5e8175f2504f4bcb04f851cc.png)


### Densely Connected Convolutional Networks
- intro:DenseNet
- arXiv:[https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)

![](https://img2018.cnblogs.com/blog/1503464/201812/1503464-20181227214438618-515355109.png)


### Xception: Deep learning with depthwise separable convolutions
- intro:Xception
- keypoint:Depthwise Separable Convolution
- arXiv:[https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357)

![](https://img-blog.csdnimg.cn/20181206103219193.png)


### Deep Pyramidal Residual Networks
- intro:Pyramidal ResNet
- arXiv:[https://arxiv.org/abs/1610.02915](https://arxiv.org/abs/1610.02915)

![](https://pic.downk.cc/item/5e818246504f4bcb04008f58.png)


### Aggregated Residual Transformations for Deep Neural Networks
- intro:ResNeXt
- keypoint:cardinality
- arXiv:[https://arxiv.org/abs/1611.05431](https://arxiv.org/abs/1611.05431)

![](https://pic.downk.cc/item/5e81810c504f4bcb04ffcb7c.png)


### MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
- intro:MobileNet
- keypoint:depthwise + pointwise
- arXiv:[https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)

![](https://pic.downk.cc/item/5e8183cb504f4bcb04016f4b.png)


### Residual Attention Network for Image Classification
- intro:RAN
- arXiv:[https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)

![]()


### ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
- intro:ShuffleNet
- keypoint:group convolution + channel shuffle
- arXiv:[https://arxiv.org/abs/1707.01083](https://arxiv.org/abs/1707.01083)

![](https://pic4.zhimg.com/v2-d2f36404c00c82af1b616fa0f1be7c13_r.jpg)
![](https://pic2.zhimg.com/v2-57dd4a153bf24c6db5b455ae4545486d_r.jpg)


### Squeeze-and-Excitation Networks
- intro:SENet
- arXiv:[https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)

![]()


### MobileNetV2: Inverted Residuals and Linear Bottlenecks
- intro:MobileNetV2
- arXiv:[https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)

![]()


### Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks
- intro:scSE
- arXiv:[https://arxiv.org/abs/1803.02579](https://arxiv.org/abs/1803.02579)

![]()


### A New Channel Boosted Convolutional Neural Network using Transfer Learning
- intro:Channel Boosted CNN
- arXiv:[https://arxiv.org/abs/1804.08528v4](https://arxiv.org/abs/1804.08528v4)

![]()


### CBAM: Convolutional Block Attention Module
- intro:CBAM
- arXiv:[https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)

![]()


### Competitive Inner-Imaging Squeeze and Excitation for Residual Network
- intro:Competitive SENet
- arXiv:[https://arxiv.org/abs/1807.08920v4](https://arxiv.org/abs/1807.08920v4)

![]()


### ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design
- intro:ShuffleNet V2
- arXiv:[https://arxiv.org/abs/1807.11164v1](https://arxiv.org/abs/1807.11164v1)

![]()


### ANTNets: Mobile Convolutional Neural Networks for Resource Efficient Image Classification
- intro:ANTNet
- arXiv:[https://arxiv.org/abs/1904.03775](https://arxiv.org/abs/1904.03775)

![]()


### Searching for MobileNetV3
- intro:MobileNetV3
- arXiv:[https://arxiv.org/abs/1905.02244](https://arxiv.org/abs/1905.02244)

![]()


### EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
- intro:EfficientNet
- arXiv:[https://arxiv.org/abs/1905.11946?context=stat.ML](https://arxiv.org/abs/1905.11946?context=stat.ML)

![]()


# CNN Benchmarks

### ImageNet Large Scale Visual Recognition Challenge
- intro:ILSVRC
- arXiv:[https://arxiv.org/abs/1409.0575](https://arxiv.org/abs/1409.0575)
