---
layout: post
title: '卷积神经网络 论文'
date: 2020-03-21
author: 郑之杰
cover: ''
tags: 深度学习
---

> Papers about Convolutional Neural Networks.

# Survey

### A Survey of the Recent Architectures of Deep Convolutional Neural Networks
- arXiv:[https://arxiv.org/abs/1901.06032](https://arxiv.org/abs/1901.06032)


# CNN History

### Receptive fields, binocular interaction and functional architecture in the cat's visual cortex
- intro:Hubel,Wiesel
- pdf:[http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf](http://www.gatsby.ucl.ac.uk/teaching/courses/sntn/sntn-2017/additional/systems/JPhysiol-1962-Hubel-106-54.pdf)

### Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition
- intro:neocognitron
- pdf:[https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf](https://www.cs.princeton.edu/courses/archive/spring08/cos598B/Readings/Fukushima1980.pdf)


# CNN Components

### A Theoretical Analysis of Feature Pooling in Visual Recognition
- intro:pooling
- pdf:[https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf](https://www.di.ens.fr/sierra/pdfs/icml2010b.pdf)

### Activation Functions: Comparison of trends in Practice and Research for Deep Learning
- intro:activation functions
- arXiv:[https://arxiv.org/abs/1811.03378](https://arxiv.org/abs/1811.03378)

### Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
- intro:batch norm
- arXiv:[https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)

### Dropout: A Simple Way to Prevent Neural Networks from Overfitting
- intro:dropout
- pdf:[http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](http://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)


# CNN Architectures

### Gradient-based learning applied to document recognition
- intro:LeNet5
- pdf:[http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)

![](https://img-blog.csdnimg.cn/20190305161316701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21tbV9qc3c=,size_16,color_FFFFFF,t_70)

### ImageNet Classification with Deep Convolutional Neural Networks
- intro:AlexNet
- pdf:[http://stanford.edu/class/cs231m/references/alexnet.pdf](http://stanford.edu/class/cs231m/references/alexnet.pdf)

![](http://picture.piggygaga.top/AlexNet/AlexNet.png)

### Visualizing and Understanding Convolutional Networks
- intro:ZFNet
- arXiv:[https://arxiv.org/abs/1311.2901](https://arxiv.org/abs/1311.2901)

### Network In Network
- intro:NiN
- arXiv:[https://arxiv.org/abs/1312.4400](https://arxiv.org/abs/1312.4400)

### Very Deep Convolutional Networks for Large-Scale Image Recognition
- intro:VGG
- arXiv:[https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)

### Going Deeper with Convolutions
- intro:GoogLeNet
- arXiv:[https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)

### Highway Networks
- intro:Highway Networks
- arXiv:[https://arxiv.org/abs/1505.00387](https://arxiv.org/abs/1505.00387)

### Rethinking the Inception Architecture for Computer Vision
- intro:Inception-V3
- arXiv:[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)

### Deep Residual Learning for Image Recognition
- intro:ResNet
- arXiv:[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)

### Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- intro:Inception-V4, Inception-ResNet
- arXiv:[https://arxiv.org/abs/1602.07261v1](https://arxiv.org/abs/1602.07261v1)

### Stacked Hourglass Networks for Human Pose Estimation
- intro:Hourglass Network
- arXiv:[https://arxiv.org/abs/1603.06937](https://arxiv.org/abs/1603.06937)

![](https://upload-images.jianshu.io/upload_images/2189093-7a07d4386633c753.png)

### Deep Networks with Stochastic Depth
- intro:Stochastic ResNet
- arXiv:[https://arxiv.org/abs/1603.09382](https://arxiv.org/abs/1603.09382)

### Wide Residual Networks
- intro:WideResNet
- arXiv:[https://arxiv.org/abs/1605.07146](https://arxiv.org/abs/1605.07146)

### Densely Connected Convolutional Networks
- intro:DenseNet
- arXiv:[https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)

### Xception: Deep learning with depthwise separable convolutions
- intro:Xception
- arXiv:[https://arxiv.org/abs/1610.02357](https://arxiv.org/abs/1610.02357)

### Deep Pyramidal Residual Networks
- intro:Pyramidal ResNet
- arXiv:[https://arxiv.org/abs/1610.02915](https://arxiv.org/abs/1610.02915)

### Aggregated Residual Transformations for Deep Neural Networks
- intro:ResNeXt
- arXiv:[https://arxiv.org/abs/1611.05431](https://arxiv.org/abs/1611.05431)

### MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
- intro:MobileNet
- arXiv:[https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)

### Residual Attention Network for Image Classification
- intro:RAN
- arXiv:[https://arxiv.org/abs/1704.06904](https://arxiv.org/abs/1704.06904)

### ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
- intro:ShuffleNet
- arXiv:[https://arxiv.org/abs/1707.01083](https://arxiv.org/abs/1707.01083)

### Squeeze-and-Excitation Networks
- intro:SENet
- arXiv:[https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)

### MobileNetV2: Inverted Residuals and Linear Bottlenecks
- intro:MobileNetV2
- arXiv:[https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)

### Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks
- intro:scSE
- arXiv:[https://arxiv.org/abs/1803.02579](https://arxiv.org/abs/1803.02579)

### A New Channel Boosted Convolutional Neural Network using Transfer Learning
- intro:Channel Boosted CNN
- arXiv:[https://arxiv.org/abs/1804.08528v4](https://arxiv.org/abs/1804.08528v4)

### CBAM: Convolutional Block Attention Module
- intro:CBAM
- arXiv:[https://arxiv.org/abs/1807.06521](https://arxiv.org/abs/1807.06521)

### Competitive Inner-Imaging Squeeze and Excitation for Residual Network
- intro:Competitive SENet
- arXiv:[https://arxiv.org/abs/1807.08920v4](https://arxiv.org/abs/1807.08920v4)

### ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design
- intro:ShuffleNet V2
- arXiv:[https://arxiv.org/abs/1807.11164v1](https://arxiv.org/abs/1807.11164v1)

### ANTNets: Mobile Convolutional Neural Networks for Resource Efficient Image Classification
- intro:ANTNet
- arXiv:[https://arxiv.org/abs/1904.03775](https://arxiv.org/abs/1904.03775)

### Searching for MobileNetV3
- intro:MobileNetV3
- arXiv:[https://arxiv.org/abs/1905.02244](https://arxiv.org/abs/1905.02244)

### EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
- intro:EfficientNet
- arXiv:[https://arxiv.org/abs/1905.11946?context=stat.ML](https://arxiv.org/abs/1905.11946?context=stat.ML)

# CNN Benchmarks

### ImageNet Large Scale Visual Recognition Challenge
- intro:ILSVRC
- arXiv:[https://arxiv.org/abs/1409.0575](https://arxiv.org/abs/1409.0575)
